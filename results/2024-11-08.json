[
    {
        "paper id": "2411.05357",
        "abstract url": "https://arxiv.org/abs/2411.05357",
        "title": "Enhancing Visual Classification using Comparative Descriptors",
        "rating": "2.5",
        "keywords": [
            [
                "vision-language",
                "VLMs"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "The performance of vision-language models (VLMs), such as CLIP, in visual classification tasks, has been enhanced by leveraging semantic knowledge from large language models (LLMs), including GPT. Recent studies have shown that in zero-shot classification tasks, descriptors incorporating additional cues, high-level concepts, or even random characters often outperform those using only the category name. In many classification tasks, while the top-1 accuracy may be relatively low, the top-5 accuracy is often significantly higher. This gap implies that most misclassifications occur among a few similar classes, highlighting the model's difficulty in distinguishing between classes with subtle differences. To address this challenge, we introduce a novel concept of comparative descriptors. These descriptors emphasize the unique features of a target class against its most similar classes, enhancing differentiation. By generating and integrating these comparative descriptors into the classification framework, we refine the semantic focus and improve classification accuracy. An additional filtering process ensures that these descriptors are closer to the image embeddings in the CLIP space, further enhancing performance. Our approach demonstrates improved accuracy and robustness in visual classification tasks by addressing the specific challenge of subtle inter-class differences.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by WACV 2025"
    },
    {
        "paper id": "2411.05603",
        "abstract url": "https://arxiv.org/abs/2411.05603",
        "title": "Efficient Audio-Visual Fusion for Video Classification",
        "rating": "2",
        "keywords": [
            [
                "Audio-Visual"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present Attend-Fusion, a novel and efficient approach for audio-visual fusion in video classification tasks. Our method addresses the challenge of exploiting both audio and visual modalities while maintaining a compact model architecture. Through extensive experiments on the YouTube-8M dataset, we demonstrate that our Attend-Fusion achieves competitive performance with significantly reduced model complexity compared to larger baseline models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "CVMP Short Paper"
    },
    {
        "paper id": "2411.05734",
        "abstract url": "https://arxiv.org/abs/2411.05734",
        "title": "Poze: Sports Technique Feedback under Data Constraints",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Access to expert coaching is essential for developing technique in sports, yet economic barriers often place it out of reach for many enthusiasts. To bridge this gap, we introduce Poze, an innovative video processing framework that provides feedback on human motion, emulating the insights of a professional coach. Poze combines pose estimation with sequence comparison and is optimized to function effectively with minimal data. Poze surpasses state-of-the-art vision-language models in video question-answering frameworks, achieving 70% and 196% increase in accuracy over GPT4V and LLaVAv1.6 7b, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05961",
        "abstract url": "https://arxiv.org/abs/2411.05961",
        "title": "Aligned Vector Quantization for Edge-Cloud Collabrative Vision-Language Models",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Vision Language Models (VLMs) are central to Visual Question Answering (VQA) systems and are typically deployed in the cloud due to their high computational demands. However, this cloud-only approach underutilizes edge computational resources and requires significant bandwidth for transmitting raw images. In this paper, we introduce an edge-cloud collaborative VQA system, called LLaVA-AlignedVQ, which features a novel Aligned Vector Quantization algorithm (AlignedVQ) that efficiently compress intermediate features without compromising accuracy to support partitioned execution. Our experiments demonstrate that LLaVA-AlignedVQ achieves approximately 1365x compression rate of intermediate features, reducing data transmission overhead by 96.8% compared to transmitting JPEG90-compressed images to the cloud. LLaVA-AlignedVQ achieves an inference speedup of 2-15x while maintaining high accuracy, remaining within -2.23% to +1.6% of the original model's accuracy performance across eight VQA datasets, compared to the cloud-only solution.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "12 pages, 7 figures"
    },
    {
        "paper id": "2411.05338",
        "abstract url": "https://arxiv.org/abs/2411.05338",
        "title": "SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Scientific literature is typically dense, requiring significant background knowledge and deep comprehension for effective engagement. We introduce SciDQA, a new dataset for reading comprehension that challenges LLMs for a deep understanding of scientific articles, consisting of 2,937 QA pairs. Unlike other scientific QA datasets, SciDQA sources questions from peer reviews by domain experts and answers by paper authors, ensuring a thorough examination of the literature. We enhance the dataset's quality through a process that carefully filters out lower quality questions, decontextualizes the content, tracks the source document across different versions, and incorporates a bibliography for multi-document question-answering. Questions in SciDQA necessitate reasoning across figures, tables, equations, appendices, and supplementary materials, and require multi-document reasoning. We evaluate several open-source and proprietary LLMs across various configurations to explore their capabilities in generating relevant and factual responses. Our comprehensive evaluation, based on metrics for surface-level similarity and LLM judgements, highlights notable performance discrepancies. SciDQA represents a rigorously curated, naturally derived scientific QA dataset, designed to facilitate research on complex scientific text understanding.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "18 pages, Accepted to EMNLP 2024"
    },
    {
        "paper id": "2411.05383",
        "abstract url": "https://arxiv.org/abs/2411.05383",
        "title": "Towards Low-Resource Harmful Meme Detection with LMM Agents",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "The proliferation of Internet memes in the age of social media necessitates effective identification of harmful ones. Due to the dynamic nature of memes, existing data-driven models may struggle in low-resource scenarios where only a few labeled examples are available. In this paper, we propose an agency-driven framework for low-resource harmful meme detection, employing both outward and inward analysis with few-shot annotated samples. Inspired by the powerful capacity of Large Multimodal Models (LMMs) on multimodal reasoning, we first retrieve relative memes with annotations to leverage label information as auxiliary signals for the LMM agent. Then, we elicit knowledge-revising behavior within the LMM agent to derive well-generalized insights into meme harmfulness. By combining these strategies, our approach enables dialectical reasoning over intricate and implicit harm-indicative patterns. Extensive experiments conducted on three meme datasets demonstrate that our proposed approach achieves superior performance than state-of-the-art methods on the low-resource harmful meme detection task.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EMNLP 2024"
    },
    {
        "paper id": "2411.05423",
        "abstract url": "https://arxiv.org/abs/2411.05423",
        "title": "VISTA: Visual Integrated System for Tailored Automation in Math Problem Generation Using LLM",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Generating accurate and consistent visual aids is a critical challenge in mathematics education, where visual representations like geometric shapes and functions play a pivotal role in enhancing student comprehension. This paper introduces a novel multi-agent framework that leverages Large Language Models (LLMs) to automate the creation of complex mathematical visualizations alongside coherent problem text. Our approach not only simplifies the generation of precise visual aids but also aligns these aids with the problem's core mathematical concepts, improving both problem creation and assessment. By integrating multiple agents, each responsible for distinct tasks such as numeric calculation, geometry validation, and visualization, our system delivers mathematically accurate and contextually relevant problems with visual aids. Evaluation across Geometry and Function problem types shows that our method significantly outperforms basic LLMs in terms of text coherence, consistency, relevance and similarity, while maintaining the essential geometrical and functional integrity of the original problems. Although some challenges remain in ensuring consistent visual outputs, our framework demonstrates the immense potential of LLMs in transforming the way educators generate and utilize visual aids in math education.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accepted at NeurIPS 2024 Workshop on Large Foundation Models for Educational Assessment (FM-Assess)"
    },
    {
        "paper id": "2411.05663",
        "abstract url": "https://arxiv.org/abs/2411.05663",
        "title": "Online-LoRA: Task-free Online Continual Learning via Low Rank Adaptation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Catastrophic forgetting is a significant challenge in online continual learning (OCL), especially for non-stationary data streams that do not have well-defined task boundaries. This challenge is exacerbated by the memory constraints and privacy concerns inherent in rehearsal buffers. To tackle catastrophic forgetting, in this paper, we introduce Online-LoRA, a novel framework for task-free OCL. Online-LoRA allows to finetune pre-trained Vision Transformer (ViT) models in real-time to address the limitations of rehearsal buffers and leverage pre-trained models' performance benefits. As the main contribution, our approach features a novel online weight regularization strategy to identify and consolidate important model parameters. Moreover, Online-LoRA leverages the training dynamics of loss values to enable the automatic recognition of the data distribution shifts. Extensive experiments across many task-free OCL scenarios and benchmark datasets (including CIFAR-100, ImageNet-R, ImageNet-S, CUB-200 and CORe50) demonstrate that Online-LoRA can be robustly adapted to various ViT architectures, while achieving better performance compared to SOTA methods. Our code will be publicly available at: https://github.com/Christina200/Online-LoRA-official.git.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "WACV 2025"
    },
    {
        "paper id": "2411.05762",
        "abstract url": "https://arxiv.org/abs/2411.05762",
        "title": "Multi-hop Evidence Pursuit Meets the Web: Team Papelo at FEVER 2024",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Separating disinformation from fact on the web has long challenged both the search and the reasoning powers of humans. We show that the reasoning power of large language models (LLMs) and the retrieval power of modern search engines can be combined to automate this process and explainably verify claims. We integrate LLMs and search under a multi-hop evidence pursuit strategy. This strategy generates an initial question based on an input claim using a sequence to sequence model, searches and formulates an answer to the question, and iteratively generates follow-up questions to pursue the evidence that is missing using an LLM. We demonstrate our system on the FEVER 2024 (AVeriTeC) shared task. Compared to a strategy of generating all the questions at once, our method obtains .045 higher label accuracy and .155 higher AVeriTeC score (evaluating the adequacy of the evidence). Through ablations, we show the importance of various design choices, such as the question generation method, medium-sized context, reasoning with one document at a time, adding metadata, paraphrasing, reducing the problem to two classes, and reconsidering the final verdict. Our submitted system achieves .510 AVeriTeC score on the dev set and .477 AVeriTeC score on the test set.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "To appear in the Seventh FEVER Workshop at EMNLP 2024"
    },
    {
        "paper id": "2411.05764",
        "abstract url": "https://arxiv.org/abs/2411.05764",
        "title": "FinDVer: Explainable Claim Verification over Long and Hybrid-Content Financial Documents",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "We introduce FinDVer, a comprehensive benchmark specifically designed to evaluate the explainable claim verification capabilities of LLMs in the context of understanding and analyzing long, hybrid-content financial documents. FinDVer contains 2,400 expert-annotated examples, divided into three subsets: information extraction, numerical reasoning, and knowledge-intensive reasoning, each addressing common scenarios encountered in real-world financial contexts. We assess a broad spectrum of LLMs under long-context and RAG settings. Our results show that even the current best-performing system, GPT-4o, still lags behind human experts. We further provide in-depth analysis on long-context and RAG setting, Chain-of-Thought reasoning, and model reasoning errors, offering insights to drive future advancements. We believe that FinDVer can serve as a valuable benchmark for evaluating LLMs in claim verification over complex, expert-domain documents.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "EMNLP 2024"
    },
    {
        "paper id": "2411.05775",
        "abstract url": "https://arxiv.org/abs/2411.05775",
        "title": "Fact or Fiction? Can LLMs be Reliable Annotators for Political Truths?",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Political misinformation poses significant challenges to democratic processes, shaping public opinion and trust in media. Manual fact-checking methods face issues of scalability and annotator bias, while machine learning models require large, costly labelled datasets. This study investigates the use of state-of-the-art large language models (LLMs) as reliable annotators for detecting political factuality in news articles. Using open-source LLMs, we create a politically diverse dataset, labelled for bias through LLM-generated annotations. These annotations are validated by human experts and further evaluated by LLM-based judges to assess the accuracy and reliability of the annotations. Our approach offers a scalable and robust alternative to traditional fact-checking, enhancing transparency and public trust in media.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted at Socially Responsible Language Modelling Research (SoLaR) Workshop at NeurIPS 2024"
    },
    {
        "paper id": "2411.05781",
        "abstract url": "https://arxiv.org/abs/2411.05781",
        "title": "Using Language Models to Disambiguate Lexical Choices in Translation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "In translation, a concept represented by a single word in a source language can have multiple variations in a target language. The task of lexical selection requires using context to identify which variation is most appropriate for a source text. We work with native speakers of nine languages to create DTAiLS, a dataset of 1,377 sentence pairs that exhibit cross-lingual concept variation when translating from English. We evaluate recent LLMs and neural machine translation systems on DTAiLS, with the best-performing model, GPT-4, achieving from 67 to 85% accuracy across languages. Finally, we use language models to generate English rules describing target-language concept variations. Providing weaker models with high-quality lexical rules improves accuracy substantially, in some cases reaching or outperforming GPT-4.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Accepted to EMNLP 2024"
    },
    {
        "paper id": "2411.05898",
        "abstract url": "https://arxiv.org/abs/2411.05898",
        "title": "Integrating Object Detection Modality into Visual Language Model for Enhanced Autonomous Driving Agent",
        "rating": "1.5",
        "keywords": [
            [
                "Visual Language",
                "VLMs"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "In this paper, we propose a novel framework for enhancing visual comprehension in autonomous driving systems by integrating visual language models (VLMs) with additional visual perception module specialised in object detection. We extend the Llama-Adapter architecture by incorporating a YOLOS-based detection network alongside the CLIP perception network, addressing limitations in object detection and localisation. Our approach introduces camera ID-separators to improve multi-view processing, crucial for comprehensive environmental awareness. Experiments on the DriveLM visual question answering challenge demonstrate significant improvements over baseline models, with enhanced performance in ChatGPT scores, BLEU scores, and CIDEr metrics, indicating closeness of model answer to ground truth. Our method represents a promising step towards more capable and interpretable autonomous driving systems. Possible safety enhancement enabled by detection modality is also discussed.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "accepted by SafeGenAI workshop of NeurIPS 2024"
    },
    {
        "paper id": "2411.05927",
        "abstract url": "https://arxiv.org/abs/2411.05927",
        "title": "Moving Off-the-Grid: Scene-Grounded Video Representations",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Current vision models typically maintain a fixed correspondence between their representation structure and image space. Each layer comprises a set of tokens arranged \"on-the-grid,\" which biases patches or tokens to encode information at a specific spatio(-temporal) location. In this work we present Moving Off-the-Grid (MooG), a self-supervised video representation model that offers an alternative approach, allowing tokens to move \"off-the-grid\" to better enable them to represent scene elements consistently, even as they move across the image plane through time. By using a combination of cross-attention and positional embeddings we disentangle the representation structure and image structure. We find that a simple self-supervised objective--next frame prediction--trained on video data, results in a set of latent tokens which bind to specific scene structures and track them as they move. We demonstrate the usefulness of MooG's learned representation both qualitatively and quantitatively by training readouts on top of the learned representation on a variety of downstream tasks. We show that MooG can provide a strong foundation for different vision tasks when compared to \"on-the-grid\" baselines.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted to NeurIPS 2024 (spotlight). Project page: https://moog-paper.github.io/"
    },
    {
        "paper id": "2411.05930",
        "abstract url": "https://arxiv.org/abs/2411.05930",
        "title": "BERTrend: Neural Topic Modeling for Emerging Trends Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Detecting and tracking emerging trends and weak signals in large, evolving text corpora is vital for applications such as monitoring scientific literature, managing brand reputation, surveilling critical infrastructure and more generally to any kind of text-based event detection. Existing solutions often fail to capture the nuanced context or dynamically track evolving patterns over time. BERTrend, a novel method, addresses these limitations using neural topic modeling in an online setting. It introduces a new metric to quantify topic popularity over time by considering both the number of documents and update frequency. This metric classifies topics as noise, weak, or strong signals, flagging emerging, rapidly growing topics for further investigation. Experimentation on two large real-world datasets demonstrates BERTrend's ability to accurately detect and track meaningful weak signals while filtering out noise, offering a comprehensive solution for monitoring emerging trends in large-scale, evolving text corpora. The method can also be used for retrospective analysis of past events. In addition, the use of Large Language Models together with BERTrend offers efficient means for the interpretability of trends of events.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "17 pages, 12 figures, FuturED 2024: Workshop on Future of Event Detection (CoLocated with EMNLP 2024)"
    },
    {
        "paper id": "2411.05978",
        "abstract url": "https://arxiv.org/abs/2411.05978",
        "title": "The Empirical Impact of Data Sanitization on Language Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Data sanitization in the context of language modeling involves identifying sensitive content, such as personally identifiable information (PII), and redacting them from a dataset corpus. It is a common practice used in natural language processing (NLP) to maintain privacy. Nevertheless, the impact of data sanitization on the language understanding capability of a language model remains less studied. This paper empirically analyzes the effects of data sanitization across several benchmark language-modeling tasks including comprehension question answering (Q&A), entailment, sentiment analysis, and text classification. Our experiments cover a wide spectrum comprising finetuning small-scale language models, to prompting large language models (LLMs), on both original and sanitized datasets, and comparing their performance across the tasks. Interestingly, our results suggest that for some tasks such as sentiment analysis or entailment, the impact of redaction is quite low, typically around 1-5%, while for tasks such as comprehension Q&A there is a big drop of >25% in performance observed in redacted queries as compared to the original. For tasks that have a higher impact, we perform a deeper dive to inspect the presence of task-critical entities. Finally, we investigate correlation between performance and number of redacted entities, and also suggest a strategy to repair an already redacted dataset by means of content-based subsampling. Additional details are available at https://sites.google.com/view/datasan.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Paper accepted at Safe Generative AI Workshop at NeurIPS 2024"
    },
    {
        "paper id": "2411.06033",
        "abstract url": "https://arxiv.org/abs/2411.06033",
        "title": "Speech-Based Estimation of Schizophrenia Severity Using Feature Fusion",
        "rating": "1.5",
        "keywords": [
            [
                "eess.AS"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Speech-based assessment of the schizophrenia spectrum has been widely researched over in the recent past. In this study, we develop a deep learning framework to estimate schizophrenia severity scores from speech using a feature fusion approach that fuses articulatory features with different self-supervised speech features extracted from pre-trained audio models. We also propose an auto-encoder-based self-supervised representation learning framework to extract compact articulatory embeddings from speech. Our top-performing speech-based fusion model with Multi-Head Attention (MHA) reduces Mean Absolute Error (MAE) by 9.18% and Root Mean Squared Error (RMSE) by 9.36% for schizophrenia severity estimation when compared with the previous models that combined speech and video inputs.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "Submitted for SPADE workshop at ICASSP 2025"
    },
    {
        "paper id": "2411.05330",
        "abstract url": "https://arxiv.org/abs/2411.05330",
        "title": "Inversion-based Latent Bayesian Optimization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Latent Bayesian optimization (LBO) approaches have successfully adopted Bayesian optimization over a continuous latent space by employing an encoder-decoder architecture to address the challenge of optimization in a high dimensional or discrete input space. LBO learns a surrogate model to approximate the black-box objective function in the latent space. However, we observed that most LBO methods suffer from the `misalignment problem`, which is induced by the reconstruction error of the encoder-decoder architecture. It hinders learning an accurate surrogate model and generating high-quality solutions. In addition, several trust region-based LBO methods select the anchor, the center of the trust region, based solely on the objective function value without considering the trust region`s potential to enhance the optimization process. To address these issues, we propose Inversion-based Latent Bayesian Optimization (InvBO), a plug-and-play module for LBO. InvBO consists of two components: an inversion method and a potential-aware trust region anchor selection. The inversion method searches the latent code that completely reconstructs the given target data. The potential-aware trust region anchor selection considers the potential capability of the trust region for better local optimization. Experimental results demonstrate the effectiveness of InvBO on nine real-world benchmarks, such as molecule design and arithmetic expression fitting tasks. Code is available at https://github.com/mlvlab/InvBO.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted to NeurIPS 2024"
    },
    {
        "paper id": "2411.05340",
        "abstract url": "https://arxiv.org/abs/2411.05340",
        "title": "Improving Multi-Domain Task-Oriented Dialogue System with Offline Reinforcement Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Task-oriented dialogue (TOD) system is designed to accomplish user-defined tasks through dialogues. The TOD system has progressed towards end-to-end modeling by leveraging pre-trained large language models. Fine-tuning the pre-trained language models using only supervised learning leads to the exposure bias and token loss problem and it deviates the models from completing the user's task. To address these issues, we propose a TOD system that leverages a unified pre-trained language model, GPT2, as a base model. It is optimized using supervised learning and reinforcement learning (RL). The issues in the TOD system are mitigated using a non-differentiable reward function. The reward is calculated using the weighted sum of the success rate and BLEU evaluation metrics. The success rate and BLEU metrics in reward calculation guide the language model for user task completion while ensuring a coherent and fluent response. Our model is acquired by fine-tuning a pre-trained model on the dialogue-session level which comprises user utterance, belief state, system act, and system response. Experimental results on MultiWOZ2.1 demonstrate that our model increases the inform rate by 1.60% and the success rate by 3.17% compared to the baseline.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05375",
        "abstract url": "https://arxiv.org/abs/2411.05375",
        "title": "Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Current automated fact-checking (AFC) approaches commonly evaluate evidence either implicitly via the predicted verdicts or by comparing retrieved evidence with a predefined closed knowledge source, such as Wikipedia. However, these methods suffer from limitations, resulting from their reliance on evaluation metrics developed for different purposes and constraints imposed by closed knowledge sources. Recent advances in natural language generation (NLG) evaluation offer new possibilities for evidence assessment. In this work, we introduce Ev2R, an evaluation framework for AFC that comprises three types of approaches for evidence evaluation: reference-based, proxy-reference, and reference-less. We evaluate their effectiveness through agreement with human ratings and adversarial tests, and demonstrate that prompt-based scorers, particularly those leveraging LLMs and reference evidence, outperform traditional evaluation approaches.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2411.05379",
        "abstract url": "https://arxiv.org/abs/2411.05379",
        "title": "Word reuse and combination support efficient communication of emerging concepts",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "A key function of the lexicon is to express novel concepts as they emerge over time through a process known as lexicalization. The most common lexicalization strategies are the reuse and combination of existing words, but they have typically been studied separately in the areas of word meaning extension and word formation. Here we offer an information-theoretic account of how both strategies are constrained by a fundamental tradeoff between competing communicative pressures: word reuse tends to preserve the average length of word forms at the cost of less precision, while word combination tends to produce more informative words at the expense of greater word length. We test our proposal against a large dataset of reuse items and compounds that appeared in English, French and Finnish over the past century. We find that these historically emerging items achieve higher levels of communicative efficiency than hypothetical ways of constructing the lexicon, and both literal reuse items and compounds tend to be more efficient than their non-literal counterparts. These results suggest that reuse and combination are both consistent with a unified account of lexicalization grounded in the theory of efficient communication.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Published in Proceedings of the National Academy of Sciences"
    },
    {
        "paper id": "2411.05403",
        "abstract url": "https://arxiv.org/abs/2411.05403",
        "title": "Benchmarking Distributional Alignment of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Language models (LMs) are increasingly used as simulacra for people, yet their ability to match the distribution of views of a specific demographic group and be \\textit{distributionally aligned} remains uncertain. This notion of distributional alignment is complex, as there is significant variation in the types of attributes that are simulated. Prior works have underexplored the role of three critical variables -- the question domain, steering method, and distribution expression method -- which motivates our contribution of a benchmark explicitly addressing these dimensions. We construct a dataset expanding beyond political values, create human baselines for this task, and evaluate the extent to which an LM can align with a particular group's opinion distribution to inform design choices of such simulation systems. Our analysis reveals open problems regarding if, and how, LMs can be used to simulate humans, and that LLMs can more accurately describe the opinion distribution than simulate such distributions.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05407",
        "abstract url": "https://arxiv.org/abs/2411.05407",
        "title": "Gap-Filling Prompting Enhances Code-Assisted Mathematical Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Despite the strong performance of large language models (LLMs) in tasks like mathematical reasoning, their practical use is limited by high computational demands and proprietary restrictions. Chain-of-thought (CoT) and program-of-thought (PoT) fine-tuning are common methods to transfer LLM knowledge to small language models (SLMs). However, CoT often leads to calculation errors in SLMs, while PoT has shown more promise. While most PoT-based approaches focus on direct problem-to-code conversion or extracting only the key information from questions and then providing code solution for it, this work emphasizes filling the gaps in the question to clearly illustrate the solution path, which can be challenging for an SLM to understand when such information is not explicitly provided. Therefore, this paper introduces Gap-Filling Prompting (GFP), a novel two-step prompting strategy designed to enhance the problem-solving process for SLMs. The first step identifies these gaps and provides hints for filling them, while the second step adds the hints to the question to generate a final code solution. Experimental results on two benchmark datasets demonstrate that GFP significantly improves the mathematical reasoning abilities of SLMs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05451",
        "abstract url": "https://arxiv.org/abs/2411.05451",
        "title": "WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLMs) have driven a revolutionary paradigm shift in process automation from Robotic Process Automation to Agentic Process Automation by automating the workflow orchestration procedure based on LLMs. However, existing LLMs (even the advanced OpenAI GPT-4o) are confined to achieving satisfactory capability in workflow orchestration. To address this limitation, we present WorkflowLLM, a data-centric framework elaborately designed to enhance the capability of LLMs in workflow orchestration. It first constructs a large-scale fine-tuning dataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83 applications across 28 categories. Specifically, the construction process can be divided into three phases: (1) Data Collection: we collect real-world workflow data from Apple Shortcuts and RoutineHub, transcribing them into Python-style code. We further equip them with generated hierarchical thought via ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task queries to enrich the diversity and complexity of workflows. (3) Workflow Generation: we leverage an annotator model trained on collected data to generate workflows for synthesized queries. Finally, we merge the synthetic samples that pass quality confirmation with the collected samples to obtain the WorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain WorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong capacity to orchestrate complex workflows, while also achieving notable generalization performance on previously unseen APIs. Additionally, WorkflowBench exhibits robust zero-shot generalization capabilities on an out-of-distribution task planning dataset, T-Eval. Our data and code are available at https://github.com/OpenBMB/WorkflowLLM.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05460",
        "abstract url": "https://arxiv.org/abs/2411.05460",
        "title": "Supporting Automated Fact-checking across Topics: Similarity-driven Gradual Topic Learning for Claim Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Selecting check-worthy claims for fact-checking is considered a crucial part of expediting the fact-checking process by filtering out and ranking the check-worthy claims for being validated among the impressive amount of claims could be found online. The check-worthy claim detection task, however, becomes more challenging when the model needs to deal with new topics that differ from those seen earlier. In this study, we propose a domain-adaptation framework for check-worthy claims detection across topics for the Arabic language to adopt a new topic, mimicking a real-life scenario of the daily emergence of events worldwide. We propose the Gradual Topic Learning (GTL) model, which builds an ability to learning gradually and emphasizes the check-worthy claims for the target topic during several stages of the learning process. In addition, we introduce the Similarity-driven Gradual Topic Learning (SGTL) model that synthesizes gradual learning with a similarity-based strategy for the target topic. Our experiments demonstrate the effectiveness of our proposed model, showing an overall tendency for improving performance over the state-of-the-art baseline across 11 out of the 14 topics under study.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05500",
        "abstract url": "https://arxiv.org/abs/2411.05500",
        "title": "FGGP: Fixed-Rate Gradient-First Gradual Pruning",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, the increasing size of deep learning models and their growing demand for computational resources have drawn significant attention to the practice of pruning neural networks, while aiming to preserve their accuracy. In unstructured gradual pruning, which sparsifies a network by gradually removing individual network parameters until a targeted network sparsity is reached, recent works show that both gradient and weight magnitudes should be considered. In this work, we show that such mechanism, e.g., the order of prioritization and selection criteria, is essential. We introduce a gradient-first magnitude-next strategy for choosing the parameters to prune, and show that a fixed-rate subselection criterion between these steps works better, in contrast to the annealing approach in the literature. We validate this on CIFAR-10 dataset, with multiple randomized initializations on both VGG-19 and ResNet-50 network backbones, for pruning targets of 90, 95, and 98% sparsity and for both initially dense and 50% sparse networks. Our proposed fixed-rate gradient-first gradual pruning (FGGP) approach outperforms its state-of-the-art alternatives in most of the above experimental settings, even occasionally surpassing the upperbound of corresponding dense network results, and having the highest ranking across the considered experimental settings.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05503",
        "abstract url": "https://arxiv.org/abs/2411.05503",
        "title": "KyrgyzNLP: Challenges, Progress, and Future",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have excelled in numerous benchmarks, advancing AI applications in both linguistic and non-linguistic tasks. However, this has primarily benefited well-resourced languages, leaving less-resourced ones (LRLs) at a disadvantage. In this paper, we highlight the current state of the NLP field in the specific LRL: kyrgyz tili. Human evaluation, including annotated datasets created by native speakers, remains an irreplaceable component of reliable NLP performance, especially for LRLs where automatic evaluations can fall short. In recent assessments of the resources for Turkic languages, Kyrgyz is labeled with the status 'Scraping By', a severely under-resourced language spoken by millions. This is concerning given the growing importance of the language, not only in Kyrgyzstan but also among diaspora communities where it holds no official status. We review prior efforts in the field, noting that many of the publicly available resources have only recently been developed, with few exceptions beyond dictionaries (the processed data used for the analysis is presented at https://kyrgyznlp.github.io/). While recent papers have made some headway, much more remains to be done. Despite interest and support from both business and government sectors in the Kyrgyz Republic, the situation for Kyrgyz language resources remains challenging. We stress the importance of community-driven efforts to build these resources, ensuring the future advancement sustainability. We then share our view of the most pressing challenges in Kyrgyz NLP. Finally, we propose a roadmap for future development in terms of research topics and language resources.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Keynote talk at the 12th International Conference on Analysis of Images, Social Networks and Texts (AIST-2024)"
    },
    {
        "paper id": "2411.05504",
        "abstract url": "https://arxiv.org/abs/2411.05504",
        "title": "LBPE: Long-token-first Tokenization to Improve Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The prevalent use of Byte Pair Encoding (BPE) in Large Language Models (LLMs) facilitates robust handling of subword units and avoids issues of out-of-vocabulary words. Despite its success, a critical challenge persists: long tokens, rich in semantic information, have fewer occurrences in tokenized datasets compared to short tokens, which can result in imbalanced learning issue across different tokens. To address that, we propose LBPE, which prioritizes long tokens during the encoding process. LBPE generates tokens according to their reverse ranks of token length rather than their ranks in the vocabulary, granting longer tokens higher priority during the encoding process. Consequently, LBPE smooths the frequency differences between short and long tokens, and thus mitigates the learning imbalance. Extensive experiments across diverse language modeling tasks demonstrate that LBPE consistently outperforms the original BPE, well demonstrating its effectiveness.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2404.17808"
    },
    {
        "paper id": "2411.05508",
        "abstract url": "https://arxiv.org/abs/2411.05508",
        "title": "An Early FIRST Reproduction and Improvements to Single-Token Decoding for Fast Listwise Reranking",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances have demonstrated that large language models (LLMs) excel as listwise rerankers, but their high computational demands remain a barrier to widespread adoption. Further, the traditional language modeling (LM) objective is not ideally suited for reranking tasks. FIRST is a novel approach that addresses these challenges by integrating a learning-to-rank objective and leveraging the logits of only the first generated token, thereby significantly reducing inference latency compared to traditional LLM rerankers. In this study, we extend the evaluation of FIRST to the TREC Deep Learning datasets (DL19-22), validating its robustness across diverse domains. We investigate the influence of different first-stage retrievers on FIRST rerankers, observing diminishing returns and patterns consistent with traditional LLM rerankers. Through applying the FIRST objective to a broader range of backbone models, we achieve effectiveness surpassing the original implementation. Our experiments confirm that fast reranking with single-token logits does not compromise out-of-domain reranking quality. To better quantify the computational savings in the original study, we measure and compare latency to find a 21%-42% gain across various models and benchmarks. Moreover, while LM training implicitly improves zero-shot single-token reranking, our experiments also raise questions about whether LM pre-training may hinder subsequent fine-tuning with the FIRST objective. These findings pave the way for more efficient and effective listwise reranking in future applications.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05527",
        "abstract url": "https://arxiv.org/abs/2411.05527",
        "title": "How Good is Your Wikipedia?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Wikipedia's perceived high quality and broad language coverage have established it as a fundamental resource in multilingual NLP. In the context of low-resource languages, however, these quality assumptions are increasingly being scrutinised. This paper critically examines the data quality of Wikipedia in a non-English setting by subjecting it to various quality filtering techniques, revealing widespread issues such as a high percentage of one-line articles and duplicate articles. We evaluate the downstream impact of quality filtering on Wikipedia and find that data quality pruning is an effective means for resource-efficient training without hurting performance, especially for low-resource languages. Moreover, we advocate for a shift in perspective from seeking a general definition of data quality towards a more language- and task-specific one. Ultimately, we aim for this study to serve as a guide to using Wikipedia for pretraining in a multilingual setting.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05547",
        "abstract url": "https://arxiv.org/abs/2411.05547",
        "title": "Assessing the Answerability of Queries in Retrieval-Augmented Code Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Thanks to unprecedented language understanding and generation capabilities of large language model (LLM), Retrieval-augmented Code Generation (RaCG) has recently been widely utilized among software developers. While this has increased productivity, there are still frequent instances of incorrect codes being provided. In particular, there are cases where plausible yet incorrect codes are generated for queries from users that cannot be answered with the given queries and API descriptions. This study proposes a task for evaluating answerability, which assesses whether valid answers can be generated based on users' queries and retrieved APIs in RaCG. Additionally, we build a benchmark dataset called Retrieval-augmented Code Generability Evaluation (RaCGEval) to evaluate the performance of models performing this task. Experimental results show that this task remains at a very challenging level, with baseline models exhibiting a low performance of 46.7%. Furthermore, this study discusses methods that could significantly improve performance.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05552",
        "abstract url": "https://arxiv.org/abs/2411.05552",
        "title": "DeepArUco++: Improved detection of square fiducial markers in challenging lighting conditions",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Fiducial markers are a computer vision tool used for object pose estimation and detection. These markers are highly useful in fields such as industry, medicine and logistics. However, optimal lighting conditions are not always available,and other factors such as blur or sensor noise can affect image quality. Classical computer vision techniques that precisely locate and decode fiducial markers often fail under difficult illumination conditions (e.g. extreme variations of lighting within the same frame). Hence, we propose DeepArUco++, a deep learning-based framework that leverages the robustness of Convolutional Neural Networks to perform marker detection and decoding in challenging lighting conditions. The framework is based on a pipeline using different Neural Network models at each step, namely marker detection, corner refinement and marker decoding. Additionally, we propose a simple method for generating synthetic data for training the different models that compose the proposed pipeline, and we present a second, real-life dataset of ArUco markers in challenging lighting conditions used to evaluate our system. The developed method outperforms other state-of-the-art methods in such tasks and remains competitive even when testing on the datasets used to develop those methods. Code available in GitHub: https://github.com/AVAuco/deeparuco/",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05561",
        "abstract url": "https://arxiv.org/abs/2411.05561",
        "title": "Training objective drives the consistency of representational similarity across datasets",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The Platonic Representation Hypothesis claims that recent foundation models are converging to a shared representation space as a function of their downstream task performance, irrespective of the objectives and data modalities used to train these models. Representational similarity is generally measured for individual datasets and is not necessarily consistent across datasets. Thus, one may wonder whether this convergence of model representations is confounded by the datasets commonly used in machine learning. Here, we propose a systematic way to measure how representational similarity between models varies with the set of stimuli used to construct the representations. We find that the objective function is the most crucial factor in determining the consistency of representational similarities across datasets. Specifically, self-supervised vision models learn representations whose relative pairwise similarities generalize better from one dataset to another compared to those of image classification or image-text models. Moreover, the correspondence between representational similarities and the models' task behavior is dataset-dependent, being most strongly pronounced for single-domain datasets. Our work provides a framework for systematically measuring similarities of model representations across datasets and linking those similarities to differences in task behavior.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "26 pages"
    },
    {
        "paper id": "2411.05636",
        "abstract url": "https://arxiv.org/abs/2411.05636",
        "title": "Video RWKV:Video Action Recognition Based RWKV",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "To address the challenges of high computational costs and long-distance dependencies in exist ing video understanding methods, such as CNNs and Transformers, this work introduces RWKV to the video domain in a novel way. We propose a LSTM CrossRWKV (LCR) framework, designed for spatiotemporal representation learning to tackle the video understanding task. Specifically, the proposed linear complexity LCR incorporates a novel Cross RWKV gate to facilitate interaction be tween current frame edge information and past features, enhancing the focus on the subject through edge features and globally aggregating inter-frame features over time. LCR stores long-term mem ory for video processing through an enhanced LSTM recurrent execution mechanism. By leveraging the Cross RWKV gate and recurrent execution, LCR effectively captures both spatial and temporal features. Additionally, the edge information serves as a forgetting gate for LSTM, guiding long-term memory management.Tube masking strategy reduces redundant information in food and reduces overfitting.These advantages enable LSTM CrossRWKV to set a new benchmark in video under standing, offering a scalable and efficient solution for comprehensive video analysis. All code and models are publicly available.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05639",
        "abstract url": "https://arxiv.org/abs/2411.05639",
        "title": "Assessing Open-Source Large Language Models on Argumentation Mining Subtasks",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We explore the capability of four open-sourcelarge language models (LLMs) in argumentation mining (AM). We conduct experiments on three different corpora; persuasive essays(PE), argumentative microtexts (AMT) Part 1 and Part 2, based on two argumentation mining sub-tasks: (i) argumentative discourse units classifications (ADUC), and (ii) argumentative relation classification (ARC). This work aims to assess the argumentation capability of open-source LLMs, including Mistral 7B, Mixtral8x7B, LlamA2 7B and LlamA3 8B in both, zero-shot and few-shot scenarios. Our analysis contributes to further assessing computational argumentation with open-source LLMs in future research efforts.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05641",
        "abstract url": "https://arxiv.org/abs/2411.05641",
        "title": "Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs), with gradually improving reading comprehension and reasoning capabilities, are being applied to a range of complex language tasks, including the automatic generation of language data for various purposes. However, research on applying LLMs for automatic data generation in low-resource languages like Vietnamese is still underdeveloped and lacks comprehensive evaluation. In this paper, we explore the use of LLMs for automatic data generation for the Vietnamese fact-checking task, which faces significant data limitations. Specifically, we focus on fact-checking data where claims are synthesized from multiple evidence sentences to assess the information synthesis capabilities of LLMs. We develop an automatic data construction process using simple prompt techniques on LLMs and explore several methods to improve the quality of the generated data. To evaluate the quality of the data generated by LLMs, we conduct both manual quality assessments and performance evaluations using language models. Experimental results and manual evaluations illustrate that while the quality of the generated data has significantly improved through fine-tuning techniques, LLMs still cannot match the data quality produced by humans.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05665",
        "abstract url": "https://arxiv.org/abs/2411.05665",
        "title": "Unmasking the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper sheds light on the limitations of Large Language Models (LLMs) by rigorously evaluating their ability to process masked text. We introduce two novel tasks: MskQA, measuring reasoning on masked question-answering datasets like RealtimeQA, and MskCal, assessing numerical reasoning on masked arithmetic problems.Testing GPT-4o and 4o-mini reveals that while LLMs exhibit some resilience to masked text, their performance is highly contingent on masking rates and semantic cues. Specifically, \"solid masking,\" where semantic clues are entirely absent, leads to a significant performance drop compared to \"partial lifting,\" where some semantic information is retained, indicating LLMs' reliance on surface-level patterns. Interestingly, GPT-4o consistently outperforms 4o-mini, particularly in MskCal, demonstrating a greater ability to handle numerical reasoning with masked text. This underscores the crucial role of semantic cues in the reasoning process of LLMs. Our study illuminates the interplay between background knowledge and reasoning ability in masked text processing, paving the way for a deeper understanding of LLM capabilities and limitations, and highlighting the need for more robust evaluation methods to accurately assess their true comprehension abilities.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2411.05691",
        "abstract url": "https://arxiv.org/abs/2411.05691",
        "title": "Asterisk*: Keep it Simple",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper describes Asterisk, a compact GPT-based model for generating text embeddings. The model uses a minimalist architecture with two layers, two attention heads, and 256 embedding dimensions. By applying knowledge distillation from larger pretrained models, we explore the trade-offs between model size and performance while minimizing computational and memory requirements. The model is primarily evaluated and optimized for classification tasks, with experimental results showing its moderate performance in zero-shot classification across various downstream applications. With additional configuration, the model performance can approach or even surpass that of larger architectures on specific classification tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05698",
        "abstract url": "https://arxiv.org/abs/2411.05698",
        "title": "Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc Explainability in Image Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Convolutional Neural Networks (CNNs) have seen significant performance improvements in recent years. However, due to their size and complexity, they function as black-boxes, leading to transparency concerns. State-of-the-art saliency methods generate local explanations that highlight the area in the input image where a class is identified but cannot explain how a concept of interest contributes to the prediction, which is essential for bias mitigation. On the other hand, concept-based methods, such as TCAV (Testing with Concept Activation Vectors), provide insights into how sensitive is the network to a concept, but cannot compute its attribution in a specific prediction nor show its location within the input image. This paper introduces a novel post-hoc explainability framework, Visual-TCAV, which aims to bridge the gap between these methods by providing both local and global explanations for CNN-based image classification. Visual-TCAV uses Concept Activation Vectors (CAVs) to generate saliency maps that show where concepts are recognized by the network. Moreover, it can estimate the attribution of these concepts to the output of any class using a generalization of Integrated Gradients. This framework is evaluated on popular CNN architectures, with its validity further confirmed via experiments where ground truth for explanations is known, and a comparison with TCAV. Our code will be made available soon.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Preprint currently under review"
    },
    {
        "paper id": "2411.05712",
        "abstract url": "https://arxiv.org/abs/2411.05712",
        "title": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "When trained on large-scale object classification datasets, certain artificial neural network models begin to approximate core object recognition (COR) behaviors and neural response patterns in the primate visual ventral stream (VVS). While recent machine learning advances suggest that scaling model size, dataset size, and compute resources improve task performance, the impact of scaling on brain alignment remains unclear. In this study, we explore scaling laws for modeling the primate VVS by systematically evaluating over 600 models trained under controlled conditions on benchmarks spanning V1, V2, V4, IT and COR behaviors. We observe that while behavioral alignment continues to scale with larger models, neural alignment saturates. This observation remains true across model architectures and training datasets, even though models with stronger inductive bias and datasets with higher-quality images are more compute-efficient. Increased scaling is especially beneficial for higher-level visual areas, where small models trained on few samples exhibit only poor alignment. Finally, we develop a scaling recipe, indicating that a greater proportion of compute should be allocated to data samples over model size. Our results suggest that while scaling alone might suffice for alignment with human core object recognition behavior, it will not yield improved models of the brain's visual ventral stream with current architectures and datasets, highlighting the need for novel strategies in building brain-like models.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "q-bio.NC"
        ],
        "comment": "9 pages for the main paper, 20 pages in total. 6 main figures and 10 supplementary figures. Code, model weights, and benchmark results can be accessed at https://github.com/epflneuroailab/scaling-primate-vvs"
    },
    {
        "paper id": "2411.05715",
        "abstract url": "https://arxiv.org/abs/2411.05715",
        "title": "On the Role of Noise in AudioVisual Integration: Evidence from Artificial Neural Networks that Exhibit the McGurk Effect",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Humans are able to fuse information from both auditory and visual modalities to help with understanding speech. This is frequently demonstrated through an phenomenon known as the McGurk Effect, during which a listener is presented with incongruent auditory and visual speech that fuse together into the percept of an illusory intermediate phoneme. Building on a recent framework that proposes how to address developmental 'why' questions using artificial neural networks, we evaluated a set of recent artificial neural networks trained on audiovisual speech by testing them with audiovisually incongruent words designed to elicit the McGurk effect. We compared networks trained on clean speech to those trained on noisy speech, and discovered that training with noisy speech led to an increase in both visual responses and McGurk responses across all models. Furthermore, we observed that systematically increasing the level of auditory noise during ANN training also increased the amount of audiovisual integration up to a point, but at extreme noise levels, this integration failed to develop. These results suggest that excessive noise exposure during critical periods of audiovisual learning may negatively influence the development of audiovisual speech integration. This work also demonstrates that the McGurk effect reliably emerges untrained from the behaviour of both supervised and unsupervised networks. This supports the notion that artificial neural networks might be useful models for certain aspects of perception and cognition.",
        "subjects": [
            "cs.SD",
            "cs.MM",
            "cs.NE",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05735",
        "abstract url": "https://arxiv.org/abs/2411.05735",
        "title": "Aioli: A Unified Optimization Framework for Language Model Data Mixing",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Language model performance depends on identifying the optimal mixture of data groups to train on (e.g., law, code, math). Prior work has proposed a diverse set of methods to efficiently learn mixture proportions, ranging from fitting regression models over training runs to dynamically updating proportions throughout training. Surprisingly, we find that no existing method consistently outperforms a simple stratified sampling baseline in terms of average test perplexity per group. In this paper, we study the cause of this inconsistency by unifying existing methods into a standard optimization framework. We show that all methods set proportions to minimize total loss, subject to a method-specific mixing law -- an assumption on how loss is a function of mixture proportions. We find that existing parameterizations of mixing laws can express the true loss-proportion relationship empirically, but the methods themselves often set the mixing law parameters inaccurately, resulting in poor and inconsistent performance. Finally, we leverage the insights from our framework to derive a new online method named Aioli, which directly estimates the mixing law parameters throughout training and uses them to dynamically adjust proportions. Empirically, Aioli outperforms stratified sampling on 6 out of 6 datasets by an average of 0.28 test perplexity points, whereas existing methods fail to consistently beat stratified sampling, doing up to 6.9 points worse. Moreover, in a practical setting where proportions are learned on shorter runs due to computational constraints, Aioli can dynamically adjust these proportions over the full training run, consistently improving performance over existing methods by up to 12.01 test perplexity points.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05747",
        "abstract url": "https://arxiv.org/abs/2411.05747",
        "title": "WavShadow: Wavelet Based Shadow Segmentation and Removal",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Shadow removal and segmentation remain challenging tasks in computer vision, particularly in complex real world scenarios. This study presents a novel approach that enhances the ShadowFormer model by incorporating Masked Autoencoder (MAE) priors and Fast Fourier Convolution (FFC) blocks, leading to significantly faster convergence and improved performance. We introduce key innovations: (1) integration of MAE priors trained on Places2 dataset for better context understanding, (2) adoption of Haar wavelet features for enhanced edge detection and multiscale analysis, and (3) implementation of a modified SAM Adapter for robust shadow segmentation. Extensive experiments on the challenging DESOBA dataset demonstrate that our approach achieves state of the art results, with notable improvements in both convergence speed and shadow removal quality.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05752",
        "abstract url": "https://arxiv.org/abs/2411.05752",
        "title": "FisherMask: Enhancing Neural Network Labeling Efficiency in Image Classification Using Fisher Information",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Deep learning (DL) models are popular across various domains due to their remarkable performance and efficiency. However, their effectiveness relies heavily on large amounts of labeled data, which are often time-consuming and labor-intensive to generate manually. To overcome this challenge, it is essential to develop strategies that reduce reliance on extensive labeled data while preserving model performance. In this paper, we propose FisherMask, a Fisher information-based active learning (AL) approach that identifies key network parameters by masking them based on their Fisher information values. FisherMask enhances batch AL by using Fisher information to select the most critical parameters, allowing the identification of the most impactful samples during AL training. Moreover, Fisher information possesses favorable statistical properties, offering valuable insights into model behavior and providing a better understanding of the performance characteristics within the AL pipeline. Our extensive experiments demonstrate that FisherMask significantly outperforms state-of-the-art methods on diverse datasets, including CIFAR-10 and FashionMNIST, especially under imbalanced settings. These improvements lead to substantial gains in labeling efficiency. Hence serving as an effective tool to measure the sensitivity of model parameters to data samples. Our code is available on \\url{https://github.com/sgchr273/FisherMask}.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05755",
        "abstract url": "https://arxiv.org/abs/2411.05755",
        "title": "End-to-End Navigation with Vision Language Models: Transforming Spatial Reasoning into Question-Answering",
        "rating": "1",
        "keywords": [
            [
                "Vision Language",
                "VLM"
            ],
            [
                "Navigation"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "We present VLMnav, an embodied framework to transform a Vision-Language Model (VLM) into an end-to-end navigation policy. In contrast to prior work, we do not rely on a separation between perception, planning, and control; instead, we use a VLM to directly select actions in one step. Surprisingly, we find that a VLM can be used as an end-to-end policy zero-shot, i.e., without any fine-tuning or exposure to navigation data. This makes our approach open-ended and generalizable to any downstream navigation task. We run an extensive study to evaluate the performance of our approach in comparison to baseline prompting methods. In addition, we perform a design analysis to understand the most impactful design decisions. Visual examples and code for our project can be found at https://jirl-upenn.github.io/VLMnav/",
        "subjects": [
            "cs.RO",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05774",
        "abstract url": "https://arxiv.org/abs/2411.05774",
        "title": "An ambient denoising method based on multi-channel non-negative matrix factorization for wheezing detection",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "In this paper, a parallel computing method is proposed to perform the background denoising and wheezing detection from a multi-channel recording captured during the auscultation process. The proposed system is based on a non-negative matrix factorization (NMF) approach and a detection strategy. Moreover, the initialization of the proposed model is based on singular value decomposition to avoid dependence on the initial values of the NMF parameters. Additionally, novel update rules to simultaneously address the multichannel denoising while preserving an orthogonal constraint to maximize source separation have been designed. The proposed system has been evaluated for the task of wheezing detection showing a significant improvement over state-of-the-art algorithms when noisy sound sources are present. Moreover, parallel and high-performance techniques have been used to speedup the execution of the proposed system, showing that it is possible to achieve fast execution times, which enables its implementation in real-world scenarios.",
        "subjects": [
            "eess.AS",
            "cs.ET",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05778",
        "abstract url": "https://arxiv.org/abs/2411.05778",
        "title": "LLMs as Method Actors: A Model for Prompt Engineering and Architecture",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce \"Method Actors\" as a mental model for guiding LLM prompt engineering and prompt architecture. Under this mental model, LLMs should be thought of as actors; prompts as scripts and cues; and LLM responses as performances. We apply this mental model to the task of improving LLM performance at playing Connections, a New York Times word puzzle game that prior research identified as a challenging benchmark for evaluating LLM reasoning. Our experiments with GPT-4o show that a \"Method Actors\" approach can significantly improve LLM performance over both a vanilla and \"Chain of Thoughts\" approach. A vanilla approach solves 27% of Connections puzzles in our dataset and a \"Chain of Thoughts\" approach solves 41% of puzzles, whereas our strongest \"Method Actor\" approach solves 86% of puzzles. We also test OpenAI's newest model designed specifically for complex reasoning tasks, o1-preview. When asked to solve a puzzle all at once, o1-preview solves 79% of Connections puzzles in our dataset, and when allowed to build puzzle solutions one guess at a time over multiple API calls, o1-preview solves 100% of the puzzles. Incorporating a \"Method Actor\" prompt architecture increases the percentage of puzzles that o1-preview solves perfectly from 76% to 87%.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05787",
        "abstract url": "https://arxiv.org/abs/2411.05787",
        "title": "Recycled Attention: Efficient inference for long-context language models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Generating long sequences of tokens given a long-context input imposes a heavy computational burden for large language models (LLMs). One of the computational bottleneck comes from computing attention over a long sequence of input at each generation step. In this paper, we propose Recycled Attention, an inference-time method which alternates between full context attention and attention over a subset of input tokens. When performing partial attention, we recycle the attention pattern of a previous token that has performed full attention and attend only to the top K most attended tokens, reducing the cost of data movement and attention computation. Compared to previously proposed inference-time acceleration method which attends only to local context or tokens with high accumulative attention scores, our approach flexibly chooses tokens that are relevant to the current decoding step. We evaluate our methods on RULER, a suite of tasks designed to comprehensively evaluate long-context abilities, and long-context language modeling tasks. Applying our method to off-the-shelf LLMs achieves comparable speedup to baselines which only consider local context while improving the performance by 2x. We further explore two ideas to improve performance-efficiency trade-offs: (1) dynamically decide when to perform recycled or full attention step based on the query similarities and (2) continued pre-training the model with Recycled Attention.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05894",
        "abstract url": "https://arxiv.org/abs/2411.05894",
        "title": "SSSD: Simply-Scalable Speculative Decoding",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Over the past year, Speculative Decoding has gained popularity as a technique for accelerating Large Language Model inference. While several methods have been introduced, most struggle to deliver satisfactory performance at batch sizes typical for data centers ($\\geq 8$) and often involve significant deployment complexities. In this work, we offer a theoretical explanation of how Speculative Decoding can be effectively utilized with larger batch sizes. We also introduce a method that integrates seamlessly into existing systems without additional training or the complexity of deploying a small LLM. In a continuous batching setting, we achieve a 4x increase in throughput without any latency impact for short context generation, and a 1.7-2x improvement in both latency and throughput for longer contexts.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "14 pages, 7 figures"
    },
    {
        "paper id": "2411.05895",
        "abstract url": "https://arxiv.org/abs/2411.05895",
        "title": "One Small and One Large for Document-level Event Argument Extraction",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Document-level Event Argument Extraction (EAE) faces two challenges due to increased input length: 1) difficulty in distinguishing semantic boundaries between events, and 2) interference from redundant information. To address these issues, we propose two methods. The first method introduces the Co and Structure Event Argument Extraction model (CsEAE) based on Small Language Models (SLMs). CsEAE includes a co-occurrences-aware module, which integrates information about all events present in the current input through context labeling and co-occurrences event prompts extraction. Additionally, CsEAE includes a structure-aware module that reduces interference from redundant information by establishing structural relationships between the sentence containing the trigger and other sentences in the document. The second method introduces new prompts to transform the extraction task into a generative task suitable for Large Language Models (LLMs), addressing gaps in EAE performance using LLMs under Supervised Fine-Tuning (SFT) conditions. We also fine-tuned multiple datasets to develop an LLM that performs better across most datasets. Finally, we applied insights from CsEAE to LLMs, achieving further performance improvements. This suggests that reliable insights validated on SLMs are also applicable to LLMs. We tested our models on the Rams, WikiEvents, and MLEE datasets. The CsEAE model achieved improvements of 2.1\\%, 2.3\\%, and 3.2\\% in the Arg-C F1 metric compared to the baseline, PAIE~\\cite{PAIE}. For LLMs, we demonstrated that their performance on document-level datasets is comparable to that of SLMs~\\footnote{All code is available at https://github.com/simon-p-j-r/CsEAE}.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05903",
        "abstract url": "https://arxiv.org/abs/2411.05903",
        "title": "Towards Multi-Modal Mastery: A 4.5B Parameter Truly Multi-Modal Small Language Model",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We present a novel 4.5B parameter small language model that can handle multiple input and output modalities, including text, images, videos, and audio. Despite its small size, the model achieves near state-of-the-art performance on a variety of tasks, demonstrating the potential of multi-modal models to tackle complex real-world problems. Our approach leverages recent advancements in language modeling and multi-task learning to create a versatile and high-performing model that can even be deployed for edge inference. Experimental results show the model's strong performance across multiple benchmarks, paving the way for further progress in multi-modal artificial intelligence.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05928",
        "abstract url": "https://arxiv.org/abs/2411.05928",
        "title": "Reducing Distraction in Long-Context Language Models by Focused Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in Large Language Models (LLMs) have significantly enhanced their capacity to process long contexts. However, effectively utilizing this long context remains a challenge due to the issue of distraction, where irrelevant information dominates lengthy contexts, causing LLMs to lose focus on the most relevant segments. To address this, we propose a novel training method that enhances LLMs' ability to discern relevant information through a unique combination of retrieval-based data augmentation and contrastive learning. Specifically, during fine-tuning with long contexts, we employ a retriever to extract the most relevant segments, serving as augmented inputs. We then introduce an auxiliary contrastive learning objective to explicitly ensure that outputs from the original context and the retrieved sub-context are closely aligned. Extensive experiments on long single-document and multi-document QA benchmarks demonstrate the effectiveness of our proposed method.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05958",
        "abstract url": "https://arxiv.org/abs/2411.05958",
        "title": "Sentiment Analysis of Cyberbullying Data in Social Media",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Social media has become an integral part of modern life, but it has also brought with it the pervasive issue of cyberbullying a serious menace in today's digital age. Cyberbullying, a form of harassment that occurs on social networks, has escalated alongside the growth of these platforms. Sentiment analysis holds significant potential not only for detecting bullying phrases but also for identifying victims who are at high risk of harm, whether to themselves or others. Our work focuses on leveraging deep learning and natural language understanding techniques to detect traces of bullying in social media posts. We developed a Recurrent Neural Network with Long Short-Term Memory (LSTM) cells, using different embeddings. One approach utilizes BERT embeddings, while the other replaces the embeddings layer with the recently released embeddings API from OpenAI. We conducted a performance comparison between these two approaches to evaluate their effectiveness in sentiment analysis of Formspring Cyberbullying data. Our Code is Available at https://github.com/ppujari/xcs224u",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05980",
        "abstract url": "https://arxiv.org/abs/2411.05980",
        "title": "FactLens: Benchmarking Fine-Grained Fact Verification",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have shown impressive capability in language generation and understanding, but their tendency to hallucinate and produce factually incorrect information remains a key limitation. To verify LLM-generated contents and claims from other sources, traditional verification approaches often rely on holistic models that assign a single factuality label to complex claims, potentially obscuring nuanced errors. In this paper, we advocate for a shift toward fine-grained verification, where complex claims are broken down into smaller sub-claims for individual verification, allowing for more precise identification of inaccuracies, improved transparency, and reduced ambiguity in evidence retrieval. However, generating sub-claims poses challenges, such as maintaining context and ensuring semantic equivalence with respect to the original claim. We introduce FactLens, a benchmark for evaluating fine-grained fact verification, with metrics and automated evaluators of sub-claim quality. The benchmark data is manually curated to ensure high-quality ground truth. Our results show alignment between automated FactLens evaluators and human judgments, and we discuss the impact of sub-claim characteristics on the overall verification performance.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "12 pages, under review"
    },
    {
        "paper id": "2411.05986",
        "abstract url": "https://arxiv.org/abs/2411.05986",
        "title": "Fine-Grained Reward Optimization for Machine Translation using Error Severity Mappings",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Reinforcement learning (RL) has been proven to be an effective and robust method for training neural machine translation systems, especially when paired with powerful reward models that accurately assess translation quality. However, most research has focused on RL methods that use sentence-level feedback, which leads to inefficient learning signals due to the reward sparsity problem -- the model receives a single score for the entire sentence. To address this, we introduce a novel approach that leverages fine-grained token-level reward mechanisms with RL methods. We use xCOMET, a state-of-the-art quality estimation system as our token-level reward model. xCOMET provides detailed feedback by predicting fine-grained error spans and their severity given source-translation pairs. We conduct experiments on small and large translation datasets to compare the impact of sentence-level versus fine-grained reward signals on translation quality. Our results show that training with token-level rewards improves translation quality across language pairs over baselines according to automatic and human evaluation. Furthermore, token-level reward optimization also improves training stability, evidenced by a steady increase in mean rewards over training epochs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "10 pages, work-in-progress"
    },
    {
        "paper id": "2411.05990",
        "abstract url": "https://arxiv.org/abs/2411.05990",
        "title": "Game-theoretic LLM: Agent Workflow for Negotiation Games",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper investigates the rationality of large language models (LLMs) in strategic decision-making contexts, specifically within the framework of game theory. We evaluate several state-of-the-art LLMs across a spectrum of complete-information and incomplete-information games. Our findings reveal that LLMs frequently deviate from rational strategies, particularly as the complexity of the game increases with larger payoff matrices or deeper sequential trees. To address these limitations, we design multiple game-theoretic workflows that guide the reasoning and decision-making processes of LLMs. These workflows aim to enhance the models' ability to compute Nash Equilibria and make rational choices, even under conditions of uncertainty and incomplete information. Experimental results demonstrate that the adoption of these workflows significantly improves the rationality and robustness of LLMs in game-theoretic tasks. Specifically, with the workflow, LLMs exhibit marked improvements in identifying optimal strategies, achieving near-optimal allocations in negotiation scenarios, and reducing susceptibility to exploitation during negotiations. Furthermore, we explore the meta-strategic considerations of whether it is rational for agents to adopt such workflows, recognizing that the decision to use or forgo the workflow constitutes a game-theoretic issue in itself. Our research contributes to a deeper understanding of LLMs' decision-making capabilities in strategic contexts and provides insights into enhancing their rationality through structured workflows. The findings have implications for the development of more robust and strategically sound AI agents capable of navigating complex interactive environments. Code and data supporting this study are available at \\url{https://github.com/Wenyueh/game_theory}.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ],
        "comment": "45 pages, 12 figures"
    },
    {
        "paper id": "2411.06008",
        "abstract url": "https://arxiv.org/abs/2411.06008",
        "title": "The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study explores how the Large Language Models (LLMs) adjust linguistic features to create personalized persuasive outputs. While research showed that LLMs personalize outputs, a gap remains in understanding the linguistic features of their persuasive capabilities. We identified 13 linguistic features crucial for influencing personalities across different levels of the Big Five model of personality. We analyzed how prompts with personality trait information influenced the output of 19 LLMs across five model families. The findings show that models use more anxiety-related words for neuroticism, increase achievement-related words for conscientiousness, and employ fewer cognitive processes words for openness to experience. Some model families excel at adapting language for openness to experience, others for conscientiousness, while only one model adapts language for neuroticism. Our findings show how LLMs tailor responses based on personality cues in prompts, indicating their potential to create persuasive content affecting the mind and well-being of the recipients.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "31 pages"
    },
    {
        "paper id": "2411.06022",
        "abstract url": "https://arxiv.org/abs/2411.06022",
        "title": "Improved intent classification based on context information using a windows-based approach",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Conversational systems have a Natural Language Understanding (NLU) module. In this module, there is a task known as an intent classification that aims at identifying what a user is attempting to achieve from an utterance. Previous works use only the current utterance to predict the intent of a given query and they do not consider the role of the context (one or a few previous utterances) in the dialog flow for this task. In this work, we propose several approaches to investigate the role of contextual information for the intent classification task. Each approach is used to carry out a concatenation between the dialogue history and the current utterance. Our intent classification method is based on a convolutional neural network that obtains effective vector representations from BERT to perform accurate intent classification using an approach window-based. Our experiments were carried out on a real-world Brazilian Portuguese corpus with dialog flows provided by Wavy global company. Our results achieved substantial improvements over the baseline, isolated utterances (without context), in three approaches using the user's utterance and system's response from previous messages as dialogue context.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "In preparation for Journal Submission"
    },
    {
        "paper id": "2411.06032",
        "abstract url": "https://arxiv.org/abs/2411.06032",
        "title": "LLM-GLOBE: A Benchmark Evaluating the Cultural Values Embedded in LLM Output",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Immense effort has been dedicated to minimizing the presence of harmful or biased generative content and better aligning AI output to human intention; however, research investigating the cultural values of LLMs is still in very early stages. Cultural values underpin how societies operate, providing profound insights into the norms, priorities, and decision making of their members. In recognition of this need for further research, we draw upon cultural psychology theory and the empirically-validated GLOBE framework to propose the LLM-GLOBE benchmark for evaluating the cultural value systems of LLMs, and we then leverage the benchmark to compare the values of Chinese and US LLMs. Our methodology includes a novel \"LLMs-as-a-Jury\" pipeline which automates the evaluation of open-ended content to enable large-scale analysis at a conceptual level. Results clarify similarities and differences that exist between Eastern and Western cultural value systems and suggest that open-generation tasks represent a more promising direction for evaluation of cultural values. We interpret the implications of this research for subsequent model development, evaluation, and deployment efforts as they relate to LLMs, AI cultural alignment more broadly, and the influence of AI cultural value systems on human-AI collaboration outcomes.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06037",
        "abstract url": "https://arxiv.org/abs/2411.06037",
        "title": "Sufficient Context: A New Lens on Retrieval Augmented Generation Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Augmenting LLMs with context leads to improved performance across many applications. Despite much research on Retrieval Augmented Generation (RAG) systems, an open question is whether errors arise because LLMs fail to utilize the context from retrieval or the context itself is insufficient to answer the query. To shed light on this, we develop a new notion of sufficient context, along with a way to classify instances that have enough information to answer the query. We then use sufficient context to analyze several models and datasets. By stratifying errors based on context sufficiency, we find that proprietary LLMs (Gemini, GPT, Claude) excel at answering queries when the context is sufficient, but often output incorrect answers instead of abstaining when the context is not. On the other hand, open-source LLMs (Llama, Mistral, Gemma) hallucinate or abstain often, even with sufficient context. We further categorize cases when the context is useful, and improves accuracy, even though it does not fully answer the query and the model errs without the context. Building on our findings, we explore ways to reduce hallucinations in RAG systems, including a new selective generation method that leverages sufficient context information for guided abstention. Our method improves the fraction of correct answers among times where the model responds by 2-10% for Gemini, GPT, and Gemma.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05325",
        "abstract url": "https://arxiv.org/abs/2411.05325",
        "title": "UKTF: Unified Knowledge Tracing Framework for Subjective and Objective Assessments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "With the continuous deepening and development of the concept of smart education, learners' comprehensive development and individual needs have received increasing attention. However, traditional educational evaluation systems tend to assess learners' cognitive abilities solely through general test scores, failing to comprehensively consider their actual knowledge states. Knowledge tracing technology can establish knowledge state models based on learners' historical answer data, thereby enabling personalized assessment of learners. Nevertheless, current classical knowledge tracing models are primarily suited for objective test questions, while subjective test questions still confront challenges such as complex data representation, imperfect modeling, and the intricate and dynamic nature of knowledge states. Drawing on the application of knowledge tracing technology in education, this study aims to fully utilize examination data and proposes a unified knowledge tracing model that integrates both objective and subjective test questions. Recognizing the differences in question structure, assessment methods, and data characteristics between objective and subjective test questions, the model employs the same backbone network for training both types of questions. Simultaneously, it achieves knowledge tracing for subjective test questions by universally modifying the training approach of the baseline model, adding branch networks, and optimizing the method of question encoding. This study conducted multiple experiments on real datasets, and the results consistently demonstrate that the model effectively addresses knowledge tracing issues in both objective and subjective test question scenarios.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2411.05331",
        "abstract url": "https://arxiv.org/abs/2411.05331",
        "title": "Discovering Latent Structural Causal Models from Spatio-Temporal Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Many important phenomena in scientific fields such as climate, neuroscience, and epidemiology are naturally represented as spatiotemporal gridded data with complex interactions. For example, in climate science, researchers aim to uncover how large-scale events, such as the North Atlantic Oscillation (NAO) and the Antarctic Oscillation (AAO), influence other global processes. Inferring causal relationships from these data is a challenging problem compounded by the high dimensionality of such data and the correlations between spatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY), a novel framework based on variational inference, designed to explicitly model latent time-series and their causal relationships from spatially confined modes in the data. Our method uses an end-to-end training process that maximizes an evidence-lower bound (ELBO) for the data likelihood. Theoretically, we show that, under some conditions, the latent variables are identifiable up to transformation by an invertible matrix. Empirically, we show that SPACY outperforms state-of-the-art baselines on synthetic data, remains scalable for large grids, and identifies key known phenomena from real-world climate data.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05346",
        "abstract url": "https://arxiv.org/abs/2411.05346",
        "title": "Reinforcement Learning for Adaptive Resource Scheduling in Complex System Environments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study presents a novel computer system performance optimization and adaptive workload management scheduling algorithm based on Q-learning. In modern computing environments, characterized by increasing data volumes, task complexity, and dynamic workloads, traditional static scheduling methods such as Round-Robin and Priority Scheduling fail to meet the demands of efficient resource allocation and real-time adaptability. By contrast, Q-learning, a reinforcement learning algorithm, continuously learns from system state changes, enabling dynamic scheduling and resource optimization. Through extensive experiments, the superiority of the proposed approach is demonstrated in both task completion time and resource utilization, outperforming traditional and dynamic resource allocation (DRA) algorithms. These findings are critical as they highlight the potential of intelligent scheduling algorithms based on reinforcement learning to address the growing complexity and unpredictability of computing environments. This research provides a foundation for the integration of AI-driven adaptive scheduling in future large-scale systems, offering a scalable, intelligent solution to enhance system performance, reduce operating costs, and support sustainable energy consumption. The broad applicability of this approach makes it a promising candidate for next-generation computing frameworks, such as edge computing, cloud computing, and the Internet of Things.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05348",
        "abstract url": "https://arxiv.org/abs/2411.05348",
        "title": "LLM-PySC2: Starcraft II learning environment for Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces a new environment LLM-PySC2 (the Large Language Model StarCraft II Learning Environment), a platform derived from DeepMind's StarCraft II Learning Environment that serves to develop Large Language Models (LLMs) based decision-making methodologies. This environment is the first to offer the complete StarCraft II action space, multi-modal observation interfaces, and a structured game knowledge database, which are seamlessly connected with various LLMs to facilitate the research of LLMs-based decision-making. To further support multi-agent research, we developed an LLM collaborative framework that supports multi-agent concurrent queries and multi-agent communication. In our experiments, the LLM-PySC2 environment is adapted to be compatible with the StarCraft Multi-Agent Challenge (SMAC) task group and provided eight new scenarios focused on macro-decision abilities. We evaluated nine mainstream LLMs in the experiments, and results show that sufficient parameters are necessary for LLMs to make decisions, but improving reasoning ability does not directly lead to better decision-making outcomes. Our findings further indicate the importance of enabling large models to learn autonomously in the deployment environment through parameter training or train-free learning techniques. Ultimately, we expect that the LLM-PySC2 environment can promote research on learning methods for LLMs, helping LLM-based methods better adapt to task scenarios.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05390",
        "abstract url": "https://arxiv.org/abs/2411.05390",
        "title": "Towards s'more connected coding camps",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Coding camps bring together individuals from diverse backgrounds to tackle given challenges within a limited timeframe. Such camps create a rich learning environment for various skills, some of which are directly associated with the camp, and some of which are a result of working as a team during the camp. Unfortunately, coding camps often remain isolated from the broader educational curriculum or other bigger context, which downplays the opportunities they can offer to students. In this paper, we present the vision of the European initiative Oscar, which aims at connecting coding camps to the educational and professional context faced by the learners. In addition, we sketch a supporting platform and its features for connected coding camps.",
        "subjects": [
            "cs.CY",
            "cs.SE"
        ],
        "comment": "Accepted for publication at SIGCSE TS 2025, Proceedings of the 56th ACM Technical Symposium on Computer Science Education"
    },
    {
        "paper id": "2411.05409",
        "abstract url": "https://arxiv.org/abs/2411.05409",
        "title": "Web Archives Metadata Generation with GPT-4o: Challenges and Insights",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Current metadata creation for web archives is time consuming and costly due to reliance on human effort. This paper explores the use of gpt-4o for metadata generation within the Web Archive Singapore, focusing on scalability, efficiency, and cost effectiveness. We processed 112 Web ARChive (WARC) files using data reduction techniques, achieving a notable 99.9% reduction in metadata generation costs. By prompt engineering, we generated titles and abstracts, which were evaluated both intrinsically using Levenshtein Distance and BERTScore, and extrinsically with human cataloguers using McNemar's test. Results indicate that while our method offers significant cost savings and efficiency gains, human curated metadata maintains an edge in quality. The study identifies key challenges including content inaccuracies, hallucinations, and translation issues, suggesting that Large Language Models (LLMs) should serve as complements rather than replacements for human cataloguers. Future work will focus on refining prompts, improving content filtering, and addressing privacy concerns through experimentation with smaller models. This research advances the integration of LLMs in web archiving, offering valuable insights into their current capabilities and outlining directions for future enhancements. The code is available at https://github.com/masamune-prog/warc2summary for further development and use by institutions facing similar challenges.",
        "subjects": [
            "cs.DL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05424",
        "abstract url": "https://arxiv.org/abs/2411.05424",
        "title": "ICE-T: A Multi-Faceted Concept for Teaching Machine Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "The topics of Artificial intelligence (AI) and especially Machine Learning (ML) are increasingly making their way into educational curricula. To facilitate the access for students, a variety of platforms, visual tools, and digital games are already being used to introduce ML concepts and strengthen the understanding of how AI works. We take a look at didactic principles that are employed for teaching computer science, define criteria, and, based on those, evaluate a selection of prominent existing platforms, tools, and games. Additionally, we criticize the approach of portraying ML mostly as a black-box and the resulting missing focus on creating an understanding of data, algorithms, and models that come with it. To tackle this issue, we present a concept that covers intermodal transfer, computational and explanatory thinking, ICE-T, as an extension of known didactic principles. With our multi-faceted concept, we believe that planners of learning units, creators of learning platforms and educators can improve on teaching ML.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted and presented at the 17th International Conference on Informatics in Schools (ISSEP 2024)"
    },
    {
        "paper id": "2411.05453",
        "abstract url": "https://arxiv.org/abs/2411.05453",
        "title": "The sampling complexity of learning invertible residual neural networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent work it has been shown that determining a feedforward ReLU neural network to within high uniform accuracy from point samples suffers from the curse of dimensionality in terms of the number of samples needed. As a consequence, feedforward ReLU neural networks are of limited use for applications where guaranteed high uniform accuracy is required. We consider the question of whether the sampling complexity can be improved by restricting the specific neural network architecture. To this end, we investigate invertible residual neural networks which are foundational architectures in deep learning and are widely employed in models that power modern generative methods. Our main result shows that the residual neural network architecture and invertibility do not help overcome the complexity barriers encountered with simpler feedforward architectures. Specifically, we demonstrate that the computational complexity of approximating invertible residual neural networks from point samples in the uniform norm suffers from the curse of dimensionality. Similar results are established for invertible convolutional Residual neural networks.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05483",
        "abstract url": "https://arxiv.org/abs/2411.05483",
        "title": "The Limits of Differential Privacy in Online Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Differential privacy (DP) is a formal notion that restricts the privacy leakage of an algorithm when running on sensitive data, in which privacy-utility trade-off is one of the central problems in private data analysis. In this work, we investigate the fundamental limits of differential privacy in online learning algorithms and present evidence that separates three types of constraints: no DP, pure DP, and approximate DP. We first describe a hypothesis class that is online learnable under approximate DP but not online learnable under pure DP under the adaptive adversarial setting. This indicates that approximate DP must be adopted when dealing with adaptive adversaries. We then prove that any private online learner must make an infinite number of mistakes for almost all hypothesis classes. This essentially generalizes previous results and shows a strong separation between private and non-private settings since a finite mistake bound is always attainable (as long as the class is online learnable) when there is no privacy requirement.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05540",
        "abstract url": "https://arxiv.org/abs/2411.05540",
        "title": "CRepair: CVAE-based Automatic Vulnerability Repair Technology",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Software vulnerabilities are flaws in computer software systems that pose significant threats to the integrity, security, and reliability of modern software and its application data. These vulnerabilities can lead to substantial economic losses across various industries. Manual vulnerability repair is not only time-consuming but also prone to errors. To address the challenges of vulnerability repair, researchers have proposed various solutions, with learning-based automatic vulnerability repair techniques gaining widespread attention. However, existing methods often focus on learning more vulnerability data to improve repair outcomes, while neglecting the diverse characteristics of vulnerable code, and suffer from imprecise vulnerability localization.To address these shortcomings, this paper proposes CRepair, a CVAE-based automatic vulnerability repair technology aimed at fixing security vulnerabilities in system code. We first preprocess the vulnerability data using a prompt-based method to serve as input to the model. Then, we apply causal inference techniques to map the vulnerability feature data to probability distributions. By employing multi-sample feature fusion, we capture diverse vulnerability feature information. Finally, conditional control is used to guide the model in repairing the vulnerabilities.Experimental results demonstrate that the proposed method significantly outperforms other benchmark models, achieving a perfect repair rate of 52%. The effectiveness of the approach is validated from multiple perspectives, advancing AI-driven code vulnerability repair and showing promising applications.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05564",
        "abstract url": "https://arxiv.org/abs/2411.05564",
        "title": "Open-set object detection: towards unified problem formulation and benchmarking",
        "rating": "0.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "In real-world applications where confidence is key, like autonomous driving, the accurate detection and appropriate handling of classes differing from those used during training are crucial. Despite the proposal of various unknown object detection approaches, we have observed widespread inconsistencies among them regarding the datasets, metrics, and scenarios used, alongside a notable absence of a clear definition for unknown objects, which hampers meaningful evaluation. To counter these issues, we introduce two benchmarks: a unified VOC-COCO evaluation, and the new OpenImagesRoad benchmark which provides clear hierarchical object definition besides new evaluation metrics. Complementing the benchmark, we exploit recent self-supervised Vision Transformers performance, to improve pseudo-labeling-based OpenSet Object Detection (OSOD), through OW-DETR++. State-of-the-art methods are extensively evaluated on the proposed benchmarks. This study provides a clear problem definition, ensures consistent evaluations, and draws new conclusions about effectiveness of OSOD strategies.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted at ECCV 2024 Workshop: \"The 3rd Workshop for Out-of-Distribution Generalization in Computer Vision Foundation Models\""
    },
    {
        "paper id": "2411.05575",
        "abstract url": "https://arxiv.org/abs/2411.05575",
        "title": "Towards a Real-Time Simulation of Elastoplastic Deformation Using Multi-Task Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study introduces a surrogate modeling framework merging proper orthogonal decomposition, long short-term memory networks, and multi-task learning, to accurately predict elastoplastic deformations in real-time. Superior to single-task neural networks, this approach achieves a mean absolute error below 0.40\\% across various state variables, with the multi-task model showing enhanced generalization by mitigating overfitting through shared layers. Moreover, in our use cases, a pre-trained multi-task model can effectively train additional variables with as few as 20 samples, demonstrating its deep understanding of complex scenarios. This is notably efficient compared to single-task models, which typically require around 100 samples. Significantly faster than traditional finite element analysis, our model accelerates computations by approximately a million times, making it a substantial advancement for real-time predictive modeling in engineering applications. While it necessitates further testing on more intricate models, this framework shows substantial promise in elevating both efficiency and accuracy in engineering applications, particularly for real-time scenarios.",
        "subjects": [
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05577",
        "abstract url": "https://arxiv.org/abs/2411.05577",
        "title": "Exploring Relationships Between Cryptocurrency News Outlets and Influencers' Twitter Activity and Market Prices",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Academics increasingly acknowledge the predictive power of social media for a wide variety of events and, more specifically, for financial markets. Anecdotal and empirical findings show that cryptocurrencies are among the financial assets that have been affected by news and influencers' activities on Twitter. However, the extent to which Twitter crypto influencer's posts about trading signals and their effect on market prices is mostly unexplored. In this paper, we use LLMs to uncover buy and not-buy signals from influencers and news outlets' Twitter posts and use a VAR analysis with Granger Causality tests and cross-correlation analysis to understand how these trading signals are temporally correlated with the top nine major cryptocurrencies' prices. Overall, the results show a mixed pattern across cryptocurrencies and temporal periods. However, we found that for the top three cryptocurrencies with the highest presence within news and influencer posts, their aggregated LLM-detected trading signal over the preceding 24 hours granger-causes fluctuations in their market prices, exhibiting a lag of at least 6 hours. In addition, the results reveal fundamental differences in how influencers and news outlets cover cryptocurrencies.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05588",
        "abstract url": "https://arxiv.org/abs/2411.05588",
        "title": "An Evidence-Based Curriculum Initiative for Hardware Reverse Engineering Education",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The increasing importance of supply chain security for digital devices -- from consumer electronics to critical infrastructure -- has created a high demand for skilled cybersecurity experts. These experts use Hardware Reverse Engineering (HRE) as a crucial technique to ensure trust in digital semiconductors. Recently, the US and EU have provided substantial funding to educate this cybersecurity-ready semiconductor workforce, but success depends on the widespread availability of academic training programs. In this paper, we investigate the current state of education in hardware security and HRE to identify efficient approaches for establishing effective HRE training programs. Through a systematic literature review, we uncover 13 relevant courses, including eight with accompanying academic publications. We identify common topics, threat models, key pedagogical features, and course evaluation methods. We find that most hardware security courses do not prioritize HRE, making HRE training scarce. While the predominant course structure of lectures paired with hands-on projects appears to be largely effective, we observe a lack of standardized evaluation methods and limited reliability of student self-assessment surveys. Our results suggest several possible improvements to HRE education and offer recommendations for developing new training courses. We advocate for the integration of HRE education into curriculum guidelines to meet the growing societal and industry demand for HRE experts.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "7 pages, 1 figure, 2 tables. To be published in Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1. For supplementary materials, see https://osf.io/dt8ne/"
    },
    {
        "paper id": "2411.05614",
        "abstract url": "https://arxiv.org/abs/2411.05614",
        "title": "Acceleration for Deep Reinforcement Learning using Parallel and Distributed Computing: A Survey",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Deep reinforcement learning has led to dramatic breakthroughs in the field of artificial intelligence for the past few years. As the amount of rollout experience data and the size of neural networks for deep reinforcement learning have grown continuously, handling the training process and reducing the time consumption using parallel and distributed computing is becoming an urgent and essential desire. In this paper, we perform a broad and thorough investigation on training acceleration methodologies for deep reinforcement learning based on parallel and distributed computing, providing a comprehensive survey in this field with state-of-the-art methods and pointers to core references. In particular, a taxonomy of literature is provided, along with a discussion of emerging topics and open issues. This incorporates learning system architectures, simulation parallelism, computing parallelism, distributed synchronization mechanisms, and deep evolutionary reinforcement learning. Further, we compare 16 current open-source libraries and platforms with criteria of facilitating rapid development. Finally, we extrapolate future directions that deserve further research.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "comment": "This paper has been accepted by ACM Computing Surveys"
    },
    {
        "paper id": "2411.05619",
        "abstract url": "https://arxiv.org/abs/2411.05619",
        "title": "WHALE: Towards Generalizable and Scalable World Models for Embodied Decision-making",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "World models play a crucial role in decision-making within embodied environments, enabling cost-free explorations that would otherwise be expensive in the real world. To facilitate effective decision-making, world models must be equipped with strong generalizability to support faithful imagination in out-of-distribution (OOD) regions and provide reliable uncertainty estimation to assess the credibility of the simulated experiences, both of which present significant challenges for prior scalable approaches. This paper introduces WHALE, a framework for learning generalizable world models, consisting of two key techniques: behavior-conditioning and retracing-rollout. Behavior-conditioning addresses the policy distribution shift, one of the primary sources of the world model generalization error, while retracing-rollout enables efficient uncertainty estimation without the necessity of model ensembles. These techniques are universal and can be combined with any neural network architecture for world model learning. Incorporating these two techniques, we present Whale-ST, a scalable spatial-temporal transformer-based world model with enhanced generalizability. We demonstrate the superiority of Whale-ST in simulation tasks by evaluating both value estimation accuracy and video generation fidelity. Additionally, we examine the effectiveness of our uncertainty estimation technique, which enhances model-based policy optimization in fully offline scenarios. Furthermore, we propose Whale-X, a 414M parameter world model trained on 970K trajectories from Open X-Embodiment datasets. We show that Whale-X exhibits promising scalability and strong generalizability in real-world manipulation scenarios using minimal demonstrations.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05648",
        "abstract url": "https://arxiv.org/abs/2411.05648",
        "title": "Enhancing Model Fairness and Accuracy with Similarity Networks: A Methodological Approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose an innovative approach to thoroughly explore dataset features that introduce bias in downstream machine-learning tasks. Depending on the data format, we use different techniques to map instances into a similarity feature space. Our method's ability to adjust the resolution of pairwise similarity provides clear insights into the relationship between the dataset classification complexity and model fairness. Experimental results confirm the promising applicability of the similarity network in promoting fair models. Moreover, leveraging our methodology not only seems promising in providing a fair downstream task such as classification, it also performs well in imputation and augmentation of the dataset satisfying the fairness criteria such as demographic parity and imbalanced classes.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "7 pages, 4 figures"
    },
    {
        "paper id": "2411.05653",
        "abstract url": "https://arxiv.org/abs/2411.05653",
        "title": "The influence of persona and conversational task on social interactions with a LLM-controlled embodied conversational agent",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in conversational tasks. Embodying an LLM as a virtual human allows users to engage in face-to-face social interactions in Virtual Reality. However, the influence of person- and task-related factors in social interactions with LLM-controlled agents remains unclear. In this study, forty-six participants interacted with a virtual agent whose persona was manipulated as extravert or introvert in three different conversational tasks (small talk, knowledge test, convincing). Social-evaluation, emotional experience, and realism were assessed using ratings. Interactive engagement was measured by quantifying participants' words and conversational turns. Finally, we measured participants' willingness to ask the agent for help during the knowledge test. Our findings show that the extraverted agent was more positively evaluated, elicited a more pleasant experience and greater engagement, and was assessed as more realistic compared to the introverted agent. Whereas persona did not affect the tendency to ask for help, participants were generally more confident in the answer when they had help of the LLM. Variation of personality traits of LLM-controlled embodied virtual agents, therefore, affects social-emotional processing and behavior in virtual interactions. Embodied virtual agents allow the presentation of naturalistic social encounters in a virtual environment.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "11 pages, 5 figures"
    },
    {
        "paper id": "2411.05661",
        "abstract url": "https://arxiv.org/abs/2411.05661",
        "title": "Multi-armed Bandits with Missing Outcome",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "While significant progress has been made in designing algorithms that minimize regret in online decision-making, real-world scenarios often introduce additional complexities, perhaps the most challenging of which is missing outcomes. Overlooking this aspect or simply assuming random missingness invariably leads to biased estimates of the rewards and may result in linear regret. Despite the practical relevance of this challenge, no rigorous methodology currently exists for systematically handling missingness, especially when the missingness mechanism is not random. In this paper, we address this gap in the context of multi-armed bandits (MAB) with missing outcomes by analyzing the impact of different missingness mechanisms on achievable regret bounds. We introduce algorithms that account for missingness under both missing at random (MAR) and missing not at random (MNAR) models. Through both analytical and simulation studies, we demonstrate the drastic improvements in decision-making by accounting for missingness in these settings.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "38 pages, 5 figures, multi-armed bandits, missing data"
    },
    {
        "paper id": "2411.05683",
        "abstract url": "https://arxiv.org/abs/2411.05683",
        "title": "Data-Driven Distributed Common Operational Picture from Heterogeneous Platforms using Multi-Agent Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The integration of unmanned platforms equipped with advanced sensors promises to enhance situational awareness and mitigate the \"fog of war\" in military operations. However, managing the vast influx of data from these platforms poses a significant challenge for Command and Control (C2) systems. This study presents a novel multi-agent learning framework to address this challenge. Our method enables autonomous and secure communication between agents and humans, which in turn enables real-time formation of an interpretable Common Operational Picture (COP). Each agent encodes its perceptions and actions into compact vectors, which are then transmitted, received and decoded to form a COP encompassing the current state of all agents (friendly and enemy) on the battlefield. Using Deep Reinforcement Learning (DRL), we jointly train COP models and agent's action selection policies. We demonstrate resilience to degraded conditions such as denied GPS and disrupted communications. Experimental validation is performed in the Starcraft-2 simulation environment to evaluate the precision of the COPs and robustness of policies. We report less than 5% error in COPs and policies resilient to various adversarial conditions. In summary, our contributions include a method for autonomous COP formation, increased resilience through distributed prediction, and joint training of COP models and multi-agent RL policies. This research advances adaptive and resilient C2, facilitating effective control of heterogeneous unmanned platforms.",
        "subjects": [
            "cs.MA",
            "cs.AI"
        ],
        "comment": "29th International Command and Control Research & Technology Symposium"
    },
    {
        "paper id": "2411.05708",
        "abstract url": "https://arxiv.org/abs/2411.05708",
        "title": "Sample and Computationally Efficient Robust Learning of Gaussian Single-Index Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "A single-index model (SIM) is a function of the form $\u03c3(\\mathbf{w}^{\\ast} \\cdot \\mathbf{x})$, where $\u03c3: \\mathbb{R} \\to \\mathbb{R}$ is a known link function and $\\mathbf{w}^{\\ast}$ is a hidden unit vector. We study the task of learning SIMs in the agnostic (a.k.a. adversarial label noise) model with respect to the $L^2_2$-loss under the Gaussian distribution. Our main result is a sample and computationally efficient agnostic proper learner that attains $L^2_2$-error of $O(\\mathrm{OPT})+\u03b5$, where $\\mathrm{OPT}$ is the optimal loss. The sample complexity of our algorithm is $\\tilde{O}(d^{\\lceil k^{\\ast}/2\\rceil}+d/\u03b5)$, where $k^{\\ast}$ is the information-exponent of $\u03c3$ corresponding to the degree of its first non-zero Hermite coefficient. This sample bound nearly matches known CSQ lower bounds, even in the realizable setting. Prior algorithmic work in this setting had focused on learning in the realizable case or in the presence of semi-random noise. Prior computationally efficient robust learners required significantly stronger assumptions on the link function.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05733",
        "abstract url": "https://arxiv.org/abs/2411.05733",
        "title": "Differential Privacy Under Class Imbalance: Methods and Empirical Insights",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Imbalanced learning occurs in classification settings where the distribution of class-labels is highly skewed in the training data, such as when predicting rare diseases or in fraud detection. This class imbalance presents a significant algorithmic challenge, which can be further exacerbated when privacy-preserving techniques such as differential privacy are applied to protect sensitive training data. Our work formalizes these challenges and provides a number of algorithmic solutions. We consider DP variants of pre-processing methods that privately augment the original dataset to reduce the class imbalance; these include oversampling, SMOTE, and private synthetic data generation. We also consider DP variants of in-processing techniques, which adjust the learning algorithm to account for the imbalance; these include model bagging, class-weighted empirical risk minimization and class-weighted deep learning. For each method, we either adapt an existing imbalanced learning technique to the private setting or demonstrate its incompatibility with differential privacy. Finally, we empirically evaluate these privacy-preserving imbalanced learning methods under various data and distributional settings. We find that private synthetic data methods perform well as a data pre-processing step, while class-weighted ERMs are an alternative in higher-dimensional settings where private synthetic data suffers from the curse of dimensionality.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2411.05746",
        "abstract url": "https://arxiv.org/abs/2411.05746",
        "title": "Continuous-Time Analysis of Adaptive Optimization and Normalization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Adaptive optimization algorithms, particularly Adam and its variant AdamW, are fundamental components of modern deep learning. However, their training dynamics lack comprehensive theoretical understanding, with limited insight into why common practices - such as specific hyperparameter choices and normalization layers - contribute to successful generalization. This work presents a continuous-time formulation of Adam and AdamW, facilitating a tractable analysis of training dynamics that can shed light on such practical questions. We theoretically derive a stable region for Adam's hyperparameters $(\u03b2, \u03b3)$ that ensures bounded updates, empirically verifying these predictions by observing unstable exponential growth of parameter updates outside this region. Furthermore, we theoretically justify the success of normalization layers by uncovering an implicit meta-adaptive effect of scale-invariant architectural components. This insight leads to an explicit optimizer, $2$-Adam, which we generalize to $k$-Adam - an optimizer that applies an adaptive normalization procedure $k$ times, encompassing Adam (corresponding to $k=1$) and Adam with a normalization layer (corresponding to $k=2$). Overall, our continuous-time formulation of Adam facilitates a principled analysis, offering deeper understanding of optimal hyperparameter choices and architectural decisions in modern deep learning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05748",
        "abstract url": "https://arxiv.org/abs/2411.05748",
        "title": "Multi-Dimensional Reconfigurable, Physically Composable Hybrid Diffractive Optical Neural Network",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Diffractive optical neural networks (DONNs), leveraging free-space light wave propagation for ultra-parallel, high-efficiency computing, have emerged as promising artificial intelligence (AI) accelerators. However, their inherent lack of reconfigurability due to fixed optical structures post-fabrication hinders practical deployment in the face of dynamic AI workloads and evolving applications. To overcome this challenge, we introduce, for the first time, a multi-dimensional reconfigurable hybrid diffractive ONN system (MDR-HDONN), a physically composable architecture that unlocks a new degree of freedom and unprecedented versatility in DONNs. By leveraging full-system learnability, MDR-HDONN repurposes fixed fabricated optical hardware, achieving exponentially expanded functionality and superior task adaptability through the differentiable learning of system variables. Furthermore, MDR-HDONN adopts a hybrid optical/photonic design, combining the reconfigurability of integrated photonics with the ultra-parallelism of free-space diffractive systems. Extensive evaluations demonstrate that MDR-HDONN has digital-comparable accuracy on various task adaptations with 74x faster speed and 194x lower energy. Compared to prior DONNs, MDR-HDONN shows exponentially larger functional space with 5x faster training speed, paving the way for a new paradigm of versatile, composable, hybrid optical/photonic AI computing. We will open-source our codes.",
        "subjects": [
            "physics.optics",
            "cs.AI",
            "cs.AR"
        ],
        "comment": "7 pages"
    },
    {
        "paper id": "2411.05750",
        "abstract url": "https://arxiv.org/abs/2411.05750",
        "title": "On Differentially Private String Distances",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Given a database of bit strings $A_1,\\ldots,A_m\\in \\{0,1\\}^n$, a fundamental data structure task is to estimate the distances between a given query $B\\in \\{0,1\\}^n$ with all the strings in the database. In addition, one might further want to ensure the integrity of the database by releasing these distance statistics in a secure manner. In this work, we propose differentially private (DP) data structures for this type of tasks, with a focus on Hamming and edit distance. On top of the strong privacy guarantees, our data structures are also time- and space-efficient. In particular, our data structure is $\u03b5$-DP against any sequence of queries of arbitrary length, and for any query $B$ such that the maximum distance to any string in the database is at most $k$, we output $m$ distance estimates. Moreover, - For Hamming distance, our data structure answers any query in $\\widetilde O(mk+n)$ time and each estimate deviates from the true distance by at most $\\widetilde O(k/e^{\u03b5/\\log k})$; - For edit distance, our data structure answers any query in $\\widetilde O(mk^2+n)$ time and each estimate deviates from the true distance by at most $\\widetilde O(k/e^{\u03b5/(\\log k \\log n)})$. For moderate $k$, both data structures support sublinear query operations. We obtain these results via a novel adaptation of the randomized response technique as a bit flipping procedure, applied to the sketched strings.",
        "subjects": [
            "cs.DS",
            "cs.AI",
            "cs.CR",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05782",
        "abstract url": "https://arxiv.org/abs/2411.05782",
        "title": "Gender Inequalities in Content Collaborations: Asymmetric Creator Synergy and Symmetric Audience Biases",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Content-creator collaborations are a widespread strategy for enhancing digital viewership and revenue. While existing research has explored the efficacy of collaborations, few have looked at inequities in collaborations, particularly from the perspective of the supply and demand of attention. Leveraging 42,376 videos and 6,117,441 comments from YouTube (across 150 channels and 3 games), this study examines gender inequality in collaborative environments. Utilizing Shapley value, a tool from cooperative game theory, results reveal dominant in-group collaborations based on in-game affordances. However, audience responses are aligned across games, reflecting symmetric biases across the gaming communities, with comments focusing more on peripherals than actual gameplay for women. We find supply-side asymmetries exist along with demand-side symmetries. Our results engage with the larger literature on digital and online biases, highlighting how genre and affordances moderate gendered collaboration, the direction of inequality, and contributing a general framework to quantify synergy across collaborations.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "22 pages, 5 figures"
    },
    {
        "paper id": "2411.05888",
        "abstract url": "https://arxiv.org/abs/2411.05888",
        "title": "Sdn Intrusion Detection Using Machine Learning Method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Software-defined network (SDN) is a new approach that allows network control to become directly programmable, and the underlying infrastructure can be abstracted from applications and network services. Control plane). When it comes to security, the centralization that this demands is ripe for a variety of cyber threats that are not typically seen in other network architectures. The authors in this research developed a novel machine-learning method to capture infections in networks. We applied the classifier to the UNSW-NB 15 intrusion detection benchmark and trained a model with this data. Random Forest and Decision Tree are classifiers used to assess with Gradient Boosting and AdaBoost. Out of these best-performing models was Gradient Boosting with an accuracy, recall, and F1 score of 99.87%,100%, and 99.85%, respectively, which makes it reliable in the detection of intrusions for SDN networks. The second best-performing classifier was also a Random Forest with 99.38% of accuracy, followed by Ada Boost and Decision Tree. The research shows that the reason that Gradient Boosting is so effective in this task is that it combines weak learners and creates a strong ensemble model that can predict if traffic belongs to a normal or malicious one with high accuracy. This paper indicates that the GBDT-IDS model is able to improve network security significantly and has better features in terms of both real-time detection accuracy and low false positive rates. In future work, we will integrate this model into live SDN space to observe its application and scalability. This research serves as an initial base on which one can make further strides forward to enhance security in SDN using ML techniques and have more secure, resilient networks.",
        "subjects": [
            "cs.CR",
            "cs.LG",
            "cs.NI"
        ],
        "comment": "15 Pages, 14 Figures"
    },
    {
        "paper id": "2411.05899",
        "abstract url": "https://arxiv.org/abs/2411.05899",
        "title": "Streaming Bayes GFlowNets",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bayes' rule naturally allows for inference refinement in a streaming fashion, without the need to recompute posteriors from scratch whenever new data arrives. In principle, Bayesian streaming is straightforward: we update our prior with the available data and use the resulting posterior as a prior when processing the next data chunk. In practice, however, this recipe entails i) approximating an intractable posterior at each time step; and ii) encapsulating results appropriately to allow for posterior propagation. For continuous state spaces, variational inference (VI) is particularly convenient due to its scalability and the tractability of variational posteriors. For discrete state spaces, however, state-of-the-art VI results in analytically intractable approximations that are ill-suited for streaming settings. To enable streaming Bayesian inference over discrete parameter spaces, we propose streaming Bayes GFlowNets (abbreviated as SB-GFlowNets) by leveraging the recently proposed GFlowNets -- a powerful class of amortized samplers for discrete compositional objects. Notably, SB-GFlowNet approximates the initial posterior using a standard GFlowNet and subsequently updates it using a tailored procedure that requires only the newly observed data. Our case studies in linear preference learning and phylogenetic inference showcase the effectiveness of SB-GFlowNets in sampling from an unnormalized posterior in a streaming setting. As expected, we also observe that SB-GFlowNets is significantly faster than repeatedly training a GFlowNet from scratch to sample from the full posterior.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "25 pages, 8 figures"
    },
    {
        "paper id": "2411.05922",
        "abstract url": "https://arxiv.org/abs/2411.05922",
        "title": "Bridging Nodes and Narrative Flows: Identifying Intervention Targets for Disinformation on Telegram",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "In recent years, mass-broadcast messaging platforms like Telegram have gained prominence for both, serving as a harbor for private communication and enabling large-scale disinformation campaigns. The encrypted and networked nature of these platforms makes it challenging to identify intervention targets since most channels that promote misleading information are not originators of the message. In this work, we examine the structural mechanisms that facilitate the propagation of debunked misinformation on Telegram, focusing on the role of cross-community hubs-nodes that bridge otherwise isolated groups in amplifying misinformation. We introduce a multi-dimensional 'bridging' metric to quantify the influence of nodal Telegram channels, exploring their role in reshaping network topology during key geopolitical events. By analyzing over 1740 Telegram channels and applying network analysis we uncover the small subset of nodes, and identify patterns that are emblematic of information 'flows' on this platform. Our findings provide insights into the structural vulnerabilities of distributed platforms, offering practical suggestions for interventions to mitigate networked disinformation flows.",
        "subjects": [
            "cs.CY",
            "cs.SI"
        ],
        "comment": "*Both Authors contributed equally to this work. 22 pages, 11 figures, 3 tables"
    },
    {
        "paper id": "2411.05934",
        "abstract url": "https://arxiv.org/abs/2411.05934",
        "title": "Qwen2.5-32B: Leveraging Self-Consistent Tool-Integrated Reasoning for Bengali Mathematical Olympiad Problem Solving",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present an innovative approach for solving mathematical problems in Bengali, developed for the DL Sprint 3.0 BUET CSE Fest 2024 Competition. Our method uses advanced deep learning models, notably the Qwen 2.5 series, with improvements made through prompt engineering, model quantization, and Tool Integrated Reasoning (TIR) to handle complex calculations. Initially, we explored various model architectures, including fine-tuned Mistral and quantized Qwen models, refining them with translation techniques, Retrieval-Augmented Generation (RAG), and custom dataset curation. Manual hyperparameter tuning optimized parameters like temperature and top-p to enhance model adaptability and accuracy. Removal of RAG and parameter adjustments further improved robustness. Our approach highlights the potential of advanced NLP techniques in solving Bengali mathematical problems.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05937",
        "abstract url": "https://arxiv.org/abs/2411.05937",
        "title": "The effect of different feature selection methods on models created with XGBoost",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study examines the effect that different feature selection methods have on models created with XGBoost, a popular machine learning algorithm with superb regularization methods. It shows that three different ways for reducing the dimensionality of features produces no statistically significant change in the prediction accuracy of the model. This suggests that the traditional idea of removing the noisy training data to make sure models do not overfit may not apply to XGBoost. But it may still be viable in order to reduce computational complexity.",
        "subjects": [
            "cs.LG",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05952",
        "abstract url": "https://arxiv.org/abs/2411.05952",
        "title": "Tackling extreme urban heat: a machine learning approach to assess the impacts of climate change and the efficacy of climate adaptation strategies in urban microclimates",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As urbanization and climate change progress, urban heat becomes a priority for climate adaptation efforts. High temperatures concentrated in urban heat can drive increased risk of heat-related death and illness as well as increased energy demand for cooling. However, estimating the effects of urban heat is an ongoing field of research typically burdened by an imprecise description of the built environment, significant computational cost, and a lack of high-resolution estimates of the impacts of climate change. Here, we present open-source, computationally efficient machine learning methods that can improve the accuracy of urban temperature estimates when compared to historical reanalysis data. These models are applied to residential buildings in Los Angeles, and we compare the energy benefits of heat mitigation strategies to the impacts of climate change. We find that cooling demand is likely to increase substantially through midcentury, but engineered high-albedo surfaces could lessen this increase by more than 50%. The corresponding increase in heating demand complicates this narrative, but total annual energy use from combined heating and cooling with electric heat pumps in the Los Angeles urban climate is shown to benefit from the engineered cooling strategies under both current and future climates.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05957",
        "abstract url": "https://arxiv.org/abs/2411.05957",
        "title": "When to Commute During the COVID-19 Pandemic and Beyond: Analysis of Traffic Crashes in Washington, D.C",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Many workers in cities across the world, who have been teleworking because of the COVID-19 pandemic, are expected to be back to their commutes. As this process is believed to be gradual and telecommuting is likely to remain an option for many workers, hybrid model and flexible schedules might become the norm in the future. This variable work schedules allows employees to commute outside of traditional rush hours. Moreover, many studies showed that commuters might be skeptical of using trains, buses, and carpools and could turn to personal vehicles to get to work, which might increase congestion and crashes in the roads. This study attempts to provide information on the safest time to commute to Washington, DC area analyzing historical traffic crash data before the COVID-19 pandemic. It also aims to advance our understanding of traffic crashes and other relating factors such as weather in the Washington, DC area. We created a model to predict crashes by time of the day, using a negative binomial regression after rejecting a Poisson regression, and additionally explored the validity of a Random Forest regression. Our main consideration for an eventual application of this study is to reduce crashes in Washington DC, using this tool that provides people with better options on when to commute and when to telework, if available. The study also provides policymakers and researchers with real-world insights that decrease the number of traffic crashes to help achieve the goals of The Vision Zero Initiative adopted by the district.",
        "subjects": [
            "cs.CY",
            "stat.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05964",
        "abstract url": "https://arxiv.org/abs/2411.05964",
        "title": "Utilisation of Vision Systems and Digital Twin for Maintaining Cleanliness in Public Spaces",
        "rating": "0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "ICCV"
            ]
        ],
        "abstract": "Nowadays, the increasing demand for maintaining high cleanliness standards in public spaces results in the search for innovative solutions. The deployment of CCTV systems equipped with modern cameras and software enables not only real-time monitoring of the cleanliness status but also automatic detection of impurities and optimisation of cleaning schedules. The Digital Twin technology allows for the creation of a virtual model of the space, facilitating the simulation, training, and testing of cleanliness management strategies before implementation in the real world. In this paper, we present the utilisation of advanced vision surveillance systems and the Digital Twin technology in cleanliness management, using a railway station as an example. The Digital Twin was created based on an actual 3D model in the Nvidia Omniverse Isaac Sim simulator. A litter detector, bin occupancy level detector, stain segmentation, and a human detector (including the cleaning crew) along with their movement analysis were implemented. A preliminary assessment was conducted, and potential modifications for further enhancement and future development of the system were identified.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "Accepted for the ICCVG 2024: International Conference on Computer Vision and Graphics, Poland"
    },
    {
        "paper id": "2411.05966",
        "abstract url": "https://arxiv.org/abs/2411.05966",
        "title": "Energy Efficient Protein Language Models: Leveraging Small Language Models with LoRA for Controllable Protein Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated significant success in natural language processing (NLP) tasks and have shown promising results in other domains such as protein sequence generation. However, there remain salient differences between LLMs used for NLP, which effectively handle multiple tasks and are available in small sizes, and protein language models that are often specialized for specific tasks and only exist in larger sizes. In this work, we introduce two small protein language models, based on Llama-3-8B and Phi-3-mini, that are capable of both uncontrollable and controllable protein generation. For the uncontrollable generation task, our best model achieves an average pLDDT score of 69.75, demonstrating robust performance in generating viable protein structures. For the controllable generation task, in which the model generates proteins according to properties specified in the prompt, we achieve a remarkable average TM-Score of 0.84, indicating high structural similarity to target proteins. We chose 10 properties, including six classes of enzymes, to extend the capabilities of prior protein language models. Our approach utilizes the Low-Rank Adaptor (LoRA) technique, reducing trainable parameters to just 4% of the original model size, lowering computational requirements. By using a subset of the UniRef50 dataset and small models, we reduced the overall training time by 70% without compromising performance. Notably, Phi-3-mini reduced trainable parameters by 60%, decreasing training cost by 30% compared to Llama 3. Consequently, Phi-3 achieved a comparable TM-Score of 0.81, demonstrating that smaller models can match the performance of larger ones, like Llama 3. We also demonstrate the deployment of our models on the energy efficient ET-SoC-1 chip, significantly improving the TPS/W by a factor of 3.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05979",
        "abstract url": "https://arxiv.org/abs/2411.05979",
        "title": "Variance-Aware Linear UCB with Deep Representation for Neural Contextual Bandits",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "By leveraging the representation power of deep neural networks, neural upper confidence bound (UCB) algorithms have shown success in contextual bandits. To further balance the exploration and exploitation, we propose Neural-$\u03c3^2$-LinearUCB, a variance-aware algorithm that utilizes $\u03c3^2_t$, i.e., an upper bound of the reward noise variance at round $t$, to enhance the uncertainty quantification quality of the UCB, resulting in a regret performance improvement. We provide an oracle version for our algorithm characterized by an oracle variance upper bound $\u03c3^2_t$ and a practical version with a novel estimation for this variance bound. Theoretically, we provide rigorous regret analysis for both versions and prove that our oracle algorithm achieves a better regret guarantee than other neural-UCB algorithms in the neural contextual bandits setting. Empirically, our practical method enjoys a similar computational efficiency, while outperforming state-of-the-art techniques by having a better calibration and lower regret across multiple standard settings, including on the synthetic, UCI, MNIST, and CIFAR-10 datasets.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05982",
        "abstract url": "https://arxiv.org/abs/2411.05982",
        "title": "Unmasking the Shadows: Pinpoint the Implementations of Anti-Dynamic Analysis Techniques in Malware Using LLM",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Sandboxes and other dynamic analysis processes are prevalent in malware detection systems nowadays to enhance the capability of detecting 0-day malware. Therefore, techniques of anti-dynamic analysis (TADA) are prevalent in modern malware samples, and sandboxes can suffer from false negatives and analysis failures when analyzing the samples with TADAs. In such cases, human reverse engineers will get involved in conducting dynamic analysis manually (i.e., debugging, patching), which in turn also gets obstructed by TADAs. In this work, we propose a Large Language Model (LLM) based workflow that can pinpoint the location of the TADA implementation in the code, to help reverse engineers place breakpoints used in debugging. Our evaluation shows that we successfully identified the locations of 87.80% known TADA implementations adopted from public repositories. In addition, we successfully pinpoint the locations of TADAs in 4 well-known malware samples that are documented in online malware analysis blogs.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05992",
        "abstract url": "https://arxiv.org/abs/2411.05992",
        "title": "Other Worlds: Using AI to Revisit Cybersyn and Rethink Economic Futures",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Neoliberalism has become orthodoxy in the present, erasing competing paradigms and alternative imaginings. Chile's radical Cybersyn project from 1971 to 1973 offers a departure point for an alternative path, albeit one that was abruptly and violently extinguished. We revisit this moment by fine-tuning AI language models on the words and writing of Salvador Allende, the Chilean President, and Stafford Beer, the cyberneticist who helped to design the project. We conduct interviews with these simulated personas, focusing on how their revolutionary ideas might be taken up in the present. We then use an AI model to generate five-year-plans from 1973 to the present, simulating an alternate history guided by Cybersyn and a progressive agenda. We frame these interventions as socialist infrastructuring that cultivates a more expansive socialist imagining. This work is not about the viability of planned economies, but about the 'inspirability' of exploring other value-systems in the present, allowing us to break out of our future-on-rails to envision alternative ways of organizing economy and society.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "11 pages, 0 figures"
    },
    {
        "paper id": "2411.05998",
        "abstract url": "https://arxiv.org/abs/2411.05998",
        "title": "Filling in Missing FX Implied Volatilities with Uncertainties: Improving VAE-Based Volatility Imputation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Missing data is a common problem in finance and often requires methods to fill in the gaps, or in other words, imputation. In this work, we focused on the imputation of missing implied volatilities for FX options. Prior work has used variational autoencoders (VAEs), a neural network-based approach, to solve this problem; however, using stronger classical baselines such as Heston with jumps can significantly outperform their results. We show that simple modifications to the architecture of the VAE lead to significant imputation performance improvements (e.g., in low missingness regimes, nearly cutting the error by half), removing the necessity of using $\u03b2$-VAEs. Further, we modify the VAE imputation algorithm in order to better handle the uncertainty in data, as well as to obtain accurate uncertainty estimates around imputed values.",
        "subjects": [
            "q-fin.ST",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "35 pages, 22 figures, 10 tables"
    },
    {
        "paper id": "2411.06011",
        "abstract url": "https://arxiv.org/abs/2411.06011",
        "title": "Exploring the Impact of Reflexivity Theory and Cognitive Social Structures on the Dynamics of Doctor-Patient Social System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Conventional economic and socio-behavioural models assume perfect symmetric access to information and rational behaviour among interacting agents in a social system. However, real-world events and observations appear to contradict such assumptions, leading to the possibility of other, more complex interaction rules existing between such agents. We investigate this possibility by creating two different models for a doctor-patient system. One retains the established assumptions, while the other incorporates principles of reflexivity theory and cognitive social structures. In addition, we utilize a microbial genetic algorithm to optimize the behaviour of the physician and patient agents in both models. The differences in results for the two models suggest that social systems may not always exhibit the behaviour or even accomplish the purpose for which they were designed and that modelling the social and cognitive influences in a social system may capture various ways a social agent balances complementary and competing information signals in making choices.",
        "subjects": [
            "cs.SI",
            "cs.NE",
            "physics.soc-ph"
        ],
        "comment": "The related code can be found in this repository: https://github.com/Al-Saqib/Cognitive-Social-System"
    },
    {
        "paper id": "2411.06018",
        "abstract url": "https://arxiv.org/abs/2411.06018",
        "title": "A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Large language models (LLMs), with demonstrated reasoning abilities across multiple domains, are largely underexplored for time-series reasoning (TsR), which is ubiquitous in the real world. In this work, we propose TimerBed, the first comprehensive testbed for evaluating LLMs' TsR performance. Specifically, TimerBed includes stratified reasoning patterns with real-world tasks, comprehensive combinations of LLMs and reasoning strategies, and various supervised models as comparison anchors. We perform extensive experiments with TimerBed, test multiple current beliefs, and verify the initial failures of LLMs in TsR, evidenced by the ineffectiveness of zero shot (ZST) and performance degradation of few shot in-context learning (ICL). Further, we identify one possible root cause: the numerical modeling of data. To address this, we propose a prompt-based solution VL-Time, using visualization-modeled data and language-guided reasoning. Experimental results demonstrate that Vl-Time enables multimodal LLMs to be non-trivial ZST and powerful ICL reasoners for time series, achieving about 140% average performance improvement and 99% average token costs reduction.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06020",
        "abstract url": "https://arxiv.org/abs/2411.06020",
        "title": "Parallel Multi-path Feed Forward Neural Networks (PMFFNN) for Long Columnar Datasets: A Novel Approach to Complexity Reduction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional Feed-Forward Neural Networks (FFNN) and one-dimensional Convolutional Neural Networks (1D CNN) often encounter difficulties when dealing with long, columnar datasets that contain numerous features. The challenge arises from two primary factors: the large volume of data and the potential absence of meaningful relationships between features. In conventional training, large datasets can overwhelm the model, causing significant portions of the input to remain underutilized. As a result, the model may fail to capture the critical information necessary for effective learning, which leads to diminished performance. To overcome these limitations, we introduce a novel architecture called Parallel Multi-path Feed Forward Neural Networks (PMFFNN). Our approach leverages multiple parallel pathways to process distinct subsets of columns from the input dataset. By doing so, the architecture ensures that each subset of features receives focused attention, which is often neglected in traditional models. This approach maximizes the utilization of feature diversity, ensuring that no critical data sections are overlooked during training. Our architecture offers two key advantages. First, it allows for more effective handling of long, columnar data by distributing the learning task across parallel paths. Second, it reduces the complexity of the model by narrowing the feature scope in each path, which leads to faster training times and improved resource efficiency. The empirical results indicate that PMFFNN outperforms traditional FFNNs and 1D CNNs, providing an optimized solution for managing large-scale data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06040",
        "abstract url": "https://arxiv.org/abs/2411.06040",
        "title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Improving generalization and achieving highly predictive, robust machine learning models necessitates learning the underlying causal structure of the variables of interest. A prominent and effective method for this is learning invariant predictors across multiple environments. In this work, we introduce a simple yet powerful approach, CGLearn, which relies on the agreement of gradients across various environments. This agreement serves as a powerful indication of reliable features, while disagreement suggests less reliability due to potential differences in underlying causal mechanisms. Our proposed method demonstrates superior performance compared to state-of-the-art methods in both linear and nonlinear settings across various regression and classification tasks. CGLearn shows robust applicability even in the absence of separate environments by exploiting invariance across different subsamples of observational data. Comprehensive experiments on both synthetic and real-world datasets highlight its effectiveness in diverse scenarios. Our findings underscore the importance of leveraging gradient agreement for learning causal invariance, providing a significant step forward in the field of robust machine learning. The source code of the linear and nonlinear implementation of CGLearn is open-source and available at: https://github.com/hasanjawad001/CGLearn.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "9 pages, 3 figures"
    },
    {
        "paper id": "2411.06056",
        "abstract url": "https://arxiv.org/abs/2411.06056",
        "title": "Learning Mixtures of Experts with EM",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mixtures of Experts (MoE) are Machine Learning models that involve partitioning the input space, with a separate \"expert\" model trained on each partition. Recently, MoE have become popular as components in today's large language models as a means to reduce training and inference costs. There, the partitioning function and the experts are both learnt jointly via gradient descent on the log-likelihood. In this paper we focus on studying the efficiency of the Expectation Maximization (EM) algorithm for the training of MoE models. We first rigorously analyze EM for the cases of linear or logistic experts, where we show that EM is equivalent to Mirror Descent with unit step size and a Kullback-Leibler Divergence regularizer. This perspective allows us to derive new convergence results and identify conditions for local linear convergence based on the signal-to-noise ratio (SNR). Experiments on synthetic and (small-scale) real-world data show that EM outperforms the gradient descent algorithm both in terms of convergence rate and the achieved accuracy.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06060",
        "abstract url": "https://arxiv.org/abs/2411.06060",
        "title": "Wild Narratives: Exploring the Effects of Animal Chatbots on Empathy and Positive Attitudes toward Animals",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Rises in the number of animal abuse cases are reported around the world. While chatbots have been effective in influencing their users' perceptions and behaviors, little if any research has hitherto explored the design of chatbots that embody animal identities for the purpose of eliciting empathy toward animals. We therefore conducted a mixed-methods experiment to investigate how specific design cues in such chatbots can shape their users' perceptions of both the chatbots' identities and the type of animal they represent. Our findings indicate that such chatbots can significantly increase empathy, improve attitudes, and promote prosocial behavioral intentions toward animals, particularly when they incorporate emotional verbal expressions and authentic details of such animals' lives. These results expand our understanding of chatbots with non-human identities and highlight their potential for use in conservation initiatives, suggesting a promising avenue whereby technology could foster a more informed and empathetic society.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06066",
        "abstract url": "https://arxiv.org/abs/2411.06066",
        "title": "Diversity and Inclusion in AI for Recruitment: Lessons from Industry Workshop",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) systems for online recruitment markets have the potential to significantly enhance the efficiency and effectiveness of job placements and even promote fairness or inclusive hiring practices. Neglecting Diversity and Inclusion (D&I) in these systems, however, can perpetuate biases, leading to unfair hiring practices and decreased workplace diversity, while exposing organisations to legal and reputational risks. Despite the acknowledged importance of D&I in AI, there is a gap in research on effectively implementing D&I guidelines in real-world recruitment systems. Challenges include a lack of awareness and framework for operationalising D&I in a cost-effective, context-sensitive manner. This study aims to investigate the practical application of D&I guidelines in AI-driven online job-seeking systems, specifically exploring how these principles can be operationalised to create more inclusive recruitment processes. We conducted a co-design workshop with a large multinational recruitment company focusing on two AI-driven recruitment use cases. User stories and personas were applied to evaluate the impacts of AI on diverse stakeholders. Follow-up interviews were conducted to assess the workshop's long-term effects on participants' awareness and application of D&I principles. The co-design workshop successfully increased participants' understanding of D&I in AI. However, translating awareness into operational practice posed challenges, particularly in balancing D&I with business goals. The results suggest developing tailored D&I guidelines and ongoing support to ensure the effective adoption of inclusive AI practices.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05335",
        "abstract url": "https://arxiv.org/abs/2411.05335",
        "title": "A Quality-Centric Framework for Generic Deepfake Detection",
        "rating": "0",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper addresses the generalization issue in deepfake detection by harnessing forgery quality in training data. Generally, the forgery quality of different deepfakes varies: some have easily recognizable forgery clues, while others are highly realistic. Existing works often train detectors on a mix of deepfakes with varying forgery qualities, potentially leading detectors to short-cut the easy-to-spot artifacts from low-quality forgery samples, thereby hurting generalization performance. To tackle this issue, we propose a novel quality-centric framework for generic deepfake detection, which is composed of a Quality Evaluator, a low-quality data enhancement module, and a learning pacing strategy that explicitly incorporates forgery quality into the training process. The framework is inspired by curriculum learning, which is designed to gradually enable the detector to learn more challenging deepfake samples, starting with easier samples and progressing to more realistic ones. We employ both static and dynamic assessments to assess the forgery quality, combining their scores to produce a final rating for each training sample. The rating score guides the selection of deepfake samples for training, with higher-rated samples having a higher probability of being chosen. Furthermore, we propose a novel frequency data augmentation method specifically designed for low-quality forgery samples, which helps to reduce obvious forgery traces and improve their overall realism. Extensive experiments show that our method can be applied in a plug-and-play manner and significantly enhance the generalization performance.",
        "subjects": [
            "cs.CV",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05345",
        "abstract url": "https://arxiv.org/abs/2411.05345",
        "title": "Reasoning Robustness of LLMs to Adversarial Typographical Errors",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning using Chain-of-Thought (CoT) prompting. However, CoT can be biased by users' instruction. In this work, we study the reasoning robustness of LLMs to typographical errors, which can naturally occur in users' queries. We design an Adversarial Typo Attack ($\\texttt{ATA}$) algorithm that iteratively samples typos for words that are important to the query and selects the edit that is most likely to succeed in attacking. It shows that LLMs are sensitive to minimal adversarial typographical changes. Notably, with 1 character edit, Mistral-7B-Instruct's accuracy drops from 43.7% to 38.6% on GSM8K, while with 8 character edits the performance further drops to 19.2%. To extend our evaluation to larger and closed-source LLMs, we develop the $\\texttt{R$^2$ATA}$ benchmark, which assesses models' $\\underline{R}$easoning $\\underline{R}$obustness to $\\underline{\\texttt{ATA}}$. It includes adversarial typographical questions derived from three widely used reasoning datasets-GSM8K, BBH, and MMLU-by applying $\\texttt{ATA}$ to open-source LLMs. $\\texttt{R$^2$ATA}$ demonstrates remarkable transferability and causes notable performance drops across multiple super large and closed-source LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05362",
        "abstract url": "https://arxiv.org/abs/2411.05362",
        "title": "From Transparent to Opaque: Rethinking Neural Implicit Surfaces with $\u03b1$-NeuS",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "radiance fields"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Traditional 3D shape reconstruction techniques from multi-view images, such as structure from motion and multi-view stereo, primarily focus on opaque surfaces. Similarly, recent advances in neural radiance fields and its variants also primarily address opaque objects, encountering difficulties with the complex lighting effects caused by transparent materials. This paper introduces $\u03b1$-NeuS, a new method for simultaneously reconstructing thin transparent objects and opaque objects based on neural implicit surfaces (NeuS). Our method leverages the observation that transparent surfaces induce local extreme values in the learned distance fields during neural volumetric rendering, contrasting with opaque surfaces that align with zero level sets. Traditional iso-surfacing algorithms such as marching cubes, which rely on fixed iso-values, are ill-suited for this data. We address this by taking the absolute value of the distance field and developing an optimization method that extracts level sets corresponding to both non-negative local minima and zero iso-values. We prove that the reconstructed surfaces are unbiased for both transparent and opaque objects. To validate our approach, we construct a benchmark that includes both real-world and synthetic scenes, demonstrating its practical utility and effectiveness. Our data and code are publicly available at https://github.com/728388808/alpha-NeuS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05419",
        "abstract url": "https://arxiv.org/abs/2411.05419",
        "title": "POC-SLT: Partial Object Completion with SDF Latent Transformers",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Signed Distance Fields",
                "SDF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D geometric shape completion hinges on representation learning and a deep understanding of geometric data. Without profound insights into the three-dimensional nature of the data, this task remains unattainable. Our work addresses this challenge of 3D shape completion given partial observations by proposing a transformer operating on the latent space representing Signed Distance Fields (SDFs). Instead of a monolithic volume, the SDF of an object is partitioned into smaller high-resolution patches leading to a sequence of latent codes. The approach relies on a smooth latent space encoding learned via a variational autoencoder (VAE), trained on millions of 3D patches. We employ an efficient masked autoencoder transformer to complete partial sequences into comprehensive shapes in latent space. Our approach is extensively evaluated on partial observations from ShapeNet and the ABC dataset where only fractions of the objects are given. The proposed POC-SLT architecture compares favorably with several baseline state-of-the-art methods, demonstrating a significant improvement in 3D shape completion, both qualitatively and quantitatively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05473",
        "abstract url": "https://arxiv.org/abs/2411.05473",
        "title": "Improving image synthesis with diffusion-negative sampling",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "For image generation with diffusion models (DMs), a negative prompt n can be used to complement the text prompt p, helping define properties not desired in the synthesized image. While this improves prompt adherence and image quality, finding good negative prompts is challenging. We argue that this is due to a semantic gap between humans and DMs, which makes good negative prompts for DMs appear unintuitive to humans. To bridge this gap, we propose a new diffusion-negative prompting (DNP) strategy. DNP is based on a new procedure to sample images that are least compliant with p under the distribution of the DM, denoted as diffusion-negative sampling (DNS). Given p, one such image is sampled, which is then translated into natural language by the user or a captioning model, to produce the negative prompt n*. The pair (p, n*) is finally used to prompt the DM. DNS is straightforward to implement and requires no training. Experiments and human evaluations show that DNP performs well both quantitatively and qualitatively and can be easily combined with several DM variants.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05479",
        "abstract url": "https://arxiv.org/abs/2411.05479",
        "title": "EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums",
        "rating": "0",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.SI",
                "cs.CL"
            ]
        ],
        "abstract": "Underground forums serve as hubs for cybercriminal activities, offering a space for anonymity and evasion of conventional online oversight. In these hidden communities, malicious actors collaborate to exchange illicit knowledge, tools, and tactics, driving a range of cyber threats from hacking techniques to the sale of stolen data, malware, and zero-day exploits. Identifying the key instigators (i.e., key hackers), behind these operations is essential but remains a complex challenge. This paper presents a novel method called EUREKHA (Enhancing User Representation for Key Hacker Identification in Underground Forums), designed to identify these key hackers by modeling each user as a textual sequence. This sequence is processed through a large language model (LLM) for domain-specific adaptation, with LLMs acting as feature extractors. These extracted features are then fed into a Graph Neural Network (GNN) to model user structural relationships, significantly improving identification accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder Representations from Transformers Topic Modeling) to extract personalized topics from user-generated content, enabling multiple textual representations per user and optimizing the selection of the most representative sequence. Our study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in identifying key hackers. Additionally, when combined with GNNs, our model achieves significant improvements, resulting in approximately 6% and 10% increases in accuracy and F1-score, respectively, over existing methods. EUREKHA was tested on the Hack-Forums dataset, and we provide open-source access to our code.",
        "subjects": [
            "cs.CR",
            "cs.CL",
            "cs.SI"
        ],
        "comment": "Accepted at IEEE Trustcom 2024"
    },
    {
        "paper id": "2411.05524",
        "abstract url": "https://arxiv.org/abs/2411.05524",
        "title": "Alignment of 3D woodblock geometrical models and 2D orthographic projection image",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The accurate alignment of 3D woodblock geometrical models with 2D orthographic projection images presents a significant challenge in the digital preservation of Vietnamese cultural heritage. This paper proposes a unified image processing algorithm to address this issue, enhancing the registration quality between 3D woodblock models and their 2D representations. The method includes determining the plane of the 3D character model, establishing a transformation matrix to align this plane with the 2D printed image plane, and creating a parallel-projected depth map for precise alignment. This process minimizes disocclusions and ensures that character shapes and strokes are correctly positioned. Experimental results highlight the importance of structure-based comparisons to optimize alignment for large-scale Han-Nom character datasets. The proposed approach, combining density-based and structure-based methods, demonstrates improved registration performance, offering an effective normalization scheme for digital heritage preservation.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05544",
        "abstract url": "https://arxiv.org/abs/2411.05544",
        "title": "Towards Lifelong Few-Shot Customization of Text-to-Image Diffusion",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Lifelong few-shot customization for text-to-image diffusion aims to continually generalize existing models for new tasks with minimal data while preserving old knowledge. Current customization diffusion models excel in few-shot tasks but struggle with catastrophic forgetting problems in lifelong generations. In this study, we identify and categorize the catastrophic forgetting problems into two folds: relevant concepts forgetting and previous concepts forgetting. To address these challenges, we first devise a data-free knowledge distillation strategy to tackle relevant concepts forgetting. Unlike existing methods that rely on additional real data or offline replay of original concept data, our approach enables on-the-fly knowledge distillation to retain the previous concepts while learning new ones, without accessing any previous data. Second, we develop an In-Context Generation (ICGen) paradigm that allows the diffusion model to be conditioned upon the input vision context, which facilitates the few-shot generation and mitigates the issue of previous concepts forgetting. Extensive experiments show that the proposed Lifelong Few-Shot Diffusion (LFS-Diffusion) method can produce high-quality and accurate images while maintaining previously learned knowledge.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05593",
        "abstract url": "https://arxiv.org/abs/2411.05593",
        "title": "Evaluating and Adapting Large Language Models to Represent Folktales in Low-Resource Languages",
        "rating": "0",
        "keywords": [
            [
                "SVM"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Folktales are a rich resource of knowledge about the society and culture of a civilisation. Digital folklore research aims to use automated techniques to better understand these folktales, and it relies on abstract representations of the textual data. Although a number of large language models (LLMs) claim to be able to represent low-resource langauges such as Irish and Gaelic, we present two classification tasks to explore how useful these representations are, and three adaptations to improve the performance of these models. We find that adapting the models to work with longer sequences, and continuing pre-training on the domain of folktales improves classification performance, although these findings are tempered by the impressive performance of a baseline SVM with non-contextual features.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05609",
        "abstract url": "https://arxiv.org/abs/2411.05609",
        "title": "A Two-Step Concept-Based Approach for Enhanced Interpretability and Trust in Skin Lesion Diagnosis",
        "rating": "0",
        "keywords": [
            [
                "Vision Language",
                "VLM"
            ],
            [
                "Diagnosis",
                "disease",
                "clinical",
                "Lesion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The main challenges hindering the adoption of deep learning-based systems in clinical settings are the scarcity of annotated data and the lack of interpretability and trust in these systems. Concept Bottleneck Models (CBMs) offer inherent interpretability by constraining the final disease prediction on a set of human-understandable concepts. However, this inherent interpretability comes at the cost of greater annotation burden. Additionally, adding new concepts requires retraining the entire system. In this work, we introduce a novel two-step methodology that addresses both of these challenges. By simulating the two stages of a CBM, we utilize a pretrained Vision Language Model (VLM) to automatically predict clinical concepts, and a Large Language Model (LLM) to generate disease diagnoses based on the predicted concepts. We validate our approach on three skin lesion datasets, demonstrating that it outperforms traditional CBMs and state-of-the-art explainable methods, all without requiring any training and utilizing only a few annotated examples. The code is available at https://github.com/CristianoPatricio/2-step-concept-based-skin-diagnosis.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Preprint submitted for review"
    },
    {
        "paper id": "2411.05705",
        "abstract url": "https://arxiv.org/abs/2411.05705",
        "title": "Image inpainting enhancement by replacing the original mask with a self-attended region from the input image",
        "rating": "0",
        "keywords": [
            [
                "inpainting"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Image inpainting, the process of restoring missing or corrupted regions of an image by reconstructing pixel information, has recently seen considerable advancements through deep learning-based approaches. In this paper, we introduce a novel deep learning-based pre-processing methodology for image inpainting utilizing the Vision Transformer (ViT). Our approach involves replacing masked pixel values with those generated by the ViT, leveraging diverse visual patches within the attention matrix to capture discriminative spatial features. To the best of our knowledge, this is the first instance of such a pre-processing model being proposed for image inpainting tasks. Furthermore, we show that our methodology can be effectively applied using the pre-trained ViT model with pre-defined patch size. To evaluate the generalization capability of the proposed methodology, we provide experimental results comparing our approach with four standard models across four public datasets, demonstrating the efficacy of our pre-processing technique in enhancing inpainting performance.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05706",
        "abstract url": "https://arxiv.org/abs/2411.05706",
        "title": "Image2Text2Image: A Novel Framework for Label-Free Evaluation of Image-to-Text Generation with Text-to-Image Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Evaluating the quality of automatically generated image descriptions is a complex task that requires metrics capturing various dimensions, such as grammaticality, coverage, accuracy, and truthfulness. Although human evaluation provides valuable insights, its cost and time-consuming nature pose limitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr attempt to fill this gap, but they often exhibit weak correlations with human judgment. To address this challenge, we propose a novel evaluation framework called Image2Text2Image, which leverages diffusion models, such as Stable Diffusion or DALL-E, for text-to-image generation. In the Image2Text2Image framework, an input image is first processed by a selected image captioning model, chosen for evaluation, to generate a textual description. Using this generated description, a diffusion model then creates a new image. By comparing features extracted from the original and generated images, we measure their similarity using a designated similarity metric. A high similarity score suggests that the model has produced a faithful textual description, while a low score highlights discrepancies, revealing potential weaknesses in the model's performance. Notably, our framework does not rely on human-annotated reference captions, making it a valuable tool for assessing image captioning models. Extensive experiments and human evaluations validate the efficacy of our proposed Image2Text2Image evaluation framework. The code and dataset will be published to support further research in the community.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2408.01723"
    },
    {
        "paper id": "2411.05718",
        "abstract url": "https://arxiv.org/abs/2411.05718",
        "title": "A Retrospective on the Robot Air Hockey Challenge: Benchmarking Robust, Reliable, and Safe Learning Techniques for Real-world Robotics",
        "rating": "0",
        "keywords": [
            [
                "Robotics",
                "Robot"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Machine learning methods have a groundbreaking impact in many application domains, but their application on real robotic platforms is still limited. Despite the many challenges associated with combining machine learning technology with robotics, robot learning remains one of the most promising directions for enhancing the capabilities of robots. When deploying learning-based approaches on real robots, extra effort is required to address the challenges posed by various real-world factors. To investigate the key factors influencing real-world deployment and to encourage original solutions from different researchers, we organized the Robot Air Hockey Challenge at the NeurIPS 2023 conference. We selected the air hockey task as a benchmark, encompassing low-level robotics problems and high-level tactics. Different from other machine learning-centric benchmarks, participants need to tackle practical challenges in robotics, such as the sim-to-real gap, low-level control issues, safety problems, real-time requirements, and the limited availability of real-world data. Furthermore, we focus on a dynamic environment, removing the typical assumption of quasi-static motions of other real-world benchmarks. The competition's results show that solutions combining learning-based approaches with prior knowledge outperform those relying solely on data when real-world deployment is challenging. Our ablation study reveals which real-world factors may be overlooked when building a learning-based solution. The successful real-world air hockey deployment of best-performing agents sets the foundation for future competitions and follow-up research directions.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accept at NeurIPS 2024 Dataset and Benchmark Track"
    },
    {
        "paper id": "2411.05731",
        "abstract url": "https://arxiv.org/abs/2411.05731",
        "title": "PEP-GS: Perceptually-Enhanced Precise Structured 3D Gaussians for View-Adaptive Rendering",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in structured 3D Gaussians for view-adaptive rendering, particularly through methods like Scaffold-GS, have demonstrated promising results in neural scene representation. However, existing approaches still face challenges in perceptual consistency and precise view-dependent effects. We present PEP-GS, a novel framework that enhances structured 3D Gaussians through three key innovations: (1) a Local-Enhanced Multi-head Self-Attention (LEMSA) mechanism that replaces spherical harmonics for more accurate view-dependent color decoding, and (2) Kolmogorov-Arnold Networks (KAN) that optimize Gaussian opacity and covariance functions for enhanced interpretability and splatting precision. (3) a Neural Laplacian Pyramid Decomposition (NLPD) that improves perceptual similarity across views. Our comprehensive evaluation across multiple datasets indicates that, compared to the current state-of-the-art methods, these improvements are particularly evident in challenging scenarios such as view-dependent effects, specular reflections, fine-scale details and false geometry generation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05777",
        "abstract url": "https://arxiv.org/abs/2411.05777",
        "title": "Quantitative Assessment of Intersectional Empathetic Bias and Understanding",
        "rating": "0",
        "keywords": [
            [
                "social biases"
            ],
            [
                "psychological"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "A growing amount of literature critiques the current operationalizations of empathy based on loose definitions of the construct. Such definitions negatively affect dataset quality, model robustness, and evaluation reliability. We propose an empathy evaluation framework that operationalizes empathy close to its psychological origins. The framework measures the variance in responses of LLMs to prompts using existing metrics for empathy and emotional valence. The variance is introduced through the controlled generation of the prompts by varying social biases affecting context understanding, thus impacting empathetic understanding. The control over generation ensures high theoretical validity of the constructs in the prompt dataset. Also, it makes high-quality translation, especially into languages that currently have little-to-no way of evaluating empathy or bias, such as the Slavonic family, more manageable. Using chosen LLMs and various prompt types, we demonstrate the empathy evaluation with the framework, including multiple-choice answers and free generation. The variance in our initial evaluation sample is small and we were unable to measure convincing differences between the empathetic understanding in contexts given by different social groups. However, the results are promising because the models showed significant alterations their reasoning chains needed to capture the relatively subtle changes in the prompts. This provides the basis for future research into the construction of the evaluation sample and statistical methods for measuring the results.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05882",
        "abstract url": "https://arxiv.org/abs/2411.05882",
        "title": "When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Contemporary machine learning models, such as language models, are powerful, but come with immense resource requirements both at training and inference time. It has been shown that decoder-only language models can be trained to a competitive state with ternary weights (1.58 bits per weight), facilitating efficient inference. Here, we start our exploration with non-transformer model architectures, investigating 1.58-bit training for multi-layer perceptrons and graph neural networks. Then, we explore 1.58-bit training in other transformer-based language models, namely encoder-only and encoder-decoder models. Our results show that in all of these settings, 1.58-bit training is on par with or sometimes even better than the standard 32/16-bit models.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "10 pages, 2 tables, 6 figures"
    },
    {
        "paper id": "2411.05884",
        "abstract url": "https://arxiv.org/abs/2411.05884",
        "title": "Untrained Perceptual Loss for image denoising of line-like structures in MR images",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "voxel",
                "depth"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In the acquisition of Magnetic Resonance (MR) images shorter scan times lead to higher image noise. Therefore, automatic image denoising using deep learning methods is of high interest. MR images containing line-like structures such as roots or vessels yield special characteristics as they display connected structures and yield sparse information. For this kind of data, it is important to consider voxel neighborhoods when training a denoising network. In this paper, we translate the Perceptual Loss to 3D data by comparing feature maps of untrained networks in the loss function as done previously for 2D data. We tested the performance of untrained Perceptual Loss (uPL) on 3D image denoising of MR images displaying brain vessels (MR angiograms - MRA) and images of plant roots in soil. We investigate the impact of various uPL characteristics such as weight initialization, network depth, kernel size, and pooling operations on the results. We tested the performance of the uPL loss on four Rician noise levels using evaluation metrics such as the Structural Similarity Index Metric (SSIM). We observe, that our uPL outperforms conventional loss functions such as the L1 loss or a loss based on the Structural Similarity Index Metric (SSIM). The uPL network's initialization is not important, while network depth and pooling operations impact denoising performance. E.g. for both datasets a network with five convolutional layers led to the best performance while a network with more layers led to a performance drop. We also find that small uPL networks led to better or comparable results than using large networks such as VGG. We observe superior performance of our loss for both datasets, all noise levels, and three network architectures. In conclusion, for images containing line-like structures, uPL is an alternative to other loss functions for 3D image denoising.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05936",
        "abstract url": "https://arxiv.org/abs/2411.05936",
        "title": "Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The growth of digital documents presents significant challenges in efficient management and knowledge extraction. Traditional methods often struggle with complex documents, leading to issues such as hallucinations and high latency in responses from Large Language Models (LLMs). ZeroG, an innovative approach, significantly mitigates these challenges by leveraging knowledge distillation and prompt tuning to enhance model performance. ZeroG utilizes a smaller model that replicates the behavior of a larger teacher model, ensuring contextually relevant and grounded responses, by employing a black-box distillation approach, it creates a distilled dataset without relying on intermediate features, optimizing computational efficiency. This method significantly enhances accuracy and reduces response times, providing a balanced solution for modern document management. Incorporating advanced techniques for document ingestion and metadata utilization, ZeroG improves the accuracy of question-and-answer systems. The integration of graph databases and robust metadata management further streamlines information retrieval, allowing for precise and context-aware responses. By transforming how organizations interact with complex data, ZeroG enhances productivity and user experience, offering a scalable solution for the growing demands of digital document management.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL",
            "cs.IT"
        ],
        "comment": "10 pages, 4 figures, 1 table"
    },
    {
        "paper id": "2411.05943",
        "abstract url": "https://arxiv.org/abs/2411.05943",
        "title": "Quantifying artificial intelligence through algebraic generalization",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid development of modern artificial intelligence (AI) systems has created an urgent need for their scientific quantification. While their fluency across a variety of domains is impressive, modern AI systems fall short on tests requiring symbolic processing and abstraction - a glaring limitation given the necessity for interpretable and reliable technology. Despite a surge of reasoning benchmarks emerging from the academic community, no comprehensive and theoretically-motivated framework exists to quantify reasoning (and more generally, symbolic ability) in AI systems. Here, we adopt a framework from computational complexity theory to explicitly quantify symbolic generalization: algebraic circuit complexity. Many symbolic reasoning problems can be recast as algebraic expressions. Thus, algebraic circuit complexity theory - the study of algebraic expressions as circuit models (i.e., directed acyclic graphs) - is a natural framework to study the complexity of symbolic computation. The tools of algebraic circuit complexity enable the study of generalization by defining benchmarks in terms of their complexity-theoretic properties (i.e., the difficulty of a problem). Moreover, algebraic circuits are generic mathematical objects; for a given algebraic circuit, an arbitrarily large number of samples can be generated for a specific circuit, making it an optimal testbed for the data-hungry machine learning algorithms that are used today. Here, we adopt tools from algebraic circuit complexity theory, apply it to formalize a science of symbolic generalization, and address key theoretical and empirical challenges for its successful application to AI science and its impact on the broader community.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05946",
        "abstract url": "https://arxiv.org/abs/2411.05946",
        "title": "Querying Perception Streams with Spatial Regular Expressions",
        "rating": "0",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Perception in fields like robotics, manufacturing, and data analysis generates large volumes of temporal and spatial data to effectively capture their environments. However, sorting through this data for specific scenarios is a meticulous and error-prone process, often dependent on the application, and lacks generality and reproducibility. In this work, we introduce SpREs as a novel querying language for pattern matching over perception streams containing spatial and temporal data derived from multi-modal dynamic environments. To highlight the capabilities of SpREs, we developed the STREM tool as both an offline and online pattern matching framework for perception data. We demonstrate the offline capabilities of STREM through a case study on a publicly available AV dataset (Woven Planet Perception) and its online capabilities through a case study integrating STREM in ROS with the CARLA simulator. We also conduct performance benchmark experiments on various SpRE queries. Using our matching framework, we are able to find over 20,000 matches within 296 ms making STREM applicable in runtime monitoring applications.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.FL"
        ],
        "comment": "This work has been submitted to the International Journal on Software Tools for Technology Transfer"
    },
    {
        "paper id": "2411.05969",
        "abstract url": "https://arxiv.org/abs/2411.05969",
        "title": "Toward Transdisciplinary Approaches to Audio Deepfake Discernment",
        "rating": "0",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This perspective calls for scholars across disciplines to address the challenge of audio deepfake detection and discernment through an interdisciplinary lens across Artificial Intelligence methods and linguistics. With an avalanche of tools for the generation of realistic-sounding fake speech on one side, the detection of deepfakes is lagging on the other. Particularly hindering audio deepfake detection is the fact that current AI models lack a full understanding of the inherent variability of language and the complexities and uniqueness of human speech. We see the promising potential in recent transdisciplinary work that incorporates linguistic knowledge into AI approaches to provide pathways for expert-in-the-loop and to move beyond expert agnostic AI-based methods for more robust and comprehensive deepfake detection.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05985",
        "abstract url": "https://arxiv.org/abs/2411.05985",
        "title": "Emotional Images: Assessing Emotions in Images and Potential Biases in Generative Models",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "psychological"
            ],
            [
                "cs.CY",
                "cs.CV"
            ]
        ],
        "abstract": "This paper examines potential biases and inconsistencies in emotional evocation of images produced by generative artificial intelligence (AI) models and their potential bias toward negative emotions. In particular, we assess this bias by comparing the emotions evoked by an AI-produced image to the emotions evoked by prompts used to create those images. As a first step, the study evaluates three approaches for identifying emotions in images -- traditional supervised learning, zero-shot learning with vision-language models, and cross-modal auto-captioning -- using EmoSet, a large dataset of image-emotion annotations that categorizes images across eight emotional types. Results show fine-tuned models, particularly Google's Vision Transformer (ViT), significantly outperform zero-shot and caption-based methods in recognizing emotions in images. For a cross-modality comparison, we then analyze the differences between emotions in text prompts -- via existing text-based emotion-recognition models -- and the emotions evoked in the resulting images. Findings indicate that AI-generated images frequently lean toward negative emotional content, regardless of the original prompt. This emotional skew in generative models could amplify negative affective content in digital spaces, perpetuating its prevalence and impact. The study advocates for a multidisciplinary approach to better align AI emotion recognition with psychological insights and address potential biases in generative AI outputs across digital media.",
        "subjects": [
            "cs.CY",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06019",
        "abstract url": "https://arxiv.org/abs/2411.06019",
        "title": "GaussianSpa: An \"Optimizing-Sparsifying\" Simplification Framework for Compact and High-Quality 3D Gaussian Splatting",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting (3DGS) has emerged as a mainstream for novel view synthesis, leveraging continuous aggregations of Gaussian functions to model scene geometry. However, 3DGS suffers from substantial memory requirements to store the multitude of Gaussians, hindering its practicality. To address this challenge, we introduce GaussianSpa, an optimization-based simplification framework for compact and high-quality 3DGS. Specifically, we formulate the simplification as an optimization problem associated with the 3DGS training. Correspondingly, we propose an efficient \"optimizing-sparsifying\" solution that alternately solves two independent sub-problems, gradually imposing strong sparsity onto the Gaussians in the training process. Our comprehensive evaluations on various datasets show the superiority of GaussianSpa over existing state-of-the-art approaches. Notably, GaussianSpa achieves an average PSNR improvement of 0.9 dB on the real-world Deep Blending dataset with 10$\\times$ fewer Gaussians compared to the vanilla 3DGS. Our project page is available at https://gaussianspa.github.io/.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "Project page at https://gaussianspa.github.io/"
    },
    {
        "paper id": "2411.06023",
        "abstract url": "https://arxiv.org/abs/2411.06023",
        "title": "Dynamic Textual Prompt For Rehearsal-free Lifelong Person Re-identification",
        "rating": "0",
        "keywords": [
            [
                "Re-identification"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Lifelong person re-identification attempts to recognize people across cameras and integrate new knowledge from continuous data streams. Key challenges involve addressing catastrophic forgetting caused by parameter updating and domain shift, and maintaining performance in seen and unseen domains. Many previous works rely on data memories to retain prior samples. However, the amount of retained data increases linearly with the number of training domains, leading to continually increasing memory consumption. Additionally, these methods may suffer significant performance degradation when data preservation is prohibited due to privacy concerns. To address these limitations, we propose using textual descriptions as guidance to encourage the ReID model to learn cross-domain invariant features without retaining samples. The key insight is that natural language can describe pedestrian instances with an invariant style, suggesting a shared textual space for any pedestrian images. By leveraging this shared textual space as an anchor, we can prompt the ReID model to embed images from various domains into a unified semantic space, thereby alleviating catastrophic forgetting caused by domain shifts. To achieve this, we introduce a task-driven dynamic textual prompt framework in this paper. This model features a dynamic prompt fusion module, which adaptively constructs and fuses two different textual prompts as anchors. This effectively guides the ReID model to embed images into a unified semantic space. Additionally, we design a text-visual feature alignment module to learn a more precise mapping between fine-grained visual and textual features. We also developed a learnable knowledge distillation module that allows our model to dynamically balance retaining existing knowledge with acquiring new knowledge. Extensive experiments demonstrate that our method outperforms SOTAs under various settings.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 6 figures"
    },
    {
        "paper id": "2411.06041",
        "abstract url": "https://arxiv.org/abs/2411.06041",
        "title": "PointCG: Self-supervised Point Cloud Learning via Joint Completion and Generation",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Point Cloud"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The core of self-supervised point cloud learning lies in setting up appropriate pretext tasks, to construct a pre-training framework that enables the encoder to perceive 3D objects effectively. In this paper, we integrate two prevalent methods, masked point modeling (MPM) and 3D-to-2D generation, as pretext tasks within a pre-training framework. We leverage the spatial awareness and precise supervision offered by these two methods to address their respective limitations: ambiguous supervision signals and insensitivity to geometric information. Specifically, the proposed framework, abbreviated as PointCG, consists of a Hidden Point Completion (HPC) module and an Arbitrary-view Image Generation (AIG) module. We first capture visible points from arbitrary views as inputs by removing hidden points. Then, HPC extracts representations of the inputs with an encoder and completes the entire shape with a decoder, while AIG is used to generate rendered images based on the visible points' representations. Extensive experiments demonstrate the superiority of the proposed method over the baselines in various downstream tasks. Our code will be made available upon acceptance.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06048",
        "abstract url": "https://arxiv.org/abs/2411.06048",
        "title": "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Large Multimodal Models (LMMs) have achieved strong performance across a range of vision and language tasks. However, their spatial reasoning capabilities are under-investigated. In this paper, we construct a novel VQA dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and reasoning capabilities. Our analyses on object-relationship and multi-hop reasoning reveal several important findings. Firstly, bounding boxes and scene graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning. Secondly, LMMs struggle more with questions posed from the human perspective than the camera perspective about the image. Thirdly, chain of thought (CoT) prompting does not improve model performance on complex multi-hop questions involving spatial relations. % Moreover, spatial reasoning steps are much less accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis on GQA-spatial reveals that LMMs are much stronger at basic object detection than complex spatial reasoning. We believe our benchmark dataset and in-depth analyses can spark further research on LMMs spatial reasoning. Spatial-MM benchmark is available at: https://github.com/FatemehShiri/Spatial-MM",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06067",
        "abstract url": "https://arxiv.org/abs/2411.06067",
        "title": "AI-Driven Stylization of 3D Environments",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this system, we discuss methods to stylize a scene of 3D primitive objects into a higher fidelity 3D scene using novel 3D representations like NeRFs and 3D Gaussian Splatting. Our approach leverages existing image stylization systems and image-to-3D generative models to create a pipeline that iteratively stylizes and composites 3D objects into scenes. We show our results on adding generated objects into a scene and discuss limitations.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.07165",
        "abstract url": "https://arxiv.org/abs/2411.07165",
        "title": "Acoustic-based 3D Human Pose Estimation Robust to Human Position",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.SD"
            ]
        ],
        "abstract": "This paper explores the problem of 3D human pose estimation from only low-level acoustic signals. The existing active acoustic sensing-based approach for 3D human pose estimation implicitly assumes that the target user is positioned along a line between loudspeakers and a microphone. Because reflection and diffraction of sound by the human body cause subtle acoustic signal changes compared to sound obstruction, the existing model degrades its accuracy significantly when subjects deviate from this line, limiting its practicality in real-world scenarios. To overcome this limitation, we propose a novel method composed of a position discriminator and reverberation-resistant model. The former predicts the standing positions of subjects and applies adversarial learning to extract subject position-invariant features. The latter utilizes acoustic signals before the estimation target time as references to enhance robustness against the variations in sound arrival times due to diffraction and reflection. We construct an acoustic pose estimation dataset that covers diverse human locations and demonstrate through experiments that our proposed method outperforms existing approaches.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "Accepted at BMVC2024"
    },
    {
        "paper id": "2411.07264",
        "abstract url": "https://arxiv.org/abs/2411.07264",
        "title": "Multi-Document Financial Question Answering using LLMs",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "We propose two new methods for multi-document financial question answering. First, a method that uses semantic tagging, and then, queries the index to get the context (RAG_SEM). And second, a Knowledge Graph (KG_RAG) based method that uses semantic tagging, and, retrieves knowledge graph triples from a graph database, as context. KG_RAG uses knowledge graphs constructed using a small model that is fine-tuned using knowledge distillation using a large teacher model. The data consists of 18 10K reports of Apple, Microsoft, Alphabet, NVIDIA, Amazon and Tesla for the years 2021, 2022 and 2023. The list of questions in the data consists of 111 complex questions including many esoteric questions that are difficult to answer and the answers are not completely obvious. As evaluation metrics, we use overall scores as well as segmented scores for measurement including the faithfulness, relevance, correctness, similarity, an LLM based overall score and the rouge scores as well as a similarity of embeddings. We find that both methods outperform plain RAG significantly. KG_RAG outperforms RAG_SEM in four out of nine metrics.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05353",
        "abstract url": "https://arxiv.org/abs/2411.05353",
        "title": "Controlling Grokking with Nonlinearity and Data Symmetry",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper demonstrates that grokking behavior in modular arithmetic with a modulus P in a neural network can be controlled by modifying the profile of the activation function as well as the depth and width of the model. Plotting the even PCA projections of the weights of the last NN layer against their odd projections further yields patterns which become significantly more uniform when the nonlinearity is increased by incrementing the number of layers. These patterns can be employed to factor P when P is nonprime. Finally, a metric for the generalization ability of the network is inferred from the entropy of the layer weights while the degree of nonlinearity is related to correlations between the local entropy of the weights of the neurons in the final layer.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "15 pages, 14 figures"
    },
    {
        "paper id": "2411.05354",
        "abstract url": "https://arxiv.org/abs/2411.05354",
        "title": "RED: Residual Estimation Diffusion for Low-Dose PET Sinogram Reconstruction",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advances in diffusion models have demonstrated exceptional performance in generative tasks across vari-ous fields. In positron emission tomography (PET), the reduction in tracer dose leads to information loss in sino-grams. Using diffusion models to reconstruct missing in-formation can improve imaging quality. Traditional diffu-sion models effectively use Gaussian noise for image re-constructions. However, in low-dose PET reconstruction, Gaussian noise can worsen the already sparse data by introducing artifacts and inconsistencies. To address this issue, we propose a diffusion model named residual esti-mation diffusion (RED). From the perspective of diffusion mechanism, RED uses the residual between sinograms to replace Gaussian noise in diffusion process, respectively sets the low-dose and full-dose sinograms as the starting point and endpoint of reconstruction. This mechanism helps preserve the original information in the low-dose sinogram, thereby enhancing reconstruction reliability. From the perspective of data consistency, RED introduces a drift correction strategy to reduce accumulated prediction errors during the reverse process. Calibrating the inter-mediate results of reverse iterations helps maintain the data consistency and enhances the stability of reconstruc-tion process. Experimental results show that RED effec-tively improves the quality of low-dose sinograms as well as the reconstruction results. The code is available at: https://github.com/yqx7150/RED.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05448",
        "abstract url": "https://arxiv.org/abs/2411.05448",
        "title": "Influencers' Reposts and Viral Diffusion: Prestige Bias in Online Communities",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Cultural evolution theory suggests that prestige bias (whereby individuals preferentially learn from prestigious figures) has played a key role in human ecological success. However, its impact within online environments remains unclear, particularly regarding whether reposts by prestigious individuals amplify diffusion more effectively than reposts by non-influential users. Here, we analyzed over 55 million posts and 520 million reposts on Twitter (currently X) to examine whether users with high influence scores (hg-index) more effectively amplified the reach of others' content. Our findings indicate that posts shared by influencers were more likely to be further shared compared to those shared by non-influencers. This effect persisted over time, especially in viral posts. Moreover, a small group of highly influential users accounted for approximately half of the information flow within repost cascades. These findings demonstrate a prestige bias in information diffusion within digital society, suggesting that cognitive biases shape content spread through reposting.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "comment": "4pages, 4Figure (+ Supplementary)"
    },
    {
        "paper id": "2411.05464",
        "abstract url": "https://arxiv.org/abs/2411.05464",
        "title": "Generalization, Expressivity, and Universality of Graph Neural Networks on Attributed Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We analyze the universality and generalization of graph neural networks (GNNs) on attributed graphs, i.e., with node attributes. To this end, we propose pseudometrics over the space of all attributed graphs that describe the fine-grained expressivity of GNNs. Namely, GNNs are both Lipschitz continuous with respect to our pseudometrics and can separate attributed graphs that are distant in the metric. Moreover, we prove that the space of all attributed graphs is relatively compact with respect to our metrics. Based on these properties, we prove a universal approximation theorem for GNNs and generalization bounds for GNNs on any data distribution of attributed graphs. The proposed metrics compute the similarity between the structures of attributed graphs via a hierarchical optimal transport between computation trees. Our work extends and unites previous approaches which either derived theory only for graphs with no attributes, derived compact metrics under which GNNs are continuous but without separation power, or derived metrics under which GNNs are continuous and separate points but the space of graphs is not relatively compact, which prevents universal approximation and generalization analysis.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05489",
        "abstract url": "https://arxiv.org/abs/2411.05489",
        "title": "Do Histopathological Foundation Models Eliminate Batch Effects? A Comparative Study",
        "rating": "-0.5",
        "keywords": [
            [
                "biomarker",
                "medical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Deep learning has led to remarkable advancements in computational histopathology, e.g., in diagnostics, biomarker prediction, and outcome prognosis. Yet, the lack of annotated data and the impact of batch effects, e.g., systematic technical data differences across hospitals, hamper model robustness and generalization. Recent histopathological foundation models -- pretrained on millions to billions of images -- have been reported to improve generalization performances on various downstream tasks. However, it has not been systematically assessed whether they fully eliminate batch effects. In this study, we empirically show that the feature embeddings of the foundation models still contain distinct hospital signatures that can lead to biased predictions and misclassifications. We further find that the signatures are not removed by stain normalization methods, dominate distances in feature space, and are evident across various principal components. Our work provides a novel perspective on the evaluation of medical foundation models, paving the way for more robust pretraining strategies and downstream predictors.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Accepted to AIM-FM Workshop @ NeurIPS'24"
    },
    {
        "paper id": "2411.05536",
        "abstract url": "https://arxiv.org/abs/2411.05536",
        "title": "Towards Active Flow Control Strategies Through Deep Reinforcement Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a deep reinforcement learning (DRL) framework for active flow control (AFC) to reduce drag in aerodynamic bodies. Tested on a 3D cylinder at Re = 100, the DRL approach achieved a 9.32% drag reduction and a 78.4% decrease in lift oscillations by learning advanced actuation strategies. The methodology integrates a CFD solver with a DRL model using an in-memory database for efficient communication between",
        "subjects": [
            "cs.LG",
            "physics.flu-dyn"
        ],
        "comment": "ECOMMAS 2024 conference proceeding paper"
    },
    {
        "paper id": "2411.05565",
        "abstract url": "https://arxiv.org/abs/2411.05565",
        "title": "Solving 7x7 Killall-Go with Seki Database",
        "rating": "-0.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Game solving is the process of finding the theoretical outcome for a game, assuming that all player choices are optimal. This paper focuses on a technique that can reduce the heuristic search space significantly for 7x7 Killall-Go. In Go and Killall-Go, live patterns are stones that are protected from opponent capture. Mutual life, also referred to as seki, is when both players' stones achieve life by sharing liberties with their opponent. Whichever player attempts to capture the opponent first will leave their own stones vulnerable. Therefore, it is critical to recognize seki patterns to avoid putting oneself in jeopardy. Recognizing seki can reduce the search depth significantly. In this paper, we enumerate all seki patterns up to a predetermined area size, then store these patterns into a seki table. This allows us to recognize seki during search, which significantly improves solving efficiency for the game of Killall-Go. Experiments show that a day-long, unsolvable position can be solved in 482 seconds with the addition of a seki table. For general positions, a 10% to 20% improvement in wall clock time and node count is observed.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted by the Computers and Games conference (CG 2024)"
    },
    {
        "paper id": "2411.05591",
        "abstract url": "https://arxiv.org/abs/2411.05591",
        "title": "Network EM Algorithm for Gaussian Mixture Model in Decentralized Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We systematically study various network Expectation-Maximization (EM) algorithms for the Gaussian mixture model within the framework of decentralized federated learning. Our theoretical investigation reveals that directly extending the classical decentralized supervised learning method to the EM algorithm exhibits poor estimation accuracy with heterogeneous data across clients and struggles to converge numerically when Gaussian components are poorly-separated. To address these issues, we propose two novel solutions. First, to handle heterogeneous data, we introduce a momentum network EM (MNEM) algorithm, which uses a momentum parameter to combine information from both the current and historical estimators. Second, to tackle the challenge of poorly-separated Gaussian components, we develop a semi-supervised MNEM (semi-MNEM) algorithm, which leverages partially labeled data. Rigorous theoretical analysis demonstrates that MNEM can achieve statistical efficiency comparable to that of the whole sample estimator when the mixture components satisfy certain separation conditions, even in heterogeneous scenarios. Moreover, the semi-MNEM estimator enhances the convergence speed of the MNEM algorithm, effectively addressing the numerical convergence challenges in poorly-separated scenarios. Extensive simulation and real data analyses are conducted to justify our theoretical findings.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05625",
        "abstract url": "https://arxiv.org/abs/2411.05625",
        "title": "Cross-validating causal discovery via Leave-One-Variable-Out",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a new approach to falsify causal discovery algorithms without ground truth, which is based on testing the causal model on a pair of variables that has been dropped when learning the causal model. To this end, we use the \"Leave-One-Variable-Out (LOVO)\" prediction where $Y$ is inferred from $X$ without any joint observations of $X$ and $Y$, given only training data from $X,Z_1,\\dots,Z_k$ and from $Z_1,\\dots,Z_k,Y$. We demonstrate that causal models on the two subsets, in the form of Acyclic Directed Mixed Graphs (ADMGs), often entail conclusions on the dependencies between $X$ and $Y$, enabling this type of prediction. The prediction error can then be estimated since the joint distribution $P(X, Y)$ is assumed to be available, and $X$ and $Y$ have only been omitted for the purpose of falsification. After presenting this graphical method, which is applicable to general causal discovery algorithms, we illustrate how to construct a LOVO predictor tailored towards algorithms relying on specific a priori assumptions, such as linear additive noise models. Simulations indicate that the LOVO prediction error is indeed correlated with the accuracy of the causal outputs, affirming the method's effectiveness.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05633",
        "abstract url": "https://arxiv.org/abs/2411.05633",
        "title": "SynDroneVision: A Synthetic Dataset for Image-Based Drone Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "Drone"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Developing robust drone detection systems is often constrained by the limited availability of large-scale annotated training data and the high costs associated with real-world data collection. However, leveraging synthetic data generated via game engine-based simulations provides a promising and cost-effective solution to overcome this issue. Therefore, we present SynDroneVision, a synthetic dataset specifically designed for RGB-based drone detection in surveillance applications. Featuring diverse backgrounds, lighting conditions, and drone models, SynDroneVision offers a comprehensive training foundation for deep learning algorithms. To evaluate the dataset's effectiveness, we perform a comparative analysis across a selection of recent YOLO detection models. Our findings demonstrate that SynDroneVision is a valuable resource for real-world data enrichment, achieving notable enhancements in model performance and robustness, while significantly reducing the time and costs of real-world data acquisition. SynDroneVision will be publicly released upon paper acceptance.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Accepted at the 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)"
    },
    {
        "paper id": "2411.05679",
        "abstract url": "https://arxiv.org/abs/2411.05679",
        "title": "Tell What You Hear From What You See -- Video to Audio Generation Through Text",
        "rating": "-0.5",
        "keywords": [
            [
                "neural codec"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "The content of visual and audio scenes is multi-faceted such that a video can be paired with various audio and vice-versa. Thereby, in video-to-audio generation task, it is imperative to introduce steering approaches for controlling the generated audio. While Video-to-Audio generation is a well-established generative task, existing methods lack such controllability. In this work, we propose VATT, a multi-modal generative framework that takes a video and an optional text prompt as input, and generates audio and optional textual description of the audio. Such a framework has two advantages: i) Video-to-Audio generation process can be refined and controlled via text which complements the context of visual information, and ii) The model can suggest what audio to generate for the video by generating audio captions. VATT consists of two key modules: VATT Converter, a LLM that is fine-tuned for instructions and includes a projection layer that maps video features to the LLM vector space; and VATT Audio, a transformer that generates audio tokens from visual frames and from optional text prompt using iterative parallel decoding. The audio tokens are converted to a waveform by pretrained neural codec. Experiments show that when VATT is compared to existing video-to-audio generation methods in objective metrics, it achieves competitive performance when the audio caption is not provided. When the audio caption is provided as a prompt, VATT achieves even more refined performance (lowest KLD score of 1.41). Furthermore, subjective studies show that VATT Audio has been chosen as preferred generated audio than audio generated by existing methods. VATT enables controllable video-to-audio generation through text as well as suggesting text prompts for videos through audio captions, unlocking novel applications such as text-guided video-to-audio generation and video-to-audio captioning.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2411.05692",
        "abstract url": "https://arxiv.org/abs/2411.05692",
        "title": "Autoregressive Adaptive Hypergraph Transformer for Skeleton-based Activity Recognition",
        "rating": "-0.5",
        "keywords": [
            [
                "Skeleton"
            ],
            [
                "Graph"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Extracting multiscale contextual information and higher-order correlations among skeleton sequences using Graph Convolutional Networks (GCNs) alone is inadequate for effective action classification. Hypergraph convolution addresses the above issues but cannot harness the long-range dependencies. Transformer proves to be effective in capturing these dependencies and making complex contextual features accessible. We propose an Autoregressive Adaptive HyperGraph Transformer (AutoregAd-HGformer) model for in-phase (autoregressive and discrete) and out-phase (adaptive) hypergraph generation. The vector quantized in-phase hypergraph equipped with powerful autoregressive learned priors produces a more robust and informative representation suitable for hyperedge formation. The out-phase hypergraph generator provides a model-agnostic hyperedge learning technique to align the attributes with input skeleton embedding. The hybrid (supervised and unsupervised) learning in AutoregAd-HGformer explores the action-dependent feature along spatial, temporal, and channel dimensions. The extensive experimental results and ablation study indicate the superiority of our model over state-of-the-art hypergraph architectures on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to WACV 2025"
    },
    {
        "paper id": "2411.05693",
        "abstract url": "https://arxiv.org/abs/2411.05693",
        "title": "YOSO: You-Only-Sample-Once via Compressed Sensing for Graph Neural Network Training",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph neural networks (GNNs) have become essential tools for analyzing non-Euclidean data across various domains. During training stage, sampling plays an important role in reducing latency by limiting the number of nodes processed, particularly in large-scale applications. However, as the demand for better prediction performance grows, existing sampling algorithms become increasingly complex, leading to significant overhead. To mitigate this, we propose YOSO (You-Only-Sample-Once), an algorithm designed to achieve efficient training while preserving prediction accuracy. YOSO introduces a compressed sensing (CS)-based sampling and reconstruction framework, where nodes are sampled once at input layer, followed by a lossless reconstruction at the output layer per epoch. By integrating the reconstruction process with the loss function of specific learning tasks, YOSO not only avoids costly computations in traditional compressed sensing (CS) methods, such as orthonormal basis calculations, but also ensures high-probability accuracy retention which equivalent to full node participation. Experimental results on node classification and link prediction demonstrate the effectiveness and efficiency of YOSO, reducing GNN training by an average of 75\\% compared to state-of-the-art methods, while maintaining accuracy on par with top-performing baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05729",
        "abstract url": "https://arxiv.org/abs/2411.05729",
        "title": "Graph-Dictionary Signal Model for Sparse Representations of Multivariate Data",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Representing and exploiting multivariate signals require capturing complex relations between variables. We define a novel Graph-Dictionary signal model, where a finite set of graphs characterizes relationships in data distribution through a weighted sum of their Laplacians. We propose a framework to infer the graph dictionary representation from observed data, along with a bilinear generalization of the primal-dual splitting algorithm to solve the learning problem. Our new formulation allows to include a priori knowledge on signal properties, as well as on underlying graphs and their coefficients. We show the capability of our method to reconstruct graphs from signals in multiple synthetic settings, where our model outperforms previous baselines. Then, we exploit graph-dictionary representations in a motor imagery decoding task on brain activity data, where we classify imagined motion better than standard methods relying on many more features.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05743",
        "abstract url": "https://arxiv.org/abs/2411.05743",
        "title": "Free Record-Level Privacy Risk Evaluation Through Artifact-Based Methods",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Membership inference attacks (MIAs) are widely used to empirically assess the privacy risks of samples used to train a target machine learning model. State-of-the-art methods however require training hundreds of shadow models, with the same size and architecture of the target model, solely to evaluate the privacy risk. While one might be able to afford this for small models, the cost often becomes prohibitive for medium and large models. We here instead propose a novel approach to identify the at-risk samples using only artifacts available during training, with little to no additional computational overhead. Our method analyzes individual per-sample loss traces and uses them to identify the vulnerable data samples. We demonstrate the effectiveness of our artifact-based approach through experiments on the CIFAR10 dataset, showing high precision in identifying vulnerable samples as determined by a SOTA shadow model-based MIA (LiRA). Impressively, our method reaches the same precision as another SOTA MIA when measured against LiRA, despite it being orders of magnitude cheaper. We then show LT-IQR to outperform alternative loss aggregation methods, perform ablation studies on hyperparameters, and validate the robustness of our method to the target metric. Finally, we study the evolution of the vulnerability score distribution throughout training as a metric for model-level risk assessment.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05780",
        "abstract url": "https://arxiv.org/abs/2411.05780",
        "title": "GazeSearch: Radiology Findings Search Benchmark",
        "rating": "-0.5",
        "keywords": [
            [
                "Medical",
                "X-ray",
                "Radiology"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Medical eye-tracking data is an important information source for understanding how radiologists visually interpret medical images. This information not only improves the accuracy of deep learning models for X-ray analysis but also their interpretability, enhancing transparency in decision-making. However, the current eye-tracking data is dispersed, unprocessed, and ambiguous, making it difficult to derive meaningful insights. Therefore, there is a need to create a new dataset with more focus and purposeful eyetracking data, improving its utility for diagnostic applications. In this work, we propose a refinement method inspired by the target-present visual search challenge: there is a specific finding and fixations are guided to locate it. After refining the existing eye-tracking datasets, we transform them into a curated visual search dataset, called GazeSearch, specifically for radiology findings, where each fixation sequence is purposefully aligned to the task of locating a particular finding. Subsequently, we introduce a scan path prediction baseline, called ChestSearch, specifically tailored to GazeSearch. Finally, we employ the newly introduced GazeSearch as a benchmark to evaluate the performance of current state-of-the-art methods, offering a comprehensive assessment for visual search in the medical imaging domain.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Aceepted WACV 2025"
    },
    {
        "paper id": "2411.05783",
        "abstract url": "https://arxiv.org/abs/2411.05783",
        "title": "ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles",
        "rating": "-0.5",
        "keywords": [
            [
                "Sign Language"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Deaf and hard-of-hearing (DHH) students face significant barriers in accessing science, technology, engineering, and mathematics (STEM) education, notably due to the scarcity of STEM resources in signed languages. To help address this, we introduce ASL STEM Wiki: a parallel corpus of 254 Wikipedia articles on STEM topics in English, interpreted into over 300 hours of American Sign Language (ASL). ASL STEM Wiki is the first continuous signing dataset focused on STEM, facilitating the development of AI resources for STEM education in ASL. We identify several use cases of ASL STEM Wiki with human-centered applications. For example, because this dataset highlights the frequent use of fingerspelling for technical concepts, which inhibits DHH students' ability to learn, we develop models to identify fingerspelled words -- which can later be used to query for appropriate ASL signs to suggest to interpreters.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.HC"
        ],
        "comment": "Accepted to EMNLP 2024"
    },
    {
        "paper id": "2411.06042",
        "abstract url": "https://arxiv.org/abs/2411.06042",
        "title": "Personalized Hierarchical Split Federated Learning in Wireless Networks",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Extreme resource constraints make large-scale machine learning (ML) with distributed clients challenging in wireless networks. On the one hand, large-scale ML requires massive information exchange between clients and server(s). On the other hand, these clients have limited battery and computation powers that are often dedicated to operational computations. Split federated learning (SFL) is emerging as a potential solution to mitigate these challenges, by splitting the ML model into client-side and server-side model blocks, where only the client-side block is trained on the client device. However, practical applications require personalized models that are suitable for the client's personal task. Motivated by this, we propose a personalized hierarchical split federated learning (PHSFL) algorithm that is specially designed to achieve better personalization performance. More specially, owing to the fact that regardless of the severity of the statistical data distributions across the clients, many of the features have similar attributes, we only train the body part of the federated learning (FL) model while keeping the (randomly initialized) classifier frozen during the training phase. We first perform extensive theoretical analysis to understand the impact of model splitting and hierarchical model aggregations on the global model. Once the global model is trained, we fine-tune each client classifier to obtain the personalized models. Our empirical findings suggest that while the globally trained model with the untrained classifier performs quite similarly to other existing solutions, the fine-tuned models show significantly improved personalized performance.",
        "subjects": [
            "cs.LG",
            "cs.NI",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06055",
        "abstract url": "https://arxiv.org/abs/2411.06055",
        "title": "Linear Spherical Sliced Optimal Transport: A Fast Metric for Comparing Spherical Data",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Efficient comparison of spherical probability distributions becomes important in fields such as computer vision, geosciences, and medicine. Sliced optimal transport distances, such as spherical and stereographic spherical sliced Wasserstein distances, have recently been developed to address this need. These methods reduce the computational burden of optimal transport by slicing hyperspheres into one-dimensional projections, i.e., lines or circles. Concurrently, linear optimal transport has been proposed to embed distributions into \\( L^2 \\) spaces, where the \\( L^2 \\) distance approximates the optimal transport distance, thereby simplifying comparisons across multiple distributions. In this work, we introduce the Linear Spherical Sliced Optimal Transport (LSSOT) framework, which utilizes slicing to embed spherical distributions into \\( L^2 \\) spaces while preserving their intrinsic geometry, offering a computationally efficient metric for spherical probability measures. We establish the metricity of LSSOT and demonstrate its superior computational efficiency in applications such as cortical surface registration, 3D point cloud interpolation via gradient flow, and shape embedding. Our results demonstrate the significant computational benefits and high accuracy of LSSOT in these applications.",
        "subjects": [
            "cs.LG",
            "math.MG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.07167",
        "abstract url": "https://arxiv.org/abs/2411.07167",
        "title": "Cascaded Dual Vision Transformer for Accurate Facial Landmark Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "Facial"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Facial landmark detection is a fundamental problem in computer vision for many downstream applications. This paper introduces a new facial landmark detector based on vision transformers, which consists of two unique designs: Dual Vision Transformer (D-ViT) and Long Skip Connections (LSC). Based on the observation that the channel dimension of feature maps essentially represents the linear bases of the heatmap space, we propose learning the interconnections between these linear bases to model the inherent geometric relations among landmarks via Channel-split ViT. We integrate such channel-split ViT into the standard vision transformer (i.e., spatial-split ViT), forming our Dual Vision Transformer to constitute the prediction blocks. We also suggest using long skip connections to deliver low-level image features to all prediction blocks, thereby preventing useful information from being discarded by intermediate supervision. Extensive experiments are conducted to evaluate the performance of our proposal on the widely used benchmarks, i.e., WFLW, COFW, and 300W, demonstrating that our model outperforms the previous SOTAs across all three benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by WACV 2025. Supplementary material is included at the end of the main paper (3 pages, 5 figures, 2 tables)"
    },
    {
        "paper id": "2411.05359",
        "abstract url": "https://arxiv.org/abs/2411.05359",
        "title": "Agricultural Landscape Understanding At Country-Scale",
        "rating": "-1",
        "keywords": [
            [
                "Agricultural"
            ],
            [
                "cs.AI",
                "cs.CY",
                "cs.CV"
            ]
        ],
        "abstract": "Agricultural landscapes are quite complex, especially in the Global South where fields are smaller, and agricultural practices are more varied. In this paper we report on our progress in digitizing the agricultural landscape (natural and man-made) in our study region of India. We use high resolution imagery and a UNet style segmentation model to generate the first of its kind national-scale multi-class panoptic segmentation output. Through this work we have been able to identify individual fields across 151.7M hectares, and delineating key features such as water resources and vegetation. We share how this output was validated by our team and externally by downstream users, including some sample use cases that can lead to targeted data driven decision making. We believe this dataset will contribute towards digitizing agriculture by generating the foundational baselayer.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CY"
        ],
        "comment": "34 pages, 7 tables, 15 figs"
    },
    {
        "paper id": "2411.05361",
        "abstract url": "https://arxiv.org/abs/2411.05361",
        "title": "Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "Multimodal foundation models, such as Gemini and ChatGPT, have revolutionized human-machine interactions by seamlessly integrating various forms of data. Developing a universal spoken language model that comprehends a wide range of natural language instructions is critical for bridging communication gaps and facilitating more intuitive interactions. However, the absence of a comprehensive evaluation benchmark poses a significant challenge. We present Dynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive evaluation of instruction-based universal speech models. Building upon the first generation, this second version incorporates 125 new tasks contributed collaboratively by the global research community, expanding the benchmark to a total of 180 tasks, making it the largest benchmark for speech and audio evaluation. While the first generation of Dynamic-SUPERB was limited to classification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation capabilities by introducing a wide array of novel and diverse tasks, including regression and sequence generation, across speech, music, and environmental audio. Evaluation results indicate that none of the models performed well universally. SALMONN-13B excelled in English ASR, while WavLLM demonstrated high accuracy in emotion recognition, but current models still require further innovations to handle a broader range of tasks. We will soon open-source all task data and the evaluation pipeline.",
        "subjects": [
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05384",
        "abstract url": "https://arxiv.org/abs/2411.05384",
        "title": "Advancing Meteorological Forecasting: AI-based Approach to Synoptic Weather Map Analysis",
        "rating": "-1",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "As global warming increases the complexity of weather patterns; the precision of weather forecasting becomes increasingly important. Our study proposes a novel preprocessing method and convolutional autoencoder model developed to improve the interpretation of synoptic weather maps. These are critical for meteorologists seeking a thorough understanding of weather conditions. This model could recognize historical synoptic weather maps that nearly match current atmospheric conditions, marking a significant step forward in modern technology in meteorological forecasting. This comprises unsupervised learning models like VQ-VQE, as well as supervised learning models like VGG16, VGG19, Xception, InceptionV3, and ResNet50 trained on the ImageNet dataset, as well as research into newer models like EfficientNet and ConvNeXt. Our findings proved that, while these models perform well in various settings, their ability to identify comparable synoptic weather maps has certain limits. Our research, motivated by the primary goal of significantly increasing meteorologists' efficiency in labor-intensive tasks, discovered that cosine similarity is the most effective metric, as determined by a combination of quantitative and qualitative assessments to accurately identify relevant historical weather patterns. This study broadens our understanding by shifting the emphasis from numerical precision to practical application, ensuring that our model is effective in theory practical, and accessible in the complex and dynamic field of meteorology.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05395",
        "abstract url": "https://arxiv.org/abs/2411.05395",
        "title": "AuthFormer: Adaptive Multimodal biometric authentication transformer for middle-aged and elderly people",
        "rating": "-1",
        "keywords": [
            [
                "biometric",
                "physiological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal biometric authentication methods address the limitations of unimodal biometric technologies in security, robustness, and user adaptability. However, most existing methods depend on fixed combinations and numbers of biometric modalities, which restricts flexibility and adaptability in real-world applications. To overcome these challenges, we propose an adaptive multimodal biometric authentication model, AuthFormer, tailored for elderly users. AuthFormer is trained on the LUTBIO multimodal biometric database, containing biometric data from elderly individuals. By incorporating a cross-attention mechanism and a Gated Residual Network (GRN), the model improves adaptability to physiological variations in elderly users. Experiments show that AuthFormer achieves an accuracy of 99.73%. Additionally, its encoder requires only two layers to perform optimally, reducing complexity compared to traditional Transformer-based models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05442",
        "abstract url": "https://arxiv.org/abs/2411.05442",
        "title": "IntellBot: Retrieval Augmented LLM Chatbot for Cyber Threat Knowledge Delivery",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "In the rapidly evolving landscape of cyber security, intelligent chatbots are gaining prominence. Artificial Intelligence, Machine Learning, and Natural Language Processing empower these chatbots to handle user inquiries and deliver threat intelligence. This helps cyber security knowledge readily available to both professionals and the public. Traditional rule-based chatbots often lack flexibility and struggle to adapt to user interactions. In contrast, Large Language Model-based chatbots offer contextually relevant information across multiple domains and adapt to evolving conversational contexts. In this work, we develop IntellBot, an advanced cyber security Chatbot built on top of cutting-edge technologies like Large Language Models and Langchain alongside a Retrieval-Augmented Generation model to deliver superior capabilities. This chatbot gathers information from diverse data sources to create a comprehensive knowledge base covering known vulnerabilities, recent cyber attacks, and emerging threats. It delivers tailored responses, serving as a primary hub for cyber security insights. By providing instant access to relevant information and resources, this IntellBot enhances threat intelligence, incident response, and overall security posture, saving time and empowering users with knowledge of cyber security best practices. Moreover, we analyzed the performance of our copilot using a two-stage evaluation strategy. We achieved BERT score above 0.8 by indirect approach and a cosine similarity score ranging from 0.8 to 1, which affirms the accuracy of our copilot. Additionally, we utilized RAGAS to evaluate the RAG model, and all evaluation metrics consistently produced scores above 0.77, highlighting the efficacy of our system.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05449",
        "abstract url": "https://arxiv.org/abs/2411.05449",
        "title": "Unmanned F/A-18 Aircraft Landing Control on Aircraft Carrier in Adverse Conditions",
        "rating": "-1",
        "keywords": [
            [
                "trajectory",
                "flight"
            ]
        ],
        "abstract": "Carrier landings are a difficult control task due to wind disturbance and a changing trajectory. Demand for carrier-based drones is increasing. A robust and accurate landing control system is crucial to meet this demand. Control performance can be improved by using observers to estimate unknown variables and disturbances for use in feedback. This paper applies a nonlinear observer to estimate the combined disturbance in the pitch dynamics of an F/A-18 during carrier landing. Additionally, controllers to regulate the velocity, rate of descent and vertical position are designed. A full model, including the nonlinear flight dynamics, controller, carrier deck motion, wind and measurement noise is modelled in software. Combined with proportional derivative control, the proposed pitch control method is shown to be very effective converging 85% faster than a PID controller. The simulations, verify that the pitch controller can quickly track a time-varying reference despite noise and disturbances.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05474",
        "abstract url": "https://arxiv.org/abs/2411.05474",
        "title": "Enhancing Robustness in Language-Driven Robotics: A Modular Approach to Failure Reduction",
        "rating": "-1",
        "keywords": [
            [
                "Robotics",
                "robot"
            ]
        ],
        "abstract": "Recent advances in large language models (LLMs) have led to significant progress in robotics, enabling embodied agents to better understand and execute open-ended tasks. However, existing approaches using LLMs face limitations in grounding their outputs within the physical environment and aligning with the capabilities of the robot. This challenge becomes even more pronounced with smaller language models, which are more computationally efficient but less robust in task planning and execution. In this paper, we present a novel modular architecture designed to enhance the robustness of LLM-driven robotics by addressing these grounding and alignment issues. We formalize the task planning problem within a goal-conditioned POMDP framework, identify key failure modes in LLM-driven planning, and propose targeted design principles to mitigate these issues. Our architecture introduces an ``expected outcomes'' module to prevent mischaracterization of subgoals and a feedback mechanism to enable real-time error recovery. Experimental results, both in simulation and on physical robots, demonstrate that our approach significantly improves task success rates for pick-and-place and manipulation tasks compared to both larger LLMs and standard baselines. Through hardware experiments, we also demonstrate how our architecture can be run efficiently and locally. This work highlights the potential of smaller, locally-executable LLMs in robotics and provides a scalable, efficient solution for robust task execution.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to ICRA 2025"
    },
    {
        "paper id": "2411.05475",
        "abstract url": "https://arxiv.org/abs/2411.05475",
        "title": "3D-Printed Dual-Polarized Magneto-Electric Dipole Antenna with Wideband High Isolation for Full-Duplex Applications",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "The paper introduces a novel dual-port dual-polarized magneto-electric dipole (MED) antenna with orthogonal Gamma and inverted-Gamma shape probes, which was fabricated by means of an additive 3D metal printing process. Electromagnetic wave simulation and RF measurement report a resonance bandwidth from 3 GHz to 4 GHz at both MED's ports with respect to a standing wave ratio of less than 2. The cross-polarization isolation (XPI) between the MED's ports was also measured to be greater than 50 dB across its entire resonance bandwidth. The paper also thoroughly examines the impact of misalignments in the polarization of the MED probes on the XPI level. The broadband resonance and excellent isolation between the MED ports make it a strong candidate for a full-duplex wireless transceiver in network infrastructure.",
        "subjects": [
            "physics.app-ph",
            "eess.SY"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.05481",
        "abstract url": "https://arxiv.org/abs/2411.05481",
        "title": "Relative Pose Estimation for Nonholonomic Robot Formation with UWB-IO Measurements",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "This article studies the problem of distributed formation control for multiple robots by using onboard ultra wide band (UWB) ranging and inertial odometer (IO) measurements. Although this problem has been widely studied, a fundamental limitation of most works is that they require each robot's pose and sensor measurements are expressed in a common reference frame. However, it is inapplicable for nonholonomic robot formations due to the practical difficulty of aligning IO measurements of individual robot in a common frame. To address this problem, firstly, a concurrent-learning based estimator is firstly proposed to achieve relative localization between neighboring robots in a local frame. Different from most relative localization methods in a global frame, both relative position and orientation in a local frame are estimated with only UWB ranging and IO measurements. Secondly, to deal with information loss caused by directed communication topology, a cooperative localization algorithm is introduced to estimate the relative pose to the leader robot. Thirdly, based on the theoretical results on relative pose estimation, a distributed formation tracking controller is proposed for nonholonomic robots. Both gazebo physical simulation and real-world experiments conducted on networked TurtleBot3 nonholonomic robots are provided to demonstrate the effectiveness of the proposed method.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "11 pages, 12 figures"
    },
    {
        "paper id": "2411.05497",
        "abstract url": "https://arxiv.org/abs/2411.05497",
        "title": "Tightly-Coupled, Speed-aided Monocular Visual-Inertial Localization in Topological Map",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "LiDAR",
                "vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper proposes a novel algorithm for vehicle speed-aided monocular visual-inertial localization using a topological map. The proposed system aims to address the limitations of existing methods that rely heavily on expensive sensors like GPS and LiDAR by leveraging relatively inexpensive camera-based pose estimation. The topological map is generated offline from LiDAR point clouds and includes depth images, intensity images, and corresponding camera poses. This map is then used for real-time localization through correspondence matching between current camera images and the stored topological images. The system employs an Iterated Error State Kalman Filter (IESKF) for optimized pose estimation, incorporating correspondence among images and vehicle speed measurements to enhance accuracy. Experimental results using both open dataset and our collected data in challenging scenario, such as tunnel, demonstrate the proposed algorithm's superior performance in topological map generation and localization tasks.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05514",
        "abstract url": "https://arxiv.org/abs/2411.05514",
        "title": "Towards Scalable Foundation Models for Digital Dermatology",
        "rating": "-1",
        "keywords": [
            [
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The growing demand for accurate and equitable AI models in digital dermatology faces a significant challenge: the lack of diverse, high-quality labeled data. In this work, we investigate the potential of domain-specific foundation models for dermatology in addressing this challenge. We utilize self-supervised learning (SSL) techniques to pre-train models on a dataset of over 240,000 dermatological images from public and private collections. Our study considers several SSL methods and compares the resulting foundation models against domain-agnostic models like those pre-trained on ImageNet and state-of-the-art models such as MONET across 12 downstream tasks. Unlike previous research, we emphasize the development of smaller models that are more suitable for resource-limited clinical settings, facilitating easier adaptation to a broad range of use cases. Results show that models pre-trained in this work not only outperform general-purpose models but also approach the performance of models 50 times larger on clinically relevant diagnostic tasks. To promote further research in this direction, we publicly release both the training code and the foundation models, which can benefit clinicians in dermatological applications.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Findings paper presented at Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages"
    },
    {
        "paper id": "2411.05548",
        "abstract url": "https://arxiv.org/abs/2411.05548",
        "title": "Equivariant IMU Preintegration with Biases: an Inhomogeneous Galilean Group Approach",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ]
        ],
        "abstract": "This letter proposes a new approach for Inertial Measurement Unit (IMU) preintegration, a fundamental building block that can be leveraged in different optimization-based Inertial Navigation System (INS) localization solutions. Inspired by recent advancements in equivariant theory applied to biased INSs, we derive a discrete-time formulation of the IMU preintegration on $\\mathbf{G}(3) \\ltimes \\mathfrak{g}(3)$, the tangent group of the inhomogeneous Galilean group $\\mathbf{G}(3)$. We define a novel preintegration error that geometrically couples the navigation states and the bias leading to lower linearization error. Our method improves in consistency compared to existing preintegration approaches which treat IMU biases as a separate state-space. Extensive validation against state-of-the-art methods, both in simulation and with real-world IMU data, implementation in the Lie++ library, and open-sourcing of the code are provided.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05549",
        "abstract url": "https://arxiv.org/abs/2411.05549",
        "title": "Streaming Network for Continual Learning of Object Relocations under Household Context Drifts",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "In most applications, robots need to adapt to new environments and be multi-functional without forgetting previous information. This requirement gains further importance in real-world scenarios where robots operate in coexistence with humans. In these complex environments, human actions inevitably lead to changes, requiring robots to adapt accordingly. To effectively address these dynamics, the concept of continual learning proves essential. It not only enables learning models to integrate new knowledge while preserving existing information but also facilitates the acquisition of insights from diverse contexts. This aspect is particularly relevant to the issue of context-switching, where robots must navigate and adapt to changing situational dynamics. Our approach introduces a novel approach to effectively tackle the problem of context drifts by designing a Streaming Graph Neural Network that incorporates both regularization and rehearsal techniques. Our Continual\\_GTM model enables us to retain previous knowledge from different contexts, and it is more effective than traditional fine-tuning approaches. We evaluated the efficacy of Continual\\_GTM in predicting human routines within household environments, leveraging spatio-temporal object dynamics across diverse scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05569",
        "abstract url": "https://arxiv.org/abs/2411.05569",
        "title": "The Framework of NAVIS: Navigating Virtual Spaces with Immersive Scooters",
        "rating": "-1",
        "keywords": [
            [
                "navigation"
            ]
        ],
        "abstract": "Virtual reality (VR) environments have greatly expanded opportunities for immersive exploration, yet physically navigating these digital spaces remains a significant challenge. In this paper, we present the conceptual framework of NAVIS (Navigating Virtual Spaces with Immersive Scooters), a novel system that utilizes a scooter-based interface to enhance both navigation and interaction within virtual environments. NAVIS combines real-time physical mobility, haptic feedback, and CAVE-like (Cave Automatic Virtual Environment) technology to create a realistic sense of travel and movement, improving both spatial awareness and the overall immersive experience. By offering a more natural and physically engaging method of exploration, NAVIS addresses key limitations found in traditional VR locomotion techniques, such as teleportation or joystick control, which can detract from immersion and realism. This approach highlights the potential of combining physical movement with virtual environments to provide a more intuitive and enjoyable experience for users, opening up new possibilities for applications in gaming, education, and beyond.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05638",
        "abstract url": "https://arxiv.org/abs/2411.05638",
        "title": "Impact of Fake News on Social Media Towards Public Users of Different Age Groups",
        "rating": "-1",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "deepfake"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study examines how fake news affects social media users across a range of age groups and how machine learning (ML) and artificial intelligence (AI) can help reduce the spread of false information. The paper evaluates various machine learning models for their efficacy in identifying and categorizing fake news and examines current trends in the spread of fake news, including deepfake technology. The study assesses four models using a Kaggle dataset: Random Forest, Support Vector Machine (SVM), Neural Networks, and Logistic Regression. The results show that SVM and neural networks perform better than other models, with accuracies of 93.29% and 93.69%, respectively. The study also emphasises how people in the elder age group diminished capacity for critical analysis of news content makes them more susceptible to disinformation. Natural language processing (NLP) and deep learning approaches have the potential to improve the accuracy of false news detection. Biases in AI and ML models and difficulties in identifying information generated by AI continue to be major problems in spite of the developments. The study recommends that datasets be expanded to encompass a wider range of languages and that detection algorithms be continuously improved to keep up with the latest advancements in disinformation tactics. In order to combat fake news and promote an informed and resilient society, this study emphasizes the value of cooperative efforts between AI researchers, social media platforms, and governments.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05658",
        "abstract url": "https://arxiv.org/abs/2411.05658",
        "title": "Towards a Re-evaluation of Data Forging Attacks in Practice",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Data forging attacks provide counterfactual proof that a model was trained on a given dataset, when in fact, it was trained on another. These attacks work by forging (replacing) mini-batches with ones containing distinct training examples that produce nearly identical gradients. Data forging appears to break any potential avenues for data governance, as adversarial model owners may forge their training set from a dataset that is not compliant to one that is. Given these serious implications on data auditing and compliance, we critically analyse data forging from both a practical and theoretical point of view, finding that a key practical limitation of current attack methods makes them easily detectable by a verifier; namely that they cannot produce sufficiently identical gradients. Theoretically, we analyse the question of whether two distinct mini-batches can produce the same gradient. Generally, we find that while there may exist an infinite number of distinct mini-batches with real-valued training examples and labels that produce the same gradient, finding those that are within the allowed domain e.g. pixel values between 0-255 and one hot labels is a non trivial task. Our results call for the reevaluation of the strength of existing attacks, and for additional research into successful data forging, given the serious consequences it may have on machine learning and privacy.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages"
    },
    {
        "paper id": "2411.05681",
        "abstract url": "https://arxiv.org/abs/2411.05681",
        "title": "A Survey of AI-Related Cyber Security Risks and Countermeasures in Mobility-as-a-Service",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Mobility-as-a-Service (MaaS) integrates different transport modalities and can support more personalisation of travellers' journey planning based on their individual preferences, behaviours and wishes. To fully achieve the potential of MaaS, a range of AI (including machine learning and data mining) algorithms are needed to learn personal requirements and needs, to optimise journey planning of each traveller and all travellers as a whole, to help transport service operators and relevant governmental bodies to operate and plan their services, and to detect and prevent cyber attacks from various threat actors including dishonest and malicious travellers and transport operators. The increasing use of different AI and data processing algorithms in both centralised and distributed settings opens the MaaS ecosystem up to diverse cyber and privacy attacks at both the AI algorithm level and the connectivity surfaces. In this paper, we present the first comprehensive review on the coupling between AI-driven MaaS design and the diverse cyber security challenges related to cyber attacks and countermeasures. In particular, we focus on how current and emerging AI-facilitated privacy risks (profiling, inference, and third-party threats) and adversarial AI attacks (evasion, extraction, and gamification) may impact the MaaS ecosystem. These risks often combine novel attacks (e.g., inverse learning) with traditional attack vectors (e.g., man-in-the-middle attacks), exacerbating the risks for the wider participation actors and the emergence of new business models.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05714",
        "abstract url": "https://arxiv.org/abs/2411.05714",
        "title": "STARS: Sensor-agnostic Transformer Architecture for Remote Sensing",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We present a sensor-agnostic spectral transformer as the basis for spectral foundation models. To that end, we introduce a Universal Spectral Representation (USR) that leverages sensor meta-data, such as sensing kernel specifications and sensing wavelengths, to encode spectra obtained from any spectral instrument into a common representation, such that a single model can ingest data from any sensor. Furthermore, we develop a methodology for pre-training such models in a self-supervised manner using a novel random sensor-augmentation and reconstruction pipeline to learn spectral features independent of the sensing paradigm. We demonstrate that our architecture can learn sensor independent spectral features that generalize effectively to sensors not seen during training. This work sets the stage for training foundation models that can both leverage and be effective for the growing diversity of spectral data.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05738",
        "abstract url": "https://arxiv.org/abs/2411.05738",
        "title": "StdGEN: Semantic-Decomposed 3D Character Generation from Single Images",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present StdGEN, an innovative pipeline for generating semantically decomposed high-quality 3D characters from single images, enabling broad applications in virtual reality, gaming, and filmmaking, etc. Unlike previous methods which struggle with limited decomposability, unsatisfactory quality, and long optimization times, StdGEN features decomposability, effectiveness and efficiency; i.e., it generates intricately detailed 3D characters with separated semantic components such as the body, clothes, and hair, in three minutes. At the core of StdGEN is our proposed Semantic-aware Large Reconstruction Model (S-LRM), a transformer-based generalizable model that jointly reconstructs geometry, color and semantics from multi-view images in a feed-forward manner. A differentiable multi-layer semantic surface extraction scheme is introduced to acquire meshes from hybrid implicit fields reconstructed by our S-LRM. Additionally, a specialized efficient multi-view diffusion model and an iterative multi-layer surface refinement module are integrated into the pipeline to facilitate high-quality, decomposable 3D character generation. Extensive experiments demonstrate our state-of-the-art performance in 3D anime character generation, surpassing existing baselines by a significant margin in geometry, texture and decomposability. StdGEN offers ready-to-use semantic-decomposed 3D characters and enables flexible customization for a wide range of applications. Project page: https://stdgen.github.io",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages, 10 figures"
    },
    {
        "paper id": "2411.05771",
        "abstract url": "https://arxiv.org/abs/2411.05771",
        "title": "Sketched Equivariant Imaging Regularization and Deep Internal Learning for Inverse Problems",
        "rating": "-1",
        "keywords": [
            [
                "CT",
                "X-ray"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Equivariant Imaging (EI) regularization has become the de-facto technique for unsupervised training of deep imaging networks, without any need of ground-truth data. Observing that the EI-based unsupervised training paradigm currently has significant computational redundancy leading to inefficiency in high-dimensional applications, we propose a sketched EI regularization which leverages the randomized sketching techniques for acceleration. We then extend our sketched EI regularization to develop an accelerated deep internal learning framework -- Sketched Equivariant Deep Image Prior (Sk.EI-DIP), which can be efficiently applied for single-image and task-adapted reconstruction. Our numerical study on X-ray CT image reconstruction tasks demonstrate that our approach can achieve order-of-magnitude computational acceleration over standard EI-based counterpart in single-input setting, and network adaptation at test time.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05779",
        "abstract url": "https://arxiv.org/abs/2411.05779",
        "title": "Curriculum Learning for Few-Shot Domain Adaptation in CT-based Airway Tree Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "CT"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Despite advances with deep learning (DL), automated airway segmentation from chest CT scans continues to face challenges in segmentation quality and generalization across cohorts. To address these, we propose integrating Curriculum Learning (CL) into airway segmentation networks, distributing the training set into batches according to ad-hoc complexity scores derived from CT scans and corresponding ground-truth tree features. We specifically investigate few-shot domain adaptation, targeting scenarios where manual annotation of a full fine-tuning dataset is prohibitively expensive. Results are reported on two large open-cohorts (ATM22 and AIIB23) with high performance using CL for full training (Source domain) and few-shot fine-tuning (Target domain), but with also some insights on potential detrimental effects if using a classic Bootstrapping scoring function or if not using proper scan sequencing.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Under review for 22nd IEEE International Symposium on Biomedical Imaging (ISBI), Houston, TX, USA"
    },
    {
        "paper id": "2411.05880",
        "abstract url": "https://arxiv.org/abs/2411.05880",
        "title": "Towards Equitable ASD Diagnostics: A Comparative Study of Machine and Deep Learning Models Using Behavioral and Facial Data",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "clinical",
                "Facial"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Autism Spectrum Disorder (ASD) is often underdiagnosed in females due to gender-specific symptom differences overlooked by conventional diagnostics. This study evaluates machine learning models, particularly Random Forest and convolutional neural networks, for enhancing ASD diagnosis through structured data and facial image analysis. Random Forest achieved 100% validation accuracy across datasets, highlighting its ability to manage complex relationships and reduce false negatives, which is crucial for early intervention and addressing gender biases. In image-based analysis, MobileNet outperformed the baseline CNN, achieving 87% accuracy, though a 30% validation loss suggests possible overfitting, requiring further optimization for robustness in clinical settings. Future work will emphasize hyperparameter tuning, regularization, and transfer learning. Integrating behavioral data with facial analysis could improve diagnosis for underdiagnosed groups. These findings suggest Random Forest's high accuracy and balanced precision-recall metrics could enhance clinical workflows. MobileNet's lightweight structure also shows promise for resource-limited environments, enabling accessible ASD screening. Addressing model explainability and clinician trust will be vital.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05881",
        "abstract url": "https://arxiv.org/abs/2411.05881",
        "title": "MIPD: A Multi-sensory Interactive Perception Dataset for Embodied Intelligent Driving",
        "rating": "-1",
        "keywords": [
            [
                "autonomous driving",
                "lidar",
                "radar",
                "vehicle"
            ]
        ],
        "abstract": "During the process of driving, humans usually rely on multiple senses to gather information and make decisions. Analogously, in order to achieve embodied intelligence in autonomous driving, it is essential to integrate multidimensional sensory information in order to facilitate interaction with the environment. However, the current multi-modal fusion sensing schemes often neglect these additional sensory inputs, hindering the realization of fully autonomous driving. This paper considers multi-sensory information and proposes a multi-modal interactive perception dataset named MIPD, enabling expanding the current autonomous driving algorithm framework, for supporting the research on embodied intelligent driving. In addition to the conventional camera, lidar, and 4D radar data, our dataset incorporates multiple sensor inputs including sound, light intensity, vibration intensity and vehicle speed to enrich the dataset comprehensiveness. Comprising 126 consecutive sequences, many exceeding twenty seconds, MIPD features over 8,500 meticulously synchronized and annotated frames. Moreover, it encompasses many challenging scenarios, covering various road and lighting conditions. The dataset has undergone thorough experimental validation, producing valuable insights for the exploration of next-generation autonomous driving frameworks.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Data, development kit and more details will be available at https://github.com/BUCT-IUSRC/Dataset MIPD"
    },
    {
        "paper id": "2411.05883",
        "abstract url": "https://arxiv.org/abs/2411.05883",
        "title": "Benchmarking 3D multi-coil NC-PDNet MRI reconstruction",
        "rating": "-1",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "3D"
            ],
            [
                "MRI",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Deep learning has shown great promise for MRI reconstruction from undersampled data, yet there is a lack of research on validating its performance in 3D parallel imaging acquisitions with non-Cartesian undersampling. In addition, the artifacts and the resulting image quality depend on the under-sampling pattern. To address this uncharted territory, we extend the Non-Cartesian Primal-Dual Network (NC-PDNet), a state-of-the-art unrolled neural network, to a 3D multi-coil setting. We evaluated the impact of channel-specific versus channel-agnostic training configurations and examined the effect of coil compression. Finally, we benchmark four distinct non-Cartesian undersampling patterns, with an acceleration factor of six, using the publicly available Calgary-Campinas dataset. Our results show that NC-PDNet trained on compressed data with varying input channel numbers achieves an average PSNR of 42.98 dB for 1 mm isotropic 32 channel whole-brain 3D reconstruction. With an inference time of 4.95sec and a GPU memory usage of 5.49 GB, our approach demonstrates significant potential for clinical research application.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05885",
        "abstract url": "https://arxiv.org/abs/2411.05885",
        "title": "Alternative Learning Paradigms for Image Quality Transfer",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "MRI"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Image Quality Transfer (IQT) aims to enhance the contrast and resolution of low-quality medical images, e.g. obtained from low-power devices, with rich information learned from higher quality images. In contrast to existing IQT methods which adopt supervised learning frameworks, in this work, we propose two novel formulations of the IQT problem. The first approach uses an unsupervised learning framework, whereas the second is a combination of both supervised and unsupervised learning. The unsupervised learning approach considers a sparse representation (SRep) and dictionary learning model, which we call IQT-SRep, whereas the combination of supervised and unsupervised learning approach is based on deep dictionary learning (DDL), which we call IQT-DDL. The IQT-SRep approach trains two dictionaries using a SRep model using pairs of low- and high-quality volumes. Subsequently, the SRep of a low-quality block, in terms of the low-quality dictionary, can be directly used to recover the corresponding high-quality block using the high-quality dictionary. On the other hand, the IQT-DDL approach explicitly learns a high-resolution dictionary to upscale the input volume, while the entire network, including high dictionary generator, is simultaneously optimised to take full advantage of deep learning methods. The two models are evaluated using a low-field magnetic resonance imaging (MRI) application aiming to recover high-quality images akin to those obtained from high-field scanners. Experiments comparing the proposed approaches against state-of-the-art supervised deep learning IQT method (IQT-DL) identify that the two novel formulations of the IQT problem can avoid bias associated with supervised methods when tested using out-of-distribution data that differs from the distribution of the data the model was trained on. This highlights the potential benefit of these novel paradigms for IQT.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2024:027"
    },
    {
        "paper id": "2411.05892",
        "abstract url": "https://arxiv.org/abs/2411.05892",
        "title": "Identifying and Decomposing Compound Ingredients in Meal Plans Using Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study explores the effectiveness of Large Language Models in meal planning, focusing on their ability to identify and decompose compound ingredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral (8x7b)-to assess their proficiency in recognizing and breaking down complex ingredient combinations. Preliminary results indicate that while Llama-3 (70b) and GPT-4o excels in accurate decomposition, all models encounter difficulties with identifying essential elements like seasonings and oils. Despite strong overall performance, variations in accuracy and completeness were observed across models. These findings underscore LLMs' potential to enhance personalized nutrition but highlight the need for further refinement in ingredient decomposition. Future research should address these limitations to improve nutritional recommendations and health outcomes.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "Comments: Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)"
    },
    {
        "paper id": "2411.05900",
        "abstract url": "https://arxiv.org/abs/2411.05900",
        "title": "Enhancing Cardiovascular Disease Prediction through Multi-Modal Self-Supervised Learning",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "diagnosis",
                "Disease",
                "cardiac"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate prediction of cardiovascular diseases remains imperative for early diagnosis and intervention, necessitating robust and precise predictive models. Recently, there has been a growing interest in multi-modal learning for uncovering novel insights not available through uni-modal datasets alone. By combining cardiac magnetic resonance images, electrocardiogram signals, and available medical information, our approach enables the capture of holistic status about individuals' cardiovascular health by leveraging shared information across modalities. Integrating information from multiple modalities and benefiting from self-supervised learning techniques, our model provides a comprehensive framework for enhancing cardiovascular disease prediction with limited annotated datasets. We employ a masked autoencoder to pre-train the electrocardiogram ECG encoder, enabling it to extract relevant features from raw electrocardiogram data, and an image encoder to extract relevant features from cardiac magnetic resonance images. Subsequently, we utilize a multi-modal contrastive learning objective to transfer knowledge from expensive and complex modality, cardiac magnetic resonance image, to cheap and simple modalities such as electrocardiograms and medical information. Finally, we fine-tuned the pre-trained encoders on specific predictive tasks, such as myocardial infarction. Our proposed method enhanced the image information by leveraging different available modalities and outperformed the supervised approach by 7.6% in balanced accuracy.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted to British Machine Vision Conference (BMVC) 2024"
    },
    {
        "paper id": "2411.05939",
        "abstract url": "https://arxiv.org/abs/2411.05939",
        "title": "GCI-ViTAL: Gradual Confidence Improvement with Vision Transformers for Active Learning on Label Noise",
        "rating": "-1",
        "keywords": [
            [
                "X-ray"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Active learning aims to train accurate classifiers while minimizing labeling costs by strategically selecting informative samples for annotation. This study focuses on image classification tasks, comparing AL methods on CIFAR10, CIFAR100, Food101, and the Chest X-ray datasets under varying label noise rates. We investigate the impact of model architecture by comparing Convolutional Neural Networks (CNNs) and Vision Transformer (ViT)-based models. Additionally, we propose a novel deep active learning algorithm, GCI-ViTAL, designed to be robust to label noise. GCI-ViTAL utilizes prediction entropy and the Frobenius norm of last-layer attention vectors compared to class-centric clean set attention vectors. Our method identifies samples that are both uncertain and semantically divergent from typical images in their assigned class. This allows GCI-ViTAL to select informative data points even in the presence of label noise while flagging potentially mislabeled candidates. Label smoothing is applied to train a model that is not overly confident about potentially noisy labels. We evaluate GCI-ViTAL under varying levels of symmetric label noise and compare it to five other AL strategies. Our results demonstrate that using ViTs leads to significant performance improvements over CNNs across all AL strategies, particularly in noisy label settings. We also find that using the semantic information of images as label grounding helps in training a more robust model under label noise. Notably, we do not perform extensive hyperparameter tuning, providing an out-of-the-box comparison that addresses the common challenge practitioners face in selecting models and active learning strategies without an exhaustive literature review on training and fine-tuning vision models on real-world application data.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "under review"
    },
    {
        "paper id": "2411.05945",
        "abstract url": "https://arxiv.org/abs/2411.05945",
        "title": "NeKo: Toward Post Recognition Generative Correction Large Language Models with Task-Oriented Experts",
        "rating": "-1",
        "keywords": [
            [
                "grammar"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "Construction of a general-purpose post-recognition error corrector poses a crucial question: how can we most effectively train a model on a large mixture of domain datasets? The answer would lie in learning dataset-specific features and digesting their knowledge in a single model. Previous methods achieve this by having separate correction language models, resulting in a significant increase in parameters. In this work, we present Mixture-of-Experts as a solution, highlighting that MoEs are much more than a scalability tool. We propose a Multi-Task Correction MoE, where we train the experts to become an ``expert'' of speech-to-text, language-to-text and vision-to-text datasets by learning to route each dataset's tokens to its mapped expert. Experiments on the Open ASR Leaderboard show that we explore a new state-of-the-art performance by achieving an average relative $5.0$% WER reduction and substantial improvements in BLEU scores for speech and translation tasks. On zero-shot evaluation, NeKo outperforms GPT-3.5 and Claude-Opus with $15.5$% to $27.6$% relative WER reduction in the Hyporadise benchmark. NeKo performs competitively on grammar and post-OCR correction as a multi-task model.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "eess.AS"
        ],
        "comment": "NeKo work has been done in June 2024. NeKo LMs will be open source on https://huggingface.co/nvidia under the MIT license"
    },
    {
        "paper id": "2411.05955",
        "abstract url": "https://arxiv.org/abs/2411.05955",
        "title": "Classification of Adventitious Sounds Combining Cochleogram and Vision Transformers",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "disease"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "Early identification of respiratory irregularities is critical for improving lung health and reducing global mortality rates. The analysis of respiratory sounds plays a significant role in characterizing the respiratory system's condition and identifying abnormalities. The main contribution of this study is to investigate the performance when the input data, represented by cochleogram, is used to feed the Vision Transformer architecture, since this input classifier combination is the first time it has been applied to adventitious sound classification to our knowledge. Although ViT has shown promising results in audio classification tasks by applying self attention to spectrogram patches, we extend this approach by applying the cochleogram, which captures specific spectro-temporal features of adventitious sounds. The proposed methodology is evaluated on the ICBHI dataset. We compare the classification performance of ViT with other state of the art CNN approaches using spectrogram, Mel frequency cepstral coefficients, constant Q transform, and cochleogram as input data. Our results confirm the superior classification performance combining cochleogram and ViT, highlighting the potential of ViT for reliable respiratory sound classification. This study contributes to the ongoing efforts in developing automatic intelligent techniques with the aim to significantly augment the speed and effectiveness of respiratory disease detection, thereby addressing a critical need in the medical field.",
        "subjects": [
            "eess.AS",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05959",
        "abstract url": "https://arxiv.org/abs/2411.05959",
        "title": "Efficient Self-Supervised Barlow Twins from Limited Tissue Slide Cohorts for Colonic Pathology Diagnostics",
        "rating": "-1",
        "keywords": [
            [
                "biopsy",
                "whole-slide",
                "cancer"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Colorectal cancer (CRC) is one of the few cancers that have an established dysplasia-carcinoma sequence that benefits from screening. Everyone over 50 years of age in Canada is eligible for CRC screening. About 20\\% of those people will undergo a biopsy for a pre-neoplastic polyp and, in many cases, multiple polyps. As such, these polyp biopsies make up the bulk of a pathologist's workload. Developing an efficient computational model to help screen these polyp biopsies can improve the pathologist's workflow and help guide their attention to critical areas on the slide. DL models face significant challenges in computational pathology (CPath) because of the gigapixel image size of whole-slide images and the scarcity of detailed annotated datasets. It is, therefore, crucial to leverage self-supervised learning (SSL) methods to alleviate the burden and cost of data annotation. However, current research lacks methods to apply SSL frameworks to analyze pathology data effectively. This paper aims to propose an optimized Barlow Twins framework for colorectal polyps screening. We adapt its hyperparameters, augmentation strategy and encoder to the specificity of the pathology data to enhance performance. Additionally, we investigate the best Field of View (FoV) for colorectal polyps screening and propose a new benchmark dataset for CRC screening, made of four types of colorectal polyps and normal tissue, by performing downstream tasking on MHIST and NCT-CRC-7K datasets. Furthermore, we show that the SSL representations are more meaningful and qualitative than the supervised ones and that Barlow Twins benefits from the Swin Transformer when applied to pathology data. Codes are avaialble from https://github.com/AtlasAnalyticsLab/PathBT.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Submission Under Review"
    },
    {
        "paper id": "2411.05983",
        "abstract url": "https://arxiv.org/abs/2411.05983",
        "title": "Longitudinal Ensemble Integration for sequential classification with multimodal data",
        "rating": "-1",
        "keywords": [
            [
                "biomedicine"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Effectively modeling multimodal longitudinal data is a pressing need in various application areas, especially biomedicine. Despite this, few approaches exist in the literature for this problem, with most not adequately taking into account the multimodality of the data. In this study, we developed multiple configurations of a novel multimodal and longitudinal learning framework, Longitudinal Ensemble Integration (LEI), for sequential classification. We evaluated LEI's performance, and compared it against existing approaches, for the early detection of dementia, which is among the most studied multimodal sequential classification tasks. LEI outperformed these approaches due to its use of intermediate base predictions arising from the individual data modalities, which enabled their better integration over time. LEI's design also enabled the identification of features that were consistently important across time for the effective prediction of dementia-related diagnoses. Overall, our work demonstrates the potential of LEI for sequential classification from longitudinal multimodal data.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "11 pages, submitted to ICLR 2025"
    },
    {
        "paper id": "2411.05991",
        "abstract url": "https://arxiv.org/abs/2411.05991",
        "title": "GUIDEQ: Framework for Guided Questioning for progressive informational collection and classification",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Question Answering (QA) is an important part of tasks like text classification through information gathering. These are finding increasing use in sectors like healthcare, customer support, legal services, etc., to collect and classify responses into actionable categories. LLMs, although can support QA systems, they face a significant challenge of insufficient or missing information for classification. Although LLMs excel in reasoning, the models rely on their parametric knowledge to answer. However, questioning the user requires domain-specific information aiding to collect accurate information. Our work, GUIDEQ, presents a novel framework for asking guided questions to further progress a partial information. We leverage the explainability derived from the classifier model for along with LLMs for asking guided questions to further enhance the information. This further information helps in more accurate classification of a text. GUIDEQ derives the most significant key-words representative of a label using occlusions. We develop GUIDEQ's prompting strategy for guided questions based on the top-3 classifier label outputs and the significant words, to seek specific and relevant information, and classify in a targeted manner. Through our experimental results, we demonstrate that GUIDEQ outperforms other LLM-based baselines, yielding improved F1-Score through the accurate collection of relevant further information. We perform various analytical studies and also report better question quality compared to our method.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06010",
        "abstract url": "https://arxiv.org/abs/2411.06010",
        "title": "Developing a Safety Management System for the Autonomous Vehicle Industry",
        "rating": "-1",
        "keywords": [
            [
                "automated driving",
                "Vehicle"
            ]
        ],
        "abstract": "Safety Management Systems (SMSs) have been used in many safety-critical industries and are now being developed and deployed in the automated driving system (ADS)-equipped vehicle (AV) sector. Industries with decades of SMS deployment have established frameworks tailored to their specific context. Several frameworks for an AV industry SMS have been proposed or are currently under development. These frameworks borrow heavily from the aviation industry although the AV and aviation industries differ in many significant ways. In this context, there is a need to review the approach to develop an SMS that is tailored to the AV industry, building on generalized lessons learned from other safety-sensitive industries. A harmonized AV-industry SMS framework would establish a single set of SMS practices to address management of broad safety risks in an integrated manner and advance the establishment of a more mature regulatory framework. This paper outlines a proposed SMS framework for the AV industry based on robust taxonomy development and validation criteria and provides rationale for such an approach. Keywords: Safety Management System (SMS), Automated Driving System (ADS), ADS-Equipped Vehicle, Autonomous Vehicles (AV)",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to SAE Technical Papers"
    },
    {
        "paper id": "2411.06015",
        "abstract url": "https://arxiv.org/abs/2411.06015",
        "title": "Multi-hop RIS-aided Learning Model Sharing for Urban Air Mobility",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Urban Air Mobility (UAM), powered by flying cars, is poised to revolutionize urban transportation by expanding vehicle travel from the ground to the air. This advancement promises to alleviate congestion and enable faster commutes. However, the fast travel speeds mean vehicles will encounter vastly different environments during a single journey. As a result, onboard learning systems need access to extensive environmental data, leading to high costs in data collection and training. These demands conflict with the limited in-vehicle computing and battery resources. Fortunately, learning model sharing offers a solution. Well-trained local Deep Learning (DL) models can be shared with other vehicles, reducing the need for redundant data collection and training. However, this sharing process relies heavily on efficient vehicular communications in UAM. To address these challenges, this paper leverages the multi-hop Reconfigurable Intelligent Surface (RIS) technology to improve DL model sharing between distant flying cars. We also employ knowledge distillation to reduce the size of the shared DL models and enable efficient integration of non-identical models at the receiver. Our approach enhances model sharing and onboard learning performance for cars entering new environments. Simulation results show that our scheme improves the total reward by 85% compared to benchmark methods.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "13pages, 17 figures"
    },
    {
        "paper id": "2411.06039",
        "abstract url": "https://arxiv.org/abs/2411.06039",
        "title": "To What Extent Does the Perceived Obesity Level of Humanoid Robots Affect People's Trust in Them?",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Despite obesity being widely discussed in the social sciences, the effect of a robot's perceived obesity level on trust is not covered by the field of HRI. While in research regarding humans, Body Mass Index (BMI) is commonly used as an indicator of obesity, this scale is completely irrelevant in the context of robots, so it is challenging to operationalize the perceived obesity level of robots; indeed, while the effect of robot's size (or height) on people's trust in it was addressed in previous HRI papers, the perceived obesity level factor has not been addressed. This work examines to what extent the perceived obesity level of humanoid robots affects people's trust in them. To test this hypothesis, we conducted a within-subjects study where, using an online pre-validated questionnaire, the subjects were asked questions while being presented with two pictures of humanoids, one with a regular obesity level and the other with a high obesity level. The results show that humanoid robots with lower perceived obesity levels are significantly more likely to be trusted.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to \"Designing Interactive Humanoids: Learning Tasks through Interaction with Humans'' workshop on Humanoids 2025"
    },
    {
        "paper id": "2411.06065",
        "abstract url": "https://arxiv.org/abs/2411.06065",
        "title": "DFT: A Dual-branch Framework of Fluctuation and Trend for Stock Price Prediction",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Stock price prediction is of significant importance in quantitative investment. Existing approaches encounter two primary issues: First, they often overlook the crucial role of capturing short-term stock fluctuations for predicting high-volatility returns. Second, mainstream methods, relying on graphs or attention mechanisms, inadequately explore the temporal relationships among stocks, often blurring distinctions in their characteristics over time and the causal relationships before and after. However, the high volatility of stocks and the intricate market correlations are crucial to accurately predicting stock prices. To address these challenges, we propose a Dual-branch Framework of Fluctuation and Trend (DFT), which decomposes stocks into trend and fluctuation components. By employing a carefully design decomposition module, DFT effectively extracts short-term fluctuations and trend information from stocks while explicitly modeling temporal variations and causal correlations. Our extensive experiments demonstrate that DFT outperforms existing methods across multiple metrics, including a 300% improvement in ranking metrics and a 400% improvement in portfolio-based indicators. Through detailed experiments, we provide valuable insights into different roles of trends and fluctuations in stock price prediction.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.07261",
        "abstract url": "https://arxiv.org/abs/2411.07261",
        "title": "Sinkage Study in Granular Material for Space Exploration Legged Robot Gripper",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Wheeled rovers have been the primary choice for lunar exploration due to their speed and efficiency. However, deeper areas, such as lunar caves and craters, require the mobility of legged robots. To do so, appropriate end effectors must be designed to enable climbing and walking on the granular surface of the Moon. This paper investigates the behavior of an underactuated soft gripper on deformable granular material when a legged robot is walking in soft soil. A modular test bench and a simulation model were developed to observe the gripper sinkage behavior under load. The gripper uses tendon-driven fingers to match its target shape and grasp on the target surface using multiple micro-spines. The sinkage of the gripper in silica sand was measured by comparing the axial displacement of the gripper with the nominal load of the robot mass. Multiple experiments were performed to observe the sinkage of the gripper over a range of slope angles. A simulation model accounting for the degrees of compliance of the gripper fingers was created using Altair MotionSolve software and coupled to Altair EDEM to compute the gripper interaction with particles utilizing the discrete element method. After validation of the model, complementary simulations using Lunar gravity and a regolith particle model were performed. The results show that a satisfactory gripper model with accurate freedom of motion can be created in simulation using the Altair simulation packages and expected sinkage under load in a particle-filled environment can be estimated using this model. By computing the sinkage of the end effector of legged robots, the results can be directly integrated into the motion control algorithm and improve the accuracy of mobility in a granular material environment.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Proceedings of the 21st International and 12th Asia-Pacific Regional Conference of the ISTVS"
    },
    {
        "paper id": "2411.05328",
        "abstract url": "https://arxiv.org/abs/2411.05328",
        "title": "Content Quality vs. Attention Allocation: An LLM-Based Case Study in Peer-to-peer Mental Health Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "Health"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "With the rise of social media and peer-to-peer networks, users increasingly rely on crowdsourced responses for information and assistance. However, the mechanisms used to rank and promote responses often prioritize and end up biasing in favor of timeliness over quality, which may result in suboptimal support for help-seekers. We analyze millions of responses to mental health-related posts, utilizing large language models (LLMs) to assess the multi-dimensional quality of content, including relevance, empathy, and cultural alignment, among other aspects. Our findings reveal a mismatch between content quality and attention allocation: earlier responses - despite being relatively lower in quality - receive disproportionately high fractions of upvotes and visibility due to platform ranking algorithms. We demonstrate that the quality of the top-ranked responses could be improved by up to 39 percent, and even the simplest re-ranking strategy could significantly improve the quality of top responses, highlighting the need for more nuanced ranking mechanisms that prioritize both timeliness and content quality, especially emotional engagement in online mental health communities.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "9 pages, 6 figures"
    },
    {
        "paper id": "2411.05349",
        "abstract url": "https://arxiv.org/abs/2411.05349",
        "title": "Enhancing Cluster Resilience: LLM-agent Based Autonomous Intelligent Cluster Diagnosis System and Evaluation Framework",
        "rating": "-1.5",
        "keywords": [
            [
                "Diagnosis"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advancements in Large Language Models (LLMs) and related technologies such as Retrieval-Augmented Generation (RAG) and Diagram of Thought (DoT) have enabled the creation of autonomous intelligent systems capable of performing cluster diagnostics and troubleshooting. By integrating these technologies with self-play methodologies, we have developed an LLM-agent system designed to autonomously diagnose and resolve issues within AI clusters. Our innovations include a knowledge base tailored for cluster diagnostics, enhanced LLM algorithms, practical deployment strategies for agents, and a benchmark specifically designed for evaluating LLM capabilities in this domain. Through extensive experimentation across multiple dimensions, we have demonstrated the superiority of our system in addressing the challenges faced in cluster diagnostics, particularly in detecting and rectifying performance issues more efficiently and accurately than traditional methods.",
        "subjects": [
            "cs.AI",
            "cs.DC"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2411.05378",
        "abstract url": "https://arxiv.org/abs/2411.05378",
        "title": "Machine learning for prediction of dose-volume histograms of organs-at-risk in prostate cancer from simple structure volume parameters",
        "rating": "-1.5",
        "keywords": [
            [
                "cancer"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Dose prediction is an area of ongoing research that facilitates radiotherapy planning. Most commercial models utilise imaging data and intense computing resources. This study aimed to predict the dose-volume of rectum and bladder from volumes of target, at-risk structure organs and their overlap regions using machine learning. Dose-volume information of 94 patients with prostate cancer planned for 6000cGy in 20 fractions was exported from the treatment planning system as text files and mined to create a training dataset. Several statistical modelling, machine learning methods, and a new fuzzy rule-based prediction (FRBP) model were explored and validated on an independent dataset of 39 patients. The median absolute error was 2.0%-3.7% for bladder and 1.7-2.4% for rectum in the 4000-6420cGy range. For 5300cGy, 5600cGy and 6000cGy, the median difference was less than 2.5% for rectum and 3.8% for bladder. The FRBP model produced errors of 1.2%, 1.3%, 0.9% and 1.6%, 1.2%, 0.1% for the rectum and bladder respectively at these dose levels. These findings indicate feasibility of obtaining accurate predictions of the clinically important dose-volume parameters for rectum and bladder using just the volumes of these structures.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05399",
        "abstract url": "https://arxiv.org/abs/2411.05399",
        "title": "Post-Hoc Robustness Enhancement in Graph Neural Networks with Conditional Random Fields",
        "rating": "-1.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs), which are nowadays the benchmark approach in graph representation learning, have been shown to be vulnerable to adversarial attacks, raising concerns about their real-world applicability. While existing defense techniques primarily concentrate on the training phase of GNNs, involving adjustments to message passing architectures or pre-processing methods, there is a noticeable gap in methods focusing on increasing robustness during inference. In this context, this study introduces RobustCRF, a post-hoc approach aiming to enhance the robustness of GNNs at the inference stage. Our proposed method, founded on statistical relational learning using a Conditional Random Field, is model-agnostic and does not require prior knowledge about the underlying model architecture. We validate the efficacy of this approach across various models, leveraging benchmark node classification datasets.",
        "subjects": [
            "cs.LG",
            "cs.SI",
            "stat.AP",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05472",
        "abstract url": "https://arxiv.org/abs/2411.05472",
        "title": "Bridging the Gap between Learning and Inference for Diffusion-Based Molecule Generation",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The efficacy of diffusion models in generating a spectrum of data modalities, including images, text, and videos, has spurred inquiries into their utility in molecular generation, yielding significant advancements in the field. However, the molecular generation process with diffusion models involves multiple autoregressive steps over a finite time horizon, leading to exposure bias issues inherently. To address the exposure bias issue, we propose a training framework named GapDiff. The core idea of GapDiff is to utilize model-predicted conformations as ground truth probabilistically during training, aiming to mitigate the data distributional disparity between training and inference, thereby enhancing the affinity of generated molecules. We conduct experiments using a 3D molecular generation model on the CrossDocked2020 dataset, and the vina energy and diversity demonstrate the potency of our framework with superior affinity. GapDiff is available at \\url{https://github.com/HUGHNew/gapdiff}.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "14 pages, 5 figures"
    },
    {
        "paper id": "2411.05685",
        "abstract url": "https://arxiv.org/abs/2411.05685",
        "title": "Beyond Pairwise Interactions: Unveiling the Role of Higher-Order Interactions via Stepwise Reduction",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Complex systems, such as economic, social, biological, and ecological systems, usually feature interactions not only between pairwise entities but also among three or more entities. These multi-entity interactions are known as higher-order interactions. Hypergraph, as a mathematical tool, can effectively characterize higher-order interactions, where nodes denote entities and hyperedges represent interactions among multiple entities. Meanwhile, all higher-order interactions can also be projected into a number of lower-order interactions or even some pairwise interactions. Whether it is necessary to consider all higher-order interactions, and whether it is with little loss to replace them by lower-order or even pairwise interactions, remain a controversial issue. If the role of higher-order interactions is insignificant, the complexity of computation and the difficulty of analysis can be drastically reduced by projecting higher-order interactions into lower-order or pairwise interactions. We use link prediction, a fundamental problem in network science, as the entry point. Specifically, we evaluate the impact of higher-order interactions on link predictive accuracy to explore the necessity of these structures. We propose a method to decompose the higher-order structures in a stepwise way, thereby allowing to systematically explore the impacts of structures at different orders on link prediction. The results indicate that in some networks, incorporating higher-order interactions significantly enhances the accuracy of link prediction, while in others, the effect is insignificant. Therefore, we think that the role of higher-order interactions varies in different types of networks. Overall, since the improvement in predictive accuracy provided by higher-order interactions is significant in some networks, we believe that the study of higher-order interactions is both necessary and valuable.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": "14 pages, 6 figures"
    },
    {
        "paper id": "2411.05730",
        "abstract url": "https://arxiv.org/abs/2411.05730",
        "title": "Learning Subsystem Dynamics in Nonlinear Systems via Port-Hamiltonian Neural Networks",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Port-Hamiltonian neural networks (pHNNs) are emerging as a powerful modeling tool that integrates physical laws with deep learning techniques. While most research has focused on modeling the entire dynamics of interconnected systems, the potential for identifying and modeling individual subsystems while operating as part of a larger system has been overlooked. This study addresses this gap by introducing a novel method for using pHNNs to identify such subsystems based solely on input-output measurements. By utilizing the inherent compositional property of the port-Hamiltonian systems, we developed an algorithm that learns the dynamics of individual subsystems, without requiring direct access to their internal states. On top of that, by choosing an output error (OE) model structure, we have been able to handle measurement noise effectively. The effectiveness of the proposed approach is demonstrated through tests on interconnected systems, including multi-physics scenarios, demonstrating its potential for identifying subsystem dynamics and facilitating their integration into new interconnected models.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": "Preprint submitted to ECC 2025"
    },
    {
        "paper id": "2411.05923",
        "abstract url": "https://arxiv.org/abs/2411.05923",
        "title": "DNAMite: Interpretable Calibrated Survival Analysis with Discretized Additive Models",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare",
                "Survival"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Survival analysis is a classic problem in statistics with important applications in healthcare. Most machine learning models for survival analysis are black-box models, limiting their use in healthcare settings where interpretability is paramount. More recently, glass-box machine learning models have been introduced for survival analysis, with both strong predictive performance and interpretability. Still, several gaps remain, as no prior glass-box survival model can produce calibrated shape functions with enough flexibility to capture the complex patterns often found in real data. To fill this gap, we introduce a new glass-box machine learning model for survival analysis called DNAMite. DNAMite uses feature discretization and kernel smoothing in its embedding module, making it possible to learn shape functions with a flexible balance of smoothness and jaggedness. Further, DNAMite produces calibrated shape functions that can be directly interpreted as contributions to the cumulative incidence function. Our experiments show that DNAMite generates shape functions closer to true shape functions on synthetic data, while making predictions with comparable predictive performance and better calibration than previous glass-box and black-box models.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05960",
        "abstract url": "https://arxiv.org/abs/2411.05960",
        "title": "A method based on Generative Adversarial Networks for disentangling physical and chemical properties of stars in astronomical spectra",
        "rating": "-1.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Data compression techniques focused on information preservation have become essential in the modern era of big data. In this work, an encoder-decoder architecture has been designed, where adversarial training, a modification of the traditional autoencoder, is used in the context of astrophysical spectral analysis. The goal of this proposal is to obtain an intermediate representation of the astronomical stellar spectra, in which the contribution to the flux of a star due to the most influential physical properties (its surface temperature and gravity) disappears and the variance reflects only the effect of the chemical composition over the spectrum. A scheme of deep learning is used with the aim of unraveling in the latent space the desired parameters of the rest of the information contained in the data. This work proposes a version of adversarial training that makes use of a discriminator per parameter to be disentangled, thus avoiding the exponential combination that occurs in the use of a single discriminator, as a result of the discretization of the values to be untangled. To test the effectiveness of the method, synthetic astronomical data are used from the APOGEE and Gaia surveys. In conjunction with the work presented, we also provide a disentangling framework (GANDALF) available to the community, which allows the replication, visualization, and extension of the method to domains of any nature.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.SR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06009",
        "abstract url": "https://arxiv.org/abs/2411.06009",
        "title": "A Comprehensive Guide to Enhancing Antibiotic Discovery Using Machine Learning Derived Bio-computation",
        "rating": "-1.5",
        "keywords": [
            [
                "Bio-computation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Traditional drug discovery is a long, expensive, and complex process. Advances in Artificial Intelligence (AI) and Machine Learning (ML) are beginning to change this narrative. Here, we provide a comprehensive overview of different AI and ML tools that can be used to streamline and accelerate the drug discovery process. By using data sets to train ML algorithms, it is possible to discover drugs or drug-like compounds relatively quickly, and efficiently. Additionally, we address limitations in AI-based drug discovery and development, including the scarcity of high-quality data to train AI models and ethical considerations. The growing impact of AI on the pharmaceutical industry is also highlighted. Finally, we discuss how AI and ML can expedite the discovery of new antibiotics to combat the problem of worldwide antimicrobial resistance (AMR).",
        "subjects": [
            "cs.AI"
        ],
        "comment": "65 pages"
    },
    {
        "paper id": "2411.06027",
        "abstract url": "https://arxiv.org/abs/2411.06027",
        "title": "A Toolkit for Measuring the Impacts of Public Funding on Open Source Software Development",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "Governments are increasingly employing funding for open source software (OSS) development as a policy lever to support the security of software supply chains, digital sovereignty, economic growth, and national competitiveness in science and innovation, among others. However, the impacts of public funding on OSS development remain poorly understood, with a lack of consensus on how to meaningfully measure them. This gap hampers assessments of the return on public investment and impedes the optimisation of public-interest funding strategies. We address this gap with a toolkit of methodological considerations that may inform such measurements, drawing on prior work on OSS valuations and community health metrics by the Community Health Analytics Open Source Software (CHAOSS) project as well as our first-hand learnings as practitioners tasked with evaluating funding programmes by the Next Generation Internet initiative and the Sovereign Tech Agency. We discuss salient considerations, including the importance of accounting for funding objectives, project life stage and social structure, and regional and organisational cost factors. Next, we present a taxonomy of potential social, economic, and technological impacts that can be both positive and negative, direct and indirect, internal (i.e. within a project) and external (i.e. among a project's ecosystem of dependents and users), and manifest over various time horizons. Furthermore, we discuss the merits and limitations of qualitative, quantitative, and mixed-methods approaches, as well as options for and hazards of estimating multiplier effects. With this toolkit, we contribute to the multi-stakeholder conversation about the value and impacts of funding on OSS developers and society at large.",
        "subjects": [
            "cs.CY",
            "cs.SE"
        ],
        "comment": "23 pages, 3 tables"
    },
    {
        "paper id": "2411.06034",
        "abstract url": "https://arxiv.org/abs/2411.06034",
        "title": "CROPS: A Deployable Crop Management System Over All Possible State Availabilities",
        "rating": "-1.5",
        "keywords": [
            [
                "agricultural"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Exploring the optimal management strategy for nitrogen and irrigation has a significant impact on crop yield, economic profit, and the environment. To tackle this optimization challenge, this paper introduces a deployable \\textbf{CR}op Management system \\textbf{O}ver all \\textbf{P}ossible \\textbf{S}tate availabilities (CROPS). CROPS employs a language model (LM) as a reinforcement learning (RL) agent to explore optimal management strategies within the Decision Support System for Agrotechnology Transfer (DSSAT) crop simulations. A distinguishing feature of this system is that the states used for decision-making are partially observed through random masking. Consequently, the RL agent is tasked with two primary objectives: optimizing management policies and inferring masked states. This approach significantly enhances the RL agent's robustness and adaptability across various real-world agricultural scenarios. Extensive experiments on maize crops in Florida, USA, and Zaragoza, Spain, validate the effectiveness of CROPS. Not only did CROPS achieve State-of-the-Art (SOTA) results across various evaluation metrics such as production, profit, and sustainability, but the trained management policies are also immediately deployable in over of ten millions of real-world contexts. Furthermore, the pre-trained policies possess a noise resilience property, which enables them to minimize potential sensor biases, ensuring robustness and generalizability. Finally, unlike previous methods, the strength of CROPS lies in its unified and elegant structure, which eliminates the need for pre-defined states or multi-stage training. These advancements highlight the potential of CROPS in revolutionizing agricultural practices.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06046",
        "abstract url": "https://arxiv.org/abs/2411.06046",
        "title": "Personalized News Recommendation System via LLM Embedding and Co-Occurrence Patterns",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the past two years, large language models (LLMs) have achieved rapid development and demonstrated remarkable emerging capabilities. Concurrently, with powerful semantic understanding and reasoning capabilities, LLMs have significantly empowered the rapid advancement of the recommendation system field. Specifically, in news recommendation (NR), systems must comprehend and process a vast amount of clicked news text to infer the probability of candidate news clicks. This requirement exceeds the capabilities of traditional NR models but aligns well with the strengths of LLMs. In this paper, we propose a novel NR algorithm to reshape the news model via LLM Embedding and Co-Occurrence Pattern (LECOP). On one hand, we fintuned LLM by contrastive learning using large-scale datasets to encode news, which can fully explore the semantic information of news to thoroughly identify user preferences. On the other hand, we explored multiple co-occurrence patterns to mine collaborative information. Those patterns include news ID co-occurrence, Item-Item keywords co-occurrence and Intra-Item keywords co-occurrence. The keywords mentioned above are all generated by LLM. As far as we know, this is the first time that constructing such detailed Co-Occurrence Patterns via LLM to capture collaboration. Extensive experiments demonstrate the superior performance of our proposed novel method",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.07263",
        "abstract url": "https://arxiv.org/abs/2411.07263",
        "title": "Analysis and Forecasting of the Dynamics of a Floating Wind Turbine Using Dynamic Mode Decomposition",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This article presents a data-driven equation-free modeling of the dynamics of a hexafloat floating offshore wind turbine based on the Dynamic Mode Decomposition (DMD). The DMD is here used to provide a modal analysis and extract knowledge from the dynamic system. A forecasting algorithm for the motions, accelerations, and forces acting on the floating system, as well as the height of the incoming waves, the wind speed, and the power extracted by the wind turbine, is developed by using a methodological extension called Hankel-DMD, that includes time-delayed copies of the states in an augmented state vector. All the analyses are performed on experimental data collected from an operating prototype. The quality of the forecasts obtained varying two main hyperparameters of the algorithm, namely the number of delayed copies and the length of the observation time, is assessed using three different error metrics, each analyzing complementary aspects of the prediction. A statistical analysis exposed the existence of optimal values for the algorithm hyperparameters. Results show the approach's capability for short-term future estimates of the system's state, which can be used for real-time prediction and control. Furthermore, a novel Stochastic Hankel-DMD formulation is introduced by considering hyperparameters as stochastic variables. The stochastic version of the method not only enriches the prediction with its related uncertainty but is also found to improve the normalized root mean square error up to 10% on a statistical basis compared to the deterministic counterpart.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05337",
        "abstract url": "https://arxiv.org/abs/2411.05337",
        "title": "Development of an indoor localization and navigation system based on monocular SLAM for mobile robots",
        "rating": "-2",
        "keywords": [
            [
                "LiDAR",
                "SLAM"
            ],
            [
                "robot",
                "navigation"
            ]
        ],
        "abstract": "Localization and navigation are two crucial issues for mobile robots. In this paper, we propose an approach for localization and navigation systems for a differential-drive robot based on monocular SLAM. The system is implemented on the Robot Operating System (ROS). The hardware includes a differential-drive robot with an embedded computing platform (Jetson Xavier AGX), a 2D camera, and a LiDAR sensor for collecting external environmental information. The A* algorithm and Dynamic Window Approach (DWA) are used for path planning based on a 2D grid map. The ORB_SLAM3 algorithm is utilized to extract environmental features, providing the robot's pose for the localization and navigation processes. Finally, the system is tested in the Gazebo simulation environment and visualized through Rviz, demonstrating the efficiency and potential of the system for indoor localization and navigation of mobile robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "In The 25th National Conference on Electronics, Communications and Information Technology (REV-ECIT 2022), Hanoi, Vietnam. in Vietnamese language"
    },
    {
        "paper id": "2411.05344",
        "abstract url": "https://arxiv.org/abs/2411.05344",
        "title": "Enhancing Depth Image Estimation for Underwater Robots by Combining Image Processing and Machine Learning",
        "rating": "-2",
        "keywords": [
            [
                "Depth"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Depth information plays a crucial role in autonomous systems for environmental perception and robot state estimation. With the rapid development of deep neural network technology, depth estimation has been extensively studied and shown potential for practical applications. However, in particularly challenging environments such as low-light and noisy underwater conditions, direct application of machine learning models may not yield the desired results. Therefore, in this paper, we present an approach to enhance underwater image quality to improve depth estimation effectiveness. First, underwater images are processed through methods such as color compensation, brightness equalization, and enhancement of contrast and sharpness of objects in the image. Next, we perform depth estimation using the Udepth model on the enhanced images. Finally, the results are evaluated and presented to verify the effectiveness and accuracy of the enhanced depth image quality approach for underwater robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "In The 26th National Conference on Electronics, Communications and Information Technology (REV-ECIT 2023), Hanoi, Vietnam, in Vietnamese language"
    },
    {
        "paper id": "2411.05360",
        "abstract url": "https://arxiv.org/abs/2411.05360",
        "title": "Quantum Rewinding for IOP-Based Succinct Arguments",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We analyze the post-quantum security of succinct interactive arguments constructed from interactive oracle proofs (IOPs) and vector commitment schemes. We prove that an interactive variant of the BCS transformation is secure in the standard model against quantum adversaries when the vector commitment scheme is collapsing. Our proof builds on and extends prior work on the post-quantum security of Kilians succinct interactive argument, which is instead based on probabilistically checkable proofs (PCPs). We introduce a new quantum rewinding strategy that works across any number of rounds. As a consequence of our results, we obtain standard-model post-quantum secure succinct arguments with the best asymptotic complexity known.",
        "subjects": [
            "cs.CR",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05418",
        "abstract url": "https://arxiv.org/abs/2411.05418",
        "title": "Development of Underactuated Geometric Compliant (UGC) Module with Variable Radial for Robotic Applications",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics",
                "robot"
            ]
        ],
        "abstract": "This paper introduces a novel underactuated geometric compliant (UGC) robot and investigates the behaviors of underactuated compliant modules with variable radial stiffness, aiming to enhance the versatility and functionality of UGC robots. We initiate the study by designing and fabricating various compliant semi-rigid geometric joints, each tailored to a specific design objective. These joints undergo physical testing to validate their stiffness characteristics and returnable angles as durability factors. Subsequently, we develop a mathematical model based on Gaussian process regression to incorporate the different geometric joint characteristics, including thickness, facilitating the development of fully functional prototypes with easy-to-3D print models. After analyzing individual joints, we present various configurational combinations to construct the overall UGC module for robotics applications. Our final prototype UGC can dynamically alter its radius, reducing to 80-85\\% of its original value while maintaining structural integrity and operational efficiency. This study discusses potential abilities, challenges, and limitations associated with employing UGC modules, offering valuable insights for future research and developments in UGC robotics.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted to TAROS 2024"
    },
    {
        "paper id": "2411.05420",
        "abstract url": "https://arxiv.org/abs/2411.05420",
        "title": "WeatherGFM: Learning A Weather Generalist Foundation Model via In-context Learning",
        "rating": "-2",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The Earth's weather system encompasses intricate weather data modalities and diverse weather understanding tasks, which hold significant value to human life. Existing data-driven models focus on single weather understanding tasks (e.g., weather forecasting). Although these models have achieved promising results, they fail to tackle various complex tasks within a single and unified model. Moreover, the paradigm that relies on limited real observations for a single scenario hinders the model's performance upper bound. In response to these limitations, we draw inspiration from the in-context learning paradigm employed in state-of-the-art visual foundation models and large language models. In this paper, we introduce the first generalist weather foundation model (WeatherGFM), designed to address a wide spectrum of weather understanding tasks in a unified manner. More specifically, we initially unify the representation and definition of the diverse weather understanding tasks. Subsequently, we devised weather prompt formats to manage different weather data modalities, namely single, multiple, and temporal modalities. Finally, we adopt a visual prompting question-answering paradigm for the training of unified weather understanding tasks. Extensive experiments indicate that our WeatherGFM can effectively handle up to ten weather understanding tasks, including weather forecasting, super-resolution, weather image translation, and post-processing. Our method also showcases generalization ability on unseen tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05450",
        "abstract url": "https://arxiv.org/abs/2411.05450",
        "title": "Analysing control-theoretic properties of nonlinear synthetic biology circuits",
        "rating": "-2",
        "keywords": [
            [
                "biology"
            ]
        ],
        "abstract": "Synthetic biology is a recent area of biological engineering, whose aim is to provide cells with novel functionalities. A number of important results regarding the development of control circuits in synthetic biology have been achieved during the last decade. A differential geometry approach can be used for the analysis of said systems, which are often nonlinear. Here we demonstrate the application of such tools to analyse the structural identifiability, observability, accessibility, and controllability of several biomolecular systems. We focus on a set of synthetic circuits of current interest, which can perform several tasks, both in open loop and closed loop settings. We analyse their properties with our own methods and tools; further, we describe a new open-source implementation of the techniques.",
        "subjects": [
            "eess.SY",
            "q-bio.QM"
        ],
        "comment": "7 pages, 1 figure, submitted to DYCOPS2025"
    },
    {
        "paper id": "2411.05478",
        "abstract url": "https://arxiv.org/abs/2411.05478",
        "title": "Cell Balancing Paradigms: Advanced Types, Algorithms, and Optimization Frameworks",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "The operation efficiency of the electric transportation, energy storage, and grids mainly depends on the fundamental characteristics of the employed batteries. Fundamental variables like voltage, current, temperature, and estimated parameters, like the State of Charge (SoC) of the battery pack, influence the functionality of the system. This motivates the implementation of a Battery Management System (BMS), critical for managing and maintaining the health, safety, and performance of a battery pack. This is ensured by measuring parameters like temperature, cell voltage, and pack current. It also involves monitoring insulation levels and fire hazards, while assessing the prevailing useful life of the batteries and estimating the SoC and State of Health (SoH). Additionally, the system manages and controls key activities like cell balancing and charge/discharge processes. Thus functioning of the battery can be optimised, by guaranteeing the vital parameters to be well within the prescribed range. This article discusses the several cell balancing schemes, and focuses on the intricacies of cell balancing algorithms and optimisation methods for cell balancing. We begin surveying recent cell balancing algorithms and then provide selection guidelines taking into account their advantages, disadvantages, and applications. Finally, we discuss various optimization algorithms and outline the essential parameters involved in the cell balancing process.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "33 pages, 8 figures, 14 tables, and 13 equations"
    },
    {
        "paper id": "2411.05516",
        "abstract url": "https://arxiv.org/abs/2411.05516",
        "title": "EROAS: 3D Efficient Reactive Obstacle Avoidance System for Autonomous Underwater Vehicles using 2.5D Forward-Looking Sonar",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "Advances in Autonomous Underwater Vehicles (AUVs) have evolved vastly in short period of time. While advancements in sonar and camera technology with deep learning aid the obstacle detection and path planning to a great extent, achieving the right balance between computational resources , precision and safety maintained remains a challenge. Finding optimal solutions for real-time navigation in cluttered environments becomes pivotal as systems have to process large amounts of data efficiently. In this work, we propose a novel obstacle avoidance method for navigating 3D underwater environments. This approach utilizes a standard multibeam forward-looking sonar to detect and map obstacle in 3D environment. Instead of using computationally expensive 3D sensors, we pivot the 2D sonar to get 3D heuristic data effectively transforming the sensor into a 2.5D sonar for real-time 3D navigation decisions. This approach enhances obstacle detection and navigation by leveraging the simplicity of 2D sonar with the depth perception typically associated with 3D systems. We have further incorporated Control Barrier Function (CBF) as a filter to ensure safety of the AUV. The effectiveness of this algorithm was tested on a six degrees of freedom (DOF) rover in various simulation scenarios. The results demonstrate that the system successfully avoids obstacles and navigates toward predefined goals, showcasing its capability to manage complex underwater environments with precision. This paper highlights the potential of 2.5D sonar for improving AUV navigation and offers insights into future enhancements and applications of this technology in underwater autonomous systems. \\url{https://github.com/AIRLabIISc/EROAS}",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to ICRA 2025"
    },
    {
        "paper id": "2411.05533",
        "abstract url": "https://arxiv.org/abs/2411.05533",
        "title": "Analyzing Logs of Large-Scale Software Systems using Time Curves Visualization",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "Logs are crucial for analyzing large-scale software systems, offering insights into system health, performance, security threats, potential bugs, etc. However, their chaotic nature$\\unicode{x2013}$characterized by sheer volume, lack of standards, and variability$\\unicode{x2013}$makes manual analysis complex. The use of clustering algorithms can assist by grouping logs into a smaller set of templates, but lose the temporal and relational context in doing so. On the contrary, Large Language Models (LLMs) can provide meaningful explanations but struggle with processing large collections efficiently. Moreover, representation techniques for both approaches are typically limited to either plain text or traditional charting, especially when dealing with large-scale systems. In this paper, we combine clustering and LLM summarization with event detection and Multidimensional Scaling through the use of Time Curves to produce a holistic pipeline that enables efficient and automatic summarization of vast collections of software system logs. The core of our approach is the proposal of a semimetric distance that effectively measures similarity between events, thus enabling a meaningful representation. We show that our method can explain the main events of logs collected from different applications without prior knowledge. We also show how the approach can be used to detect general trends as well as outliers in parallel and distributed systems by overlapping multiple projections. As a result, we expect a significant reduction of the time required to analyze and resolve system-wide issues, identify performance bottlenecks and security risks, debug applications, etc.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05557",
        "abstract url": "https://arxiv.org/abs/2411.05557",
        "title": "A Nerf-Based Color Consistency Method for Remote Sensing Images",
        "rating": "-2",
        "keywords": [
            [
                "Nerf"
            ],
            [
                "Remote Sensing",
                "UAV",
                "satellite"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Due to different seasons, illumination, and atmospheric conditions, the photometric of the acquired image varies greatly, which leads to obvious stitching seams at the edges of the mosaic image. Traditional methods can be divided into two categories, one is absolute radiation correction and the other is relative radiation normalization. We propose a NeRF-based method of color consistency correction for multi-view images, which weaves image features together using implicit expressions, and then re-illuminates feature space to generate a fusion image with a new perspective. We chose Superview-1 satellite images and UAV images with large range and time difference for the experiment. Experimental results show that the synthesize image generated by our method has excellent visual effect and smooth color transition at the edges.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "4 pages, 4 figures, The International Geoscience and Remote Sensing Symposium (IGARSS2023)"
    },
    {
        "paper id": "2411.05574",
        "abstract url": "https://arxiv.org/abs/2411.05574",
        "title": "Parameterized Voter Relevance in Facility Location Games with Tree-Shaped Invitation Graphs",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Graphs"
            ]
        ],
        "abstract": "Diffusion mechanism design, which investigate how to incentivise agents to invite as many colleagues to a multi-agent decision making as possible, is a new research paradigm at the intersection between microeconomics and computer science. In this paper we extend traditional facility location games into the model of diffusion mechanism design. Our objective is to completely understand to what extent of anonymity/voter-relevance we can achieve, along with strategy-proofness and Pareto efficiency when voters strategically invite collegues. We define a series of anonymity properties applicable to the diffusion mechanism design model, as well as parameterized voter-relevance properties for guaranteeing reasonably-fair decision making. We obtained two impossibility theorems and two existence theorems, which partially answer the question we have raised in the beginning of the paper",
        "subjects": [
            "cs.GT",
            "econ.TH"
        ],
        "comment": "To appear in Proceedings of WALCOM-25"
    },
    {
        "paper id": "2411.05584",
        "abstract url": "https://arxiv.org/abs/2411.05584",
        "title": "Mitigating Consequences of Prestige in Citations of Publications",
        "rating": "-2",
        "keywords": [
            [
                "biomedical"
            ]
        ],
        "abstract": "For many public research organizations, funding creation of science and maximizing scientific output is of central interest. Typically, when evaluating scientific production for funding, citations are utilized as a proxy, although these are severely influenced by factors beyond scientific impact. This study aims to mitigate the consequences of the Matthew effect in citations, where prominent authors and prestigious journals receive more citations regardless of the scientific content of the publications. To this end, the study presents an approach to predicting citations of papers based solely on observable characteristics available at the submission stage of a double-blind peer-review process. Combining classical linear models, generalized linear models and utilizing large-scale data sets on biomedical papers based on the PubMed database, the results demonstrate that it is possible to make fairly accurate predictions of citations using only observable characteristics of papers excluding information on authors and journals, thereby mitigating the Matthew effect. Thus, the outcomes have important implications for the field of scientometrics, providing a more objective method for citation prediction by relying on pre-publication variables that are immune to manipulation by authors and journals, thereby enhancing the objectivity of the evaluation process. Our approach is thus important for government agencies responsible for funding the creation of high-quality scientific content rather than perpetuating prestige.",
        "subjects": [
            "cs.DL",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05616",
        "abstract url": "https://arxiv.org/abs/2411.05616",
        "title": "Learning-based Nonlinear Model Predictive Control of Articulated Soft Robots using Recurrent Neural Networks",
        "rating": "-2",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Soft robots pose difficulties in terms of control, requiring novel strategies to effectively manipulate their compliant structures. Model-based approaches face challenges due to the high dimensionality and nonlinearities such as hysteresis effects. In contrast, learning-based approaches provide nonlinear models of different soft robots based only on measured data. In this paper, recurrent neural networks (RNNs) predict the behavior of an articulated soft robot (ASR) with five degrees of freedom (DoF). RNNs based on gated recurrent units (GRUs) are compared to the more commonly used long short-term memory (LSTM) networks and show better accuracy. The recurrence enables the capture of hysteresis effects that are inherent in soft robots due to viscoelasticity or friction but cannot be captured by simple feedforward networks. The data-driven model is used within a nonlinear model predictive control (NMPC), whereby the correct handling of the RNN's hidden states is focused. A training approach is presented that allows measured values to be utilized in each control cycle. This enables accurate predictions of short horizons based on sensor data, which is crucial for closed-loop NMPC. The proposed learning-based NMPC enables trajectory tracking with an average error of 1.2deg in experiments with the pneumatic five-DoF ASR.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted for publication in IEEE Robotics and Automation Letters (RA-L) 2024"
    },
    {
        "paper id": "2411.05655",
        "abstract url": "https://arxiv.org/abs/2411.05655",
        "title": "Joint Age and Coverage-Optimal Satellite Constellation Relaying in Cislunar Communications with Hybrid Orbits",
        "rating": "-2",
        "keywords": [
            [
                "Satellite"
            ]
        ],
        "abstract": "With the ever-increasing lunar missions, a growing interest develops in designing data relay satellite constellations for cislunar communications, which is challenged by the constrained visibility and huge distance between the earth and moon in pursuit of establishing real-time communication links. In this work, therefore, we propose an age and coverage optimal relay satellite constellation for cislunar communication by considering the self-rotation of the earth as well as the orbital motion of the moon, which consists of hybrid Earth-Moon Libration 1/2 (EML1/L2) points Halo orbits, ordinary lunar orbits, and Geostationary Earth Orbit (GEO) satellites. In particular, by minimizing both the number of satellites and the average per-device Age of Information (AoI) while maximizing the coverage ratio of specific lunar surface regions, a multi-objective optimization problem is formulated and solved by using a well-designed Nondominated Sorting Genetic Algorithm-II (NSGA-II). The simulation results demonstrate that our proposed hybrid constellation significantly outperforms traditional Walker Star and Delta constellations in terms of both AoI and the coverage of communication.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "13pages,10figures"
    },
    {
        "paper id": "2411.05664",
        "abstract url": "https://arxiv.org/abs/2411.05664",
        "title": "Digital Twin Backed Closed-Loops for Energy-Aware and Open RAN-based Fixed Wireless Access Serving Rural Areas",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Internet access in rural areas should be improved to support digital inclusion and 5G services. Due to the high deployment costs of fiber optics in these areas, Fixed Wireless Access (FWA) has become a preferable alternative. Additionally, the Open Radio Access Network (O-RAN) can facilitate the interoperability of FWA elements, allowing some FWA functions to be deployed at the edge cloud. However, deploying edge clouds in rural areas can increase network and energy costs. To address these challenges, we propose a closed-loop system assisted by a Digital Twin (DT) to automate energy-aware O-RAN based FWA resource management in rural areas. We consider the FWA and edge cloud as the Physical Twin (PT) and design a closed-loop that distributes radio resources to edge cloud instances for scheduling. We develop another closed-loop for intra-slice resource allocation to houses. We design an energy model that integrates radio resource allocation and formulate ultra-small and small-timescale optimizations for the PT to maximize slice requirement satisfaction while minimizing energy costs. We then design a reinforcement learning approach and successive convex approximation to address the formulated problems. We present a DT that replicates the PT by incorporating solution experiences into future states. The results show that our approach efficiently uses radio and energy resources.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05697",
        "abstract url": "https://arxiv.org/abs/2411.05697",
        "title": "IPMN Risk Assessment under Federated Learning Paradigm",
        "rating": "-2",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "medical",
                "MRI"
            ],
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "Accurate classification of Intraductal Papillary Mucinous Neoplasms (IPMN) is essential for identifying high-risk cases that require timely intervention. In this study, we develop a federated learning framework for multi-center IPMN classification utilizing a comprehensive pancreas MRI dataset. This dataset includes 653 T1-weighted and 656 T2-weighted MRI images, accompanied by corresponding IPMN risk scores from 7 leading medical institutions, making it the largest and most diverse dataset for IPMN classification to date. We assess the performance of DenseNet-121 in both centralized and federated settings for training on distributed data. Our results demonstrate that the federated learning approach achieves high classification accuracy comparable to centralized learning while ensuring data privacy across institutions. This work marks a significant advancement in collaborative IPMN classification, facilitating secure and high-accuracy model training across multiple centers.",
        "subjects": [
            "eess.IV",
            "cs.DC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05699",
        "abstract url": "https://arxiv.org/abs/2411.05699",
        "title": "Renewable Energy Powered and Open RAN-based Architecture for 5G Fixed Wireless Access Provisioning in Rural Areas",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Due to the high costs of optical fiber deployment in Low-Density and Rural Areas (LDRAs), 5G Fixed Wireless Access (5G FWA) recently emerged as an affordable solution. A widely adopted deployment scenario of 5G FWA includes edge cloud that supports computing services and Radio Access Network (RAN) functions. Such edge cloud requires network and energy resources for 5G FWA. This paper proposes renewable energy powered and Open RAN-based architecture for 5G FWA serving LDRAs using three-level closed-loops. Open RAN is a new 5G RAN architecture allowing Open Central Unit and Open Distributed Unit to be distributed in virtualized environment. The first closed-loop distributes radio resources to Open RAN instances and slices at the edge cloud. The second closed-loop allocates radio resources to houses. We design a new energy model that leverages renewable energy. We jointly optimize radio and energy resource allocation in closed-loop 3. We formulate ultra-small and small-time scale optimization problems that link closed-loops to maximize communication utility while minimizing energy costs. We propose reinforcement learning and successive convex approximation to solve the formulated problems. Then, we use solution data and continual learning to improve resource allocation on a large timescale. Our proposal satisfies 97.14% slice delay budget.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05736",
        "abstract url": "https://arxiv.org/abs/2411.05736",
        "title": "Unstructured Adiabatic Quantum Optimization: Optimality with Limitations",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "In the circuit model of quantum computing, amplitude amplification techniques can be used to find solutions to NP-hard problems defined on $n$-bits in time $\\text{poly}(n) 2^{n/2}$. In this work, we investigate whether such general statements can be made for adiabatic quantum optimization, as provable results regarding its performance are mostly unknown. Although a lower bound of $\u03a9(2^{n/2})$ has existed in such a setting for over a decade, a purely adiabatic algorithm with this running time has been absent. We show that adiabatic quantum optimization using an unstructured search approach results in a running time that matches this lower bound (up to a polylogarithmic factor) for a broad class of classical local spin Hamiltonians. For this, it is necessary to bound the spectral gap throughout the adiabatic evolution and compute beforehand the position of the avoided crossing with sufficient precision so as to adapt the adiabatic schedule accordingly. However, we show that the position of the avoided crossing is approximately given by a quantity that depends on the degeneracies and inverse gaps of the problem Hamiltonian and is NP-hard to compute even within a low additive precision. Furthermore, computing it exactly (or nearly exactly) is \\#P-hard. Our work indicates a possible limitation of adiabatic quantum optimization algorithms, leaving open the question of whether provable Grover-like speed-ups can be obtained for any optimization problem using this approach.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.DS"
        ],
        "comment": "29+17 pages, 3 figures"
    },
    {
        "paper id": "2411.05887",
        "abstract url": "https://arxiv.org/abs/2411.05887",
        "title": "Predictive Digital Twin for Condition Monitoring Using Thermal Imaging",
        "rating": "-2",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "Thermal"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "This paper explores the development and practical application of a predictive digital twin specifically designed for condition monitoring, using advanced mathematical models and thermal imaging techniques. Our work presents a comprehensive approach to integrating Proper Orthogonal Decomposition (POD), Robust Principal Component Analysis (RPCA), and Dynamic Mode Decomposition (DMD) to establish a robust predictive digital twin framework. We employ these methods in a real-time experimental setup involving a heated plate monitored through thermal imaging. This system effectively demonstrates the digital twin's capabilities in real-time predictions, condition monitoring, and anomaly detection. Additionally, we introduce the use of a human-machine interface that includes virtual reality, enhancing user interaction and system understanding. The primary contributions of our research lie in the demonstration of these advanced techniques in a tangible setup, showcasing the potential of digital twins to transform industry practices by enabling more proactive and strategic asset management.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05901",
        "abstract url": "https://arxiv.org/abs/2411.05901",
        "title": "ViT Enhanced Privacy-Preserving Secure Medical Data Sharing and Classification",
        "rating": "-2",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Medical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Privacy-preserving and secure data sharing are critical for medical image analysis while maintaining accuracy and minimizing computational overhead are also crucial. Applying existing deep neural networks (DNNs) to encrypted medical data is not always easy and often compromises performance and security. To address these limitations, this research introduces a secure framework consisting of a learnable encryption method based on the block-pixel operation to encrypt the data and subsequently integrate it with the Vision Transformer (ViT). The proposed framework ensures data privacy and security by creating unique scrambling patterns per key, providing robust performance against leading bit attacks and minimum difference attacks.",
        "subjects": [
            "cs.CR",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "2 pages, 2 figures"
    },
    {
        "paper id": "2411.05902",
        "abstract url": "https://arxiv.org/abs/2411.05902",
        "title": "Autoregressive Models in Vision: A Survey",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Autoregressive modeling has been a huge success in the field of natural language processing (NLP). Recently, autoregressive models have emerged as a significant area of focus in computer vision, where they excel in producing high-quality visual content. Autoregressive models in NLP typically operate on subword tokens. However, the representation strategy in computer vision can vary in different levels, \\textit{i.e.}, pixel-level, token-level, or scale-level, reflecting the diverse and hierarchical nature of visual data compared to the sequential structure of language. This survey comprehensively examines the literature on autoregressive models applied to vision. To improve readability for researchers from diverse research backgrounds, we start with preliminary sequence representation and modeling in vision. Next, we divide the fundamental frameworks of visual autoregressive models into three general sub-categories, including pixel-based, token-based, and scale-based models based on the strategy of representation. We then explore the interconnections between autoregressive models and other generative models. Furthermore, we present a multi-faceted categorization of autoregressive models in computer vision, including image generation, video generation, 3D generation, and multi-modal generation. We also elaborate on their applications in diverse domains, including emerging domains such as embodied AI and 3D medical AI, with about 250 related references. Finally, we highlight the current challenges to autoregressive models in vision with suggestions about potential research directions. We have also set up a Github repository to organize the papers included in this survey at: \\url{https://github.com/ChaofanTao/Autoregressive-Models-in-Vision-Survey}.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05904",
        "abstract url": "https://arxiv.org/abs/2411.05904",
        "title": "Autonomous Industrial Control using an Agentic Framework with Large Language Models",
        "rating": "-2",
        "keywords": [
            [
                "Industrial",
                "chemical"
            ]
        ],
        "abstract": "As chemical plants evolve towards full autonomy, the need for effective fault handling and control in dynamic, unpredictable environments becomes increasingly critical. This paper proposes an innovative approach to industrial automation, introducing validation and reprompting architectures utilizing large language model (LLM)-based autonomous control agents. The proposed agentic system, comprising of operator, validator, and reprompter agents, enables autonomous management of control tasks, adapting to unforeseen disturbances without human intervention. By utilizing validation and reprompting architectures, the framework allows agents to recover from errors and continuously improve decision-making in real-time industrial scenarios. We hypothesize that this mechanism will enhance performance and reliability across a variety of LLMs, offering a path toward fully autonomous systems capable of handling unexpected challenges, paving the way for robust, adaptive control in complex industrial environments. To demonstrate the concept's effectiveness, we created a simple case study involving a temperature control experiment embedded on a microcontroller device, validating the proposed approach.",
        "subjects": [
            "cs.MA",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05963",
        "abstract url": "https://arxiv.org/abs/2411.05963",
        "title": "Assessing Foundational Medical 'Segment Anything' (Med-SAM1, Med-SAM2) Deep Learning Models for Left Atrial Segmentation in 3D LGE MRI",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Medical",
                "MRI",
                "cardiac"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Atrial fibrillation (AF), the most common cardiac arrhythmia, is associated with heart failure and stroke. Accurate segmentation of the left atrium (LA) in 3D late gadolinium-enhanced (LGE) MRI is helpful for evaluating AF, as fibrotic remodeling in the LA myocardium contributes to arrhythmia and serves as a key determinant of therapeutic strategies. However, manual LA segmentation is labor-intensive and challenging. Recent foundational deep learning models, such as the Segment Anything Model (SAM), pre-trained on diverse datasets, have demonstrated promise in generic segmentation tasks. MedSAM, a fine-tuned version of SAM for medical applications, enables efficient, zero-shot segmentation without domain-specific training. Despite the potential of MedSAM model, it has not yet been evaluated for the complex task of LA segmentation in 3D LGE-MRI. This study aims to (1) evaluate the performance of MedSAM in automating LA segmentation, (2) compare the performance of the MedSAM2 model, which uses a single prompt with automated tracking, with the MedSAM1 model, which requires separate prompt for each slice, and (3) analyze the performance of MedSAM1 in terms of Dice score(i.e., segmentation accuracy) by varying the size and location of the box prompt.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05993",
        "abstract url": "https://arxiv.org/abs/2411.05993",
        "title": "A Modular Conditional Diffusion Framework for Image Reconstruction",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "super-resolution"
            ],
            [
                "image restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion Probabilistic Models (DPMs) have been recently utilized to deal with various blind image restoration (IR) tasks, where they have demonstrated outstanding performance in terms of perceptual quality. However, the task-specific nature of existing solutions and the excessive computational costs related to their training, make such models impractical and challenging to use for different IR tasks than those that were initially trained for. This hinders their wider adoption, especially by those who lack access to powerful computational resources and vast amount of training data. In this work we aim to address the above issues and enable the successful adoption of DPMs in practical IR-related applications. Towards this goal, we propose a modular diffusion probabilistic IR framework (DP-IR), which allows us to combine the performance benefits of existing pre-trained state-of-the-art IR networks and generative DPMs, while it requires only the additional training of a relatively small module (0.7M params) related to the particular IR task of interest. Moreover, the architecture of the proposed framework allows for a sampling strategy that leads to at least four times reduction of neural function evaluations without suffering any performance loss, while it can also be combined with existing acceleration techniques such as DDIM. We evaluate our model on four benchmarks for the tasks of burst JDD-SR, dynamic scene deblurring, and super-resolution. Our method outperforms existing approaches in terms of perceptual quality while it retains a competitive performance with respect to fidelity metrics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05994",
        "abstract url": "https://arxiv.org/abs/2411.05994",
        "title": "Modelling, design and control of middle-size tilt-rotor quadrotor",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "flight"
            ]
        ],
        "abstract": "This paper explores the mathematical modelling and 3D design of a tilt-rotor quadrotor aircraft. The aircraft is a VTOL design and has capacity for one pilot. The design incorporates a part manual part automatic computerised flight control system and hybrid powertrain providing energy to eight ducted contrarotating propellers. Analysis of controllability was performed using the parameters derived from the developed model for the take-off phase of flight. The aircraft is of a lightweight design and is intended to fill a niche in the aviation market with potential for civilian and military applications. The aircraft has multiple redundancies in the instance of propeller failure. The viability of a hybrid powerplant is explored by combining industry standard gas turbine technology with electrical motor and battery systems. The combination of these systems results in a safe, versatile aircraft that can operate at different levels of automation depending on environmental factors or phase of flight. Simulation confirms the design of the aircraft.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05999",
        "abstract url": "https://arxiv.org/abs/2411.05999",
        "title": "Cyber-Physical Security of Vehicles: Zero Dynamics Attacks Against Vehicle's Lateral Dynamics",
        "rating": "-2",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "Attacks"
            ]
        ],
        "abstract": "Modern vehicles have evolved from mechanical systems to complex and connected ones controlled by numerous digital computers interconnected through internal networks. While this development has improved their efficiency and safety, it also brings new potential risks, particularly cyber-attacks. Several studies have explored the security of vehicle dynamics against such threats. Among these dynamics, the vehicle's lateral dynamics are crucial for maintaining stability and control during turns and maneuvers, making them a key focus of research. However, only a few recent studies have specifically investigated the security of lateral dynamics. This paper explores the potential for zero dynamics attacks on the vehicle's lateral dynamics, where the attacker can remain undetected by leaving no trace on the system's outputs. Three scenarios are studied: when the output includes yaw rate, lateral acceleration, and their combination. These two critical measurements of a vehicle's lateral motion are accessible through the inertial measurement units (IMU) in every vehicle. For each scenario, the impact of zero dynamics attacks on system performance is analyzed and illustrated through simulations. Finally, the paper provides recommendations for securing vehicles' lateral dynamics against such attacks.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "Submitted to the 23rd European Control Conference (ECC)"
    },
    {
        "paper id": "2411.06021",
        "abstract url": "https://arxiv.org/abs/2411.06021",
        "title": "Advanced Network Planning in 6G Smart Radio Environments",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "The growing demand for high-speed, reliable wireless connectivity in 6G networks necessitates innovative approaches to overcome the limitations of traditional Radio Access Network (RAN). Reconfigurable Intelligent Surface (RIS) and Network-Controlled Repeater (NCR) have emerged as promising technologies to address coverage challenges in high-frequency millimeter wave (mmW) bands by enhancing signal reach in environments susceptible to blockage and severe propagation losses. In this paper, we propose an optimized deployment framework aimed at minimizing infrastructure costs while ensuring full area coverage using only RIS and NCR. We formulate a cost-minimization optimization problem that integrates the deployment and configuration of these devices to achieve seamless coverage, particularly in dense urban scenarios. Simulation results confirm that this framework significantly reduces the network planning costs while guaranteeing full coverage, demonstrating RIS and NCR's viability as cost-effective solutions for next-generation network infrastructure.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": "Submitted to IEEE International Conference on Communications 2025"
    },
    {
        "paper id": "2411.07805",
        "abstract url": "https://arxiv.org/abs/2411.07805",
        "title": "Effects of charging and discharging capabilities on trade-offs between model accuracy and computational efficiency in pumped thermal electricity storage",
        "rating": "-2",
        "keywords": [
            [
                "thermal"
            ]
        ],
        "abstract": "The increasing need for energy storage solutions to balance variable renewable energy sources has highlighted the potential of Pumped Thermal Electricity Storage (PTES). In this paper, we investigate the trade-offs between model accuracy and computational efficiency in PTES systems. We evaluate a range of PTES models, from physically detailed to simplified variants, focusing on their non-linear charging and discharging capabilities. Our results show that while detailed models provide the most accurate representation of PTES operation by considering mass flow rate ($\\dot{m}$) and state of charge (SoC) dependencies, they come at the cost of increased computational complexity. In contrast, simplified models tend to produce overly optimistic predictions by disregarding capability constraints. Other approximated model variants offer a practical compromise, balancing computational efficiency with acceptable accuracy. In particular, models that disregard $\\dot{m}$-dependency and approximate nonlinear SoC-dependency with a piecewise linear function achieve similar accuracy to more detailed models but with significantly faster computation times. Our findings offer guidance to modelers in selecting the appropriate PTES representation for their investment models.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05486",
        "abstract url": "https://arxiv.org/abs/2411.05486",
        "title": "Handling geometrical variability in nonlinear reduced order modeling through Continuous Geometry-Aware DL-ROMs",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "biology"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep Learning-based Reduced Order Models (DL-ROMs) provide nowadays a well-established class of accurate surrogate models for complex physical systems described by parametrized PDEs, by nonlinearly compressing the solution manifold into a handful of latent coordinates. Until now, design and application of DL-ROMs mainly focused on physically parameterized problems. Within this work, we provide a novel extension of these architectures to problems featuring geometrical variability and parametrized domains, namely, we propose Continuous Geometry-Aware DL-ROMs (CGA-DL-ROMs). In particular, the space-continuous nature of the proposed architecture matches the need to deal with multi-resolution datasets, which are quite common in the case of geometrically parametrized problems. Moreover, CGA-DL-ROMs are endowed with a strong inductive bias that makes them aware of geometrical parametrizations, thus enhancing both the compression capability and the overall performance of the architecture. Within this work, we justify our findings through a thorough theoretical analysis, and we practically validate our claims by means of a series of numerical tests encompassing physically-and-geometrically parametrized PDEs, ranging from the unsteady Navier-Stokes equations for fluid dynamics to advection-diffusion-reaction equations for mathematical biology.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": "30 pages, 15 figures"
    },
    {
        "paper id": "2411.05596",
        "abstract url": "https://arxiv.org/abs/2411.05596",
        "title": "Machine learning-driven Anomaly Detection and Forecasting for Euclid Space Telescope Operations",
        "rating": "-2.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "State-of-the-art space science missions increasingly rely on automation due to spacecraft complexity and the costs of human oversight. The high volume of data, including scientific and telemetry data, makes manual inspection challenging. Machine learning offers significant potential to meet these demands. The Euclid space telescope, in its survey phase since February 2024, exemplifies this shift. Euclid's success depends on accurate monitoring and interpretation of housekeeping telemetry and science-derived data. Thousands of telemetry parameters, monitored as time series, may or may not impact the quality of scientific data. These parameters have complex interdependencies, often due to physical relationships (e.g., proximity of temperature sensors). Optimising science operations requires careful anomaly detection and identification of hidden parameter states. Moreover, understanding the interactions between known anomalies and physical quantities is crucial yet complex, as related parameters may display anomalies with varied timing and intensity. We address these challenges by analysing temperature anomalies in Euclid's telemetry from February to August 2024, focusing on eleven temperature parameters and 35 covariates. We use a predictive XGBoost model to forecast temperatures based on historical values, detecting anomalies as deviations from predictions. A second XGBoost model predicts anomalies from covariates, capturing their relationships to temperature anomalies. We identify the top three anomalies per parameter and analyse their interactions with covariates using SHAP (Shapley Additive Explanations), enabling rapid, automated analysis of complex parameter relationships. Our method demonstrates how machine learning can enhance telemetry monitoring, offering scalable solutions for other missions with similar data challenges.",
        "subjects": [
            "cs.LG",
            "astro-ph.IM"
        ],
        "comment": "Presented at IAC 2024"
    },
    {
        "paper id": "2411.05599",
        "abstract url": "https://arxiv.org/abs/2411.05599",
        "title": "Expectation vs. Reality: Towards Verification of Psychological Games",
        "rating": "-2.5",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "Psychological"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Game theory provides an effective way to model strategic interactions among rational agents. In the context of formal verification, these ideas can be used to produce guarantees on the correctness of multi-agent systems, with a diverse range of applications from computer security to autonomous driving. Psychological games (PGs) were developed as a way to model and analyse agents with belief-dependent motivations, opening up the possibility to model how human emotions can influence behaviour. In PGs, players' utilities depend not only on what actually happens (which strategies players choose to adopt), but also on what the players had expected to happen (their belief as to the strategies that would be played). Despite receiving much attention in fields such as economics and psychology, very little consideration has been given to their applicability to problems in computer science, nor to practical algorithms and tool support. In this paper, we start to bridge that gap, proposing methods to solve PGs and implementing them within PRISM-games, a formal verification tool for stochastic games. We discuss how to model these games, highlight specific challenges for their analysis and illustrate the usefulness of our approach on several case studies, including human behaviour in traffic scenarios.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05618",
        "abstract url": "https://arxiv.org/abs/2411.05618",
        "title": "Knowledge Distillation Neural Network for Predicting Car-following Behaviour of Human-driven and Autonomous Vehicles",
        "rating": "-2.5",
        "keywords": [
            [
                "trajectory",
                "vehicle"
            ],
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "As we move towards a mixed-traffic scenario of Autonomous vehicles (AVs) and Human-driven vehicles (HDVs), understanding the car-following behaviour is important to improve traffic efficiency and road safety. Using a real-world trajectory dataset, this study uses descriptive and statistical analysis to investigate the car-following behaviours of three vehicle pairs: HDV-AV, AV-HDV and HDV-HDV in mixed traffic. The ANOVA test showed that car-following behaviours across different vehicle pairs are statistically significant (p-value < 0.05). We also introduce a data-driven Knowledge Distillation Neural Network (KDNN) model for predicting car-following behaviour in terms of speed. The KDNN model demonstrates comparable predictive accuracy to its teacher network, a Long Short-Term Memory (LSTM) network, and outperforms both the standalone student network, a Multilayer Perceptron (MLP), and traditional physics-based models like the Gipps model. Notably, the KDNN model better prevents collisions, measured by minimum Time-to-Collision (TTC), and operates with lower computational power, making it ideal for AVs or driving simulators requiring efficient computing.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "27th IEEE International Conference on Intelligent Transportation Systems"
    },
    {
        "paper id": "2411.05631",
        "abstract url": "https://arxiv.org/abs/2411.05631",
        "title": "Physics-constrained coupled neural differential equations for one dimensional blood flow modeling",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Computational cardiovascular flow modeling plays a crucial role in understanding blood flow dynamics. While 3D models provide acute details, they are computationally expensive, especially with fluid-structure interaction (FSI) simulations. 1D models offer a computationally efficient alternative, by simplifying the 3D Navier-Stokes equations through axisymmetric flow assumption and cross-sectional averaging. However, traditional 1D models based on finite element methods (FEM) often lack accuracy compared to 3D averaged solutions. This study introduces a novel physics-constrained machine learning technique that enhances the accuracy of 1D blood flow models while maintaining computational efficiency. Our approach, utilizing a physics-constrained coupled neural differential equation (PCNDE) framework, demonstrates superior performance compared to conventional FEM-based 1D models across a wide range of inlet boundary condition waveforms and stenosis blockage ratios. A key innovation lies in the spatial formulation of the momentum conservation equation, departing from the traditional temporal approach and capitalizing on the inherent temporal periodicity of blood flow. This spatial neural differential equation formulation switches space and time and overcomes issues related to coupling stability and smoothness, while simplifying boundary condition implementation. The model accurately captures flow rate, area, and pressure variations for unseen waveforms and geometries. We evaluate the model's robustness to input noise and explore the loss landscapes associated with the inclusion of different physics terms. This advanced 1D modeling technique offers promising potential for rapid cardiovascular simulations, achieving computational efficiency and accuracy. By combining the strengths of physics-based and data-driven modeling, this approach enables fast and accurate cardiovascular simulations.",
        "subjects": [
            "physics.flu-dyn",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05732",
        "abstract url": "https://arxiv.org/abs/2411.05732",
        "title": "Foundations for the psychological safety of human and autonomous vehicles interaction",
        "rating": "-2.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "psychological"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "This paper addresses the critical issue of psychological safety in the design and operation of autonomous vehicles, which are increasingly integrated with artificial intelligence technologies. While traditional safety standards focus primarily on physical safety, this paper emphasizes the psychological implications that arise from human interactions with autonomous vehicles, highlighting the importance of trust and perceived risk as significant factors influencing user acceptance. Through a review of existing safety techniques, the paper defines psychological safety in the context of autonomous vehicles, proposes a risk model to identify and assess psychological risks, and adopts a system-theoretic analysis method. The paper illustrates the potential psychological hazards using a scenario involving a family's experience with an autonomous vehicle, aiming to systematically evaluate situations that could lead to psychological harm. By establishing a framework that incorporates psychological safety alongside physical safety, the paper contributes to the broader discourse on the safe deployment of autonomous vehicle and aims to guide future developments in user-cantered design and regulatory practices.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05742",
        "abstract url": "https://arxiv.org/abs/2411.05742",
        "title": "Topology-aware Reinforcement Feature Space Reconstruction for Graph Data",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Feature space is an environment where data points are vectorized to represent the original dataset. Reconstructing a good feature space is essential to augment the AI power of data, improve model generalization, and increase the availability of downstream ML models. Existing literature, such as feature transformation and feature selection, is labor-intensive (e.g., heavy reliance on empirical experience) and mostly designed for tabular data. Moreover, these methods regard data samples as independent, which ignores the unique topological structure when applied to graph data, thus resulting in a suboptimal reconstruction feature space. Can we consider the topological information to automatically reconstruct feature space for graph data without heavy experiential knowledge? To fill this gap, we leverage topology-aware reinforcement learning to automate and optimize feature space reconstruction for graph data. Our approach combines the extraction of core subgraphs to capture essential structural information with a graph neural network (GNN) to encode topological features and reduce computing complexity. Then we introduce three reinforcement agents within a hierarchical structure to systematically generate meaningful features through an iterative process, effectively reconstructing the feature space. This framework provides a principled solution for attributed graph feature space reconstruction. The extensive experiments demonstrate the effectiveness and efficiency of including topological awareness.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05757",
        "abstract url": "https://arxiv.org/abs/2411.05757",
        "title": "Tract-RLFormer: A Tract-Specific RL policy based Decoder-only Transformer Network",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "MRI"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Fiber tractography is a cornerstone of neuroimaging, enabling the detailed mapping of the brain's white matter pathways through diffusion MRI. This is crucial for understanding brain connectivity and function, making it a valuable tool in neurological applications. Despite its importance, tractography faces challenges due to its complexity and susceptibility to false positives, misrepresenting vital pathways. To address these issues, recent strategies have shifted towards deep learning, utilizing supervised learning, which depends on precise ground truth, or reinforcement learning, which operates without it. In this work, we propose Tract-RLFormer, a network utilizing both supervised and reinforcement learning, in a two-stage policy refinement process that markedly improves the accuracy and generalizability across various data-sets. By employing a tract-specific approach, our network directly delineates the tracts of interest, bypassing the traditional segmentation process. Through rigorous validation on datasets such as TractoInferno, HCP, and ISMRM-2015, our methodology demonstrates a leap forward in tractography, showcasing its ability to accurately map the brain's white matter tracts.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05890",
        "abstract url": "https://arxiv.org/abs/2411.05890",
        "title": "A Comparative Analysis of Machine Learning Models for DDoS Detection in IoT Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents the detection of DDoS attacks in IoT networks using machine learning models. Their rapid growth has made them highly susceptible to various forms of cyberattacks, many of whose security procedures are implemented in an irregular manner. It evaluates the efficacy of different machine learning models, such as XGBoost, K-Nearest Neighbours, Stochastic Gradient Descent, and Na\u00efve Bayes, in detecting DDoS attacks from normal network traffic. Each model has been explained on several performance metrics, such as accuracy, precision, recall, and F1-score to understand the suitability of each model in real-time detection and response against DDoS threats. This comparative analysis will, therefore, enumerate the unique strengths and weaknesses of each model with respect to the IoT environments that are dynamic and hence moving in nature. The effectiveness of these models is analyzed, showing how machine learning can greatly enhance IoT security frameworks, offering adaptive, efficient, and reliable DDoS detection capabilities. These findings have shown the potential of machine learning in addressing the pressing need for robust IoT security solutions that can mitigate modern cyber threats and assure network integrity.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": "6 pages, 6 figures"
    },
    {
        "paper id": "2411.05355",
        "abstract url": "https://arxiv.org/abs/2411.05355",
        "title": "Improving Computational Cost of Bayesian Optimization for Controller Tuning with a Multi-stage Tuning Framework",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "Control auto-tuning for industrial and robotic systems, when framed as an optimization problem, provides an excellent means to tune these systems. However, most optimization methods are computationally costly, and this is problematic for high-dimension control parameter spaces. In this paper, we present a multi-stage control tuning framework that decomposes control tuning into subtasks, each with a reduced-dimension search space. We show formally that this framework reduces the sample complexity of the control-tuning task. We empirically validate this result by applying a Bayesian optimization approach to tuning multiple PID controllers in an unmanned underwater vehicle benchmark system. We demonstrate an 86\\% decrease in computational time and 36\\% decrease in sample complexity.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05421",
        "abstract url": "https://arxiv.org/abs/2411.05421",
        "title": "Learning the rules of peptide self-assembly through data mining with large language models",
        "rating": "-3",
        "keywords": [
            [
                "biologically"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Peptides are ubiquitous and important biologically derived molecules, that have been found to self-assemble to form a wide array of structures. Extensive research has explored the impacts of both internal chemical composition and external environmental stimuli on the self-assembly behaviour of these systems. However, there is yet to be a systematic study that gathers this rich literature data and collectively examines these experimental factors to provide a global picture of the fundamental rules that govern protein self-assembly behavior. In this work, we curate a peptide assembly database through a combination of manual processing by human experts and literature mining facilitated by a large language model. As a result, we collect more than 1,000 experimental data entries with information about peptide sequence, experimental conditions and corresponding self-assembly phases. Utilizing the collected data, ML models are trained and evaluated, demonstrating excellent accuracy (>80\\%) and efficiency in peptide assembly phase classification. Moreover, we fine-tune our GPT model for peptide literature mining with the developed dataset, which exhibits markedly superior performance in extracting information from academic publications relative to the pre-trained model. We find that this workflow can substantially improve efficiency when exploring potential self-assembling peptide candidates, through guiding experimental work, while also deepening our understanding of the mechanisms governing peptide self-assembly. In doing so, novel structures can be accessed for a range of applications including sensing, catalysis and biomaterials.",
        "subjects": [
            "cond-mat.soft",
            "cond-mat.dis-nn",
            "cond-mat.mes-hall",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05456",
        "abstract url": "https://arxiv.org/abs/2411.05456",
        "title": "Comparative Study of Probabilistic Atlas and Deep Learning Approaches for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field Correction and Anisotropic Diffusion Pre-processing Techniques",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "medical",
                "diagnosis",
                "MRI"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. Despite advancements in segmentation techniques, a comprehensive comparison between traditional statistical methods and modern deep learning approaches using pre-processing techniques like N4 Bias Field Correction and Anisotropic Diffusion remains underexplored. This study provides a comparative analysis of various segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these pre-processing techniques to segment brain tissues (white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the Internet Brain Segmentation Repository (IBSR18) dataset. Our results demonstrate that the 3D nnU-Net model outperforms others, achieving the highest mean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model recorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest mean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test samples. The findings highlight the superiority of nnU-Net models in brain tissue segmentation, particularly when combined with N4 Bias Field Correction and Anisotropic Diffusion pre-processing techniques. Our implemented code can be accessed via GitHub.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05510",
        "abstract url": "https://arxiv.org/abs/2411.05510",
        "title": "Fast Stochastic Subspace Identification of Densely Instrumented Bridges Using Randomized SVD",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Health"
            ]
        ],
        "abstract": "The rising number of bridge collapses worldwide has compelled governments to introduce predictive maintenance strategies to extend structural lifespan. In this context, vibration-based Structural Health Monitoring (SHM) techniques utilizing Operational Modal Analysis (OMA) are favored for their non-destructive and global assessment capabilities. However, long multi-span bridges instrumented with dense arrays of accelerometers present a particular challenge, as the computational demands of classical OMA techniques in such cases are incompatible with long-term SHM. To address this issue, this paper introduces Randomized Singular Value Decomposition (RSVD) as an efficient alternative to traditional SVD within Covariance-driven Stochastic Subspace Identification (CoV-SSI). The efficacy of RSVD is also leveraged to enhance modal identification results and reduce the need for expert intervention by means of 3D stabilization diagrams, which facilitate the investigation of the modal estimates over different model orders and time lags. The approach's effectiveness is demonstrated on the San Faustino Bridge in Italy, equipped with over 60 multiaxial accelerometers.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05537",
        "abstract url": "https://arxiv.org/abs/2411.05537",
        "title": "A Lightweight QoS-Aware Resource Allocation Method for NR-V2X Networks",
        "rating": "-3",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "5G"
            ]
        ],
        "abstract": "Vehicle-to-Everything (V2X) communication, which includes Vehicle-to-Infrastructure (V2I), Vehicle-to-Vehicle (V2V), and Vehicle-to-Pedestrian (V2P) networks, is gaining significant attention due to the rise of connected and autonomous vehicles. V2X systems require diverse Quality of Service (QoS) provisions, with V2V communication demanding stricter latency and reliability compared to V2I. The 5G New Radio-V2X (NR-V2X) standard addresses these needs using multi-numerology Orthogonal Frequency Division Multiple Access (OFDMA), which allows for flexible allocation of radio resources. However, V2I and V2V users sharing the same radio resources leads to interference, necessitating efficient power and resource allocation. In this work, we propose a novel resource allocation and sharing algorithm for 5G-based V2X systems. Our approach first groups Resource Blocks (RBs) into Resource Chunks (RCs) and allocates them to V2I users using the Gale-Shapley stable matching algorithm. Power is then allocated to RCs to facilitate efficient resource sharing between V2I and V2V users through a bisection search method. Finally, the Gale-Shapley algorithm is used to pair V2I and V2V users, maintaining low computational complexity while ensuring high performance. Simulation results demonstrate that our proposed Gale-Shapley Resource Allocation with Gale-Shapley Sharing (GSRAGS) achieves competitive performance with lower complexity compared to existing works while effectively meeting the QoS demands of V2X communication systems.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": "8 pages, 10 figures"
    },
    {
        "paper id": "2411.05784",
        "abstract url": "https://arxiv.org/abs/2411.05784",
        "title": "Safe Reinforcement Learning of Robot Trajectories in the Presence of Moving Obstacles",
        "rating": "-3",
        "keywords": [
            [
                "Robot"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "In this paper, we present an approach for learning collision-free robot trajectories in the presence of moving obstacles. As a first step, we train a backup policy to generate evasive movements from arbitrary initial robot states using model-free reinforcement learning. When learning policies for other tasks, the backup policy can be used to estimate the potential risk of a collision and to offer an alternative action if the estimated risk is considered too high. No matter which action is selected, our action space ensures that the kinematic limits of the robot joints are not violated. We analyze and evaluate two different methods for estimating the risk of a collision. A physics simulation performed in the background is computationally expensive but provides the best results in deterministic environments. If a data-based risk estimator is used instead, the computational effort is significantly reduced, but an additional source of error is introduced. For evaluation, we successfully learn a reaching task and a basketball task while keeping the risk of collisions low. The results demonstrate the effectiveness of our approach for deterministic and stochastic environments, including a human-robot scenario and a ball environment, where no state can be considered permanently safe. By conducting experiments with a real robot, we show that our approach can generate safe trajectories in real time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "IEEE Robotics and Automation Letters (RA-L); 8 pages; 7 figures"
    },
    {
        "paper id": "2411.05897",
        "abstract url": "https://arxiv.org/abs/2411.05897",
        "title": "Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators",
        "rating": "-3",
        "keywords": [
            [
                "Medical",
                "diagnosis",
                "disease",
                "Clinical"
            ],
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Although large language models (LLMs) have been assessed for general medical knowledge using medical licensing exams, their ability to effectively support clinical decision-making tasks, such as selecting and using medical calculators, remains uncertain. Here, we evaluate the capability of both medical trainees and LLMs to recommend medical calculators in response to various multiple-choice clinical scenarios such as risk stratification, prognosis, and disease diagnosis. We assessed eight LLMs, including open-source, proprietary, and domain-specific models, with 1,009 question-answer pairs across 35 clinical calculators and measured human performance on a subset of 100 questions. While the highest-performing LLM, GPT-4o, provided an answer accuracy of 74.3% (CI: 71.5-76.9%), human annotators, on average, outperformed LLMs with an accuracy of 79.5% (CI: 73.5-85.0%). With error analysis showing that the highest-performing LLMs continue to make mistakes in comprehension (56.6%) and calculator knowledge (8.1%), our findings emphasize that humans continue to surpass LLMs on complex clinical tasks such as calculator recommendation.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05971",
        "abstract url": "https://arxiv.org/abs/2411.05971",
        "title": "A Kalman Filter model for synchronization in musical ensembles",
        "rating": "-3",
        "keywords": [
            [
                "biological"
            ],
            [
                "music"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "The synchronization of motor responses to rhythmic auditory cues is a fundamental biological phenomenon observed across various species. While the importance of temporal alignment varies across different contexts, achieving precise temporal synchronization is a prominent goal in musical performances. Musicians often incorporate expressive timing variations, which require precise control over timing and synchronization, particularly in ensemble performance. This is crucial because both deliberate expressive nuances and accidental timing deviations can affect the overall timing of a performance. This discussion prompts the question of how musicians adjust their temporal dynamics to achieve synchronization within an ensemble. This paper introduces a novel feedback correction model based on the Kalman Filter, aimed at improving the understanding of interpersonal timing in ensemble music performances. The proposed model performs similarly to other linear correction models in the literature, with the advantage of low computational cost and good performance even in scenarios where the underlying tempo varies.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "7 pages, 1 figure. Accepted for publication on the 25th International Society for Music Information Retrieval (ISMIR 2024)"
    },
    {
        "paper id": "2411.05586",
        "abstract url": "https://arxiv.org/abs/2411.05586",
        "title": "Tangled Program Graphs as an alternative to DRL-based control algorithms for UAVs",
        "rating": "-3.5",
        "keywords": [
            [
                "LiDAR",
                "vehicle"
            ],
            [
                "Graphs"
            ],
            [
                "UAV"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep reinforcement learning (DRL) is currently the most popular AI-based approach to autonomous vehicle control. An agent, trained for this purpose in simulation, can interact with the real environment with a human-level performance. Despite very good results in terms of selected metrics, this approach has some significant drawbacks: high computational requirements and low explainability. Because of that, a DRL-based agent cannot be used in some control tasks, especially when safety is the key issue. Therefore we propose to use Tangled Program Graphs (TPGs) as an alternative for deep reinforcement learning in control-related tasks. In this approach, input signals are processed by simple programs that are combined in a graph structure. As a result, TPGs are less computationally demanding and their actions can be explained based on the graph structure. In this paper, we present our studies on the use of TPGs as an alternative for DRL in control-related tasks. In particular, we consider the problem of navigating an unmanned aerial vehicle (UAV) through the unknown environment based solely on the on-board LiDAR sensor. The results of our work show promising prospects for the use of TPGs in control related-tasks.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "eess.SY"
        ],
        "comment": "The papers was accepted for the 2024 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA) conference in Poznan, Poland"
    },
    {
        "paper id": "2411.05886",
        "abstract url": "https://arxiv.org/abs/2411.05886",
        "title": "UnDIVE: Generalized Underwater Video Enhancement Using Generative Priors",
        "rating": "-3.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Video Enhancement"
            ],
            [
                "physics"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "With the rise of marine exploration, underwater imaging has gained significant attention as a research topic. Underwater video enhancement has become crucial for real-time computer vision tasks in marine exploration. However, most existing methods focus on enhancing individual frames and neglect video temporal dynamics, leading to visually poor enhancements. Furthermore, the lack of ground-truth references limits the use of abundant available underwater video data in many applications. To address these issues, we propose a two-stage framework for enhancing underwater videos. The first stage uses a denoising diffusion probabilistic model to learn a generative prior from unlabeled data, capturing robust and descriptive feature representations. In the second stage, this prior is incorporated into a physics-based image formulation for spatial enhancement, while also enforcing temporal consistency between video frames. Our method enables real-time and computationally-efficient processing of high-resolution underwater videos at lower resolutions, and offers efficient enhancement in the presence of diverse water-types. Extensive experiments on four datasets show that our approach generalizes well and outperforms existing enhancement methods. Our code is available at github.com/suhas-srinath/undive.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted to IEEE/CVF WACV 2025"
    },
    {
        "paper id": "2411.07814",
        "abstract url": "https://arxiv.org/abs/2411.07814",
        "title": "Community Research Earth Digital Intelligence Twin (CREDIT)",
        "rating": "-3.5",
        "keywords": [
            [
                "Forecast"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advancements in artificial intelligence (AI) for numerical weather prediction (NWP) have significantly transformed atmospheric modeling. AI NWP models outperform traditional physics-based systems, such as the Integrated Forecast System (IFS), across several global metrics while requiring fewer computational resources. However, existing AI NWP models face limitations related to training datasets and timestep choices, often resulting in artifacts that reduce model performance. To address these challenges, we introduce the Community Research Earth Digital Intelligence Twin (CREDIT) framework, developed at NSF NCAR. CREDIT provides a flexible, scalable, and user-friendly platform for training and deploying AI-based atmospheric models on high-performance computing systems. It offers an end-to-end pipeline for data preprocessing, model training, and evaluation, democratizing access to advanced AI NWP capabilities. We demonstrate CREDIT's potential through WXFormer, a novel deterministic vision transformer designed to predict atmospheric states autoregressively, addressing common AI NWP issues like compounding error growth with techniques such as spectral normalization, padding, and multi-step training. Additionally, to illustrate CREDIT's flexibility and state-of-the-art model comparisons, we train the FUXI architecture within this framework. Our findings show that both FUXI and WXFormer, trained on six-hourly ERA5 hybrid sigma-pressure levels, generally outperform IFS HRES in 10-day forecasts, offering potential improvements in efficiency and forecast accuracy. CREDIT's modular design enables researchers to explore various models, datasets, and training configurations, fostering innovation within the scientific community.",
        "subjects": [
            "cs.AI",
            "physics.ao-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05342",
        "abstract url": "https://arxiv.org/abs/2411.05342",
        "title": "Development of a Human-Robot Interaction Platform for Dual-Arm Robots Based on ROS and Multimodal Artificial Intelligence",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "Robot"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "In this paper, we propose the development of an interactive platform between humans and a dual-arm robotic system based on the Robot Operating System (ROS) and a multimodal artificial intelligence model. Our proposed platform consists of two main components: a dual-arm robotic hardware system and software that includes image processing tasks and natural language processing using a 3D camera and embedded computing. First, we designed and developed a dual-arm robotic system with a positional accuracy of less than 2 cm, capable of operating independently, performing industrial and service tasks while simultaneously simulating and modeling the robot in the ROS environment. Second, artificial intelligence models for image processing are integrated to execute object picking and classification tasks with an accuracy of over 90%. Finally, we developed remote control software using voice commands through a natural language processing model. Experimental results demonstrate the accuracy of the multimodal artificial intelligence model and the flexibility of the dual-arm robotic system in interactive human environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "In The 25th National Conference on Electronics, Communications and Information Technology (REV-ECIT 2022), Hanoi, Vietnam. in Vietnamese language"
    },
    {
        "paper id": "2411.05411",
        "abstract url": "https://arxiv.org/abs/2411.05411",
        "title": "Quantum Annealing for Active User Detection in NOMA Systems",
        "rating": "-4",
        "keywords": [
            [
                "5G",
                "6G"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Detecting active users in a non-orthogonal multiple access (NOMA) network poses a significant challenge for 5G/6G applications. Traditional algorithms tackling this task, relying on classical processors, have to make a compromise between performance and complexity. However, a quantum computing based strategy called quantum annealing (QA) can mitigate this trade-off. In this paper, we first propose a mapping between the AUD searching problem and the identification of the ground state of an Ising Hamiltonian. Then, we compare the execution times of our QA approach for several code domain multiple access (CDMA) scenarios. We evaluate the impact of the cross-correlation properties of the chosen codes in a NOMA network for detecting the active user's set.",
        "subjects": [
            "quant-ph",
            "eess.SP"
        ],
        "comment": "2024 58th Asilomar Conference on Signals, Systems, and Computers, Oct 2024, Pacific Grove (CA), USA, United States"
    },
    {
        "paper id": "2411.05445",
        "abstract url": "https://arxiv.org/abs/2411.05445",
        "title": "Agile UAV landing control on moving ship in adverse conditions",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "Vehicle",
                "flight"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "This paper presents an agile Unmanned Aerial Vehicle (UAV) landing control by considering the effect of ship's oscillations and moving, and also disturbance (i.e., crosswind) is considered. The presented control system can make the quadrotor UAV autonomously land whilst overcoming these adverse conditions, and the addition of a rudder beneath each propeller is designed to increase the yaw authority which is found to be lacking in heavy-lift quadrotor UAV. The PID flight control system is proposed based on reference-point tracking, allowing the UAV to follow any desired path in 3D space whilst simultaneously yawing to face any desired heading. Realistic saturation limits on actuator outputs to ensure the real-world performance of actuators. Disturbances include randomised gusting wind in 3 axes, and sensor noise on translation and rotation signals to represent noise from the GPS and accelerometer respectively. The results from the simulations demonstrate that the UAV is capable of landing on a ship which is moving with varying heading and oscillating vertically on ocean waves and has the ability to time its descent such that it meets the ship at the peak of a wave to minimise the relative velocity.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05521",
        "abstract url": "https://arxiv.org/abs/2411.05521",
        "title": "SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark",
        "rating": "-4",
        "keywords": [
            [
                "graph"
            ],
            [
                "Medical",
                "health",
                "CT"
            ],
            [
                "SQL"
            ],
            [
                "cs.AI"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Electronic health records (EHRs) are stored in various database systems with different database models on heterogeneous storage architectures, such as relational databases, document stores, or graph databases. These different database models have a big impact on query complexity and performance. While this has been a known fact in database research, its implications for the growing number of Text-to-Query systems have surprisingly not been investigated so far. In this paper, we present SM3-Text-to-Query, the first multi-model medical Text-to-Query benchmark based on synthetic patient data from Synthea, following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology covering medical terminology. SM3-Text-to-Query provides data representations for relational databases (PostgreSQL), document stores (MongoDB), and graph databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically and manually develop 408 template questions, which we augment to construct a benchmark of 10K diverse natural language question/query pairs for these four query languages (40K pairs overall). On our dataset, we evaluate several common in-context-learning (ICL) approaches for a set of representative closed and open-source LLMs. Our evaluation sheds light on the trade-offs between database models and query languages for different ICL strategies and LLMs. Last, SM3-Text-to-Query is easily extendable to additional query languages or real, standard-based patient databases.",
        "subjects": [
            "cs.DB",
            "cs.AI"
        ],
        "comment": "NeurIPS 2024 Track Datasets and Benchmarks"
    },
    {
        "paper id": "2411.05597",
        "abstract url": "https://arxiv.org/abs/2411.05597",
        "title": "Predicting Stroke through Retinal Graphs and Multimodal Self-supervised Learning",
        "rating": "-4",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "medical",
                "health",
                "disease",
                "clinical",
                "Retinal"
            ],
            [
                "tabular"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Early identification of stroke is crucial for intervention, requiring reliable models. We proposed an efficient retinal image representation together with clinical information to capture a comprehensive overview of cardiovascular health, leveraging large multimodal datasets for new medical insights. Our approach is one of the first contrastive frameworks that integrates graph and tabular data, using vessel graphs derived from retinal images for efficient representation. This method, combined with multimodal contrastive learning, significantly enhances stroke prediction accuracy by integrating data from multiple sources and using contrastive learning for transfer learning. The self-supervised learning techniques employed allow the model to learn effectively from unlabeled data, reducing the dependency on large annotated datasets. Our framework showed an AUROC improvement of 3.78% from supervised to self-supervised approaches. Additionally, the graph-level representation approach achieved superior performance to image encoders while significantly reducing pre-training and fine-tuning runtimes. These findings indicate that retinal images are a cost-effective method for improving cardiovascular disease predictions and pave the way for future research into retinal and cerebral vessel connections and the use of graph-based retinal vessel representations.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted as oral paper at ML-CDS workshop, MICCAI 2024"
    },
    {
        "paper id": "2411.05649",
        "abstract url": "https://arxiv.org/abs/2411.05649",
        "title": "Harnessing High-Level Song Descriptors towards Natural Language-Based Music Recommendation",
        "rating": "-4",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "Song",
                "Music"
            ]
        ],
        "abstract": "Recommender systems relying on Language Models (LMs) have gained popularity in assisting users to navigate large catalogs. LMs often exploit item high-level descriptors, i.e. categories or consumption contexts, from training data or user preferences. This has been proven effective in domains like movies or products. However, in the music domain, understanding how effectively LMs utilize song descriptors for natural language-based music recommendation is relatively limited. In this paper, we assess LMs effectiveness in recommending songs based on user natural language descriptions and items with descriptors like genres, moods, and listening contexts. We formulate the recommendation task as a dense retrieval problem and assess LMs as they become increasingly familiar with data pertinent to the task and domain. Our findings reveal improved performance as LMs are fine-tuned for general language similarity, information retrieval, and mapping longer descriptions to shorter, high-level descriptors in music.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05947",
        "abstract url": "https://arxiv.org/abs/2411.05947",
        "title": "Ideal Pseudorandom Codes",
        "rating": "-4",
        "keywords": [
            [
                "watermarking"
            ],
            [
                "Song"
            ]
        ],
        "abstract": "Pseudorandom codes are error-correcting codes with the property that no efficient adversary can distinguish encodings from uniformly random strings. They were recently introduced by Christ and Gunn [CRYPTO 2024] for the purpose of watermarking the outputs of randomized algorithms, such as generative AI models. Several constructions of pseudorandom codes have since been proposed, but none of them are robust to error channels that depend on previously seen codewords. This stronger kind of robustness is referred to as adaptive robustness, and it is important for meaningful applications to watermarking. In this work, we show the following. - Adaptive robustness: We show that the pseudorandom codes of Christ and Gunn are adaptively robust, resolving a conjecture posed by Cohen, Hoover, and Schoenbach [S&P 2025]. - Ideal security: We define an ideal pseudorandom code as one which is indistinguishable from the ideal functionality, capturing both the pseudorandomness and robustness properties in one simple definition. We show that any adaptively robust pseudorandom code for single-bit messages can be bootstrapped to build an ideal pseudorandom code with linear information rate, under no additional assumptions. - CCA security: In the setting where the encoding key is made public, we define a CCA-secure pseudorandom code in analogy with CCA-secure encryption. We show that any adaptively robust public-key pseudorandom code for single-bit messages can be used to build a CCA-secure pseudorandom code with linear information rate, in the random oracle model. These results immediately imply stronger robustness guarantees for generative AI watermarking schemes, such as the practical quality-preserving image watermarks of Gunn, Zhao, and Song (2024).",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08056",
        "abstract url": "https://arxiv.org/abs/2411.08056",
        "title": "Biodynamic Analysis of Alpine Skiing with a Skier-Ski-Snow Interaction Model",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory"
            ],
            [
                "Biodynamic"
            ]
        ],
        "abstract": "This study establishes a skier-ski-snow interaction (SSSI) model that integrates a 3D full-body musculoskeletal model, a flexible ski model, a ski-snow contact model, and an air resistance model. An experimental method is developed to collect kinematic and kinetic data using IMUs, GPS, and plantar pressure measurement insoles, which are cost-effective and capable of capturing motion in large-scale field conditions. The ski-snow interaction parameters are optimized for dynamic alignment with snow conditions and individual turning techniques. Forward-inverse dynamics simulation is performed using only the skier's posture as model input and leaving the translational degrees of freedom (DOFs) between the pelvis and the ground unconstrained. The effectiveness of our model is further verified by comparing the simulated results with the collected GPS and plantar pressure data. The correlation coefficient between the simulated ski-snow contact force and the measured plantar pressure data is 0.964, and the error between the predicted motion trajectory and GPS data is 0.7%. By extracting kinematic and kinetic parameters from skiers of different skill levels, quantitative performance analysis helps quantify ski training. The SSSI model with the parameter optimization algorithm of the ski-snow interaction allows for the description of skiing characteristics across varied snow conditions and different turning techniques, such as carving and skidding. Our research advances the understanding of alpine skiing dynamics, informing the development of training programs and facility designs to enhance athlete performance and safety.",
        "subjects": [
            "physics.soc-ph",
            "cs.ET",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05676",
        "abstract url": "https://arxiv.org/abs/2411.05676",
        "title": "Improving Molecular Graph Generation with Flow Matching and Optimal Transport",
        "rating": "-4.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "Graph"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Generating molecular graphs is crucial in drug design and discovery but remains challenging due to the complex interdependencies between nodes and edges. While diffusion models have demonstrated their potentiality in molecular graph design, they often suffer from unstable training and inefficient sampling. To enhance generation performance and training stability, we propose GGFlow, a discrete flow matching generative model incorporating optimal transport for molecular graphs and it incorporates an edge-augmented graph transformer to enable the direct communications among chemical bounds. Additionally, GGFlow introduces a novel goal-guided generation framework to control the generative trajectory of our model, aiming to design novel molecular structures with the desired properties. GGFlow demonstrates superior performance on both unconditional and conditional molecule generation tasks, outperforming existing baselines and underscoring its effectiveness and potential for wider application.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05333",
        "abstract url": "https://arxiv.org/abs/2411.05333",
        "title": "Error-controlled Progressive Retrieval of Scientific Data under Derivable Quantities of Interest",
        "rating": "-10",
        "keywords": [],
        "abstract": "The unprecedented amount of scientific data has introduced heavy pressure on the current data storage and transmission systems. Progressive compression has been proposed to mitigate this problem, which offers data access with on-demand precision. However, existing approaches only consider precision control on primary data, leaving uncertainties on the quantities of interest (QoIs) derived from it. In this work, we present a progressive data retrieval framework with guaranteed error control on derivable QoIs. Our contributions are three-fold. (1) We carefully derive the theories to strictly control QoI errors during progressive retrieval. Our theory is generic and can be applied to any QoIs that can be composited by the basis of derivable QoIs proved in the paper. (2) We design and develop a generic progressive retrieval framework based on the proposed theories, and optimize it by exploring feasible progressive representations. (3) We evaluate our framework using five real-world datasets with a diverse set of QoIs. Experiments demonstrate that our framework can faithfully respect any user-specified QoI error bounds in the evaluated applications. This leads to over 2.02x performance gain in data transfer tasks compared to transferring the primary data while guaranteeing a QoI error that is less than 1E-5.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "SC'24"
    },
    {
        "paper id": "2411.05363",
        "abstract url": "https://arxiv.org/abs/2411.05363",
        "title": "Single-Collision Model for Non-Line-of-Sight UV Communication Channel With Obstacle",
        "rating": "-10",
        "keywords": [],
        "abstract": "Existing research on non-line-of-sight (NLoS) ultraviolet (UV) channel modeling mainly focuses on scenarios where the signal propagation process is not affected by any obstacle and the radiation intensity (RI) of the light source is uniformly distributed. To eliminate these restrictions, we propose a single-collision model for the NLoS UV channel incorporating a cuboid-shaped obstacle, where the RI of the UV light source is modeled as the Lambertian distribution. For easy interpretation, we categorize the intersection circumstances between the receiver field-of-view and the obstacle into six cases and provide derivations of the weighting factor for each case. To investigate the accuracy of the proposed model, we compare it with the associated Monte Carlo photon tracing model via simulations and experiments. Results verify the correctness of the proposed model. This work reveals that obstacle avoidance is not always beneficial for NLoS UV communications and provides guidelines for relevant system design.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to IEEE International Conference on Communications (ICC) 2025"
    },
    {
        "paper id": "2411.05368",
        "abstract url": "https://arxiv.org/abs/2411.05368",
        "title": "Comparative Study of MAC Protocols for Wireless Mesh Network",
        "rating": "-10",
        "keywords": [],
        "abstract": "Wireless networking is encouraged by the constant enhancement of sensors' ability and wireless communication. To provide service quality support for multimedia viz. audio and video streams, the IEEE 802.11e MAC (Media Access Control) improves basic 802.11 MAC. IEEE 802.11 standard series such as IEEE 802.11a, b, g, n, p, and ac have been promoted and specified in the current communications and connection development. Each standard has functionality that matches the kind of applications for which the standard is intended. IEEE 802.11ac has better performance with fewer interferences and achieves gigabits per second capacity transfer rates. This paper discusses the comparative examination of the IEEE 802.11a, IEEE 802.11b, IEEE 802.11g, IEEE 802.11n, IEEE 802.11p, and IEEE 802.11ac standards which increase accuracy and performance pertaining to the IEEE 802.11 standard. In this paper, we investigate the design requirements for numerous simultaneous peer-to-peer connections. Further, this study offers a systematic review and analysis of the MAC layer in WMN (Wireless Mesh Network) and also highlights their open research issues and challenges. Finally, this paper discusses various potential directions for future research in this area with an emphasis on their strengths and limitations.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "20 pages, 5 figures, to be published in Wireless Pers Commun"
    },
    {
        "paper id": "2411.05374",
        "abstract url": "https://arxiv.org/abs/2411.05374",
        "title": "Interdisciplinary Translations: Sensory Perception as a Universal Language",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates sensory perception's pivotal role as a universal communicative bridge across varied cultures and disciplines, and how it manifests its value in the study of media art, human computer interaction and artificial intelligence. By analyzing its function in non-verbal communication through interactive systems, and drawing on the interpretive model in translation studies where \"sense\" acts as a mediation between two languages, this paper illustrates how interdisciplinary communication in media art and human-computer interaction is afforded by the abstract language of human sensory perception. Specific examples from traditional art, interactive media art, HCI, communication, and translation studies demonstrate how sensory feedback translates and conveys meaning across diverse modalities of expression and how it fosters connections between humans, art, and technology. Pertaining to this topic, this paper analyzes the impact of sensory feedback systems in designing interactive experiences, and reveals the guiding role of sensory perception in the design philosophy of AI systems. Overall, the study aims to broaden the understanding of sensory perception's role in communication, highlighting its significance in the evolution of interactive experiences and its capacity to unify art, science, and the human experience.",
        "subjects": [
            "cs.MM"
        ],
        "comment": "This paper has been accepted to the International Symposium of Electronic Arts 2024, and the proceedings version will be available at https://isea-archives.siggraph.org/publications/ with DOI to be added once published"
    },
    {
        "paper id": "2411.05400",
        "abstract url": "https://arxiv.org/abs/2411.05400",
        "title": "Palermo: Improving the Performance of Oblivious Memory using Protocol-Hardware Co-Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Oblivious RAM (ORAM) hides the memory access patterns, enhancing data privacy by preventing attackers from discovering sensitive information based on the sequence of memory accesses. The performance of ORAM is often limited by its inherent trade-off between security and efficiency, as concealing memory access patterns imposes significant computational and memory overhead. While prior works focus on improving the ORAM performance by prefetching and eliminating ORAM requests, we find that their performance is very sensitive to workload locality behavior and incurs additional management overhead caused by the ORAM stash pressure. This paper presents Palermo: a protocol-hardware co-design to improve ORAM performance. The key observation in Palermo is that classical ORAM protocols enforce restrictive dependencies between memory operations that result in low memory bandwidth utilization. Palermo introduces a new protocol that overlaps large portions of memory operations, within a single and between multiple ORAM requests, without breaking correctness and security guarantees. Subsequently, we propose an ORAM controller architecture that executes the proposed protocol to service ORAM requests. The hardware is responsible for concurrently issuing memory requests as well as imposing the necessary dependencies to ensure a consistent view of the ORAM tree across requests. Using a rich workload mix, we demonstrate that Palermo outperforms the RingORAM baseline by 2.8x, on average, incurring a negligible area overhead of 5.78mm^2 (less than 2% in 12th generation Intel CPU after technology scaling) and 2.14W without sacrificing security. We further show that Palermo also outperforms the state-of-the-art works PageORAM, PrORAM, and IR-ORAM.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "comment": "To appear in HPCA'25"
    },
    {
        "paper id": "2411.05410",
        "abstract url": "https://arxiv.org/abs/2411.05410",
        "title": "Proposition pour une gestion dynamique de l'inter-activit{\u00e9}s dans le TCAO",
        "rating": "-10",
        "keywords": [],
        "abstract": "Using some results coming from human and social sciences, we are working on the still important problem of tailorability inside CSCW systems. Our proposition aims at favouring the dynamic integration of groupware systems in a global and integrated environment that creates a context for their use. This work leads us to define the problem of the inter-activities management. This study helps us to propose a technical solution to this problem and that is realized in the CooLDA platform.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "in French language"
    },
    {
        "paper id": "2411.05432",
        "abstract url": "https://arxiv.org/abs/2411.05432",
        "title": "Near-Optimal Dimension Reduction for Facility Location",
        "rating": "-10",
        "keywords": [],
        "abstract": "Oblivious dimension reduction, \u00e0 la the Johnson-Lindenstrauss (JL) Lemma, is a fundamental approach for processing high-dimensional data. We study this approach for Uniform Facility Location (UFL) on a Euclidean input $X\\subset\\mathbb{R}^d$, where facilities can lie in the ambient space (not restricted to $X$). Our main result is that target dimension $m=\\tilde{O}(\u03b5^{-2}\\mathrm{ddim})$ suffices to $(1+\u03b5)$-approximate the optimal value of UFL on inputs whose doubling dimension is bounded by $\\mathrm{ddim}$. It significantly improves over previous results, that could only achieve $O(1)$-approximation [Narayanan, Silwal, Indyk, and Zamir, ICML 2021] or dimension $m=O(\u03b5^{-2}\\log n)$ for $n=|X|$, which follows from [Makarychev, Makarychev, and Razenshteyn, STOC 2019]. Our oblivious dimension reduction has immediate implications to streaming and offline algorithms, by employing known algorithms for low dimension. In dynamic geometric streams, it implies a $(1+\u03b5)$-approximation algorithm that uses $O(\u03b5^{-1}\\log n)^{\\tilde{O}(\\mathrm{ddim}/\u03b5^{2})}$ bits of space, which is the first streaming algorithm for UFL to utilize the doubling dimension. In the offline setting, it implies a $(1+\u03b5)$-approximation algorithm, which we further refine to run in time $( (1/\u03b5)^{\\tilde{O}(\\mathrm{ddim})} d + 2^{(1/\u03b5)^{\\tilde{O}(\\mathrm{ddim})}}) \\cdot \\tilde{O}(n) $. Prior work has a similar running time but requires some restriction on the facilities [Cohen-Addad, Feldmann and Saulpic, JACM 2021]. Our main technical contribution is a fast procedure to decompose an input $X$ into several $k$-median instances for small $k$. This decomposition is inspired by, but has several significant differences from [Czumaj, Lammersen, Monemizadeh and Sohler, SODA 2013], and is key to both our dimension reduction and our PTAS.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05433",
        "abstract url": "https://arxiv.org/abs/2411.05433",
        "title": "Computing the Low-Weight codewords of Punctured and Shortened Pre-Transformed polar Codes",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we present a deterministic algorithm to count the low-weight codewords of punctured and shortened pure and pre-transformed polar codes. The method first evaluates the weight properties of punctured/shortened polar cosets. Then, a method that discards the cosets that have no impact on the computation of the low-weight codewords is introduced. A key advantage of this method is its applicability, regardless of the frozen bit set, puncturing/shortening pattern, or pretransformation. Results confirm the method's efficiency while showing reduced computational complexity compared to stateof-the-art algorithms.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05435",
        "abstract url": "https://arxiv.org/abs/2411.05435",
        "title": "StoryExplorer: A Visualization Framework for Storyline Generation of Textual Narratives",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the context of the exponentially increasing volume of narrative texts such as novels and news, readers struggle to extract and consistently remember storyline from these intricate texts due to the constraints of human working memory and attention span. To tackle this issue, we propose a visualization approach StoryExplorer, which facilitates the process of knowledge externalization of narrative texts and further makes the form of mental models more coherent. Through the formative study and close collaboration with 2 domain experts, we identified key challenges for the extraction of the storyline. Guided by the distilled requirements, we then propose a set of workflow (i.e., insight finding-scripting-storytelling) to enable users to interactively generate fragments of narrative structures. We then propose a visualization system StoryExplorer which combines stroke annotation and GPT-based visual hints to quickly extract story fragments and interactively construct storyline. To evaluate the effectiveness and usefulness of StoryExplorer, we conducted 2 case studies and in-depth user interviews with 16 target users. The result shows that users can better extract the storyline by using StoryExplorer along with the proposed workflow.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05443",
        "abstract url": "https://arxiv.org/abs/2411.05443",
        "title": "ClusterGraph: a new tool for visualization and compression of multidimensional data",
        "rating": "-10",
        "keywords": [],
        "abstract": "Understanding the global organization of complicated and high dimensional data is of primary interest for many branches of applied sciences. It is typically achieved by applying dimensionality reduction techniques mapping the considered data into lower dimensional space. This family of methods, while preserving local structures and features, often misses the global structure of the dataset. Clustering techniques are another class of methods operating on the data in the ambient space. They group together points that are similar according to a fixed similarity criteria, however unlike dimensionality reduction techniques, they do not provide information about the global organization of the data. Leveraging ideas from Topological Data Analysis, in this paper we provide an additional layer on the output of any clustering algorithm. Such data structure, ClusterGraph, provides information about the global layout of clusters, obtained from the considered clustering algorithm. Appropriate measures are provided to assess the quality and usefulness of the obtained representation. Subsequently the ClusterGraph, possibly with an appropriate structure--preserving simplification, can be visualized and used in synergy with state of the art exploratory data analysis techniques.",
        "subjects": [
            "cs.CG",
            "math.AT",
            "stat.ML"
        ],
        "comment": "19 pages, 8 figures"
    },
    {
        "paper id": "2411.05446",
        "abstract url": "https://arxiv.org/abs/2411.05446",
        "title": "Digitalization and Virtual Assistive Systems in Tourist Mobility: Evolution, an Experience (with Observed Mistakes), Appropriate Orientations and Recommendations",
        "rating": "-10",
        "keywords": [],
        "abstract": "Digitalization and virtualization are extremely active and important approaches in a large scope of activities (marketing, selling, enterprise management, logistics). Tourism management is also highly concerned by this evolution. In this paper we try to present today's situation based on a 7-week trip showing appropriate and shame situations. After this case study, we give a list of appropriate practices and orientations and confirm the fundamental role of User Experience in validating the proposed assistive system and the User Interfaces needed for client/user satisfaction. We also outline the expected role of Metaverse in the future of the evolution of this domain.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05454",
        "abstract url": "https://arxiv.org/abs/2411.05454",
        "title": "Emergent Cooperative Strategies for Multi-Agent Shepherding via Reinforcement Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a decentralized reinforcement learning (RL) approach to address the multi-agent shepherding control problem, departing from the conventional assumption of cohesive target groups. Our two-layer control architecture consists of a low-level controller that guides each herder to contain a specific target within a goal region, while a high-level layer dynamically selects from multiple targets the one an herder should aim at corralling and containing. Cooperation emerges naturally, as herders autonomously choose distinct targets to expedite task completion. We further extend this approach to large-scale systems, where each herder applies a shared policy, trained with few agents, while managing a fixed subset of agents.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05457",
        "abstract url": "https://arxiv.org/abs/2411.05457",
        "title": "Improving the detection of technical debt in Java source code with an enriched dataset",
        "rating": "-10",
        "keywords": [],
        "abstract": "Technical debt (TD) is a term used to describe the additional work and costs that emerge when developers have opted for a quick and easy solution to a problem, rather than a more effective and well-designed, but time-consuming approach. Self-Admitted Technical Debts (SATDs) are a specific type of technical debts that developers intentionally document and acknowledge, typically via textual comments. While these self-admitted comments are a useful tool for identifying technical debts, most of the existing approaches focus on capturing crucial tokens associated with various categories of TD, neglecting the rich information embedded within the source code itself. Recent research has focused on detecting SATDs by analyzing comments embedded in source code, and there has been little work dealing with technical debts contained in the source code. To fill such a gap, in this study, through the analysis of comments and their associated source code from 974 Java projects hosted in the Stack corpus, we curated the first ever dataset of TD identified by code comments, coupled with its associated source code. Through an empirical evaluation, we found out that the comments of the resulting dataset help enhance the prediction performance of state-of-the-art SATD detection models. More importantly, including the classified source code significantly improves the accuracy in predicting various types of technical debt. In this respect, our work is two-fold: (i) We believe that our dataset will catalyze future work in the domain, inspiring various research issues related to the recognition of technical debt; (ii) The proposed classifiers may serve as baselines for other studies on the detection of TD by means of the curated dataset.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "The paper has been submitted to the Transactions on Software Engineering, and is now under review"
    },
    {
        "paper id": "2411.05458",
        "abstract url": "https://arxiv.org/abs/2411.05458",
        "title": "Recursive and iterative approaches to generate rotation Gray codes for stamp foldings and semi-meanders",
        "rating": "-10",
        "keywords": [],
        "abstract": "We first present a simple recursive algorithm that generates cyclic rotation Gray codes for stamp foldings and semi-meanders, where consecutive strings differ by a stamp rotation. These are the first known Gray codes for stamp foldings and semi-meanders, and we thus solve an open problem posted by Sawada and Li in [Electron. J. Comb. 19(2), 2012]. We then introduce an iterative algorithm that generates the same rotation Gray codes for stamp foldings and semi-meanders. Both the recursive and iterative algorithms generate stamp foldings and semi-meanders in constant amortized time and $O(n)$-amortized time per string respectively, using a linear amount of memory.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05463",
        "abstract url": "https://arxiv.org/abs/2411.05463",
        "title": "Dave: a decentralized, secure, and lively fraud-proof algorithm",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we introduce a new fraud-proof algorithm that offers an unprecedented combination of decentralization, security, and liveness. The resources that must be mobilized by an honest participant to defeat an adversary grow only logarithmically with what the adversary ultimately loses. As a consequence, there is no need to introduce high bonds that prevent an adversary from creating too many Sybils. This makes the system very inclusive and frees participants from having to pool resources among themselves to engage the protocol. Finally, the maximum delay to finalization also grows only logarithmically with total adversarial expenditure, with the smallest multiplicative factor to date. In summary: the entire dispute completes in 2--5 challenge periods, the only way to break consensus is to censor the honest party for more than one challenge period, and the costs of engaging in the dispute are minimal.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05471",
        "abstract url": "https://arxiv.org/abs/2411.05471",
        "title": "Some notes on the pseudorandomness of Legendre symbol and Liouville function",
        "rating": "-10",
        "keywords": [],
        "abstract": "We improve bounds on the degree and sparsity of Boolean functions representing the Legendre symbol as well as on the $N$th linear complexity of the Legendre sequence. We also prove similar results for both the Liouville function for integers and its analog for polynomials over $\\mathbb{F}_2$, or more general for any (binary) arithmetic function which satisfies $f(2n)=-f(n)$ for $n=1,2,\\ldots$",
        "subjects": [
            "math.NT",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05482",
        "abstract url": "https://arxiv.org/abs/2411.05482",
        "title": "Soft Gripping System for Space Exploration Legged Robots",
        "rating": "-10",
        "keywords": [],
        "abstract": "Although wheeled robots have been predominant for planetary exploration, their geometry limits their capabilities when traveling over steep slopes, through rocky terrains, and in microgravity. Legged robots equipped with grippers are a viable alternative to overcome these obstacles. This paper proposes a gripping system that can provide legged space-explorer robots a reliable anchor on uneven rocky terrain. This gripper provides the benefits of soft gripping technology by using segmented tendon-driven fingers to adapt to the target shape, and creates a strong adhesion to rocky surfaces with the help of microspines. The gripping performances are showcased, and multiple experiments demonstrate the impact of the pulling angle, target shape, spine configuration, and actuation power on the performances. The results show that the proposed gripper can be a suitable solution for advanced space exploration, including climbing, lunar caves, or exploration of the surface of asteroids.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "The 27th issue of the International Conference Series on Climbing and Walking Robots and the Support Technologies for Mobile Machines (CLAWAR)"
    },
    {
        "paper id": "2411.05491",
        "abstract url": "https://arxiv.org/abs/2411.05491",
        "title": "Overhead Measurement Noise in Different Runtime Environments",
        "rating": "-10",
        "keywords": [],
        "abstract": "In order to detect performance changes, measurements are performed with the same execution environment. In cloud environments, the noise from different processes running on the same cluster nodes might change measurement results and thereby make performance changes hard to measure. The benchmark MooBench determines the overhead of different observability tools and is executed continuously. In this study, we compare the suitability of different execution environments to benchmark the observability overhead using MooBench. To do so, we compare the execution times and standard deviation of MooBench in a cloud execution environment to three bare-metal execution environments. We find that bare metal servers have lower runtime and standard deviation for multi-threaded MooBench execution. Nevertheless, we see that performance changes up to 4.41% are detectable by GitHub actions, as long as only sequential workloads are examined.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05492",
        "abstract url": "https://arxiv.org/abs/2411.05492",
        "title": "Covariance-Based Device Activity Detection with Massive MIMO for Near-Field Correlated Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper studies the device activity detection problem in a massive multiple-input multiple-output (MIMO) system for near-field communications (NFC). In this system, active devices transmit their signature sequences to the base station (BS), which detects the active devices based on the received signal. In this paper, we model the near-field channels as correlated Rician fading channels and formulate the device activity detection problem as a maximum likelihood estimation (MLE) problem. Compared to the traditional uncorrelated channel model, the correlation of channels complicates both algorithm design and theoretical analysis of the MLE problem. On the algorithmic side, we propose two computationally efficient algorithms for solving the MLE problem: an exact coordinate descent (CD) algorithm and an inexact CD algorithm. The exact CD algorithm solves the one-dimensional optimization subproblem exactly using matrix eigenvalue decomposition and polynomial root-finding. By approximating the objective function appropriately, the inexact CD algorithm solves the one-dimensional optimization subproblem inexactly with lower complexity and more robust numerical performance. Additionally, we analyze the detection performance of the MLE problem under correlated channels by comparing it with the case of uncorrelated channels. The analysis shows that when the overall number of devices $N$ is large or the signature sequence length $L$ is small, the detection performance of MLE under correlated channels tends to be better than that under uncorrelated channels. Conversely, when $N$ is small or $L$ is large, MLE performs better under uncorrelated channels than under correlated ones. Simulation results demonstrate the computational efficiency of the proposed algorithms and verify the correctness of the analysis.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.OC"
        ],
        "comment": "15 pages, 8 figures, submitted for possible publication"
    },
    {
        "paper id": "2411.05495",
        "abstract url": "https://arxiv.org/abs/2411.05495",
        "title": "Filtration Order Coface Generation Algorithm",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose novel algorithms for generating cofaces in the Vietoris-Rips complex. Cofaces -- simplices that contain a given simplex -- have multiple important uses in generating and using a Vietoris-Rips filtered complex: both in creating the coboundary matrix for computing cohomology, and as a more recent approach for generating the simplex stream in the first place. Traditionally, most methods have generated simplices first, and then sorted them in filtration order after the generation step. In this paper, we propose generating simplex streams by generating non-expanding cofaces, which by construction produces simplices in filtration order, and we propose generating additional cofaces in filtration order using sorted neighborhood lists to produce coboundaries directly in filtration order.",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05511",
        "abstract url": "https://arxiv.org/abs/2411.05511",
        "title": "Towards computational methods for category theory",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we describe a computational model for categories and functors. The categories that are handled by this model are locally finitely presentable categories which can be \"sufficiently finitely\" described to a computer. As an application of this model, we introduce a criterion to show whether a functor, as described in the model, is a left adjoint. The verification of this criterion can be partially automatised, if not fully in some cases, as witnessed by an implementation. While this work is focused on computational aspects, it is relevant to the broader categorical community, as it presents a new way to check whether functors are left adjoints and outlines a new computational methodology in category theory.",
        "subjects": [
            "math.CT",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05531",
        "abstract url": "https://arxiv.org/abs/2411.05531",
        "title": "Sparse Regression Codes for Integrated Passive Sensing and Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a novel integrated sensing and communication (ISAC) system, where the base station (BS) passively senses the channel parameters using the information carrying signals from a user. To simultaneously guarantee decoding and sensing performance, the user adopts sparse regression codes (SPARCs) with cyclic redundancy check (CRC) to transmit its information bits. The BS generates an initial coarse channel estimation of the parameters after receiving the pilot signal. Then, a novel iterative decoding and parameter sensing algorithm is proposed, where the correctly decoded codewords indicated by the CRC bits are utilized to improve the sensing and channel estimation performance at the BS. In turn, the improved estimate of the channel parameters lead to a better decoding performance. Simulation results show the effectiveness of the proposed iterative decoding and sensing algorithm, where both the sensing and the communication performance are significantly improved with a few iterations. Extensive ablation studies concerning different channel estimation methods and number of CRC bits are carried out for a comprehensive evaluation of the proposed scheme.",
        "subjects": [
            "eess.SP",
            "cs.IT"
        ],
        "comment": "7 pages, conference version"
    },
    {
        "paper id": "2411.05553",
        "abstract url": "https://arxiv.org/abs/2411.05553",
        "title": "Separating Coverage and Submodular: Maximization Subject to a Cardinality Constraint",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider two classic problems: maximum coverage and monotone submodular maximization subject to a cardinality constraint. [Nemhauser--Wolsey--Fisher '78] proved that the greedy algorithm provides an approximation of $1-1/e$ for both problems, and it is known that this guarantee is tight ([Nemhauser--Wolsey '78; Feige '98]). Thus, one would naturally assume that everything is resolved when considering the approximation guarantees of these two problems, as both exhibit the same tight approximation and hardness. In this work we show that this is not the case, and study both problems when the cardinality constraint is a constant fraction $c \\in (0,1]$ of the ground set. We prove that monotone submodular maximization subject to a cardinality constraint admits an approximation of $1-(1-c)^{1/c}$; This approximation equals $1$ when $c=1$ and it gracefully degrades to $1-1/e$ when $c$ approaches $0$. Moreover, for every $c=1/s$ (for any integer $s \\in \\mathbb{N}$) we present a matching hardness. Surprisingly, for $c=1/2$ we prove that Maximum Coverage admits an approximation of $0.7533$, thus separating the two problems. To the best of our knowledge, this is the first known example of a well-studied maximization problem for which coverage and monotone submodular objectives exhibit a different best possible approximation.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2411.05554",
        "abstract url": "https://arxiv.org/abs/2411.05554",
        "title": "Time-to-reach Bounds for Verification of Dynamical Systems Using the Koopman Spectrum",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this work, we present a novel Koopman spectrum-based reachability verification method for nonlinear systems. Contrary to conventional methods that focus on characterizing all potential states of a dynamical system over a presupposed time span, our approach seeks to verify the reachability by assessing the non-emptiness of estimated time-to-reach intervals without engaging in the explicit computation of reachable set. Based on the spectral analysis of the Koopman operator, we reformulate the problem of verifying existence of reachable trajectories into the problem of determining feasible time-to-reach bounds required for system reachability. By solving linear programming (LP) problems, our algorithm can effectively estimate all potential time intervals during which a dynamical system can enter (and exit) target sets from given initial sets over an unbounded time horizon. Finally, we demonstrate our method in challenging settings, such as verifying the reachability between non-convex or even disconnected sets, as well as backward reachability and multiple entries into target sets. Additionally, we validate its applicability in addressing real-world challenges and scalability to high-dimensional systems through case studies in verifying the reachability of the cart-pole and multi-agent consensus systems.",
        "subjects": [
            "eess.SY",
            "math.DS"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.05555",
        "abstract url": "https://arxiv.org/abs/2411.05555",
        "title": "AcceLLM: Accelerating LLM Inference using Redundancy for Load Balancing and Data Locality",
        "rating": "-10",
        "keywords": [],
        "abstract": "Large Language Model (LLM) inference on large-scale systems is expected to dominate future cloud infrastructures. Efficient LLM inference in cloud environments with numerous AI accelerators is challenging, necessitating extensive optimizations for optimal performance. Current systems batch prefill and decoding to boost throughput but encounter latency issues, while others disaggregate these phases, leading to resource underutilization. We propose AcceLLM, a novel method addressing latency and load balancing, inspired by the cache data management. It strategically utilizes redundant data to enhance inference via load balancing and optimal hardware use. Simulated evaluations on Nvidia H100 GPU and Huawei Ascend 910B2 show AcceLLM surpasses state-of-the-art systems up to 30% in latency and efficiency, handling diverse workloads effectively.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2411.05570",
        "abstract url": "https://arxiv.org/abs/2411.05570",
        "title": "Obfuscation as Instruction Decorrelation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Obfuscation of computer programs has historically been approached either as a practical but \\textit{ad hoc} craft to make reverse engineering subjectively difficult, or as a sound theoretical investigation unfortunately detached from the numerous existing constraints of engineering practical systems. In this paper, we propose \\textit{instruction decorrelation} as a new approach that makes the instructions of a set of real-world programs appear independent from one another. We contribute: a formal definition of \\textit{instruction independence} with multiple instantiations for various aspects of programs; a combination of program transformations that meet the corresponding instances of instruction independence against an honest-but-curious adversary, specifically random interleaving and memory access obfuscation; and an implementation of an interpreter that uses a trusted execution environment (TEE) only to perform memory address translation and memory shuffling, leaving instructions execution outside the TEE. These first steps highlight the practicality of our approach. Combined with additional techniques to protect the content of memory and to hopefully lower the requirements on TEEs, this work could potentially lead to more secure obfuscation techniques that could execute on commonly available hardware.",
        "subjects": [
            "cs.CR",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05572",
        "abstract url": "https://arxiv.org/abs/2411.05572",
        "title": "Why These Documents? Explainable Generative Retrieval with Hierarchical Category Paths",
        "rating": "-10",
        "keywords": [],
        "abstract": "Generative retrieval has recently emerged as a new alternative of traditional information retrieval approaches. However, existing generative retrieval methods directly decode docid when a query is given, making it impossible to provide users with explanations as an answer for \"Why this document is retrieved?\". To address this limitation, we propose Hierarchical Category Path-Enhanced Generative Retrieval(HyPE), which enhances explainability by generating hierarchical category paths step-by-step before decoding docid. HyPE leverages hierarchical category paths as explanation, progressing from broad to specific semantic categories. This approach enables diverse explanations for the same document depending on the query by using shared category paths between the query and the document, and provides reasonable explanation by reflecting the document's semantic structure through a coarse-to-fine manner. HyPE constructs category paths with external high-quality semantic hierarchy, leverages LLM to select appropriate candidate paths for each document, and optimizes the generative retrieval model with path-augmented dataset. During inference, HyPE utilizes path-aware reranking strategy to aggregate diverse topic information, allowing the most relevant documents to be prioritized in the final ranked list of docids. Our extensive experiments demonstrate that HyPE not only offers a high level of explainability but also improves the retrieval performance in the document retrieval task.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05583",
        "abstract url": "https://arxiv.org/abs/2411.05583",
        "title": "Inter-RIS Beam Focusing Codebook Design in Cooperative Distributed RIS Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper explores distributed Reconfigurable Intelligent Surfaces (RISs) by introducing a cooperative dimension that enhances adaptability and performance. It focuses on strategically deploying multiple RISs to improve connectivity with the Base Station (BS) and among RISs, thereby aiding users in areas with weak BS coverage and enhancing spatial multiplexing gains. Each RIS can function as a primary surface to directly support users or as an intermediary surface to reflect signals to another primary surface. This dual functionality enables flexible responses to changing conditions. We implement an inter-RIS signal focusing design for phase shifts, creating a tailored codebook for precise control over signal direction. This design considers the interplay of incidence and reflection angles to maximize reflected signal power, based on the RIS response function and the physical properties of the RIS elements.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05622",
        "abstract url": "https://arxiv.org/abs/2411.05622",
        "title": "From Resource Control to Digital Trust with User-Managed Access",
        "rating": "-10",
        "keywords": [],
        "abstract": "The User-Managed Access (UMA) extension to OAuth 2.0 is a promising candidate for increasing Digital Trust in personal data ecosystems like Solid. With minor modifications, it can achieve many requirements regarding usage control and transaction contextualization, even though additional specification is needed to address delegation of control and retraction of usage policies.",
        "subjects": [
            "cs.CR",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05624",
        "abstract url": "https://arxiv.org/abs/2411.05624",
        "title": "Data-Driven Min-Max MPC for LPV Systems with Unknown Scheduling Signal",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a data-driven min-max model predictive control (MPC) scheme for linear parameter-varying (LPV) systems. Contrary to existing data-driven LPV control approaches, we assume that the scheduling signal is unknown during offline data collection and online system operation. Assuming a quadratic matrix inequality (QMI) description for the scheduling signal, we develop a novel data-driven characterization of the consistent system matrices using only input-state data. The proposed data-driven min-max MPC minimizes a tractable upper bound on the worst-case cost over the consistent system matrices set and over all scheduling signals satisfying the QMI. The proposed approach guarantees recursive feasibility, closed-loop exponential stability and constraint satisfaction if it is feasible at the initial time. We demonstrate the effectiveness of the proposed method in simulation.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05627",
        "abstract url": "https://arxiv.org/abs/2411.05627",
        "title": "Large problems are not necessarily hard: A case study on distributed NMPC paying off",
        "rating": "-10",
        "keywords": [],
        "abstract": "A key motivation in the development of distributed Model Predictive Control (MPC) is to widen the computational bottleneck of centralized MPC for large-scale systems. Parallelizing computations among individual subsystems, distributed MPC has the prospect of scaling well for large networks. However, the communication demand may deteriorate the performance of iterative decentralized optimization, if excessively many optimizer iterations are required per control step. Moreover, centralized solvers often exhibit faster asymptotic convergence rates and, by parallelizing costly linear algebra operations, they can also benefit from modern multi-core computing architectures. On this canvas, we study the computational performance of cooperative distributed MPC for linear and nonlinear systems. To this end, we apply a tailored decentralized real-time iteration scheme to frequency control for power systems. For the considered linear and nonlinear benchmarks, distributed MPC and distributed Nonlinear MPC (NMPC) scale well as the required number of iterations does not depend on the number of subsystems. Comparisons with multithreaded centralized solvers show competitive performance of the considered decentralized optimization algorithms.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05646",
        "abstract url": "https://arxiv.org/abs/2411.05646",
        "title": "Weak Ties Explain Open Source Innovation",
        "rating": "-10",
        "keywords": [],
        "abstract": "In a real-world social network, weak ties (reflecting low-intensity, infrequent interactions) act as bridges and connect people to different social circles, giving them access to diverse information and opportunities that are not available within one's immediate, close-knit vicinity. Weak ties can be crucial for creativity and innovation, as it introduces new ideas and approaches that people can then combine in novel ways, leading to innovative solutions and creative breakthroughs. Do weak ties facilitate creativity in software in similar ways? In this paper, we show that the answer is ``yes.'' Concretely, we study the correlation between developers' knowledge acquisition through three distinct interaction networks on GitHub and the innovativeness of the projects they develop, across over 38,000 Python projects hosted on GitHub. Our findings suggest that the diversity of projects in which developers engage correlates positively with the innovativeness of their future project developments, whereas the volume of interactions exerts minimal influence. Notably, acquiring knowledge through weak interactions (e.g., starring) as opposed to strong ones (e.g., committing) emerges as a stronger predictor of future novelty.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2411.05651",
        "abstract url": "https://arxiv.org/abs/2411.05651",
        "title": "LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution",
        "rating": "-10",
        "keywords": [],
        "abstract": "Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights. This process demands skills in programming, data processing, and visualization tools, highlighting the need for a more intelligent, streamlined VA approach. Large language models (LLMs) have recently been developed as agents to handle various tasks with dynamic planning and tool-using capabilities, offering the potential to enhance the efficiency and versatility of VA. We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration. Our method is designed to help users progressively translate high-level analytical goals into low-level tasks, producing visualizations and deriving insights. Specifically, we introduce an LLM agent-based task planning and execution strategy, employing a recursive process involving a planner, executor, and controller. The planner is responsible for recommending and decomposing tasks, the executor handles task execution, including data analysis, visualization generation and multi-view composition, and the controller coordinates the interaction between the planner and executor. Building on the framework, we develop a system with a hybrid user interface that includes a task flow diagram for monitoring and managing the task planning process, a visualization panel for interactive data exploration, and a chat view for guiding the model through natural language instructions. We examine the effectiveness of our method through a usage scenario and an expert study.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05659",
        "abstract url": "https://arxiv.org/abs/2411.05659",
        "title": "Investigation of Holographic Beamforming via Dynamic Metasurface Antennas in QoS Guaranteed Power Efficient Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work focuses on designing a power-efficient network for Dynamic Metasurface Antennas (DMAs)-aided multiuser multiple-input single output (MISO) antenna systems. The main objective is to minimize total transmitted power by the DMAs while ensuring a guaranteed signal-to-noise-and-interference ratio (SINR) for multiple users in downlink beamforming. Unlike conventional MISO systems, which have well-explored beamforming solutions, DMAs require specialized methods due to their unique physical constraints and wavedomain precoding capabilities. To achieve this, optimization algorithms relying on alternating optimization and semi-definite programming, are developed, including spherical-wave channel modelling of near-field communication. The dynamic reconfigurability and holography-based beamforming of metasurface arrays make DMAs promising candidates for power-efficient networks by reducing the need for power-hungry RF chains. On the other hand, the physical constraints on DMA weights and wave-domain precoding of multiple DMA elements through reduced number of RF suppliers can limit the degrees of freedom (DoF) in beamforming optimizations compared to conventional fully digital (FD) architectures. This paper investigates the optimization of downlink beamforming in DMA-aided networks, focusing on power efficiency and addressing these challenges.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Submitted to ICC 2025"
    },
    {
        "paper id": "2411.05666",
        "abstract url": "https://arxiv.org/abs/2411.05666",
        "title": "Super Unique Tarski is in UEOPL",
        "rating": "-10",
        "keywords": [],
        "abstract": "We define the Super-Unique-Tarski problem, which is a Tarski instance in which all slices are required to have a unique fixed point. We show that Super-Unique-Tarski lies in UEOPL under promise-preserving reductions.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05689",
        "abstract url": "https://arxiv.org/abs/2411.05689",
        "title": "optipoly: A Python package for boxed-constrained multi-variable polynomial cost functions optimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, a new python package (optipoly) is described that solves box-constrained optimization problem over multivariate polynomial cost functions. The principle of the algorithm is described before its performance is compared to three general purpose NLP solvers implemented in the state-of-the-art Gekko and scipy packages. The comparison show statistically better best solution provided by the algorithm with significantly less computation times. The package will be shortly made freely and easily available through the simple (pip install) process.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "18 pages, 6 figures, 3 tables"
    },
    {
        "paper id": "2411.05713",
        "abstract url": "https://arxiv.org/abs/2411.05713",
        "title": "Settling the Complexity of Popularity in Additively Separable and Fractional Hedonic Games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study coalition formation in the framework of hedonic games. There, a set of agents needs to be partitioned into disjoint coalitions, where agents have a preference order over coalitions. A partition is called popular if it does not lose a majority vote among the agents against any other partition. Unfortunately, hedonic games need not admit popular partitions and prior work suggests significant computational hardness. We confirm this impression by proving that deciding about the existence of popular partitions in additively separable and fractional hedonic games is $\u03a3_2^p$-complete. This settles the complexity of these problems and is the first work that proves completeness of popularity for the second level of the polynomial hierarchy.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05721",
        "abstract url": "https://arxiv.org/abs/2411.05721",
        "title": "Symmetrization maps and minimal border rank Comon's conjecture",
        "rating": "-10",
        "keywords": [],
        "abstract": "One of the fundamental open problems in the field of tensors is the border Comon's conjecture: given a symmetric tensor $F\\in(\\mathbb{C}^n)^{\\otimes d}$ for $d\\geq 3$, its border and symmetric border ranks are equal. In this paper, we prove the conjecture for large classes of concise tensors in $(\\mathbb{C}^n)^{\\otimes d}$ of border rank $n$, i.e., tensors of minimal border rank. These families include all tame tensors and all tensors whenever $n\\leq d+1$. Our technical tools are border apolarity and border varieties of sums of powers.",
        "subjects": [
            "math.AG",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05722",
        "abstract url": "https://arxiv.org/abs/2411.05722",
        "title": "Characterizing Implementability of Global Protocols with Infinite States and Data",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the implementability problem for an expressive class of symbolic communication protocols involving multiple participants. Our symbolic protocols describe infinite states and data values using dependent refinement predicates. Implementability asks whether a global protocol specification admits a distributed, asynchronous implementation, namely one for each participant, that is deadlock-free and exhibits the same behavior as the specification. We provide a unified explanation of seemingly disparate sources of non-implementability through a precise semantic characterization of implementability for infinite protocols. Our characterization reduces the problem of implementability to (co)reachability in the global protocol restricted to each participant. This compositional reduction yields the first sound and relatively complete algorithm for checking implementability of symbolic protocols. We use our characterization to show that for finite protocols, implementability is co-NP-complete for explicit representations and PSPACE-complete for symbolic representations. The finite, explicit fragment subsumes a previously studied fragment of multiparty session types for which our characterization yields a PTIME decision procedure, improving upon a prior PSPACE upper bound.",
        "subjects": [
            "cs.PL",
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05740",
        "abstract url": "https://arxiv.org/abs/2411.05740",
        "title": "Bias correction and instrumental variables for direct data-driven model-reference control",
        "rating": "-10",
        "keywords": [],
        "abstract": "Managing noisy data is a central challenge in direct data-driven control design. We propose an approach for synthesizing model-reference controllers for linear time-invariant (LTI) systems using noisy state-input data, employing novel noise mitigation techniques. Specifically, we demonstrate that using data-based covariance parameterization of the controller enables bias-correction and instrumental variable techniques within the data-driven optimization, thus reducing measurement noise effects as data volume increases. The number of decision variables remains independent of dataset size, making this method scalable to large datasets. The approach's effectiveness is demonstrated with a numerical example.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "8 pages, 3 figures, preprint submitted to the European Control Conference, ECC 2025"
    },
    {
        "paper id": "2411.05763",
        "abstract url": "https://arxiv.org/abs/2411.05763",
        "title": "Frequency stability of grid-forming power-limiting droop control",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we analyze power-limiting grid-forming droop control used for grid-connected power converters. Compared to conventional grid-forming droop control, power-limiting droop control explicitly accounts for active power limits of the generation (e.g., renewables) interfaced by the converter. While power-limiting droop control has been demonstrated to work well in simulation and experiment, analytical results are not readily available. To address this gap, we first reformulate the dynamics of a power system comprised of converters using power-limiting droop controller as a projected dynamical system in nodal coordinates. Next, we change coordinates from nodal coordinates to edge coordinates to interpret the resulting dynamics as primal-dual dynamics associated with a constrained power flow problem. Leveraging convergence results for primal-dual dynamics, we show that, under mild feasibility assumptions, the frequency dynamics of a power system comprised of converters using power-limiting droop control are globally asymptotically stable with respect to the set of optimizers of its associated constrained power flow problem. Moreover, we show that (i) the converter frequencies synchronize to a common synchronous frequency for each grid-forming converter, and (ii) characterize the synchronous frequency in the case of converters operating at their power limit. Specifically, this result establishes that power-limiting droop control exhibits properties similar to so-called power-sharing in conventional unconstrained droop control.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05769",
        "abstract url": "https://arxiv.org/abs/2411.05769",
        "title": "Effects of Distributed Friction Actuation During Sliding Touch",
        "rating": "-10",
        "keywords": [],
        "abstract": "Friction modulation allows for a range of different sensations and textures to be simulated on flat touchscreens, yet is largely unable to render fundamental tactile interactions such as path following or shape discrimination due to lack of spatial force distribution across the fingerpad. In order to expand the range of sensations rendered via friction modulation, in this paper we explore the possibility of applying spatial feedback on the fingerpad via differing friction forces on flat touchscreens. To this end, we fabricated six distinct flat surfaces with different spatial distributions of friction and observed deformation of the fingerpad skin in response to motion along these physical samples. In our study, friction changes that occur sequentially along the sliding direction introduced little transitory spatial warping such as compression or stretching to the fingerpad, suggesting limited perceptual differences in comparison to 'classic' friction modulation. Distributing friction across the direction of motion, however, showed pattern-dependent shearing of the fingertip skin, opening avenues for new sensations and illusions heretofore unachievable on flat touchscreen surfaces.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "6 pages, short journal paper"
    },
    {
        "paper id": "2411.05916",
        "abstract url": "https://arxiv.org/abs/2411.05916",
        "title": "Coboundary expansion inside Chevalley coset complex HDXs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recent major results in property testing~\\cite{BLM24,DDL24} and PCPs~\\cite{BMV24} were unlocked by moving to high-dimensional expanders (HDXs) constructed from $\\widetilde{C}_d$-type buildings, rather than the long-known $\\widetilde{A}_d$-type ones. At the same time, these building quotient HDXs are not as easy to understand as the more elementary (and more symmetric/explicit) \\emph{coset complex} HDXs constructed by Kaufman--Oppenheim~\\cite{KO18} (of $A_d$-type) and O'Donnell--Pratt~\\cite{OP22} (of $B_d$-, $C_d$-, $D_d$-type). Motivated by these considerations, we study the $B_3$-type generalization of a recent work of Kaufman--Oppenheim~\\cite{KO21}, which showed that the $A_3$-type coset complex HDXs have good $1$-coboundary expansion in their links, and thus yield $2$-dimensional topological expanders. The crux of Kaufman--Oppenheim's proof of $1$-coboundary expansion was: (1)~identifying a group-theoretic result by Biss and Dasgupta~\\cite{BD01} on small presentations for the $A_3$-unipotent group over~$\\mathbb{F}_q$; (2)~``lifting'' it to an analogous result for an $A_3$-unipotent group over polynomial extensions~$\\mathbb{F}_q[x]$. For our $B_3$-type generalization, the analogue of~(1) appears to not hold. We manage to circumvent this with a significantly more involved strategy: (1)~getting a computer-assisted proof of vanishing $1$-cohomology of $B_3$-type unipotent groups over~$\\mathbb{F}_5$; (2)~developing significant new ``lifting'' technology to deduce the required quantitative $1$-cohomology results in $B_3$-type unipotent groups over $\\mathbb{F}_{5^k}[x]$.",
        "subjects": [
            "math.GR",
            "cs.DM"
        ],
        "comment": "130 pages"
    },
    {
        "paper id": "2411.05933",
        "abstract url": "https://arxiv.org/abs/2411.05933",
        "title": "A Passivity Analysis for Nonlinear Consensus on Balanced Digraphs",
        "rating": "-10",
        "keywords": [],
        "abstract": "This work deals with the output consensus problem for multiagent systems over balanced digraphs by passivity analysis. As the standard diffusive coupling structure only models the undirected interconnection, we propose a general approach capable of processing directed coupling and performing passivity analysis. To mitigate the complexity arising from the nonlinearity and directed interconnections, we reformulate the output consensus problem as a convergence analysis on a submanifold. We provide passivity analysis and establish a sufficient condition based on passivity for achieving output agreement in multi-agent systems over balanced digraphs. The results are supported by a numerical example.",
        "subjects": [
            "math.OC",
            "eess.SY"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2411.05942",
        "abstract url": "https://arxiv.org/abs/2411.05942",
        "title": "Diamond open access and open infrastructures have shaped the Canadian scholarly journal landscape since the start of the digital era",
        "rating": "-10",
        "keywords": [],
        "abstract": "Scholarly publishing involves multiple stakeholders having various types of interest. In Canada, the implication of universities, the presence of societies and the availability of governmental support for periodicals seem to have contributed to a rather diverse ecosystem of journals. This study presents in detail the current state of these journals, in addition to past trends and transformations during the 20th century and, in particular, the digital era. To this effect, we created a new dataset, including a total of 1256 journals, 944 of which appeared to be active today, specifically focusing on the supporting organizations behind the journals, the types of (open) access, disciplines, geographic origins, languages of publication and hosting platforms and tools. The main overarching traits across Canadian scholarly journals are an important presence of Diamond open access, which has been adopted by 62% of the journals, a predominance of the Social Sciences and Humanities disciplines and a scarce presence of the major commercial publishers. The digital era allowed for the development of open infrastructures, which contributed to the creation of a new generation of journals that massively adopted Diamond open access, often supported by university libraries. However, journal cessation also increased, especially among the recently founded journals. These results provide valuable insights for the design of tailored practices and policies that cater to the needs of different types of periodicals and that take into account the evolving practices across the Canadian scholarly journal landscape.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "23 pages; 7 figures and 3 tables"
    },
    {
        "paper id": "2411.05951",
        "abstract url": "https://arxiv.org/abs/2411.05951",
        "title": "Approaching multifractal complexity in decentralized cryptocurrency trading",
        "rating": "-10",
        "keywords": [],
        "abstract": "Multifractality is a concept that helps compactly grasping the most essential features of the financial dynamics. In its fully developed form, this concept applies to essentially all mature financial markets and even to more liquid cryptocurrencies traded on the centralized exchanges. A new element that adds complexity to cryptocurrency markets is the possibility of decentralized trading. Based on the extracted tick-by-tick transaction data from the Universal Router contract of the Uniswap decentralized exchange, from June 6, 2023, to June 30, 2024, the present study using Multifractal Detrended Fluctuation Analysis (MFDFA) shows that even though liquidity on these new exchanges is still much lower compared to centralized exchanges convincing traces of multifractality are already emerging on this new trading as well. The resulting multifractal spectra are however strongly left-side asymmetric which indicates that this multifractality comes primarily from large fluctuations and small ones are more of the uncorrelated noise type. What is particularly interesting here is the fact that multifractality is more developed for time series representing transaction volumes than rates of return. On the level of these larger events a trace of multifractal cross-correlations between the two characteristics is also observed.",
        "subjects": [
            "q-fin.ST",
            "cs.CE",
            "q-fin.TR",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05975",
        "abstract url": "https://arxiv.org/abs/2411.05975",
        "title": "Adaptive Tracking Control with Binary-Valued Output Observations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper considers real-time control and learning problems for finite-dimensional linear systems under binary-valued and randomly disturbed output observations. This has long been regarded as an open problem because the exact values of the traditional regression vectors used in the construction of adaptive algorithms are unavailable, as one only has binary-valued output information. To overcome this difficulty, we consider the adaptive estimation problem of the corresponding infinite-impulse-response (IIR) dynamical systems, and apply the double array martingale theory that has not been previously used in adaptive control. This enables us to establish global convergence results for both the adaptive prediction regret and the parameter estimation error, without resorting to such stringent data conditions as persistent excitation and bounded system signals that have been used in almost all existing related literature. Based on this, an adaptive control law will be designed that can effectively combine adaptive learning and feedback control. Finally, we are able to show that the closed-loop adaptive control system is optimal in the sense that the long-run average tracking error is minimized almost surely for any given bounded reference signals. To the best of the authors' knowledge, this appears to be the first adaptive control result for general linear systems with general binary sensors and arbitrarily given bounded reference signals.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05987",
        "abstract url": "https://arxiv.org/abs/2411.05987",
        "title": "Multiuser Commitment over Noisy Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider multi-user commitment models that capture the problem of enabling multiple bidders to simultaneously submit auctions to verifiers while ensuring that i) verifiers do not obtain information on the auctions until bidders reveal them at a later stage; and, ii) bidders cannot change their auction once committed. Specifically, we assume that bidders and verifiers have access to a noiseless channel as well as a noisy multiple-access channel or broadcast channel, where inputs are controlled by the bidders and outputs are observed by verifiers. In the case of multiple bidders and a single verifier connected by a non-redundant multiple-access channel, we characterize the commitment capacity region when bidders are not colluding. When the bidders are colluding, we derive an achievable region and a tight converse for the sum rate. In both cases our proposed achievable commitment schemes are constructive. In the case of a single bidder and multiple verifiers connected by a non-redundant broadcast channel, in which verifiers could drop out of the network after auctions are committed, we also characterize the commitment capacity. Our results demonstrate how commitment schemes can benefit from multi-user protocols, and develop resilience when some verifiers may become unavailable.",
        "subjects": [
            "cs.IT",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.05989",
        "abstract url": "https://arxiv.org/abs/2411.05989",
        "title": "Filter-Banks for Ultra-Wideband Communications: Advantages and Design Challenges",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recently, filter-bank multicarrier spread spectrum (FBMC-SS) has been proposed as a candidate waveform for ultra-wideband (UWB) communications. It has been noted that FBMC-SS is a perfect match to this application, leading to a trivial method of matching to the required spectral mask at different regions of the world. FBMC-SS also allows easy rejection of high-power interfering signals that may appear over different parts of the UWB spectral band. In this paper, we concentrate on the use of staggered multitone spread spectrum (SMT-SS) for UWB communications. SMT makes use of offset quadrature amplitude modulation (OQAM) to transmit data symbols over narrowband, overlapping subcarrier bands. This form of FBMC-SS is well-suited to UWB communications because it has good spectral efficiency and a flat power spectral density (PSD), resulting in good utilization of the UWB spectral mask. Additionally, we explore new methods for multi-coding that result in higher bit rates than previous FBMC-SS systems. Moreover, we study methods for equalizing the UWB multipath channel and cancelling narrowband interference. Excellent performance of the proposed methods are substantiated by presenting simulation results.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 6 figures, submitted to IEEE International Communications Conference"
    },
    {
        "paper id": "2411.06004",
        "abstract url": "https://arxiv.org/abs/2411.06004",
        "title": "Do Data Center Network Metrics Predict Application-Facing Performance?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Applications that run in large-scale data center networks (DCNs) rely on the DCN's ability to deliver application requests in a performant manner. DCNs expose a complex design and operational space, and network designers and operators care how different options along this space affect application performance. One might run controlled experiments and measure the corresponding application-facing performance, but such experiments become progressively infeasible at a large scale, and simulations risk yielding inaccurate or incomplete results. Instead, we show that we can predict application-facing performance through more easily measured network metrics. For example, network telemetry metrics (e.g., link utilization) can predict application-facing metrics (e.g., transfer latency). Through large-scale measurements of production networks, we study the correlation between the two types of metrics, and construct predictive, interpretable models that serve as a suggestive guideline to network designers and operators. We show that no single network metric is universally the best predictor (even though some prior work has focused on a single predictor). We found that simple linear models often have the lowest error, while queueing-based models are better in a few cases.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "17 (main body) + 5 (appendix) pages"
    },
    {
        "paper id": "2411.06017",
        "abstract url": "https://arxiv.org/abs/2411.06017",
        "title": "Provocation on Expertise in Social Impact Evaluations of Generative AI (and Beyond)",
        "rating": "-10",
        "keywords": [],
        "abstract": "Social impact evaluations are emerging as a useful tool to understand, document, and evaluate the societal impacts of generative AI. In this provocation, we begin to think carefully about the types of experts and expertise that are needed to conduct robust social impact evaluations of generative AI. We suggest that doing so will require thoughtfully eliciting and integrating insights from a range of \"domain experts\" and \"experiential experts,\" and close with five open questions.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06043",
        "abstract url": "https://arxiv.org/abs/2411.06043",
        "title": "The subTuring degrees",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this article, we introduce a notion of reducibility for partial functions on the natural numbers, which we call subTuring reducibility. One important aspect is that the subTuring degrees correspond to the structure of the realizability subtoposes of the effective topos. We show that the subTuring degrees (that is, the realizability subtoposes of the effective topos) form a dense non-modular (thus, non-distributive) lattice. We also show that there is a nonzero join-irreducible subTuring degree (which implies that there is a realizability subtopos of the effective topos that cannot be decomposed into two smaller realizability subtoposes).",
        "subjects": [
            "math.LO",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06059",
        "abstract url": "https://arxiv.org/abs/2411.06059",
        "title": "ANCoEF: Asynchronous Neuromorphic Algorithm/Hardware Co-Exploration Framework with a Fully Asynchronous Simulator",
        "rating": "-10",
        "keywords": [],
        "abstract": "Developing asynchronous neuromorphic hardware to meet the demands of diverse real-life edge scenarios remains significant challenges. These challenges include constraints on hardware resources and power budgets while satisfying the requirements for real-time responsiveness, reliable inference accuracy, and so on. Besides, the existing system-level simulators for asynchronous neuromorphic hardware suffer from runtime limitations. To address these challenges, we propose an Asynchronous Neuromorphic algorithm/hardware Co-Exploration Framework (ANCoEF) including multi-objective reinforcement learning (RL)-based hardware architecture optimization method, and a fully asynchronous simulator (TrueAsync) which achieves over 2 times runtime speedups than the state-of-the-art (SOTA) simulator. Our experimental results show that, the RL-based hardware architecture optimization approach of ANCoEF outperforms the SOTA method by reducing 1.81 times hardware energy-delay product (EDP) with 2.73 times less search time on N-MNIST dataset, and the co-exploration framework of ANCoEF improves SNN accuracy by 9.72% and reduces hardware EDP by 28.85 times compared to the SOTA work on DVS128Gesture dataset. Furthermore, ANCoEF framework is evaluated on external neuromorphic dataset CIFAR10-DVS, and static datasets including CIFAR10, CIFAR100, SVHN, and Tiny-ImageNet. For instance, after 26.23 ThreadHour of co-exploration process, the result on CIFAR10-DVS dataset achieves an SNN accuracy of 98.48% while consuming hardware EDP of 0.54 s nJ per sample.",
        "subjects": [
            "cs.AR",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2411.06064",
        "abstract url": "https://arxiv.org/abs/2411.06064",
        "title": "Snippet-based Conversational Recommender System",
        "rating": "-10",
        "keywords": [],
        "abstract": "Conversational Recommender Systems (CRS) engage users in interactive dialogues to gather preferences and provide personalized recommendations. Traditionally, CRS rely on pre-defined attributes or expensive, domain-specific annotated datasets to guide conversations, which limits flexibility and adaptability across domains. In this work, we introduce SnipRec, a novel CRS that enhances dialogues and recommendations by extracting diverse expressions and preferences from user-generated content (UGC) like customer reviews. Using large language models, SnipRec maps user responses and UGC to concise snippets, which are used to generate clarification questions and retrieve relevant items. Our approach eliminates the need for domain-specific training, making it adaptable to new domains and effective without prior knowledge of user preferences. Extensive experiments on the Yelp dataset demonstrate the effectiveness of snippet-based representations against document and sentence-based representations. Additionally, SnipRec is able to improve Hits@10 by 0.25 over the course of five conversational turns, underscoring the efficiency of SnipRec in capturing user preferences through multi-turn conversations.",
        "subjects": [
            "cs.IR"
        ],
        "comment": null
    }
]