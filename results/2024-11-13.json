[
    {
        "paper id": "2411.08606",
        "abstract url": "https://arxiv.org/abs/2411.08606",
        "title": "LG-Gaze: Learning Geometry-aware Continuous Prompts for Language-Guided Gaze Estimation",
        "rating": "2.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "The ability of gaze estimation models to generalize is often significantly hindered by various factors unrelated to gaze, especially when the training dataset is limited. Current strategies aim to address this challenge through different domain generalization techniques, yet they have had limited success due to the risk of overfitting when solely relying on value labels for regression. Recent progress in pre-trained vision-language models has motivated us to capitalize on the abundant semantic information available. We propose a novel approach in this paper, reframing the gaze estimation task as a vision-language alignment issue. Our proposed framework, named Language-Guided Gaze Estimation (LG-Gaze), learns continuous and geometry-sensitive features for gaze estimation benefit from the rich prior knowledges of vision-language models. Specifically, LG-Gaze aligns gaze features with continuous linguistic features through our proposed multimodal contrastive regression loss, which customizes adaptive weights for different negative samples. Furthermore, to better adapt to the labels for gaze estimation task, we propose a geometry-aware interpolation method to obtain more precise gaze embeddings. Through extensive experiments, we validate the efficacy of our framework in four different cross-domain evaluation tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted to ECCV 2024"
    },
    {
        "paper id": "2411.08610",
        "abstract url": "https://arxiv.org/abs/2411.08610",
        "title": "Dynamic Subset Tuning: Expanding the Operational Range of Parameter-Efficient Training for Large Language Models",
        "rating": "2.5",
        "keywords": [
            [
                "Parameter-Efficient"
            ],
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We propose a novel parameter-efficient training (PET) method for large language models that adapts models to downstream tasks by optimizing a small subset of the existing model parameters. Unlike prior methods, this subset is not fixed in location but rather which parameters are modified evolves over the course of training. This dynamic parameter selection can yield good performance with many fewer parameters than extant methods. Our method enables a seamless scaling of the subset size across an arbitrary proportion of the total model size, while popular PET approaches like prompt tuning and LoRA cover only a small part of this spectrum. We match or outperform prompt tuning and LoRA in most cases on a variety of NLP tasks (MT, QA, GSM8K, SuperGLUE) for a given parameter budget across different model families and sizes.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "NeurIPS 2024 Workshop on Adaptive Foundation Models"
    },
    {
        "paper id": "2411.08768",
        "abstract url": "https://arxiv.org/abs/2411.08768",
        "title": "Sharingan: Extract User Action Sequence from Desktop Recordings",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Video recordings of user activities, particularly desktop recordings, offer a rich source of data for understanding user behaviors and automating processes. However, despite advancements in Vision-Language Models (VLMs) and their increasing use in video analysis, extracting user actions from desktop recordings remains an underexplored area. This paper addresses this gap by proposing two novel VLM-based methods for user action extraction: the Direct Frame-Based Approach (DF), which inputs sampled frames directly into VLMs, and the Differential Frame-Based Approach (DiffF), which incorporates explicit frame differences detected via computer vision techniques. We evaluate these methods using a basic self-curated dataset and an advanced benchmark adapted from prior work. Our results show that the DF approach achieves an accuracy of 70% to 80% in identifying user actions, with the extracted action sequences being re-playable though Robotic Process Automation. We find that while VLMs show potential, incorporating explicit UI changes can degrade performance, making the DF approach more reliable. This work represents the first application of VLMs for extracting user action sequences from desktop recordings, contributing new methods, benchmarks, and insights for future research.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09018",
        "abstract url": "https://arxiv.org/abs/2411.09018",
        "title": "Bridging the Visual Gap: Fine-Tuning Multimodal Models with Knowledge-Adapted Captions",
        "rating": "2",
        "keywords": [
            [
                "vision-language",
                "VLMs"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Recent research increasingly focuses on training vision-language models (VLMs) with long, detailed image captions. However, small-scale VLMs often struggle to balance the richness of these captions with the risk of hallucinating content during fine-tuning. In this paper, we explore how well VLMs adapt to such captions. To quantify caption quality, we propose Decomposed NLI (DNLI), an evaluation framework that breaks down generated captions into individual propositions, assessing each in isolation. This fine-grained analysis reveals a critical balance between capturing descriptive details and preventing hallucinations. Our findings show that simply reducing caption complexity or employing standard data curation techniques does not effectively resolve this issue. To tackle this challenge, we introduce Knowledge Adapted (KnowAda) fine-tuning, a data-centric approach that automatically adapts training data with the model's existing knowledge and visual understanding. KnowAda minimizes hallucinations while preserving high descriptiveness. We validate this approach across several small-scale VLMs (up to 7B parameters) and dense caption datasets, demonstrating that KnowAda effectively balances hallucination reduction and descriptiveness. Our results show that KnowAda outperforms various baselines in both automatic metrics and human evaluations. We will release our code and models.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09126",
        "abstract url": "https://arxiv.org/abs/2411.09126",
        "title": "SCAN: Bootstrapping Contrastive Pre-training for Data Efficiency",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While contrastive pre-training is widely employed, its data efficiency problem has remained relatively under-explored thus far. Existing methods often rely on static coreset selection algorithms to pre-identify important data for training. However, this static nature renders them unable to dynamically track the data usefulness throughout pre-training, leading to subpar pre-trained models. To address this challenge, our paper introduces a novel dynamic bootstrapping dataset pruning method. It involves pruning data preparation followed by dataset mutation operations, both of which undergo iterative and dynamic updates. We apply this method to two prevalent contrastive pre-training frameworks: \\textbf{CLIP} and \\textbf{MoCo}, representing vision-language and vision-centric domains, respectively. In particular, we individually pre-train seven CLIP models on two large-scale image-text pair datasets, and two MoCo models on the ImageNet dataset, resulting in a total of 16 pre-trained models. With a data pruning rate of 30-35\\% across all 16 models, our method exhibits only marginal performance degradation (less than \\textbf{1\\%} on average) compared to corresponding models trained on the full dataset counterparts across various downstream datasets, and also surpasses several baselines with a large performance margin. Additionally, the byproduct from our method, \\ie coresets derived from the original datasets after pre-training, also demonstrates significant superiority in terms of downstream performance over other static coreset selection approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08470",
        "abstract url": "https://arxiv.org/abs/2411.08470",
        "title": "HyperFace: Generating Synthetic Face Recognition Datasets by Exploring Face Embedding Hypersphere",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Face recognition datasets are often collected by crawling Internet and without individuals' consents, raising ethical and privacy concerns. Generating synthetic datasets for training face recognition models has emerged as a promising alternative. However, the generation of synthetic datasets remains challenging as it entails adequate inter-class and intra-class variations. While advances in generative models have made it easier to increase intra-class variations in face datasets (such as pose, illumination, etc.), generating sufficient inter-class variation is still a difficult task. In this paper, we formulate the dataset generation as a packing problem on the embedding space (represented on a hypersphere) of a face recognition model and propose a new synthetic dataset generation approach, called HyperFace. We formalize our packing problem as an optimization problem and solve it with a gradient descent-based approach. Then, we use a conditional face generator model to synthesize face images from the optimized embeddings. We use our generated datasets to train face recognition models and evaluate the trained models on several benchmarking real datasets. Our experimental results show that models trained with HyperFace achieve state-of-the-art performance in training face recognition using synthetic datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted in NeurIPS 2024 Safe Generative AI Workshop"
    },
    {
        "paper id": "2411.08553",
        "abstract url": "https://arxiv.org/abs/2411.08553",
        "title": "CorrSynth -- A Correlated Sampling Method for Diverse Dataset Generation from LLMs",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated remarkable performance in diverse tasks using zero-shot and few-shot prompting. Even though their capabilities of data synthesis have been studied well in recent years, the generated data suffers from a lack of diversity, less adherence to the prompt, and potential biases that creep into the data from the generator model. In this work, we tackle the challenge of generating datasets with high diversity, upon which a student model is trained for downstream tasks. Taking the route of decoding-time guidance-based approaches, we propose CorrSynth, which generates data that is more diverse and faithful to the input prompt using a correlated sampling strategy. Further, our method overcomes the complexity drawbacks of some other guidance-based techniques like classifier-based guidance. With extensive experiments, we show the effectiveness of our approach and substantiate our claims. In particular, we perform intrinsic evaluation to show the improvements in diversity. Our experiments show that CorrSynth improves both student metrics and intrinsic metrics upon competitive baselines across four datasets, showing the innate advantage of our method.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Published as a main conference paper at EMNLP 2024; First two authors contributed equally"
    },
    {
        "paper id": "2411.08715",
        "abstract url": "https://arxiv.org/abs/2411.08715",
        "title": "Retrieval Augmented Recipe Generation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Given the potential applications of generating recipes from food images, this area has garnered significant attention from researchers in recent years. Existing works for recipe generation primarily utilize a two-stage training method, first generating ingredients and then obtaining instructions from both the image and ingredients. Large Multi-modal Models (LMMs), which have achieved notable success across a variety of vision and language tasks, shed light to generating both ingredients and instructions directly from images. Nevertheless, LMMs still face the common issue of hallucinations during recipe generation, leading to suboptimal performance. To tackle this, we propose a retrieval augmented large multimodal model for recipe generation. We first introduce Stochastic Diversified Retrieval Augmentation (SDRA) to retrieve recipes semantically related to the image from an existing datastore as a supplement, integrating them into the prompt to add diverse and rich context to the input image. Additionally, Self-Consistency Ensemble Voting mechanism is proposed to determine the most confident prediction recipes as the final output. It calculates the consistency among generated recipe candidates, which use different retrieval recipes as context for generation. Extensive experiments validate the effectiveness of our proposed method, which demonstrates state-of-the-art (SOTA) performance in recipe generation tasks on the Recipe1M dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "ACCEPT on IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2025"
    },
    {
        "paper id": "2411.08733",
        "abstract url": "https://arxiv.org/abs/2411.08733",
        "title": "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Aligning Large Language Models (LLMs) traditionally relies on costly training and human preference annotations. Self-alignment seeks to reduce these expenses by enabling models to align themselves. To further lower costs and achieve alignment without any expensive tuning or annotations, we introduce a new tuning-free approach for self-alignment, Dynamic Rewarding with Prompt Optimization (DRPO). Our approach leverages a search-based optimization framework that allows LLMs to iteratively self-improve and craft the optimal alignment instructions, all without additional training or human intervention. The core of DRPO is a dynamic rewarding mechanism, which identifies and rectifies model-specific alignment weaknesses, allowing LLMs to adapt efficiently to diverse alignment challenges. Empirical evaluations on eight recent LLMs, both open- and closed-sourced, demonstrate that DRPO significantly enhances alignment performance, with base models outperforming their SFT/RLHF-tuned counterparts. Moreover, the prompts automatically optimized by DRPO surpass those curated by human experts, further validating the effectiveness of our approach. Our findings highlight the great potential of current LLMs to achieve adaptive self-alignment through inference-time optimization, complementing tuning-based alignment methods.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EMNLP 2024 Main"
    },
    {
        "paper id": "2411.08745",
        "abstract url": "https://arxiv.org/abs/2411.08745",
        "title": "Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "ICML"
            ]
        ],
        "abstract": "A central question in multilingual language modeling is whether large language models (LLMs) develop a universal concept representation, disentangled from specific languages. In this paper, we address this question by analyzing latent representations (latents) during a word translation task in transformer-based LLMs. We strategically extract latents from a source translation prompt and insert them into the forward pass on a target translation prompt. By doing so, we find that the output language is encoded in the latent at an earlier layer than the concept to be translated. Building on this insight, we conduct two key experiments. First, we demonstrate that we can change the concept without changing the language and vice versa through activation patching alone. Second, we show that patching with the mean over latents across different languages does not impair and instead improves the models' performance in translating the concept. Our results provide evidence for the existence of language-agnostic concept representations within the investigated models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "12 pages, 10 figures, previous version published under the title \"How Do Llamas Process Multilingual Text? A Latent Exploration through Activation Patching\" at the ICML 2024 mechanistic interpretability workshop at https://openreview.net/forum?id=0ku2hIm4BS"
    },
    {
        "paper id": "2411.08968",
        "abstract url": "https://arxiv.org/abs/2411.08968",
        "title": "Sparse Upcycling: Inference Inefficient Finetuning",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Small, highly trained, open-source large language models are widely used due to their inference efficiency, but further improving their quality remains a challenge. Sparse upcycling is a promising approach that transforms a pretrained dense model into a Mixture-of-Experts (MoE) architecture, increasing the model's parameter count and quality. In this work, we compare the effectiveness of sparse upcycling against continued pretraining (CPT) across different model sizes, compute budgets, and pretraining durations. Our experiments show that sparse upcycling can achieve better quality, with improvements of over 20% relative to CPT in certain scenarios. However, this comes with a significant inference cost, leading to 40% slowdowns in high-demand inference settings for larger models. Our findings highlight the trade-off between model quality and inference efficiency, offering insights for practitioners seeking to balance model quality and deployment constraints.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "12 pages, 4 figures, To appear in the 4th NeurIPS Workshop on Efficient Natural Language and Speech Processing (ENLSP), 2024"
    },
    {
        "paper id": "2411.10480",
        "abstract url": "https://arxiv.org/abs/2411.10480",
        "title": "Hateful Meme Detection through Context-Sensitive Prompting and Fine-Grained Labeling",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "The prevalence of multi-modal content on social media complicates automated moderation strategies. This calls for an enhancement in multi-modal classification and a deeper understanding of understated meanings in images and memes. Although previous efforts have aimed at improving model performance through fine-tuning, few have explored an end-to-end optimization pipeline that accounts for modalities, prompting, labeling, and fine-tuning. In this study, we propose an end-to-end conceptual framework for model optimization in complex tasks. Experiments support the efficacy of this traditional yet novel framework, achieving the highest accuracy and AUROC. Ablation experiments demonstrate that isolated optimizations are not ineffective on their own.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.MM"
        ],
        "comment": "AAAI-25 Student Abstract, Oral Presentation"
    },
    {
        "paper id": "2411.08348",
        "abstract url": "https://arxiv.org/abs/2411.08348",
        "title": "Refining Translations with LLMs: A Constraint-Aware Iterative Prompting Approach",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in machine translation (MT), even without specific training on the languages in question. However, translating rare words in low-resource or domain-specific contexts remains challenging for LLMs. To address this issue, we propose a multi-step prompt chain that enhances translation faithfulness by prioritizing key terms crucial for semantic accuracy. Our method first identifies these keywords and retrieves their translations from a bilingual dictionary, integrating them into the LLM's context using Retrieval-Augmented Generation (RAG). We further mitigate potential output hallucinations caused by long prompts through an iterative self-checking mechanism, where the LLM refines its translations based on lexical and semantic constraints. Experiments using Llama and Qwen as base models on the FLORES-200 and WMT datasets demonstrate significant improvements over baselines, highlighting the effectiveness of our approach in enhancing translation faithfulness and robustness, particularly in low-resource scenarios.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08375",
        "abstract url": "https://arxiv.org/abs/2411.08375",
        "title": "Developing an Effective Training Dataset to Enhance the Performance of AI-based Speaker Separation Systems",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper addresses the challenge of speaker separation, which remains an active research topic despite the promising results achieved in recent years. These results, however, often degrade in real recording conditions due to the presence of noise, echo, and other interferences. This is because neural models are typically trained on synthetic datasets consisting of mixed audio signals and their corresponding ground truths, which are generated using computer software and do not fully represent the complexities of real-world recording scenarios. The lack of realistic training sets for speaker separation remains a major hurdle, as obtaining individual sounds from mixed audio signals is a nontrivial task. To address this issue, we propose a novel method for constructing a realistic training set that includes mixture signals and corresponding ground truths for each speaker. We evaluate this dataset on a deep learning model and compare it to a synthetic dataset. We got a 1.65 dB improvement in Scale Invariant Signal to Distortion Ratio (SI-SDR) for speaker separation accuracy in realistic mixing. Our findings highlight the potential of realistic training sets for enhancing the performance of speaker separation models in real-world scenarios.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "comment": "in Arabic language"
    },
    {
        "paper id": "2411.08380",
        "abstract url": "https://arxiv.org/abs/2411.08380",
        "title": "EgoVid-5M: A Large-Scale Video-Action Dataset for Egocentric Video Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video generation has emerged as a promising tool for world simulation, leveraging visual data to replicate real-world environments. Within this context, egocentric video generation, which centers on the human perspective, holds significant potential for enhancing applications in virtual reality, augmented reality, and gaming. However, the generation of egocentric videos presents substantial challenges due to the dynamic nature of egocentric viewpoints, the intricate diversity of actions, and the complex variety of scenes encountered. Existing datasets are inadequate for addressing these challenges effectively. To bridge this gap, we present EgoVid-5M, the first high-quality dataset specifically curated for egocentric video generation. EgoVid-5M encompasses 5 million egocentric video clips and is enriched with detailed action annotations, including fine-grained kinematic control and high-level textual descriptions. To ensure the integrity and usability of the dataset, we implement a sophisticated data cleaning pipeline designed to maintain frame consistency, action coherence, and motion smoothness under egocentric conditions. Furthermore, we introduce EgoDreamer, which is capable of generating egocentric videos driven simultaneously by action descriptions and kinematic control signals. The EgoVid-5M dataset, associated action annotations, and all data cleansing metadata will be released for the advancement of research in egocentric video generation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://egovid.github.io/"
    },
    {
        "paper id": "2411.08384",
        "abstract url": "https://arxiv.org/abs/2411.08384",
        "title": "Interpretable Syntactic Representations Enable Hierarchical Word Vectors",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The distributed representations currently used are dense and uninterpretable, leading to interpretations that themselves are relative, overcomplete, and hard to interpret. We propose a method that transforms these word vectors into reduced syntactic representations. The resulting representations are compact and interpretable allowing better visualization and comparison of the word vectors and we successively demonstrate that the drawn interpretations are in line with human judgment. The syntactic representations are then used to create hierarchical word vectors using an incremental learning approach similar to the hierarchical aspect of human learning. As these representations are drawn from pre-trained vectors, the generation process and learning approach are computationally efficient. Most importantly, we find out that syntactic representations provide a plausible interpretation of the vectors and subsequent hierarchical vectors outperform the original vectors in benchmark tests.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08395",
        "abstract url": "https://arxiv.org/abs/2411.08395",
        "title": "MambaXCTrack: Mamba-based Tracker with SSM Cross-correlation and Motion Prompt for Ultrasound Needle Tracking",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Ultrasound (US)-guided needle insertion is widely employed in percutaneous interventions. However, providing feedback on the needle tip position via US image presents challenges due to noise, artifacts, and the thin imaging plane of US, which degrades needle features and leads to intermittent tip visibility. In this paper, a Mamba-based US needle tracker MambaXCTrack utilizing structured state space models cross-correlation (SSMX-Corr) and implicit motion prompt is proposed, which is the first application of Mamba in US needle tracking. The SSMX-Corr enhances cross-correlation by long-range modeling and global searching of distant semantic features between template and search maps, benefiting the tracking under noise and artifacts by implicitly learning potential distant semantic cues. By combining with cross-map interleaved scan (CIS), local pixel-wise interaction with positional inductive bias can also be introduced to SSMX-Corr. The implicit low-level motion descriptor is proposed as a non-visual prompt to enhance tracking robustness, addressing the intermittent tip visibility problem. Extensive experiments on a dataset with motorized needle insertion in both phantom and tissue samples demonstrate that the proposed tracker outperforms other state-of-the-art trackers while ablation studies further highlight the effectiveness of each proposed tracking module.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.08397",
        "abstract url": "https://arxiv.org/abs/2411.08397",
        "title": "CLaSP: Learning Concepts for Time-Series Signals from Natural Language Supervision",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "This paper proposes a foundation model called \"CLaSP\" that can search time series signals using natural language that describes the characteristics of the signals as queries. Previous efforts to represent time series signal data in natural language have had challenges in designing a conventional class of time series signal characteristics, formulating their quantification, and creating a dictionary of synonyms. To overcome these limitations, the proposed method introduces a neural network based on contrastive learning. This network is first trained using the datasets TRUCE and SUSHI, which consist of time series signals and their corresponding natural language descriptions. Previous studies have proposed vocabularies that data analysts use to describe signal characteristics, and SUSHI was designed to cover these terms. We believe that a neural network trained on these datasets will enable data analysts to search using natural language vocabulary. Furthermore, our method does not require a dictionary of predefined synonyms, and it leverages common sense knowledge embedded in a large-scale language model (LLM). Experimental results demonstrate that CLaSP enables natural language search of time series signal data and can accurately learn the points at which signal data changes.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08432",
        "abstract url": "https://arxiv.org/abs/2411.08432",
        "title": "One STEP at a time: Language Agents are Stepwise Planners",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Language agents have shown promising adaptability in dynamic environments to perform complex tasks. However, despite the versatile knowledge embedded in large language models, these agents still fall short when it comes to tasks that require planning. We introduce STEP, a novel framework designed to efficiently learn from previous experiences to enhance the planning capabilities of language agents in future steps. Concretely, STEP functions through four interconnected components. First, the Planner takes on the task, breaks it down into subtasks and provides relevant insights. Then the Executor generates action candidates, while the Evaluator ensures the actions align with learned rules from previous experiences. Lastly, Memory stores experiences to inform future decisions. In the ScienceWorld benchmark, our results show that STEP consistently outperforms state-of-the-art models, achieving an overall score of 67.4 and successfully completing 12 out of 18 tasks. These findings highlight STEP's potential as a framework for enhancing planning capabilities in language agents, paving the way for more sophisticated task-solving in dynamic environments.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08451",
        "abstract url": "https://arxiv.org/abs/2411.08451",
        "title": "AD-DINO: Attention-Dynamic DINO for Distance-Aware Embodied Reference Understanding",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Embodied reference understanding is crucial for intelligent agents to predict referents based on human intention through gesture signals and language descriptions. This paper introduces the Attention-Dynamic DINO, a novel framework designed to mitigate misinterpretations of pointing gestures across various interaction contexts. Our approach integrates visual and textual features to simultaneously predict the target object's bounding box and the attention source in pointing gestures. Leveraging the distance-aware nature of nonverbal communication in visual perspective taking, we extend the virtual touch line mechanism and propose an attention-dynamic touch line to represent referring gesture based on interactive distances. The combination of this distance-aware approach and independent prediction of the attention source, enhances the alignment between objects and the gesture represented line. Extensive experiments on the YouRefIt dataset demonstrate the efficacy of our gesture information understanding method in significantly improving task performance. Our model achieves 76.4% accuracy at the 0.25 IoU threshold and, notably, surpasses human performance at the 0.75 IoU threshold, marking a first in this domain. Comparative experiments with distance-unaware understanding methods from previous research further validate the superiority of the Attention-Dynamic Touch Line across diverse contexts.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08466",
        "abstract url": "https://arxiv.org/abs/2411.08466",
        "title": "Can MLLMs Guide Weakly-Supervised Temporal Action Localization Tasks?",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent breakthroughs in Multimodal Large Language Models (MLLMs) have gained significant recognition within the deep learning community, where the fusion of the Video Foundation Models (VFMs) and Large Language Models(LLMs) has proven instrumental in constructing robust video understanding systems, effectively surmounting constraints associated with predefined visual tasks. These sophisticated MLLMs exhibit remarkable proficiency in comprehending videos, swiftly attaining unprecedented performance levels across diverse benchmarks. However, their operation demands substantial memory and computational resources, underscoring the continued importance of traditional models in video comprehension tasks. In this paper, we introduce a novel learning paradigm termed MLLM4WTAL. This paradigm harnesses the potential of MLLM to offer temporal action key semantics and complete semantic priors for conventional Weakly-supervised Temporal Action Localization (WTAL) methods. MLLM4WTAL facilitates the enhancement of WTAL by leveraging MLLM guidance. It achieves this by integrating two distinct modules: Key Semantic Matching (KSM) and Complete Semantic Reconstruction (CSR). These modules work in tandem to effectively address prevalent issues like incomplete and over-complete outcomes common in WTAL methods. Rigorous experiments are conducted to validate the efficacy of our proposed approach in augmenting the performance of various heterogeneous WTAL models.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08504",
        "abstract url": "https://arxiv.org/abs/2411.08504",
        "title": "Towards Objective and Unbiased Decision Assessments with LLM-Enhanced Hierarchical Attention Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "How objective and unbiased are we while making decisions? This work investigates cognitive bias identification in high-stake decision making process by human experts, questioning its effectiveness in real-world settings, such as candidates assessments for university admission. We begin with a statistical analysis assessing correlations among different decision points among in the current process, which discovers discrepancies that imply cognitive bias and inconsistency in decisions. This motivates our exploration of bias-aware AI-augmented workflow that surpass human judgment. We propose BGM-HAN, an enhanced Hierarchical Attention Network with Byte-Pair Encoding, Gated Residual Connections and Multi-Head Attention. Using it as a backbone model, we further propose a Shortlist-Analyse-Recommend (SAR) agentic workflow, which simulate real-world decision-making. In our experiments, both the proposed model and the agentic workflow significantly improves on both human judgment and alternative models, validated with real-world data.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Source code is available at: https://github.com/junhua/bgm-han"
    },
    {
        "paper id": "2411.08506",
        "abstract url": "https://arxiv.org/abs/2411.08506",
        "title": "Towards Operationalizing Right to Data Protection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The widespread practice of indiscriminate data scraping to fine-tune language models (LMs) raises significant legal and ethical concerns, particularly regarding compliance with data protection laws such as the General Data Protection Regulation (GDPR). This practice often results in the unauthorized use of personal information, prompting growing debate within the academic and regulatory communities. Recent works have introduced the concept of generating unlearnable datasets (by adding imperceptible noise to the clean data), such that the underlying model achieves lower loss during training but fails to generalize to the unseen test setting. Though somewhat effective, these approaches are predominantly designed for images and are limited by several practical constraints like requiring knowledge of the target model. To this end, we introduce RegText, a framework that injects imperceptible spurious correlations into natural language datasets, effectively rendering them unlearnable without affecting semantic content. We demonstrate RegText's utility through rigorous empirical analysis of small and large LMs. Notably, RegText can restrict newer models like GPT-4o and Llama from learning on our generated data, resulting in a drop in their test accuracy compared to their zero-shot performance and paving the way for generating unlearnable text to protect public data.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": "First two authors contributed equally to this work"
    },
    {
        "paper id": "2411.08534",
        "abstract url": "https://arxiv.org/abs/2411.08534",
        "title": "Neural Topic Modeling with Large Language Models in the Loop",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Topic modeling is a fundamental task in natural language processing, allowing the discovery of latent thematic structures in text corpora. While Large Language Models (LLMs) have demonstrated promising capabilities in topic discovery, their direct application to topic modeling suffers from issues such as incomplete topic coverage, misalignment of topics, and inefficiency. To address these limitations, we propose LLM-ITL, a novel LLM-in-the-loop framework that integrates LLMs with many existing Neural Topic Models (NTMs). In LLM-ITL, global topics and document representations are learned through the NTM, while an LLM refines the topics via a confidence-weighted Optimal Transport (OT)-based alignment objective. This process enhances the interpretability and coherence of the learned topics, while maintaining the efficiency of NTMs. Extensive experiments demonstrate that LLM-ITL can help NTMs significantly improve their topic interpretability while maintaining the quality of document representation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08545",
        "abstract url": "https://arxiv.org/abs/2411.08545",
        "title": "APDDv2: Aesthetics of Paintings and Drawings Dataset with Artist Labeled Scores and Comments",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Datasets play a pivotal role in training visual models, facilitating the development of abstract understandings of visual features through diverse image samples and multidimensional attributes. However, in the realm of aesthetic evaluation of artistic images, datasets remain relatively scarce. Existing painting datasets are often characterized by limited scoring dimensions and insufficient annotations, thereby constraining the advancement and application of automatic aesthetic evaluation methods in the domain of painting. To bridge this gap, we introduce the Aesthetics Paintings and Drawings Dataset (APDD), the first comprehensive collection of paintings encompassing 24 distinct artistic categories and 10 aesthetic attributes. Building upon the initial release of APDDv1, our ongoing research has identified opportunities for enhancement in data scale and annotation precision. Consequently, APDDv2 boasts an expanded image corpus and improved annotation quality, featuring detailed language comments to better cater to the needs of both researchers and practitioners seeking high-quality painting datasets. Furthermore, we present an updated version of the Art Assessment Network for Specific Painting Styles, denoted as ArtCLIP. Experimental validation demonstrates the superior performance of this revised model in the realm of aesthetic evaluation, surpassing its predecessor in accuracy and efficacy. The dataset and model are available at https://github.com/BestiVictory/APDDv2.git.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08557",
        "abstract url": "https://arxiv.org/abs/2411.08557",
        "title": "Learning Locally Adaptive Metrics that Enhance Structural Representation with $\\texttt{LAMINAR}$",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We present $\\texttt{LAMINAR}$, a novel unsupervised machine learning pipeline designed to enhance the representation of structure within data via producing a more-informative distance metric. Analysis methods in the physical sciences often rely on standard metrics to define geometric relationships in data, which may fail to capture the underlying structure of complex data sets. $\\texttt{LAMINAR}$ addresses this by using a continuous-normalising-flow and inverse-transform-sampling to define a Riemannian manifold in the data space without the need for the user to specify a metric over the data a-priori. The result is a locally-adaptive-metric that produces structurally-informative density-based distances. We demonstrate the utility of $\\texttt{LAMINAR}$ by comparing its output to the Euclidean metric for structured data sets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to the NeurIPS 2024 Machine Learning and the Physical Sciences workshop. 6 pages, 6 figures"
    },
    {
        "paper id": "2411.08567",
        "abstract url": "https://arxiv.org/abs/2411.08567",
        "title": "Saliency Map-based Image Retrieval using Invariant Krawtchouk Moments",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the widespread adoption of digital devices equipped with cameras and the rapid development of Internet technology, numerous content-based image retrieval systems and novel image feature extraction techniques have emerged in recent years. This paper introduces a saliency map-based image retrieval approach using invariant Krawtchouk moments (SM-IKM) to enhance retrieval speed and accuracy. The proposed method applies a global contrast-based salient region detection algorithm to create a saliency map that effectively isolates the foreground from the background. It then combines multiple orders of invariant Krawtchouk moments (IKM) with local binary patterns (LBPs) and color histograms to comprehensively represent the foreground and background. Additionally, it incorporates LBPs derived from the saliency map to improve discriminative power, facilitating more precise image differentiation. A bag-of-visual-words (BoVW) model is employed to generate a codebook for classification and discrimination. By using compact IKMs in the BoVW framework and integrating a range of region-based feature-including color histograms, LBPs, and saliency map-enhanced LBPs, our proposed SM-IKM achieves efficient and accurate image retrieval. Extensive experiments on publicly available datasets, such as Caltech 101 and Wang, demonstrate that SM-IKM outperforms recent state-of-the-art retrieval methods. The source code for SM-IKM is available at github.com/arnejad/SMIKM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08569",
        "abstract url": "https://arxiv.org/abs/2411.08569",
        "title": "UIFormer: A Unified Transformer-based Framework for Incremental Few-Shot Object Detection and Instance Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a novel framework for unified incremental few-shot object detection (iFSOD) and instance segmentation (iFSIS) using the Transformer architecture. Our goal is to create an optimal solution for situations where only a few examples of novel object classes are available, with no access to training data for base or old classes, while maintaining high performance across both base and novel classes. To achieve this, We extend Mask-DINO into a two-stage incremental learning framework. Stage 1 focuses on optimizing the model using the base dataset, while Stage 2 involves fine-tuning the model on novel classes. Besides, we incorporate a classifier selection strategy that assigns appropriate classifiers to the encoder and decoder according to their distinct functions. Empirical evidence indicates that this approach effectively mitigates the over-fitting on novel classes learning. Furthermore, we implement knowledge distillation to prevent catastrophic forgetting of base classes. Comprehensive evaluations on the COCO and LVIS datasets for both iFSIS and iFSOD tasks demonstrate that our method significantly outperforms state-of-the-art approaches.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 3 figures"
    },
    {
        "paper id": "2411.08587",
        "abstract url": "https://arxiv.org/abs/2411.08587",
        "title": "DeepUQ: Assessing the Aleatoric Uncertainties from two Deep Learning Methods",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Assessing the quality of aleatoric uncertainty estimates from uncertainty quantification (UQ) deep learning methods is important in scientific contexts, where uncertainty is physically meaningful and important to characterize and interpret exactly. We systematically compare aleatoric uncertainty measured by two UQ techniques, Deep Ensembles (DE) and Deep Evidential Regression (DER). Our method focuses on both zero-dimensional (0D) and two-dimensional (2D) data, to explore how the UQ methods function for different data dimensionalities. We investigate uncertainty injected on the input and output variables and include a method to propagate uncertainty in the case of input uncertainty so that we can compare the predicted aleatoric uncertainty to the known values. We experiment with three levels of noise. The aleatoric uncertainty predicted across all models and experiments scales with the injected noise level. However, the predicted uncertainty is miscalibrated to $\\rm{std}(\u03c3_{\\rm al})$ with the true uncertainty for half of the DE experiments and almost all of the DER experiments. The predicted uncertainty is the least accurate for both UQ methods for the 2D input uncertainty experiment and the high-noise level. While these results do not apply to more complex data, they highlight that further research on post-facto calibration for these methods would be beneficial, particularly for high-noise and high-dimensional settings.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Accepted to the Machine Learning for Physical Sciences workshop at NeurIPS 2024; 11 pages, 2 figures, 2 tables"
    },
    {
        "paper id": "2411.08708",
        "abstract url": "https://arxiv.org/abs/2411.08708",
        "title": "Are Triggers Needed for Document-Level Event Extraction?",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Most existing work on event extraction has focused on sentence-level texts and presumes the identification of a trigger-span -- a word or phrase in the input that evokes the occurrence of an event of interest. Event arguments are then extracted with respect to the trigger. Indeed, triggers are treated as integral to, and trigger detection as an essential component of, event extraction. In this paper, we provide the first investigation of the role of triggers for the more difficult and much less studied task of document-level event extraction. We analyze their usefulness in multiple end-to-end and pipelined neural event extraction models for three document-level event extraction datasets, measuring performance using triggers of varying quality (human-annotated, LLM-generated, keyword-based, and random). Our research shows that trigger effectiveness varies based on the extraction task's characteristics and data quality, with basic, automatically-generated triggers serving as a viable alternative to human-annotated ones. Furthermore, providing detailed event descriptions to the extraction model helps maintain robust performance even when trigger quality degrades. Perhaps surprisingly, we also find that the mere existence of trigger input, even random ones, is important for prompt-based LLM approaches to the task.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08726",
        "abstract url": "https://arxiv.org/abs/2411.08726",
        "title": "Analyst Reports and Stock Performance: Evidence from the Chinese Market",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This article applies natural language processing (NLP) to extract and quantify textual information to predict stock performance. Using an extensive dataset of Chinese analyst reports and employing a customized BERT deep learning model for Chinese text, this study categorizes the sentiment of the reports as positive, neutral, or negative. The findings underscore the predictive capacity of this sentiment indicator for stock volatility, excess returns, and trading volume. Specifically, analyst reports with strong positive sentiment will increase excess return and intraday volatility, and vice versa, reports with strong negative sentiment also increase volatility and trading volume, but decrease future excess return. The magnitude of this effect is greater for positive sentiment reports than for negative sentiment reports. This article contributes to the empirical literature on sentiment analysis and the response of the stock market to news in the Chinese stock market.",
        "subjects": [
            "cs.CL",
            "q-fin.CP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08742",
        "abstract url": "https://arxiv.org/abs/2411.08742",
        "title": "A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "With the rise of Speech Large Language Models (Speech LLMs), there has been growing interest in discrete speech tokens for their ability to integrate with text-based tokens seamlessly. Compared to most studies that focus on continuous speech features, although discrete-token based LLMs have shown promising results on certain tasks, the performance gap between these two paradigms is rarely explored. In this paper, we present a fair and thorough comparison between discrete and continuous features across a variety of semantic-related tasks using a light-weight LLM (Qwen1.5-0.5B). Our findings reveal that continuous features generally outperform discrete tokens, particularly in tasks requiring fine-grained semantic understanding. Moreover, this study goes beyond surface-level comparison by identifying key factors behind the under-performance of discrete tokens, such as limited token granularity and inefficient information retention. To enhance the performance of discrete tokens, we explore potential aspects based on our analysis. We hope our results can offer new insights into the opportunities for advancing discrete speech tokens in Speech LLMs.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "5 tables, 4 figures"
    },
    {
        "paper id": "2411.08752",
        "abstract url": "https://arxiv.org/abs/2411.08752",
        "title": "Multi-Perspective Stance Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Subjective NLP tasks usually rely on human annotations provided by multiple annotators, whose judgments may vary due to their diverse backgrounds and life experiences. Traditional methods often aggregate multiple annotations into a single ground truth, disregarding the diversity in perspectives that arises from annotator disagreement. In this preliminary study, we examine the effect of including multiple annotations on model accuracy in classification. Our methodology investigates the performance of perspective-aware classification models in stance detection task and further inspects if annotator disagreement affects the model confidence. The results show that multi-perspective approach yields better classification performance outperforming the baseline which uses the single label. This entails that designing more inclusive perspective-aware AI models is not only an essential first step in implementing responsible and ethical AI, but it can also achieve superior results than using the traditional approaches.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08753",
        "abstract url": "https://arxiv.org/abs/2411.08753",
        "title": "Which Viewpoint Shows it Best? Language for Weakly Supervising View Selection in Multi-view Videos",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Given a multi-view video, which viewpoint is most informative for a human observer? Existing methods rely on heuristics or expensive ``best-view\" supervision to answer this question, limiting their applicability. We propose a weakly supervised approach that leverages language accompanying an instructional multi-view video as a means to recover its most informative viewpoint(s). Our key hypothesis is that the more accurately an individual view can predict a view-agnostic text summary, the more informative it is. To put this into action, we propose a framework that uses the relative accuracy of view-dependent caption predictions as a proxy for best view pseudo-labels. Then, those pseudo-labels are used to train a view selector, together with an auxiliary camera pose predictor that enhances view-sensitivity. During inference, our model takes as input only a multi-view video -- no language or camera poses -- and returns the best viewpoint to watch at each timestep. On two challenging datasets comprised of diverse multi-camera setups and how-to activities, our model consistently outperforms state-of-the-art baselines, both with quantitative metrics and human evaluation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08756",
        "abstract url": "https://arxiv.org/abs/2411.08756",
        "title": "Masked Image Modeling Boosting Semi-Supervised Semantic Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In view of the fact that semi- and self-supervised learning share a fundamental principle, effectively modeling knowledge from unlabeled data, various semi-supervised semantic segmentation methods have integrated representative self-supervised learning paradigms for further regularization. However, the potential of the state-of-the-art generative self-supervised paradigm, masked image modeling, has been scarcely studied. This paradigm learns the knowledge through establishing connections between the masked and visible parts of masked image, during the pixel reconstruction process. By inheriting and extending this insight, we successfully leverage masked image modeling to boost semi-supervised semantic segmentation. Specifically, we introduce a novel class-wise masked image modeling that independently reconstructs different image regions according to their respective classes. In this way, the mask-induced connections are established within each class, mitigating the semantic confusion that arises from plainly reconstructing images in basic masked image modeling. To strengthen these intra-class connections, we further develop a feature aggregation strategy that minimizes the distances between features corresponding to the masked and visible parts within the same class. Additionally, in semantic space, we explore the application of masked image modeling to enhance regularization. Extensive experiments conducted on well-known benchmarks demonstrate that our approach achieves state-of-the-art performance. The code will be available at https://github.com/haoxt/S4MIM.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "13 pages. This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.08785",
        "abstract url": "https://arxiv.org/abs/2411.08785",
        "title": "Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The majority of previous researches addressing multi-lingual IE are limited to zero-shot cross-lingual single-transfer (one-to-one) setting, with high-resource languages predominantly as source training data. As a result, these works provide little understanding and benefit for the realistic goal of developing a multi-lingual IE system that can generalize to as many languages as possible. Our study aims to fill this gap by providing a detailed analysis on Cross-Lingual Multi-Transferability (many-to-many transfer learning), for the recent IE corpora that cover a diverse set of languages. Specifically, we first determine the correlation between single-transfer performance and a wide range of linguistic-based distances. From the obtained insights, a combined language distance metric can be developed that is not only highly correlated but also robust across different tasks and model scales. Next, we investigate the more general zero-shot multi-lingual transfer settings where multiple languages are involved in the training and evaluation processes. Language clustering based on the newly defined distance can provide directions for achieving the optimal cost-performance trade-off in data (languages) selection problem. Finally, a relational-transfer setting is proposed to further incorporate multi-lingual unlabeled data based on adversarial training using the relation induced from the above linguistic distance.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08790",
        "abstract url": "https://arxiv.org/abs/2411.08790",
        "title": "Can sparse autoencoders be used to decompose and interpret steering vectors?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Steering vectors are a promising approach to control the behaviour of large language models. However, their underlying mechanisms remain poorly understood. While sparse autoencoders (SAEs) may offer a potential method to interpret steering vectors, recent findings show that SAE-reconstructed vectors often lack the steering properties of the original vectors. This paper investigates why directly applying SAEs to steering vectors yields misleading decompositions, identifying two reasons: (1) steering vectors fall outside the input distribution for which SAEs are designed, and (2) steering vectors can have meaningful negative projections in feature directions, which SAEs are not designed to accommodate. These limitations hinder the direct use of SAEs for interpreting steering vectors.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08813",
        "abstract url": "https://arxiv.org/abs/2411.08813",
        "title": "Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique",
        "rating": "1",
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "A key development in the cybersecurity evaluations space is the work carried out by Meta, through their CyberSecEval approach. While this work is undoubtedly a useful contribution to a nascent field, there are notable features that limit its utility. Key drawbacks focus on the insecure code detection part of Meta's methodology. We explore these limitations, and use our exploration as a test case for LLM-assisted benchmark analysis.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "NeurIPS 2024, 2 pages"
    },
    {
        "paper id": "2411.08840",
        "abstract url": "https://arxiv.org/abs/2411.08840",
        "title": "Multimodal Instruction Tuning with Hybrid State Space Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Handling lengthy context is crucial for enhancing the recognition and understanding capabilities of multimodal large language models (MLLMs) in applications such as processing high-resolution images or high frame rate videos. The rise in image resolution and frame rate substantially increases computational demands due to the increased number of input tokens. This challenge is further exacerbated by the quadratic complexity with respect to sequence length of the self-attention mechanism. Most prior works either pre-train models with long contexts, overlooking the efficiency problem, or attempt to reduce the context length via downsampling (e.g., identify the key image patches or frames) to decrease the context length, which may result in information loss. To circumvent this issue while keeping the remarkable effectiveness of MLLMs, we propose a novel approach using a hybrid transformer-MAMBA model to efficiently handle long contexts in multimodal applications. Our multimodal model can effectively process long context input exceeding 100k tokens, outperforming existing models across various benchmarks. Remarkably, our model enhances inference efficiency for high-resolution images and high-frame-rate videos by about 4 times compared to current models, with efficiency gains increasing as image resolution or video frames rise. Furthermore, our model is the first to be trained on low-resolution images or low-frame-rate videos while being capable of inference on high-resolution images and high-frame-rate videos, offering flexibility for inference in diverse scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08878",
        "abstract url": "https://arxiv.org/abs/2411.08878",
        "title": "A Short Note on Evaluating RepNet for Temporal Repetition Counting in Videos",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We discuss some consistent issues on how RepNet has been evaluated in various papers. As a way to mitigate these issues, we report RepNet performance results on different datasets, and release evaluation code and the RepNet checkpoint to obtain these results. Code URL: https://github.com/google-research/google-research/blob/master/repnet/",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08937",
        "abstract url": "https://arxiv.org/abs/2411.08937",
        "title": "Dual-Head Knowledge Distillation: Enhancing Logits Utilization with an Auxiliary Head",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Traditional knowledge distillation focuses on aligning the student's predicted probabilities with both ground-truth labels and the teacher's predicted probabilities. However, the transition to predicted probabilities from logits would obscure certain indispensable information. To address this issue, it is intuitive to additionally introduce a logit-level loss function as a supplement to the widely used probability-level loss function, for exploiting the latent information of logits. Unfortunately, we empirically find that the amalgamation of the newly introduced logit-level loss and the previous probability-level loss will lead to performance degeneration, even trailing behind the performance of employing either loss in isolation. We attribute this phenomenon to the collapse of the classification head, which is verified by our theoretical analysis based on the neural collapse theory. Specifically, the gradients of the two loss functions exhibit contradictions in the linear classifier yet display no such conflict within the backbone. Drawing from the theoretical analysis, we propose a novel method called dual-head knowledge distillation, which partitions the linear classifier into two classification heads responsible for different losses, thereby preserving the beneficial effects of both losses on the backbone while eliminating adverse influences on the classification head. Extensive experiments validate that our method can effectively exploit the information inside the logits and achieve superior performance against state-of-the-art counterparts.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2411.08977",
        "abstract url": "https://arxiv.org/abs/2411.08977",
        "title": "Robustness and Confounders in the Demographic Alignment of LLMs with Human Perceptions of Offensiveness",
        "rating": "1",
        "keywords": [
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) are known to exhibit demographic biases, yet few studies systematically evaluate these biases across multiple datasets or account for confounding factors. In this work, we examine LLM alignment with human annotations in five offensive language datasets, comprising approximately 220K annotations. Our findings reveal that while demographic traits, particularly race, influence alignment, these effects are inconsistent across datasets and often entangled with other factors. Confounders -- such as document difficulty, annotator sensitivity, and within-group agreement -- account for more variation in alignment patterns than demographic traits alone. Specifically, alignment increases with higher annotator sensitivity and group agreement, while greater document difficulty corresponds to reduced alignment. Our results underscore the importance of multi-dataset analyses and confounder-aware methodologies in developing robust measures of demographic bias in LLMs.",
        "subjects": [
            "cs.CY",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08979",
        "abstract url": "https://arxiv.org/abs/2411.08979",
        "title": "CoCoP: Enhancing Text Classification with LLM through Code Completion Prompt",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Text classification is a fundamental task in natural language processing (NLP), and large language models (LLMs) have demonstrated their capability to perform this task across various domains. However, the performance of LLMs heavily depends on the quality of their input prompts. Recent studies have also shown that LLMs exhibit remarkable results in code-related tasks. To leverage the capabilities of LLMs in text classification, we propose the Code Completion Prompt (CoCoP) method, which transforms the text classification problem into a code completion task. CoCoP significantly improves text classification performance across diverse datasets by utilizing LLMs' code-completion capability. For instance, CoCoP enhances the accuracy of the SST2 dataset by more than 20%. Moreover, when CoCoP integrated with LLMs specifically designed for code-related tasks (code models), such as CodeLLaMA, this method demonstrates better or comparable performance to few-shot learning techniques while using only one-tenth of the model size. The source code of our proposed method will be available to the public upon the acceptance of the paper.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08992",
        "abstract url": "https://arxiv.org/abs/2411.08992",
        "title": "IDCIA: Immunocytochemistry Dataset for Cellular Image Analysis",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We present a new annotated microscopic cellular image dataset to improve the effectiveness of machine learning methods for cellular image analysis. Cell counting is an important step in cell analysis. Typically, domain experts manually count cells in a microscopic image. Automated cell counting can potentially eliminate this tedious, time-consuming process. However, a good, labeled dataset is required for training an accurate machine learning model. Our dataset includes microscopic images of cells, and for each image, the cell count and the location of individual cells. The data were collected as part of an ongoing study investigating the potential of electrical stimulation to modulate stem cell differentiation and possible applications for neural repair. Compared to existing publicly available datasets, our dataset has more images of cells stained with more variety of antibodies (protein components of immune responses against invaders) typically used for cell analysis. The experimental results on this dataset indicate that none of the five existing models under this study are able to achieve sufficiently accurate count to replace the manual methods. The dataset is available at https://figshare.com/articles/dataset/Dataset/21970604.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08995",
        "abstract url": "https://arxiv.org/abs/2411.08995",
        "title": "Computed tomography using meta-optics",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Computer vision tasks require processing large amounts of data to perform image classification, segmentation, and feature extraction. Optical preprocessors can potentially reduce the number of floating point operations required by computer vision tasks, enabling low-power and low-latency operation. However, existing optical preprocessors are mostly learned and hence strongly depend on the training data, and thus lack universal applicability. In this paper, we present a metaoptic imager, which implements the Radon transform obviating the need for training the optics. High quality image reconstruction with a large compression ratio of 0.6% is presented through the use of the Simultaneous Algebraic Reconstruction Technique. Image classification with 90% accuracy is presented on an experimentally measured Radon dataset through neural network trained on digitally transformed images.",
        "subjects": [
            "cs.CV",
            "physics.optics"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09003",
        "abstract url": "https://arxiv.org/abs/2411.09003",
        "title": "Refusal in LLMs is an Affine Function",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "We propose affine concept editing (ACE) as an approach for steering language models' behavior by intervening directly in activations. We begin with an affine decomposition of model activation vectors and show that prior methods for steering model behavior correspond to subsets of terms of this decomposition. We then provide a derivation of ACE and use it to control refusal behavior on ten different models, including Llama 3 70B. ACE combines affine subspace projection and activation addition to reliably control the model's refusal responses across prompt types. We evaluate the results using LLM-based scoring on a collection of harmful and harmless prompts. Our experiments demonstrate that ACE consistently achieves more precise control over model behavior than existing methods and generalizes to models where directional ablation via affine subspace projection alone produces incoherent outputs. Code for reproducing our results is available at https://github.com/EleutherAI/steering-llama3 .",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "added plots for results from additional models"
    },
    {
        "paper id": "2411.09009",
        "abstract url": "https://arxiv.org/abs/2411.09009",
        "title": "Cut Your Losses in Large-Vocabulary Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "As language models grow ever larger, so do their vocabularies. This has shifted the memory footprint of LLMs during training disproportionately to one single layer: the cross-entropy in the loss computation. Cross-entropy builds up a logit matrix with entries for each pair of input tokens and vocabulary items and, for small models, consumes an order of magnitude more memory than the rest of the LLM combined. We propose Cut Cross-Entropy (CCE), a method that computes the cross-entropy loss without materializing the logits for all tokens into global memory. Rather, CCE only computes the logit for the correct token and evaluates the log-sum-exp over all logits on the fly. We implement a custom kernel that performs the matrix multiplications and the log-sum-exp reduction over the vocabulary in flash memory, making global memory consumption for the cross-entropy computation negligible. This has a dramatic effect. Taking the Gemma 2 (2B) model as an example, CCE reduces the memory footprint of the loss computation from 24 GB to 1 MB, and the total training-time memory consumption of the classifier head from 28 GB to 1 GB. To improve the throughput of CCE, we leverage the inherent sparsity of softmax and propose to skip elements of the gradient computation that have a negligible (i.e., below numerical precision) contribution to the gradient. Experiments demonstrate that the dramatic reduction in memory consumption is accomplished without sacrificing training speed or convergence.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "Code is available at https://github.com/apple/ml-cross-entropy"
    },
    {
        "paper id": "2411.09052",
        "abstract url": "https://arxiv.org/abs/2411.09052",
        "title": "ClevrSkills: Compositional Language and Visual Reasoning in Robotics",
        "rating": "1",
        "keywords": [
            [
                "vision language",
                "VLMs"
            ],
            [
                "Robotics",
                "robot"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Robotics tasks are highly compositional by nature. For example, to perform a high-level task like cleaning the table a robot must employ low-level capabilities of moving the effectors to the objects on the table, pick them up and then move them off the table one-by-one, while re-evaluating the consequently dynamic scenario in the process. Given that large vision language models (VLMs) have shown progress on many tasks that require high level, human-like reasoning, we ask the question: if the models are taught the requisite low-level capabilities, can they compose them in novel ways to achieve interesting high-level tasks like cleaning the table without having to be explicitly taught so? To this end, we present ClevrSkills - a benchmark suite for compositional reasoning in robotics. ClevrSkills is an environment suite developed on top of the ManiSkill2 simulator and an accompanying dataset. The dataset contains trajectories generated on a range of robotics tasks with language and visual annotations as well as multi-modal prompts as task specification. The suite includes a curriculum of tasks with three levels of compositional understanding, starting with simple tasks requiring basic motor skills. We benchmark multiple different VLM baselines on ClevrSkills and show that even after being pre-trained on large numbers of tasks, these models fail on compositional reasoning in robotics tasks.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "To appear at NeurIPS 2024 (D&B track)"
    },
    {
        "paper id": "2411.09073",
        "abstract url": "https://arxiv.org/abs/2411.09073",
        "title": "Code-mixed LLM: Improve Large Language Models' Capability to Handle Code-Mixing through Reinforcement Learning from AI Feedback",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Code-mixing(CM) or code-switching(CSW) refers to the juxtaposition of linguistic units from two or more languages during the conversation or sometimes even a single utterance. Code-mixing introduces unique challenges in daily life, such as syntactic mismatches and semantic blending, that are rarely encountered in monolingual settings. Large language models (LLMs) have revolutionized the field of natural language processing (NLP) by offering unprecedented capabilities in understanding human languages. However, the effectiveness of current state-of-the-art multilingual LLMs has not yet been fully explored in the CM scenario. To fill this gap, we first benchmark the performance of multilingual LLMs on various code-mixing NLP tasks. Then we propose to improve the multilingual LLMs' ability to understand code-mixing through reinforcement learning from human feedback (RLHF) and code-mixed machine translation tasks. Given the high-cost and time-consuming preference labeling procedure, we improve this by utilizing LLMs as annotators to perform the reinforcement learning from AI feedback (RLAIF). The experiments show the effectiveness of the proposed method.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "initial version: 5 pages, 2 figures"
    },
    {
        "paper id": "2411.09102",
        "abstract url": "https://arxiv.org/abs/2411.09102",
        "title": "Provocation: Who benefits from \"inclusion\" in Generative AI?",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "The demands for accurate and representative generative AI systems means there is an increased demand on participatory evaluation structures. While these participatory structures are paramount to to ensure non-dominant values, knowledge and material culture are also reflected in AI models and the media they generate, we argue that dominant structures of community participation in AI development and evaluation are not explicit enough about the benefits and harms that members of socially marginalized groups may experience as a result of their participation. Without explicit interrogation of these benefits by AI developers, as a community we may remain blind to the immensity of systemic change that is needed as well. To support this provocation, we present a speculative case study, developed from our own collective experiences as AI researchers. We use this speculative context to itemize the barriers that need to be overcome in order for the proposed benefits to marginalized communities to be realized, and harms mitigated.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "comment": "3 pages, 1 figure. Published as a Short Paper in the NeurIPS 2024 Workshop on Evaluating Evaluations: Examining Best Practices for Measuring Broader Impacts of Generative AI"
    },
    {
        "paper id": "2411.09105",
        "abstract url": "https://arxiv.org/abs/2411.09105",
        "title": "VCBench: A Controllable Benchmark for Symbolic and Abstract Challenges in Video Cognition",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in Large Video-Language Models (LVLMs) have driven the development of benchmarks designed to assess cognitive abilities in video-based tasks. However, most existing benchmarks heavily rely on web-collected videos paired with human annotations or model-generated questions, which limit control over the video content and fall short in evaluating advanced cognitive abilities involving symbolic elements and abstract concepts. To address these limitations, we introduce VCBench, a controllable benchmark to assess LVLMs' cognitive abilities, involving symbolic and abstract concepts at varying difficulty levels. By generating video data with the Python-based engine, VCBench allows for precise control over the video content, creating dynamic, task-oriented videos that feature complex scenes and abstract concepts. Each task pairs with tailored question templates that target specific cognitive challenges, providing a rigorous evaluation test. Our evaluation reveals that even state-of-the-art (SOTA) models, such as Qwen2-VL-72B, struggle with simple video cognition tasks involving abstract concepts, with performance sharply dropping by 19% as video complexity rises. These findings reveal the current limitations of LVLMs in advanced cognitive tasks and highlight the critical role of VCBench in driving research toward more robust LVLMs for complex video cognition challenges.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09109",
        "abstract url": "https://arxiv.org/abs/2411.09109",
        "title": "Personalized Help for Optimizing Low-Skilled Users' Strategy",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "AIs can beat humans in game environments; however, how helpful those agents are to human remains understudied. We augment CICERO, a natural language agent that demonstrates superhuman performance in Diplomacy, to generate both move and message advice based on player intentions. A dozen Diplomacy games with novice and experienced players, with varying advice settings, show that some of the generated advice is beneficial. It helps novices compete with experienced players and in some instances even surpass them. The mere presence of advice can be advantageous, even if players do not follow it.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "9 pages, 3 figures"
    },
    {
        "paper id": "2411.09111",
        "abstract url": "https://arxiv.org/abs/2411.09111",
        "title": "Reducing Reasoning Costs -- The Path of Optimization for Chain of Thought via Sparse Attention Mechanism",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "In order to address the chain of thought in the large language model inference cost surge, this research proposes to use a sparse attention mechanism that only focuses on a few relevant tokens. The researcher constructed a new attention mechanism and used GiantRabbit trained with custom GPTs as an experimental tool. The experiment tested and compared the reasoning time, correctness score and chain of thought length of this model and o1 Preview in solving the linear algebra test questions of MIT OpenCourseWare. The results show that GiantRabbit's reasoning time and chain of thought length are significantly lower than o1 Preview, confirming the feasibility of the sparse attention mechanism in reducing chain of thought reasoning. Detailed architectural details and experimental process have been uploaded to Github, the link is:https://github.com/brucewang123456789/GeniusTrail.git.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "The main text is 9 pages, totaling 13 pages; 5 figures, 3 tables; preprints have been submitted to NeurIPS 2024 Workshop MusIML and OpenReview"
    },
    {
        "paper id": "2411.09116",
        "abstract url": "https://arxiv.org/abs/2411.09116",
        "title": "P-MMEval: A Parallel Multilingual Multitask Benchmark for Consistent Evaluation of LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advancements in large language models (LLMs) showcase varied multilingual capabilities across tasks like translation, code generation, and reasoning. Previous assessments often limited their scope to fundamental natural language processing (NLP) or isolated capability-specific tasks. To alleviate this drawback, we aim to present a comprehensive multilingual multitask benchmark. First, we present a pipeline for selecting available and reasonable benchmarks from massive ones, addressing the oversight in previous work regarding the utility of these benchmarks, i.e., their ability to differentiate between models being evaluated. Leveraging this pipeline, we introduce P-MMEval, a large-scale benchmark covering effective fundamental and capability-specialized datasets. Furthermore, P-MMEval delivers consistent language coverage across various datasets and provides parallel samples. Finally, we conduct extensive experiments on representative multilingual model series to compare performances across models, analyze dataset effectiveness, examine prompt impacts on model performances, and explore the relationship between multilingual performances and factors such as tasks, model sizes, and languages. These insights offer valuable guidance for future research. The dataset is available at https://huggingface.co/datasets/Qwen/P-MMEval.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09137",
        "abstract url": "https://arxiv.org/abs/2411.09137",
        "title": "Fast probabilistic snake algorithm",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Few people use the probability theory in order to achieve image segmentation with snake models. In this article, we are presenting an active contour algorithm based on a probability approach inspired by A. Blake work and P. R{\u00e9}fr{\u00e9}gier's team research in France. Our algorithm, both very fast and highly accurate as far as contour description is concerned, is easily adaptable to any specific application.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09166",
        "abstract url": "https://arxiv.org/abs/2411.09166",
        "title": "Unstructured Text Enhanced Open-domain Dialogue System: A Systematic Survey",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Incorporating external knowledge into dialogue generation has been proven to benefit the performance of an open-domain Dialogue System (DS), such as generating informative or stylized responses, controlling conversation topics. In this article, we study the open-domain DS that uses unstructured text as external knowledge sources (\\textbf{U}nstructured \\textbf{T}ext \\textbf{E}nhanced \\textbf{D}ialogue \\textbf{S}ystem, \\textbf{UTEDS}). The existence of unstructured text entails distinctions between UTEDS and traditional data-driven DS and we aim to analyze these differences. We first give the definition of the UTEDS related concepts, then summarize the recently released datasets and models. We categorize UTEDS into Retrieval and Generative models and introduce them from the perspective of model components. The retrieval models consist of Fusion, Matching, and Ranking modules, while the generative models comprise Dialogue and Knowledge Encoding, Knowledge Selection, and Response Generation modules. We further summarize the evaluation methods utilized in UTEDS and analyze the current models' performance. At last, we discuss the future development trends of UTEDS, hoping to inspire new research in this field.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "45 pages, 3 Figures, 11 Tables"
    },
    {
        "paper id": "2411.09176",
        "abstract url": "https://arxiv.org/abs/2411.09176",
        "title": "Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Imagine searching a collection of coins for quarters ($0.25$), dimes ($0.10$), nickels ($0.05$), and pennies ($0.01$)-a hybrid foraging task where observers look for multiple instances of multiple target types. In such tasks, how do target values and their prevalence influence foraging and eye movement behaviors (e.g., should you prioritize rare quarters or common nickels)? To explore this, we conducted human psychophysics experiments, revealing that humans are proficient reward foragers. Their eye fixations are drawn to regions with higher average rewards, fixation durations are longer on more valuable targets, and their cumulative rewards exceed chance, approaching the upper bound of optimal foragers. To probe these decision-making processes of humans, we developed a transformer-based Visual Forager (VF) model trained via reinforcement learning. Our VF model takes a series of targets, their corresponding values, and the search image as inputs, processes the images using foveated vision, and produces a sequence of eye movements along with decisions on whether to collect each fixated item. Our model outperforms all baselines, achieves cumulative rewards comparable to those of humans, and approximates human foraging behavior in eye movements and foraging biases within time-limited environments. Furthermore, stress tests on out-of-distribution tasks with novel targets, unseen values, and varying set sizes demonstrate the VF model's effective generalization. Our work offers valuable insights into the relationship between eye movements and decision-making, with our model serving as a powerful tool for further exploration of this connection. All data, code, and models will be made publicly available.",
        "subjects": [
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.14453",
        "abstract url": "https://arxiv.org/abs/2411.14453",
        "title": "Direct Speech-to-Speech Neural Machine Translation: A Survey",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Speech-to-Speech Translation (S2ST) models transform speech from one language to another target language with the same linguistic information. S2ST is important for bridging the communication gap among communities and has diverse applications. In recent years, researchers have introduced direct S2ST models, which have the potential to translate speech without relying on intermediate text generation, have better decoding latency, and the ability to preserve paralinguistic and non-linguistic features. However, direct S2ST has yet to achieve quality performance for seamless communication and still lags behind the cascade models in terms of performance, especially in real-world translation. To the best of our knowledge, no comprehensive survey is available on the direct S2ST system, which beginners and advanced researchers can look upon for a quick survey. The present work provides a comprehensive review of direct S2ST models, data and application issues, and performance metrics. We critically analyze the models' performance over the benchmark datasets and provide research challenges and future directions.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.17708",
        "abstract url": "https://arxiv.org/abs/2411.17708",
        "title": "Towards Efficient Neurally-Guided Program Induction for ARC-AGI",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "ARC-AGI is an open-world problem domain in which the ability to generalize out-of-distribution is a crucial quality. Under the program induction paradigm, we present a series of experiments that reveal the efficiency and generalization characteristics of various neurally-guided program induction approaches. The three paradigms we consider are Learning the grid space, Learning the program space, and Learning the transform space. We implement and experiment thoroughly on the first two, and retain the second one for ARC-AGI submission. After identifying the strengths and weaknesses of both of these approaches, we suggest the third as a potential solution, and run preliminary experiments.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08363",
        "abstract url": "https://arxiv.org/abs/2411.08363",
        "title": "On Algorithmic Fairness and the EU Regulations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The paper discusses algorithmic fairness by focusing on non-discrimination and a few important laws in the European Union (EU). In addition to the EU laws addressing discrimination explicitly, the discussion is based on the EU's recently enacted regulation for artificial intelligence (AI) and the older General Data Protection Regulation (GDPR). Through theoretical case analysis, on one hand, the paper demonstrates that correcting discriminatory biases in AI systems can be legally done under the EU regulations. On the other hand, the cases also illustrate some practical scenarios from which legal non-compliance may follow. With these cases and the accompanying discussion, the paper contributes to the algorithmic fairness research with a few legal insights, enlarging and strengthening also the growing research domain of compliance in software engineering.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "Submitted"
    },
    {
        "paper id": "2411.08367",
        "abstract url": "https://arxiv.org/abs/2411.08367",
        "title": "Surprisingly Popular Voting for Concentric Rank-Order Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "An important problem on social information sites is the recovery of ground truth from individual reports when the experts are in the minority. The wisdom of the crowd, i.e. the collective opinion of a group of individuals fails in such a scenario. However, the surprisingly popular (SP) algorithm~\\cite{prelec2017solution} can recover the ground truth even when the experts are in the minority, by asking the individuals to report additional prediction reports--their beliefs about the reports of others. Several recent works have extended the surprisingly popular algorithm to an equivalent voting rule (SP-voting) to recover the ground truth ranking over a set of $m$ alternatives. However, we are yet to fully understand when SP-voting can recover the ground truth ranking, and if so, how many samples (votes and predictions) it needs. We answer this question by proposing two rank-order models and analyzing the sample complexity of SP-voting under these models. In particular, we propose concentric mixtures of Mallows and Plackett-Luce models with $G (\\ge 2)$ groups. Our models generalize previously proposed concentric mixtures of Mallows models with $2$ groups, and we highlight the importance of $G > 2$ groups by identifying three distinct groups (expert, intermediate, and non-expert) from existing datasets. Next, we provide conditions on the parameters of the underlying models so that SP-voting can recover ground-truth rankings with high probability, and also derive sample complexities under the same. We complement the theoretical results by evaluating SP-voting on simulated and real datasets.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08400",
        "abstract url": "https://arxiv.org/abs/2411.08400",
        "title": "BAMAX: Backtrack Assisted Multi-Agent Exploration using Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Autonomous robots collaboratively exploring an unknown environment is still an open problem. The problem has its roots in coordination among non-stationary agents, each with only a partial view of information. The problem is compounded when the multiple robots must completely explore the environment. In this paper, we introduce Backtrack Assisted Multi-Agent Exploration using Reinforcement Learning (BAMAX), a method for collaborative exploration in multi-agent systems which attempts to explore an entire virtual environment. As in the name, BAMAX leverages backtrack assistance to enhance the performance of agents in exploration tasks. To evaluate BAMAX against traditional approaches, we present the results of experiments conducted across multiple hexagonal shaped grids sizes, ranging from 10x10 to 60x60. The results demonstrate that BAMAX outperforms other methods in terms of faster coverage and less backtracking across these environments.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08418",
        "abstract url": "https://arxiv.org/abs/2411.08418",
        "title": "Enhanced Classroom Dialogue Sequences Analysis with a Hybrid AI Agent: Merging Expert Rule-Base with Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Classroom dialogue plays a crucial role in fostering student engagement and deeper learning. However, analysing dialogue sequences has traditionally relied on either theoretical frameworks or empirical descriptions of practice, with limited integration between the two. This study addresses this gap by developing a comprehensive rule base of dialogue sequences and an Artificial Intelligence (AI) agent that combines expert-informed rule-based systems with a large language model (LLM). The agent applies expert knowledge while adapting to the complexities of natural language, enabling accurate and flexible categorisation of classroom dialogue sequences. By synthesising findings from over 30 studies, we established a comprehensive framework for dialogue analysis. The agent was validated against human expert coding, achieving high levels of precision and reliability. The results demonstrate that the agent provides theory-grounded and adaptive functions, tremendously enhancing the efficiency and scalability of classroom dialogue analysis, offering significant potential in improving classroom teaching practices and supporting teacher professional development.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08425",
        "abstract url": "https://arxiv.org/abs/2411.08425",
        "title": "Properties of fairness measures in the context of varying class imbalance and protected group ratios",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Society is increasingly relying on predictive models in fields like criminal justice, credit risk management, or hiring. To prevent such automated systems from discriminating against people belonging to certain groups, fairness measures have become a crucial component in socially relevant applications of machine learning. However, existing fairness measures have been designed to assess the bias between predictions for protected groups without considering the imbalance in the classes of the target variable. Current research on the potential effect of class imbalance on fairness focuses on practical applications rather than dataset-independent measure properties. In this paper, we study the general properties of fairness measures for changing class and protected group proportions. For this purpose, we analyze the probability mass functions of six of the most popular group fairness measures. We also measure how the probability of achieving perfect fairness changes for varying class imbalance ratios. Moreover, we relate the dataset-independent properties of fairness measures described in this paper to classifier fairness in real-life tasks. Our results show that measures such as Equal Opportunity and Positive Predictive Parity are more sensitive to changes in class imbalance than Accuracy Equality. These findings can help guide researchers and practitioners in choosing the most appropriate fairness measures for their classification problems.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08438",
        "abstract url": "https://arxiv.org/abs/2411.08438",
        "title": "Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Given the growing trend of many organizations integrating Retrieval Augmented Generation (RAG) into their operations, we assess RAG on domain-specific data and test state-of-the-art models across various optimization techniques. We incorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble Retriever, and In-Context-Learning, to enhance the functionality and performance in the academic domain. We focus on data retrieval, specifically targeting various study programs at a large technical university. We additionally introduce a novel evaluation approach, the RAG Confusion Matrix designed to assess the effectiveness of various configurations within the RAG framework. By exploring the integration of both open-source (e.g., Llama2, Mistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer valuable insights into the application and optimization of RAG frameworks in domain-specific contexts. Our experiments show a significant performance increase when including multi-query in the retrieval phase.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08446",
        "abstract url": "https://arxiv.org/abs/2411.08446",
        "title": "LSH-MoE: Communication-efficient MoE Training via Locality-Sensitive Hashing",
        "rating": "0.5",
        "keywords": [
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Larger transformer models always perform better on various tasks but require more costs to scale up the model size. To efficiently enlarge models, the mixture-of-experts (MoE) architecture is widely adopted, which consists of a gate network and a series of experts and keep the training cost constant by routing the input data to a fixed number of experts instead of all. In existing large-scale MoE training systems, experts would be distributed among different GPUs for parallelization, and thus input data requires additional all-to-all communications to access the target experts and conduct corresponding computations. However, upon evaluating the training process of three mainstream MoE models on commonly used GPU clusters, we found that the all-to-all communication ratio averaged around 45%, which significantly hinders the efficiency and scalability of training MoE models. In this paper, we propose LSH-MoE, a communication-efficient MoE training framework using locality-sensitive hashing (LSH). We first present the problems of scaling MoE training in existing systems and highlight the potential of exploiting token similarity to facilitate data compression. Then, we introduce an efficient LSH-based compression technique, which utilizes the cross-polytope hashing for rapid clustering and implements a residual-based error compensation scheme to alleviate the adverse impact of compression. To verify the effectiveness of our methods, we conduct experiments on both language models (e.g., RoBERTa, GPT, and T5) and vision models (e.g., Swin) for pre-training and fine-tuning tasks. The results demonstrate that our method substantially outperforms its counterparts across different tasks by 1.28x - 2.2x of speedup.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Accepted by NeurIPS 2024"
    },
    {
        "paper id": "2411.08450",
        "abstract url": "https://arxiv.org/abs/2411.08450",
        "title": "DecentPeeR: A Self-Incentivised & Inclusive Decentralized Peer Review System",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Peer review, as a widely used practice to ensure the quality and integrity of publications, lacks a well-defined and common mechanism to self-incentivize virtuous behavior across all the conferences and journals. This is because information about reviewer efforts and author feedback typically remains local to a single venue, while the same group of authors and reviewers participate in the publication process across many venues. Previous attempts to incentivize the reviewing process assume that the quality of reviews and papers authored correlate for the same person, or they assume that the reviewers can receive physical rewards for their work. In this paper, we aim to keep track of reviewing and authoring efforts by users (who review and author) across different venues while ensuring self-incentivization. We show that our system, DecentPeeR, incentivizes reviewers to behave according to the rules, i.e., it has a unique Nash equilibrium in which virtuous behavior is rewarded.",
        "subjects": [
            "cs.DL",
            "cs.CY",
            "cs.GT"
        ],
        "comment": "This paper was part of 2024 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)"
    },
    {
        "paper id": "2411.08460",
        "abstract url": "https://arxiv.org/abs/2411.08460",
        "title": "Trap-MID: Trapdoor-based Defense against Model Inversion Attacks",
        "rating": "0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Model Inversion (MI) attacks pose a significant threat to the privacy of Deep Neural Networks by recovering training data distribution from well-trained models. While existing defenses often rely on regularization techniques to reduce information leakage, they remain vulnerable to recent attacks. In this paper, we propose the Trapdoor-based Model Inversion Defense (Trap-MID) to mislead MI attacks. A trapdoor is integrated into the model to predict a specific label when the input is injected with the corresponding trigger. Consequently, this trapdoor information serves as the \"shortcut\" for MI attacks, leading them to extract trapdoor triggers rather than private data. We provide theoretical insights into the impacts of trapdoor's effectiveness and naturalness on deceiving MI attacks. In addition, empirical experiments demonstrate the state-of-the-art defense performance of Trap-MID against various MI attacks without the requirements for extra data or large computational overhead. Our source code is publicly available at https://github.com/ntuaislab/Trap-MID.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by Neural Information Processing Systems (NeurIPS) 2024"
    },
    {
        "paper id": "2411.08464",
        "abstract url": "https://arxiv.org/abs/2411.08464",
        "title": "Crystal Structure Generation Based On Material Properties",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The discovery of new materials is very important to the field of materials science. When researchers explore new materials, they often have expected performance requirements for their crystal structure. In recent years, data-driven methods have made great progress in the direction plane of crystal structure generation, but there is still a lack of methods that can effectively map material properties to crystal structure. In this paper, we propose a Crystal DiT model to generate the crystal structure from the expected material properties by embedding the material properties and combining the symmetry information predicted by the large language model. Experimental verification shows that our proposed method has good performance.",
        "subjects": [
            "cs.AI",
            "cond-mat.mtrl-sci"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08478",
        "abstract url": "https://arxiv.org/abs/2411.08478",
        "title": "Learning Model Agnostic Explanations via Constraint Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Interpretable Machine Learning faces a recurring challenge of explaining the predictions made by opaque classifiers such as ensemble models, kernel methods, or neural networks in terms that are understandable to humans. When the model is viewed as a black box, the objective is to identify a small set of features that jointly determine the black box response with minimal error. However, finding such model-agnostic explanations is computationally demanding, as the problem is intractable even for binary classifiers. In this paper, the task is framed as a Constraint Optimization Problem, where the constraint solver seeks an explanation of minimum error and bounded size for an input data instance and a set of samples generated by the black box. From a theoretical perspective, this constraint programming approach offers PAC-style guarantees for the output explanation. We evaluate the approach empirically on various datasets and show that it statistically outperforms the state-of-the-art heuristic Anchors method.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08514",
        "abstract url": "https://arxiv.org/abs/2411.08514",
        "title": "Explainers' Mental Representations of Explainees' Needs in Everyday Explanations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In explanations, explainers have mental representations of explainees' developing knowledge and shifting interests regarding the explanandum. These mental representations are dynamic in nature and develop over time, thereby enabling explainers to react to explainees' needs by adapting and customizing the explanation. XAI should be able to react to explainees' needs in a similar manner. Therefore, a component that incorporates aspects of explainers' mental representations of explainees is required. In this study, we took first steps by investigating explainers' mental representations in everyday explanations of technological artifacts. According to the dual nature theory, technological artifacts require explanations with two distinct perspectives, namely observable and measurable features addressing \"Architecture\" or interpretable aspects addressing \"Relevance\". We conducted extended semi structured pre-, post- and video recall-interviews with explainers (N=9) in the context of an explanation. The transcribed interviews were analyzed utilizing qualitative content analysis. The explainers' answers regarding the explainees' knowledge and interests with regard to the technological artifact emphasized the vagueness of early assumptions of explainers toward strong beliefs in the course of explanations. The assumed knowledge of explainees in the beginning is centered around Architecture and develops toward knowledge with regard to both Architecture and Relevance. In contrast, explainers assumed higher interests in Relevance in the beginning to interests regarding both Architecture and Relevance in the further course of explanations. Further, explainers often finished the explanation despite their perception that explainees still had gaps in knowledge. These findings are transferred into practical implications relevant for user models for adaptive explainable systems.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08544",
        "abstract url": "https://arxiv.org/abs/2411.08544",
        "title": "Deeper Insights into Learning Performance of Stochastic Configuration Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Stochastic Configuration Networks (SCNs) are a class of randomized neural networks that integrate randomized algorithms within an incremental learning framework. A defining feature of SCNs is the supervisory mechanism, which adaptively adjusts the distribution to generate effective random basis functions, thereby enabling error-free learning. In this paper, we present a comprehensive analysis of the impact of the supervisory mechanism on the learning performance of SCNs. Our findings reveal that the current SCN framework evaluates the effectiveness of each random basis function in reducing residual errors using a lower bound on its error reduction potential, which constrains SCNs' overall learning efficiency. Specifically, SCNs may fail to consistently select the most effective random candidate as the new basis function during each training iteration. To overcome this problem, we propose a novel method for evaluating the hidden layer's output matrix, supported by a new supervisory mechanism that accurately assesses the error reduction potential of random basis functions without requiring the computation of the Moore-Penrose inverse of the output matrix. This approach enhances the selection of basis functions, reducing computational complexity and improving the overall scalability and learning capabilities of SCNs. We introduce a Recursive Moore-Penrose Inverse-SCN (RMPI-SCN) training scheme based on the new supervisory mechanism and demonstrate its effectiveness through simulations over some benchmark datasets. Experiments show that RMPI-SCN outperforms the conventional SCN in terms of learning capability, underscoring its potential to advance the SCN framework for large-scale data modeling applications.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08563",
        "abstract url": "https://arxiv.org/abs/2411.08563",
        "title": "Leveraging LLMs for Predictive Insights in Food Policy and Behavioral Interventions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Food consumption and production contribute significantly to global greenhouse gas emissions, making them crucial entry points for mitigating climate change and maintaining a liveable planet. Over the past two decades, food policy initiatives have explored interventions to reshape production and consumption patterns, focusing on reducing food waste and curbing ruminant meat consumption. While the evidence of \"what works\" improves, evaluating which policies are appropriate and effective in specific contexts remains difficult due to external validity challenges. This paper demonstrates that a fine-tuned large language model (LLM) can accurately predict the direction of outcomes in approximately 80\\% of empirical studies measuring dietary-based impacts (e.g. food choices, sales, waste) resulting from behavioral interventions and policies. Approximately 75 prompts were required to achieve optimal results, with performance showing signs of catastrophic loss beyond this point. Our findings indicate that greater input detail enhances predictive accuracy, although the model still faces challenges with unseen studies, underscoring the importance of a representative training sample. As LLMs continue to improve and diversify, they hold promise for advancing data-driven, evidence-based policymaking.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08590",
        "abstract url": "https://arxiv.org/abs/2411.08590",
        "title": "Hopfield-Fenchel-Young Networks: A Unified Framework for Associative Memory Retrieval",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Associative memory models, such as Hopfield networks and their modern variants, have garnered renewed interest due to advancements in memory capacity and connections with self-attention in transformers. In this work, we introduce a unified framework-Hopfield-Fenchel-Young networks-which generalizes these models to a broader family of energy functions. Our energies are formulated as the difference between two Fenchel-Young losses: one, parameterized by a generalized entropy, defines the Hopfield scoring mechanism, while the other applies a post-transformation to the Hopfield output. By utilizing Tsallis and norm entropies, we derive end-to-end differentiable update rules that enable sparse transformations, uncovering new connections between loss margins, sparsity, and exact retrieval of single memory patterns. We further extend this framework to structured Hopfield networks using the SparseMAP transformation, allowing the retrieval of pattern associations rather than a single pattern. Our framework unifies and extends traditional and modern Hopfield networks and provides an energy minimization perspective for widely used post-transformations like $\\ell_2$-normalization and layer normalization-all through suitable choices of Fenchel-Young losses and by using convex analysis as a building block. Finally, we validate our Hopfield-Fenchel-Young networks on diverse memory recall tasks, including free and sequential recall. Experiments on simulated data, image retrieval, multiple instance learning, and text rationalization demonstrate the effectiveness of our approach.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "49 pages, 14 figures. arXiv admin note: text overlap with arXiv:2402.13725"
    },
    {
        "paper id": "2411.08625",
        "abstract url": "https://arxiv.org/abs/2411.08625",
        "title": "A Conjecture on Group Decision Accuracy in Voter Networks through the Regularized Incomplete Beta Function",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "This paper presents a conjecture on the regularized incomplete beta function in the context of majority decision systems modeled through a voter framework. We examine a network where voters interact, with some voters fixed in their decisions while others are free to change their states based on the influence of their neighbors. We demonstrate that as the number of free voters increases, the probability of selecting the correct majority outcome converges to $1-I_{0.5}(\u03b1,\u03b2)$, where $I_{0.5}(\u03b1,\u03b2)$ is the regularized incomplete beta function. The conjecture posits that when $\u03b1> \u03b2$, $1-I_{0.5}(\u03b1,\u03b2) > \u03b1/(\u03b1+\u03b2)$, meaning the group's decision accuracy exceeds that of an individual voter. We provide partial results, including a proof for integer values of $\u03b1$ and $\u03b2$, and support the general case using a probability bound. This work extends Condorcet's Jury Theorem by incorporating voter dependence driven by network dynamics, showing that group decision accuracy can exceed individual accuracy under certain conditions.",
        "subjects": [
            "stat.ME",
            "cs.GT",
            "cs.SI"
        ],
        "comment": "14 pages, 1 figure"
    },
    {
        "paper id": "2411.08631",
        "abstract url": "https://arxiv.org/abs/2411.08631",
        "title": "Deep Generative Demand Learning for Newsvendor and Pricing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider data-driven inventory and pricing decisions in the feature-based newsvendor problem, where demand is influenced by both price and contextual features and is modeled without any structural assumptions. The unknown demand distribution results in a challenging conditional stochastic optimization problem, further complicated by decision-dependent uncertainty and the integration of features. Inspired by recent advances in deep generative learning, we propose a novel approach leveraging conditional deep generative models (cDGMs) to address these challenges. cDGMs learn the demand distribution and generate probabilistic demand forecasts conditioned on price and features. This generative approach enables accurate profit estimation and supports the design of algorithms for two key objectives: (1) optimizing inventory for arbitrary prices, and (2) jointly determining optimal pricing and inventory levels. We provide theoretical guarantees for our approach, including the consistency of profit estimation and convergence of our decisions to the optimal solution. Extensive simulations-ranging from simple to complex scenarios, including one involving textual features-and a real-world case study demonstrate the effectiveness of our approach. Our method opens a new paradigm in management science and operations research, is adaptable to extensions of the newsvendor and pricing problems, and holds potential for solving other conditional stochastic optimization problems.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC"
        ],
        "comment": "30 pages, 6 figures"
    },
    {
        "paper id": "2411.08640",
        "abstract url": "https://arxiv.org/abs/2411.08640",
        "title": "Towards Secure Intelligent O-RAN Architecture: Vulnerabilities, Threats and Promising Technical Solutions using LLMs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The evolution of wireless communication systems will be fundamentally impacted by an open radio access network (O-RAN), a new concept defining an intelligent architecture with enhanced flexibility, openness, and the ability to slice services more efficiently. For all its promises, and like any technological advancement, O-RAN is not without risks that need to be carefully assessed and properly addressed to accelerate its wide adoption in future mobile networks. In this paper, we present an in-depth security analysis of the O-RAN architecture, discussing the potential threats that may arise in the different O-RAN architecture layers and their impact on the Confidentiality, Integrity, and Availability (CIA) triad. We also promote the potential of zero trust, Moving Target Defense (MTD), blockchain, and large language models(LLM) technologies in fortifying O-RAN's security posture. Furthermore, we numerically demonstrate the effectiveness of MTD in empowering robust deep reinforcement learning methods for dynamic network slice admission control in the O-RAN architecture. Moreover, we examine the effect of explainable AI (XAI) based on LLMs in securing the system.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2411.08641",
        "abstract url": "https://arxiv.org/abs/2411.08641",
        "title": "DipMe: Haptic Recognition of Granular Media for Tangible Interactive Applications",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "While tangible user interface has shown its power in naturally interacting with rigid or soft objects, users cannot conveniently use different types of granular materials as the interaction media. We introduce DipMe as a smart device to recognize the types of granular media in real time, which can be used to connect the granular materials in the physical world with various virtual content. Other than vision-based solutions, we propose a dip operation of our device and exploit the haptic signals to recognize different types of granular materials. With modern machine learning tools, we find the haptic signals from different granular media are distinguishable by DipMe. With the online granular object recognition, we build several tangible interactive applications, demonstrating the effects of DipMe in perceiving granular materials and its potential in developing a tangible user interface with granular objects as the new media.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "17 pages, 10 figures"
    },
    {
        "paper id": "2411.08645",
        "abstract url": "https://arxiv.org/abs/2411.08645",
        "title": "A System Level Performance Evaluation for Superconducting Digital Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Superconducting Digital (SCD) technology offers significant potential for enhancing the performance of next generation large scale compute workloads. By leveraging advanced lithography and a 300 mm platform, SCD devices can reduce energy consumption and boost computational power. This paper presents a cross-layer modeling approach to evaluate the system-level performance benefits of SCD architectures for Large Language Model (LLM) training and inference. Our findings, based on experimental data and Pulse Conserving Logic (PCL) design principles, demonstrate substantial performance gain in both training and inference. We are, thus, able to convincingly show that the SCD technology can address memory and interconnect limitations of present day solutions for next-generation compute systems.",
        "subjects": [
            "cs.AR",
            "cs.AI",
            "cs.ET"
        ],
        "comment": "8 figures"
    },
    {
        "paper id": "2411.08651",
        "abstract url": "https://arxiv.org/abs/2411.08651",
        "title": "Estimating unknown parameters in differential equations with a reinforcement learning based PSO method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Differential equations offer a foundational yet powerful framework for modeling interactions within complex dynamic systems and are widely applied across numerous scientific fields. One common challenge in this area is estimating the unknown parameters of these dynamic relationships. However, traditional numerical optimization methods rely on the selection of initial parameter values, making them prone to local optima. Meanwhile, deep learning and Bayesian methods require training models on specific differential equations, resulting in poor versatility. This paper reformulates the parameter estimation problem of differential equations as an optimization problem by introducing the concept of particles from the particle swarm optimization algorithm. Building on reinforcement learning-based particle swarm optimization (RLLPSO), this paper proposes a novel method, DERLPSO, for estimating unknown parameters of differential equations. We compared its performance on three typical ordinary differential equations with the state-of-the-art methods, including the RLLPSO algorithm, traditional numerical methods, deep learning approaches, and Bayesian methods. The experimental results demonstrate that our DERLPSO consistently outperforms other methods in terms of performance, achieving an average Mean Square Error of 1.13e-05, which reduces the error by approximately 4 orders of magnitude compared to other methods. Apart from ordinary differential equations, our DERLPSO also show great promise for estimating unknown parameters of partial differential equations. The DERLPSO method proposed in this paper has high accuracy, is independent of initial parameter values, and possesses strong versatility and stability. This work provides new insights into unknown parameter estimation for differential equations.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08652",
        "abstract url": "https://arxiv.org/abs/2411.08652",
        "title": "Accelerating Quasi-Static Time Series Simulations with Foundation Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quasi-static time series (QSTS) simulations have great potential for evaluating the grid's ability to accommodate the large-scale integration of distributed energy resources. However, as grids expand and operate closer to their limits, iterative power flow solvers, central to QSTS simulations, become computationally prohibitive and face increasing convergence issues. Neural power flow solvers provide a promising alternative, speeding up power flow computations by 3 to 4 orders of magnitude, though they are costly to train. In this paper, we envision how recently introduced grid foundation models could improve the economic viability of neural power flow solvers. Conceptually, these models amortize training costs by serving as a foundation for a range of grid operation and planning tasks beyond power flow solving, with only minimal fine-tuning required. We call for collaboration between the AI and power grid communities to develop and open-source these models, enabling all operators, even those with limited resources, to benefit from AI without building solutions from scratch.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Equal contributors: A.P. and F.M.; Lead contact: A.P"
    },
    {
        "paper id": "2411.08684",
        "abstract url": "https://arxiv.org/abs/2411.08684",
        "title": "Analogical Reasoning Within a Conceptual Hyperspace",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We propose an approach to analogical inference that marries the neuro-symbolic computational power of complex-sampled hyperdimensional computing (HDC) with Conceptual Spaces Theory (CST), a promising theory of semantic meaning. CST sketches, at an abstract level, approaches to analogical inference that go beyond the standard predicate-based structure mapping theories. But it does not describe how such an approach can be operationalized. We propose a concrete HDC-based architecture that computes several types of analogy classified by CST. We present preliminary proof-of-concept experimental results within a toy domain and describe how it can perform category-based and property-based analogical reasoning.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Analogy-angle workshop full paper at IJCAI 2024"
    },
    {
        "paper id": "2411.08706",
        "abstract url": "https://arxiv.org/abs/2411.08706",
        "title": "Searching Latent Program Spaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Program synthesis methods aim to automatically generate programs restricted to a language that can explain a given specification of input-output pairs. While purely symbolic approaches suffer from a combinatorial search space, recent methods leverage neural networks to learn distributions over program structures to narrow this search space significantly, enabling more efficient search. However, for challenging problems, it remains difficult to train models to perform program synthesis in one shot, making test-time search essential. Most neural methods lack structured search mechanisms during inference, relying instead on stochastic sampling or gradient updates, which can be inefficient. In this work, we propose the Latent Program Network (LPN), a general algorithm for program induction that learns a distribution over latent programs in a continuous space, enabling efficient search and test-time adaptation. We explore how to train these networks to optimize for test-time computation and demonstrate the use of gradient-based search both during training and at test time. We evaluate LPN on ARC-AGI, a program synthesis benchmark that evaluates performance by generalizing programs to new inputs rather than explaining the underlying specification. We show that LPN can generalize beyond its training distribution and adapt to unseen tasks by utilizing test-time computation, outperforming algorithms without test-time adaptation mechanisms.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Code available at https://github.com/clement-bonnet/lpn"
    },
    {
        "paper id": "2411.08717",
        "abstract url": "https://arxiv.org/abs/2411.08717",
        "title": "Short note on the mapping of heritage sites impacted by the 2024 floods in Valencia, Spain",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This short note presents preliminary findings on the impact of the October 2024 floods on cultural heritage sites in Valencia, Spain. Using publicly available data, we assess the extent of potential damage by overlaying flood maps with heritage site coordinates. We identify that 3.3\\% of heritage sites in the region have been potentially impacted, with churches and shrines (81), outdoor religious iconography (78), and historic irrigation features (45) being the most heavily affected. Our analysis utilizes data from OpenStreetMap and listings from the Generalitat Valenciana, suggesting that while OpenStreetMap's crowd-sourced data can provide useful estimates of the proportion of impacted sites, it may not be suitable for a detailed damage assessment. By sharing this data openly, we aim to contribute to international efforts in preserving cultural heritage after the disaster and provide a foundation for future assessments of heritage site vulnerability to climate-related events.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08739",
        "abstract url": "https://arxiv.org/abs/2411.08739",
        "title": "Bayesian Comparisons Between Representations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Which neural networks are similar is a fundamental question for both machine learning and neuroscience. Our novel method compares representations based on Bayesian statistics about linear readouts from the representations. Concretely, we suggest to use the total variation distance or Jensen-Shannon distance between prior predictive distributions to compare representations. The prior predictive distribution is a full description of the inductive bias and generalization of a model in Bayesian statistics, making it a great basis for comparisons. As Jensen-Shannon distance and total variation distance are metrics our dissimilarity measures are pseudo-metrics for representations. For a linear readout, our metrics just depend on the linear kernel matrix of the representations. Thus, our metrics connects linear read-out based comparisons to kernel based metrics like centered kernel alignment and representational similarity analysis. We apply our new metrics to deep neural networks trained on ImageNet-1k. Our new metrics can be computed efficiently including a stochastic gradient without dimensionality reductions of the representations. It broadly agrees with existing metrics, but is more stringent. It varies less across different random image samples, and it measures how well two representations could be distinguished based on a linear read out. Thus our metric nicely extends our toolkit for comparing representations.",
        "subjects": [
            "cs.LG",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08773",
        "abstract url": "https://arxiv.org/abs/2411.08773",
        "title": "Optimal Oblivious Subspace Embeddings with Near-optimal Sparsity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "An oblivious subspace embedding is a random $m\\times n$ matrix $\u03a0$ such that, for any $d$-dimensional subspace, with high probability $\u03a0$ preserves the norms of all vectors in that subspace within a $1\\pm\u03b5$ factor. In this work, we give an oblivious subspace embedding with the optimal dimension $m=\u0398(d/\u03b5^2)$ that has a near-optimal sparsity of $\\tilde O(1/\u03b5)$ non-zero entries per column of $\u03a0$. This is the first result to nearly match the conjecture of Nelson and Nguyen [FOCS 2013] in terms of the best sparsity attainable by an optimal oblivious subspace embedding, improving on a prior bound of $\\tilde O(1/\u03b5^6)$ non-zeros per column [Chenakkod et al., STOC 2024]. We further extend our approach to the non-oblivious setting, proposing a new family of Leverage Score Sparsified embeddings with Independent Columns, which yield faster runtimes for matrix approximation and regression tasks. In our analysis, we develop a new method which uses a decoupling argument together with the cumulant method for bounding the edge universality error of isotropic random matrices. To achieve near-optimal sparsity, we combine this general-purpose approach with new traces inequalities that leverage the specific structure of our subspace embedding construction.",
        "subjects": [
            "cs.DS",
            "cs.LG",
            "math.NA",
            "math.PR",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08791",
        "abstract url": "https://arxiv.org/abs/2411.08791",
        "title": "Locally Private Sampling with Public Data",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Local differential privacy (LDP) is increasingly employed in privacy-preserving machine learning to protect user data before sharing it with an untrusted aggregator. Most LDP methods assume that users possess only a single data record, which is a significant limitation since users often gather extensive datasets (e.g., images, text, time-series data) and frequently have access to public datasets. To address this limitation, we propose a locally private sampling framework that leverages both the private and public datasets of each user. Specifically, we assume each user has two distributions: $p$ and $q$ that represent their private dataset and the public dataset, respectively. The objective is to design a mechanism that generates a private sample approximating $p$ while simultaneously preserving $q$. We frame this objective as a minimax optimization problem using $f$-divergence as the utility measure. We fully characterize the minimax optimal mechanisms for general $f$-divergences provided that $p$ and $q$ are discrete distributions. Remarkably, we demonstrate that this optimal mechanism is universal across all $f$-divergences. Experiments validate the effectiveness of our minimax optimal sampler compared to the state-of-the-art locally private sampler.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08794",
        "abstract url": "https://arxiv.org/abs/2411.08794",
        "title": "Evaluating World Models with LLM for Decision Making",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "World model emerges as a key module in decision making, where MuZero and Dreamer achieve remarkable successes in complex tasks. Recent work leverages Large Language Models (LLMs) as general world simulators to simulate the dynamics of the world due to their generalizability. LLMs also serve as the world model for deliberative reasoning in Reasoning via Planning (RAP) and Tree of Thought (ToT). However, the world models are either evaluated as a general world simulator, or as a functional module of the agent, i.e., predicting the transitions to assist the planning. In this work, we propose a comprehensive evaluation of the world models with LLMs from the decision making perspective. Specifically, we leverage the 31 diverse environments from (Wang et al., 2023;2024) and curate the rule-based policy of each environment for the diverse evaluation. Then, we design three main tasks, i.e., policy verification, action proposal, and policy planning, where the world models can be used for decision making solely. Finally, we conduct the comprehensive evaluation of the advanced LLMs, i.e., GPT-4o and GPT-4o-mini, on the environments for the three main tasks under various settings. The key observations include: i) GPT-4o significantly outperforms GPT-4o-mini on the three main tasks, especially for the tasks which require the domain knowledge, ii) the performance of the world model with LLM will be decreased for long-term decision-making tasks, and iii) the combination of different functionalities of the world model will brings additional unstabilities of the performance.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08798",
        "abstract url": "https://arxiv.org/abs/2411.08798",
        "title": "Learning Gaussian Multi-Index Models with Gradient Flow: Time Complexity and Directional Convergence",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This work focuses on the gradient flow dynamics of a neural network model that uses correlation loss to approximate a multi-index function on high-dimensional standard Gaussian data. Specifically, the multi-index function we consider is a sum of neurons $f^*(x) \\!=\\! \\sum_{j=1}^k \\! \u03c3^*(v_j^T x)$ where $v_1, \\dots, v_k$ are unit vectors, and $\u03c3^*$ lacks the first and second Hermite polynomials in its Hermite expansion. It is known that, for the single-index case ($k\\!=\\!1$), overcoming the search phase requires polynomial time complexity. We first generalize this result to multi-index functions characterized by vectors in arbitrary directions. After the search phase, it is not clear whether the network neurons converge to the index vectors, or get stuck at a sub-optimal solution. When the index vectors are orthogonal, we give a complete characterization of the fixed points and prove that neurons converge to the nearest index vectors. Therefore, using $n \\! \\asymp \\! k \\log k$ neurons ensures finding the full set of index vectors with gradient flow with high probability over random initialization. When $ v_i^T v_j \\!=\\! \u03b2\\! \\geq \\! 0$ for all $i \\neq j$, we prove the existence of a sharp threshold $\u03b2_c \\!=\\! c/(c+k)$ at which the fixed point that computes the average of the index vectors transitions from a saddle point to a minimum. Numerical simulations show that using a correlation loss and a mild overparameterization suffices to learn all of the index vectors when they are nearly orthogonal, however, the correlation loss fails when the dot product between the index vectors exceeds a certain threshold.",
        "subjects": [
            "cs.LG",
            "cs.NE",
            "math.AG"
        ],
        "comment": "21 pages, 6 figures, under review by AISTATS 2025"
    },
    {
        "paper id": "2411.08804",
        "abstract url": "https://arxiv.org/abs/2411.08804",
        "title": "FinRobot: AI Agent for Equity Research and Valuation with Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As financial markets grow increasingly complex, there is a rising need for automated tools that can effectively assist human analysts in equity research, particularly within sell-side research. While Generative AI (GenAI) has attracted significant attention in this field, existing AI solutions often fall short due to their narrow focus on technical factors and limited capacity for discretionary judgment. These limitations hinder their ability to adapt to new data in real-time and accurately assess risks, which diminishes their practical value for investors. This paper presents FinRobot, the first AI agent framework specifically designed for equity research. FinRobot employs a multi-agent Chain of Thought (CoT) system, integrating both quantitative and qualitative analyses to emulate the comprehensive reasoning of a human analyst. The system is structured around three specialized agents: the Data-CoT Agent, which aggregates diverse data sources for robust financial integration; the Concept-CoT Agent, which mimics an analysts reasoning to generate actionable insights; and the Thesis-CoT Agent, which synthesizes these insights into a coherent investment thesis and report. FinRobot provides thorough company analysis supported by precise numerical data, industry-appropriate valuation metrics, and realistic risk assessments. Its dynamically updatable data pipeline ensures that research remains timely and relevant, adapting seamlessly to new financial information. Unlike existing automated research tools, such as CapitalCube and Wright Reports, FinRobot delivers insights comparable to those produced by major brokerage firms and fundamental research vendors. We open-source FinRobot at \\url{https://github. com/AI4Finance-Foundation/FinRobot}.",
        "subjects": [
            "q-fin.CP",
            "cs.LG",
            "q-fin.ST",
            "q-fin.TR"
        ],
        "comment": "The 1st Workshop on LLMs and Generative AI for Finance, ICAIF 2024"
    },
    {
        "paper id": "2411.08814",
        "abstract url": "https://arxiv.org/abs/2411.08814",
        "title": "Process-aware Human Activity Recognition",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Humans naturally follow distinct patterns when conducting their daily activities, which are driven by established practices and processes, such as production workflows, social norms and daily routines. Human activity recognition (HAR) algorithms usually use neural networks or machine learning techniques to analyse inherent relationships within the data. However, these approaches often overlook the contextual information in which the data are generated, potentially limiting their effectiveness. We propose a novel approach that incorporates process information from context to enhance the HAR performance. Specifically, we align probabilistic events generated by machine learning models with process models derived from contextual information. This alignment adaptively weighs these two sources of information to optimise HAR accuracy. Our experiments demonstrate that our approach achieves better accuracy and Macro F1-score compared to baseline models.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08821",
        "abstract url": "https://arxiv.org/abs/2411.08821",
        "title": "Model agnostic local variable importance for locally dependent relationships",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Global variable importance measures are commonly used to interpret machine learning model results. Local variable importance techniques assess how variables contribute to individual observations rather than the entire dataset. Current methods typically fail to accurately reflect locally dependent relationships between variables and instead focus on marginal importance values. Additionally, they are not natively adapted for multi-class classification problems. We propose a new model-agnostic method for calculating local variable importance, CLIQUE, that captures locally dependent relationships, contains improvements over permutation-based methods, and can be directly applied to multi-class classification problems. Simulated and real-world examples show that CLIQUE emphasizes locally dependent information and properly reduces bias in regions where variables do not affect the response.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08849",
        "abstract url": "https://arxiv.org/abs/2411.08849",
        "title": "Oblique Bayesian additive regression trees",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Current implementations of Bayesian Additive Regression Trees (BART) are based on axis-aligned decision rules that recursively partition the feature space using a single feature at a time. Several authors have demonstrated that oblique trees, whose decision rules are based on linear combinations of features, can sometimes yield better predictions than axis-aligned trees and exhibit excellent theoretical properties. We develop an oblique version of BART that leverages a data-adaptive decision rule prior that recursively partitions the feature space along random hyperplanes. Using several synthetic and real-world benchmark datasets, we systematically compared our oblique BART implementation to axis-aligned BART and other tree ensemble methods, finding that oblique BART was competitive with -- and sometimes much better than -- those methods.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08861",
        "abstract url": "https://arxiv.org/abs/2411.08861",
        "title": "Interaction Testing in Variation Analysis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Relationships of cause and effect are of prime importance for explaining scientific phenomena. Often, rather than just understanding the effects of causes, researchers also wish to understand how a cause $X$ affects an outcome $Y$ mechanistically -- i.e., what are the causal pathways that are activated between $X$ and $Y$. For analyzing such questions, a range of methods has been developed over decades under the rubric of causal mediation analysis. Traditional mediation analysis focuses on decomposing the average treatment effect (ATE) into direct and indirect effects, and therefore focuses on the ATE as the central quantity. This corresponds to providing explanations for associations in the interventional regime, such as when the treatment $X$ is randomized. Commonly, however, it is of interest to explain associations in the observational regime, and not just in the interventional regime. In this paper, we introduce \\text{variation analysis}, an extension of mediation analysis that focuses on the total variation (TV) measure between $X$ and $Y$, written as $\\mathrm{E}[Y \\mid X=x_1] - \\mathrm{E}[Y \\mid X=x_0]$. The TV measure encompasses both causal and confounded effects, as opposed to the ATE which only encompasses causal (direct and mediated) variations. In this way, the TV measure is suitable for providing explanations in the natural regime and answering questions such as ``why is $X$ associated with $Y$?''. Our focus is on decomposing the TV measure, in a way that explicitly includes direct, indirect, and confounded variations. Furthermore, we also decompose the TV measure to include interaction terms between these different pathways. Subsequently, interaction testing is introduced, involving hypothesis tests to determine if interaction terms are significantly different from zero. If interactions are not significant, more parsimonious decompositions of the TV measure can be used.",
        "subjects": [
            "stat.ME",
            "cs.AI",
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08867",
        "abstract url": "https://arxiv.org/abs/2411.08867",
        "title": "Unsupervised Parameter-free Outlier Detection using HDBSCAN* Outlier Profiles",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In machine learning and data mining, outliers are data points that significantly differ from the dataset and often introduce irrelevant information that can induce bias in its statistics and models. Therefore, unsupervised methods are crucial to detect outliers if there is limited or no information about them. Global-Local Outlier Scores based on Hierarchies (GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a state-of-the-art hierarchical clustering method. GLOSH estimates outlier scores for each data point by comparing its density to the highest density of the region they reside in the HDBSCAN* hierarchy. GLOSH may be sensitive to HDBSCAN*'s minpts parameter that influences density estimation. With limited knowledge about the data, choosing an appropriate minpts value beforehand is challenging as one or some minpts values may better represent the underlying cluster structure than others. Additionally, in the process of searching for ``potential outliers'', one has to define the number of outliers n a dataset has, which may be impractical and is often unknown. In this paper, we propose an unsupervised strategy to find the ``best'' minpts value, leveraging the range of GLOSH scores across minpts values to identify the value for which GLOSH scores can best identify outliers from the rest of the dataset. Moreover, we propose an unsupervised strategy to estimate a threshold for classifying points into inliers and (potential) outliers without the need to pre-define any value. Our experiments show that our strategies can automatically find the minpts value and threshold that yield the best or near best outlier detection results using GLOSH.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted at IEEE International Conference on Big Data, IEEE BigData 2024"
    },
    {
        "paper id": "2411.08870",
        "abstract url": "https://arxiv.org/abs/2411.08870",
        "title": "The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "biomedical",
                "Medical",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining (DAPT) improves performance on downstream medical tasks, such as answering medical licensing exam questions. In this paper, we compare ten public \"medical\" LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting and supervised fine-tuning regimes for medical question-answering (QA). For instance, across all tasks and model pairs we consider in the 3-shot setting, medical LLMs only outperform their base models in 22.7% of cases, reach a (statistical) tie in 36.8% of cases, and are significantly worse than their base models in the remaining 40.5% of cases. Our conclusions are based on (i) comparing each medical model head-to-head, directly against the corresponding base model; (ii) optimizing the prompts for each model separately in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty in comparisons. While these basic practices are not consistently adopted in the literature, our ablations show that they substantially impact conclusions. Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs can show performance improvements, but the benefits do not carry over to tasks based on clinical notes. Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Extended version of EMNLP 2024 paper arXiv:2411.04118. Includes additional results on clinical note QA tasks and supervised fine-tuning evaluations"
    },
    {
        "paper id": "2411.08875",
        "abstract url": "https://arxiv.org/abs/2411.08875",
        "title": "Causal Explanations for Image Classifiers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Existing algorithms for explaining the output of image classifiers use different definitions of explanations and a variety of techniques to extract them. However, none of the existing tools use a principled approach based on formal definitions of causes and explanations for the explanation extraction. In this paper we present a novel black-box approach to computing explanations grounded in the theory of actual causality. We prove relevant theoretical results and present an algorithm for computing approximate explanations based on these definitions. We prove termination of our algorithm and discuss its complexity and the amount of approximation compared to the precise definition. We implemented the framework in a tool rex and we present experimental results and a comparison with state-of-the-art tools. We demonstrate that rex is the most efficient tool and produces the smallest explanations, in addition to outperforming other black-box tools on standard quality measures.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08981",
        "abstract url": "https://arxiv.org/abs/2411.08981",
        "title": "Reliability, Resilience and Human Factors Engineering for Trustworthy AI Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "As AI systems become integral to critical operations across industries and services, ensuring their reliability and safety is essential. We offer a framework that integrates established reliability and resilience engineering principles into AI systems. By applying traditional metrics such as failure rate and Mean Time Between Failures (MTBF) along with resilience engineering and human reliability analysis, we propose an integrate framework to manage AI system performance, and prevent or efficiently recover from failures. Our work adapts classical engineering methods to AI systems and outlines a research agenda for future technical studies. We apply our framework to a real-world AI system, using system status data from platforms such as openAI, to demonstrate its practical applicability. This framework aligns with emerging global standards and regulatory frameworks, providing a methodology to enhance the trustworthiness of AI systems. Our aim is to guide policy, regulation, and the development of reliable, safe, and adaptable AI technologies capable of consistent performance in real-world environments.",
        "subjects": [
            "cs.AI",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08982",
        "abstract url": "https://arxiv.org/abs/2411.08982",
        "title": "Lynx: Enabling Efficient MoE Inference through Dynamic Batch-Aware Expert Selection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mixture-of-Experts (MoE) architectures have recently gained popularity in enabling efficient scaling of large language models. However, we uncover a fundamental tension: while MoEs are designed for selective expert activation, production serving requires request batching, which forces the activation of all experts and negates MoE's efficiency benefits during the decode phase. We present Lynx, a system that enables efficient MoE inference through dynamic, batch-aware expert selection. Our key insight is that expert importance varies significantly across tokens and inference phases, creating opportunities for runtime optimization. Lynx leverages this insight through a lightweight framework that dynamically reduces active experts while preserving model accuracy. Our evaluations show that Lynx achieves up to 1.55x reduction in inference latency while maintaining negligible accuracy loss from baseline model across complex code generation and mathematical reasoning tasks.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08987",
        "abstract url": "https://arxiv.org/abs/2411.08987",
        "title": "Non-Euclidean High-Order Smooth Convex Optimization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We develop algorithms for the optimization of convex objectives that have H\u00f6lder continuous $q$-th derivatives with respect to a $p$-norm by using a $q$-th order oracle, for $p, q \\geq 1$. We can also optimize other structured functions. We do this by developing a non-Euclidean inexact accelerated proximal point method that makes use of an inexact uniformly convex regularizer. We also provide nearly matching lower bounds for any deterministic algorithm that interacts with the function via a local oracle.",
        "subjects": [
            "math.OC",
            "cs.DS",
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08998",
        "abstract url": "https://arxiv.org/abs/2411.08998",
        "title": "Microfoundation Inference for Strategic Prediction",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Often in prediction tasks, the predictive model itself can influence the distribution of the target variable, a phenomenon termed performative prediction. Generally, this influence stems from strategic actions taken by stakeholders with a vested interest in predictive models. A key challenge that hinders the widespread adaptation of performative prediction in machine learning is that practitioners are generally unaware of the social impacts of their predictions. To address this gap, we propose a methodology for learning the distribution map that encapsulates the long-term impacts of predictive models on the population. Specifically, we model agents' responses as a cost-adjusted utility maximization problem and propose estimates for said cost. Our approach leverages optimal transport to align pre-model exposure (ex ante) and post-model exposure (ex post) distributions. We provide a rate of convergence for this proposed estimate and assess its quality through empirical demonstrations on a credit-scoring dataset.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09001",
        "abstract url": "https://arxiv.org/abs/2411.09001",
        "title": "Virtual teaching assistant for undergraduate students using natural language processing & deep learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Online education's popularity has been continuously increasing over the past few years. Many universities were forced to switch to online education as a result of COVID-19. In many cases, even after more than two years of online instruction, colleges were unable to resume their traditional classroom programs. A growing number of institutions are considering blended learning with some parts in-person and the rest of the learning taking place online. Nevertheless, many online education systems are inefficient, and this results in a poor rate of student retention. In this paper, we are offering a primary dataset, the initial implementation of a virtual teaching assistant named VTA-bot, and its system architecture. Our primary implementation of the suggested system consists of a chatbot that can be queried about the content and topics of the fundamental python programming language course. Students in their first year of university will be benefited from this strategy, which aims to increase student participation and involvement in online education.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09050",
        "abstract url": "https://arxiv.org/abs/2411.09050",
        "title": "The Systems Engineering Approach in Times of Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Using Large Language Models (LLMs) to address critical societal problems requires adopting this novel technology into socio-technical systems. However, the complexity of such systems and the nature of LLMs challenge such a vision. It is unlikely that the solution to such challenges will come from the Artificial Intelligence (AI) community itself. Instead, the Systems Engineering approach is better equipped to facilitate the adoption of LLMs by prioritising the problems and their context before any other aspects. This paper introduces the challenges LLMs generate and surveys systems research efforts for engineering AI-based systems. We reveal how the systems engineering principles have supported addressing similar issues to the ones LLMs pose and discuss our findings to provide future directions for adopting LLMs.",
        "subjects": [
            "cs.AI",
            "cs.CY",
            "cs.SE"
        ],
        "comment": "This paper has been accepted for the upcoming 58th Hawaii International Conference on System Sciences (HICSS-58)"
    },
    {
        "paper id": "2411.09056",
        "abstract url": "https://arxiv.org/abs/2411.09056",
        "title": "Optimisation Strategies for Ensuring Fairness in Machine Learning: With and Without Demographics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Ensuring fairness has emerged as one of the primary concerns in AI and its related algorithms. Over time, the field of machine learning fairness has evolved to address these issues. This paper provides an extensive overview of this field and introduces two formal frameworks to tackle open questions in machine learning fairness. In one framework, operator-valued optimisation and min-max objectives are employed to address unfairness in time-series problems. This approach showcases state-of-the-art performance on the notorious COMPAS benchmark dataset, demonstrating its effectiveness in real-world scenarios. In the second framework, the challenge of lacking sensitive attributes, such as gender and race, in commonly used datasets is addressed. This issue is particularly pressing because existing algorithms in this field predominantly rely on the availability or estimations of such attributes to assess and mitigate unfairness. Here, a framework for a group-blind bias-repair is introduced, aiming to mitigate bias without relying on sensitive attributes. The efficacy of this approach is showcased through analyses conducted on the Adult Census Income dataset. Additionally, detailed algorithmic analyses for both frameworks are provided, accompanied by convergence guarantees, ensuring the robustness and reliability of the proposed methodologies.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "PhD thesis. arXiv admin note: text overlap with arXiv:2310.11407"
    },
    {
        "paper id": "2411.09064",
        "abstract url": "https://arxiv.org/abs/2411.09064",
        "title": "Minimax Optimal Two-Sample Testing under Local Differential Privacy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We explore the trade-off between privacy and statistical utility in private two-sample testing under local differential privacy (LDP) for both multinomial and continuous data. We begin by addressing the multinomial case, where we introduce private permutation tests using practical privacy mechanisms such as Laplace, discrete Laplace, and Google's RAPPOR. We then extend our multinomial approach to continuous data via binning and study its uniform separation rates under LDP over H\u00f6lder and Besov smoothness classes. The proposed tests for both discrete and continuous cases rigorously control the type I error for any finite sample size, strictly adhere to LDP constraints, and achieve minimax separation rates under LDP. The attained minimax rates reveal inherent privacy-utility trade-offs that are unavoidable in private testing. To address scenarios with unknown smoothness parameters in density testing, we propose an adaptive test based on a Bonferroni-type approach that ensures robust performance without prior knowledge of the smoothness parameters. We validate our theoretical findings with extensive numerical experiments and demonstrate the practical relevance and effectiveness of our proposed methods.",
        "subjects": [
            "stat.ML",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "66 pages, 6 figures, 1 table; added a graphical illustration of central and local differential privacy in Section 1, referenced the Python package, fixed typos, and changed the citation style"
    },
    {
        "paper id": "2411.09068",
        "abstract url": "https://arxiv.org/abs/2411.09068",
        "title": "Liner Shipping Network Design with Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper proposes a novel reinforcement learning framework to address the Liner Shipping Network Design Problem (LSNDP), a challenging combinatorial optimization problem focused on designing cost-efficient maritime shipping routes. Traditional methods for solving the LSNDP typically involve decomposing the problem into sub-problems, such as network design and multi-commodity flow, which are then tackled using approximate heuristics or large neighborhood search (LNS) techniques. In contrast, our approach employs a model-free reinforcement learning algorithm on the network design, integrated with a heuristic-based multi-commodity flow solver, to produce competitive results on the publicly available LINERLIB benchmark. Additionally, our method also demonstrates generalization capabilities by producing competitive solutions on the benchmark instances after training on perturbed instances.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09089",
        "abstract url": "https://arxiv.org/abs/2411.09089",
        "title": "Set-Based Retrograde Analysis: Precomputing the Solution to 24-card Bridge Double Dummy Deals",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Retrograde analysis is used in game-playing programs to solve states at the end of a game, working backwards toward the start of the game. The algorithm iterates through and computes the perfect-play value for as many states as resources allow. We introduce setrograde analysis which achieves the same results by operating on sets of states that have the same game value. The algorithm is demonstrated by computing exact solutions for Bridge double dummy card-play. For deals with 24 cards remaining to be played ($10^{27}$ states, which can be reduced to $10^{15}$ states using preexisting techniques), we strongly solve all deals. The setrograde algorithm performs a factor of $10^3$ fewer search operations than a standard retrograde algorithm, producing a database with a factor of $10^4$ fewer entries. For applicable domains, this allows retrograde searching to reach unprecedented search depths.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09118",
        "abstract url": "https://arxiv.org/abs/2411.09118",
        "title": "FxTS-Net: Fixed-Time Stable Learning Framework for Neural ODEs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Neural Ordinary Differential Equations (Neural ODEs), as a novel category of modeling big data methods, cleverly link traditional neural networks and dynamical systems. However, it is challenging to ensure the dynamics system reaches a correctly predicted state within a user-defined fixed time. To address this problem, we propose a new method for training Neural ODEs using fixed-time stability (FxTS) Lyapunov conditions. Our framework, called FxTS-Net, is based on the novel FxTS loss (FxTS-Loss) designed on Lyapunov functions, which aims to encourage convergence to accurate predictions in a user-defined fixed time. We also provide an innovative approach for constructing Lyapunov functions to meet various tasks and network architecture requirements, achieved by leveraging supervised information during training. By developing a more precise time upper bound estimation for bounded non-vanishingly perturbed systems, we demonstrate that minimizing FxTS-Loss not only guarantees FxTS behavior of the dynamics but also input perturbation robustness. For optimising FxTS-Loss, we also propose a learning algorithm, in which the simulated perturbation sampling method can capture sample points in critical regions to approximate FxTS-Loss. Experimentally, we find that FxTS-Net provides better prediction performance and better robustness under input perturbation.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09127",
        "abstract url": "https://arxiv.org/abs/2411.09127",
        "title": "Complexity-Aware Training of Deep Neural Networks for Optimal Structure Discovery",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel algorithm for combined unit/filter and layer pruning of deep neural networks that functions during training and without requiring a pre-trained network to apply. Our algorithm optimally trades-off learning accuracy and pruning levels while balancing layer vs. unit/filter pruning and computational vs. parameter complexity using only three user-defined parameters, which are easy to interpret and tune. The optimal network structure is found as the solution of a stochastic optimization problem over the network weights and the parameters of variational Bernoulli distributions for 0/1 Random Variables scaling the units and layers of the network. Pruning occurs when a variational parameter converges to 0 rendering the corresponding structure permanently inactive, thus saving computations during training and prediction. A key contribution of our approach is to define a cost function that combines the objectives of prediction accuracy and network pruning in a computational/parameter complexity-aware manner and the automatic selection of the many regularization parameters. We show that the solutions of the optimization problem to which the algorithm converges are deterministic networks. We analyze the ODE system that underlies our stochastic optimization algorithm and establish domains of attraction around zero for the dynamics of the network parameters. These results provide theoretical support for safely pruning units/filters and/or layers during training and lead to practical pruning conditions. We evaluate our method on the CIFAR-10/100 and ImageNet datasets using ResNet architectures and demonstrate that our method improves upon layer only or unit only pruning and favorably competes with combined unit/filter and layer pruning algorithms requiring pre-trained networks with respect to pruning ratios and test accuracy.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "28 pages, 4 figures, 5 tables"
    },
    {
        "paper id": "2411.09134",
        "abstract url": "https://arxiv.org/abs/2411.09134",
        "title": "ABCI 3.0: Evolution of the leading AI infrastructure in Japan",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "ABCI 3.0 is the latest version of the ABCI, a large-scale open AI infrastructure that AIST has been operating since August 2018 and will be fully operational in January 2025. ABCI 3.0 consists of computing servers equipped with 6128 of the NVIDIA H200 GPUs and an all-flash storage system. Its peak performance is 6.22 exaflops in half precision and 3.0 exaflops in single precision, which is 7 to 13 times faster than the previous system, ABCI 2.0. It also more than doubles both storage capacity and theoretical read/write performance. ABCI 3.0 is expected to accelerate research and development, evaluation, and workforce development of cutting-edge AI technologies, with a particular focus on generative AI.",
        "subjects": [
            "cs.NI",
            "cs.AI"
        ],
        "comment": "4 pages, 2 figures"
    },
    {
        "paper id": "2411.09142",
        "abstract url": "https://arxiv.org/abs/2411.09142",
        "title": "Laplace Transform Interpretation of Differential Privacy",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a set of useful expressions of Differential Privacy (DP) notions in terms of the Laplace transform of the privacy loss distribution. Its bare form expression appears in several related works on analyzing DP, either as an integral or an expectation. We show that recognizing the expression as a Laplace transform unlocks a new way to reason about DP properties by exploiting the duality between time and frequency domains. Leveraging our interpretation, we connect the $(q, \u03c1(q))$-R\u00e9nyi DP curve and the $(\u03b5, \u03b4(\u03b5))$-DP curve as being the Laplace and inverse-Laplace transforms of one another. This connection shows that the R\u00e9nyi divergence is well-defined for complex orders $q = \u03b3+ i \u03c9$. Using our Laplace transform-based analysis, we also prove an adaptive composition theorem for $(\u03b5, \u03b4)$-DP guarantees that is exactly tight (i.e., matches even in constants) for all values of $\u03b5$. Additionally, we resolve an issue regarding symmetry of $f$-DP on subsampling that prevented equivalence across all functional DP notions.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09160",
        "abstract url": "https://arxiv.org/abs/2411.09160",
        "title": "Rationality based Innate-Values-driven Reinforcement Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Innate values describe agents' intrinsic motivations, which reflect their inherent interests and preferences to pursue goals and drive them to develop diverse skills satisfying their various needs. The essence of reinforcement learning (RL) is learning from interaction based on reward-driven behaviors, much like natural agents. It is an excellent model to describe the innate-values-driven (IV) behaviors of AI agents. Especially developing the awareness of the AI agent through balancing internal and external utilities based on its needs in different tasks is a crucial problem for individuals learning to support AI agents integrating human society with safety and harmony in the long term. This paper proposes a hierarchical compound intrinsic value reinforcement learning model -- innate-values-driven reinforcement learning termed IVRL to describe the complex behaviors of AI agents' interaction. We formulated the IVRL model and proposed two IVRL models: DQN and A2C. By comparing them with benchmark algorithms such as DQN, DDQN, A2C, and PPO in the Role-Playing Game (RPG) reinforcement learning test platform VIZDoom, we demonstrated that rationally organizing various individual needs can effectively achieve better performance.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2401.05572"
    },
    {
        "paper id": "2411.09169",
        "abstract url": "https://arxiv.org/abs/2411.09169",
        "title": "Artificial Theory of Mind and Self-Guided Social Organisation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "One of the challenges artificial intelligence (AI) faces is how a collection of agents coordinate their behaviour to achieve goals that are not reachable by any single agent. In a recent article by Ozmen et al this was framed as one of six grand challenges: That AI needs to respect human cognitive processes at the human-AI interaction frontier. We suggest that this extends to the AI-AI frontier and that it should also reflect human psychology, as it is the only successful framework we have from which to build out. In this extended abstract we first make the case for collective intelligence in a general setting, drawing on recent work from single neuron complexity in neural networks and ant network adaptability in ant colonies. From there we introduce how species relate to one another in an ecological network via niche selection, niche choice, and niche conformity with the aim of forming an analogy with human social network development as new agents join together and coordinate. From there we show how our social structures are influenced by our neuro-physiology, our psychology, and our language. This emphasises how individual people within a social network influence the structure and performance of that network in complex tasks, and that cognitive faculties such as Theory of Mind play a central role. We finish by discussing the current state of the art in AI and where there is potential for further development of a socially embodied collective artificial intelligence that is capable of guiding its own social structures.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.CY",
            "cs.HC",
            "nlin.AO"
        ],
        "comment": "4 pages"
    },
    {
        "paper id": "2411.09175",
        "abstract url": "https://arxiv.org/abs/2411.09175",
        "title": "Hybrid deep additive neural networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Traditional neural networks (multi-layer perceptrons) have become an important tool in data science due to their success across a wide range of tasks. However, their performance is sometimes unsatisfactory, and they often require a large number of parameters, primarily due to their reliance on the linear combination structure. Meanwhile, additive regression has been a popular alternative to linear regression in statistics. In this work, we introduce novel deep neural networks that incorporate the idea of additive regression. Our neural networks share architectural similarities with Kolmogorov-Arnold networks but are based on simpler yet flexible activation and basis functions. Additionally, we introduce several hybrid neural networks that combine this architecture with that of traditional neural networks. We derive their universal approximation properties and demonstrate their effectiveness through simulation studies and a real-data application. The numerical results indicate that our neural networks generally achieve better performance than traditional neural networks while using fewer parameters.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "29 pages, 13 figures"
    },
    {
        "paper id": "2411.09178",
        "abstract url": "https://arxiv.org/abs/2411.09178",
        "title": "SAFES: Sequential Privacy and Fairness Enhancing Data Synthesis for Responsible AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As data-driven and AI-based decision making gains widespread adoption in most disciplines, it is crucial that both data privacy and decision fairness are appropriately addressed. While differential privacy (DP) provides a robust framework for guaranteeing privacy and several widely accepted methods have been proposed for improving fairness, the vast majority of existing literature treats the two concerns independently. For methods that do consider privacy and fairness simultaneously, they often only apply to a specific machine learning task, limiting their generalizability. In response, we introduce SAFES, a Sequential PrivAcy and Fairness Enhancing data Synthesis procedure that sequentially combines DP data synthesis with a fairness-aware data transformation. SAFES allows full control over the privacy-fairness-utility trade-off via tunable privacy and fairness parameters. We illustrate SAFES by combining AIM, a graphical model-based DP data synthesizer, with a popular fairness-aware data pre-processing transformation. Empirical evaluations on the Adult and COMPAS datasets demonstrate that for reasonable privacy loss, SAFES-generated synthetic data achieve significantly improved fairness metrics with relatively low utility loss.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08340",
        "abstract url": "https://arxiv.org/abs/2411.08340",
        "title": "DyConfidMatch: Dynamic Thresholding and Re-sampling for 3D Semi-supervised Learning",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Semi-supervised learning (SSL) leverages limited labeled and abundant unlabeled data but often faces challenges with data imbalance, especially in 3D contexts. This study investigates class-level confidence as an indicator of learning status in 3D SSL, proposing a novel method that utilizes dynamic thresholding to better use unlabeled data, particularly from underrepresented classes. A re-sampling strategy is also introduced to mitigate bias towards well-represented classes, ensuring equitable class representation. Through extensive experiments in 3D SSL, our method surpasses state-of-the-art counterparts in classification and detection tasks, highlighting its effectiveness in tackling data imbalance. This approach presents a significant advancement in SSL for 3D datasets, providing a robust solution for data imbalance issues.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted by Pattern Recognition Journal"
    },
    {
        "paper id": "2411.08410",
        "abstract url": "https://arxiv.org/abs/2411.08410",
        "title": "The VLLM Safety Paradox: Dual Ease in Jailbreak Attack and Defense",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The vulnerability of Vision Large Language Models (VLLMs) to jailbreak attacks appears as no surprise. However, recent defense mechanisms against these attacks have reached near-saturation performance on benchmarks, often with minimal effort. This simultaneous high performance in both attack and defense presents a perplexing paradox. Resolving it is critical for advancing the development of trustworthy models. To address this research gap, we first investigate why VLLMs are prone to these attacks. We then make a key observation: existing defense mechanisms suffer from an \\textbf{over-prudence} problem, resulting in unexpected abstention even in the presence of benign inputs. Additionally, we find that the two representative evaluation methods for jailbreak often exhibit chance agreement. This limitation makes it potentially misleading when evaluating attack strategies or defense mechanisms. Beyond these empirical observations, our another contribution in this work is to repurpose the guardrails of LLMs on the shelf, as an effective alternative detector prior to VLLM response. We believe these findings offer useful insights to rethink the foundational development of VLLM safety with respect to benchmark datasets, evaluation methods, and defense strategies.",
        "subjects": [
            "cs.CR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08443",
        "abstract url": "https://arxiv.org/abs/2411.08443",
        "title": "Machine Unlearning on Pre-trained Models by Residual Feature Alignment Using LoRA",
        "rating": "0",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Machine unlearning is new emerged technology that removes a subset of the training data from a trained model without affecting the model performance on the remaining data. This topic is becoming increasingly important in protecting user privacy and eliminating harmful or outdated data. The key challenge lies in effectively and efficiently unlearning specific information without compromising the model's utility on the retained data. For the pre-trained models, fine-tuning is an important way to achieve the unlearning target. Previous work typically fine-tuned the entire model's parameters, which incurs significant computation costs. In addition, the fine-tuning process may cause shifts in the intermediate layer features, affecting the model's overall utility. In this work, we propose a novel and efficient machine unlearning method on pre-trained models. We term the method as Residual Feature Alignment Unlearning. Specifically, we leverage LoRA (Low-Rank Adaptation) to decompose the model's intermediate features into pre-trained features and residual features. By adjusting the residual features, we align the unlearned model with the pre-trained model at the intermediate feature level to achieve both unlearning and remaining targets. The method aims to learn the zero residuals on the retained set and shifted residuals on the unlearning set. Extensive experiments on numerous datasets validate the effectiveness of our approach.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08477",
        "abstract url": "https://arxiv.org/abs/2411.08477",
        "title": "State-Space Estimation of Spatially Dynamic Room Impulse Responses using a Room Acoustic Model-based Prior",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "The estimation of room impulse responses (RIRs) between static loudspeaker and microphone locations can be done using a number of well-established measurement and inference procedures. While these procedures assume a time-invariant acoustic system, time variations need to be considered for the case of spatially dynamic scenarios where loudspeakers and microphones are subject to movement. If the RIR is modeled using image sources, then movement implies that the distance to each image source varies over time, making the estimation of the spatially dynamic RIR particularly challenging. In this paper, we propose a procedure to estimate the early part of the spatially dynamic RIR between a stationary source and a microphone moving on a linear trajectory at constant velocity. The procedure is built upon a state-space model, where the state to be estimated represents the early RIR, the observation corresponds to a microphone recording in a spatially dynamic scenario, and time-varying distances to the image sources are incorporated into the state transition matrix obtained from static RIRs at the start and end point of the trajectory. The performance of the proposed approach is evaluated against state-of-the-art RIR interpolation and state-space estimation methods using simulations, demonstrating the potential of the proposed state-space model.",
        "subjects": [
            "eess.AS",
            "eess.SP"
        ],
        "comment": "30 pages, 13 figures"
    },
    {
        "paper id": "2411.08508",
        "abstract url": "https://arxiv.org/abs/2411.08508",
        "title": "BillBoard Splatting (BBSplat): Learnable Textured Primitives for Novel View Synthesis",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present billboard Splatting (BBSplat) - a novel approach for 3D scene representation based on textured geometric primitives. BBSplat represents the scene as a set of optimizable textured planar primitives with learnable RGB textures and alpha-maps to control their shape. BBSplat primitives can be used in any Gaussian Splatting pipeline as drop-in replacements for Gaussians. Our method's qualitative and quantitative improvements over 3D and 2D Gaussians are most noticeable when fewer primitives are used, when BBSplat achieves over 1200 FPS. Our novel regularization term encourages textures to have a sparser structure, unlocking an efficient compression that leads to a reduction in storage space of the model. Our experiments show the efficiency of BBSplat on standard datasets of real indoor and outdoor scenes such as Tanks&Temples, DTU, and Mip-NeRF-360. We demonstrate improvements on PSNR, SSIM, and LPIPS metrics compared to the state-of-the-art, especially for the case when fewer primitives are used, which, on the other hand, leads to up to 2 times inference speed improvement for the same rendering quality.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08603",
        "abstract url": "https://arxiv.org/abs/2411.08603",
        "title": "Generalized Pose Space Embeddings for Training In-the-Wild using Anaylis-by-Synthesis",
        "rating": "0",
        "keywords": [
            [
                "skeleton"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Modern pose estimation models are trained on large, manually-labelled datasets which are costly and may not cover the full extent of human poses and appearances in the real world. With advances in neural rendering, analysis-by-synthesis and the ability to not only predict, but also render the pose, is becoming an appealing framework, which could alleviate the need for large scale manual labelling efforts. While recent work have shown the feasibility of this approach, the predictions admit many flips due to a simplistic intermediate skeleton representation, resulting in low precision and inhibiting the acquisition of any downstream knowledge such as three-dimensional positioning. We solve this problem with a more expressive intermediate skeleton representation capable of capturing the semantics of the pose (left and right), which significantly reduces flips. To successfully train this new representation, we extend the analysis-by-synthesis framework with a training protocol based on synthetic data. We show that our representation results in less flips and more accurate predictions. Our approach outperforms previous models trained with analysis-by-synthesis on standard benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08656",
        "abstract url": "https://arxiv.org/abs/2411.08656",
        "title": "MikuDance: Animating Character Art with Mixed Motion Dynamics",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We propose MikuDance, a diffusion-based pipeline incorporating mixed motion dynamics to animate stylized character art. MikuDance consists of two key techniques: Mixed Motion Modeling and Mixed-Control Diffusion, to address the challenges of high-dynamic motion and reference-guidance misalignment in character art animation. Specifically, a Scene Motion Tracking strategy is presented to explicitly model the dynamic camera in pixel-wise space, enabling unified character-scene motion modeling. Building on this, the Mixed-Control Diffusion implicitly aligns the scale and body shape of diverse characters with motion guidance, allowing flexible control of local character motion. Subsequently, a Motion-Adaptive Normalization module is incorporated to effectively inject global scene motion, paving the way for comprehensive character art animation. Through extensive experiments, we demonstrate the effectiveness and generalizability of MikuDance across various character art and motion guidance, consistently producing high-quality animations with remarkable motion dynamics.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08727",
        "abstract url": "https://arxiv.org/abs/2411.08727",
        "title": "Voxeland: Probabilistic Instance-Aware Semantic Mapping with Evidence-based Uncertainty Quantification",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "robot"
            ]
        ],
        "abstract": "Robots in human-centered environments require accurate scene understanding to perform high-level tasks effectively. This understanding can be achieved through instance-aware semantic mapping, which involves reconstructing elements at the level of individual instances. Neural networks, the de facto solution for scene understanding, still face limitations such as overconfident incorrect predictions with out-of-distribution objects or generating inaccurate masks.Placing excessive reliance on these predictions makes the reconstruction susceptible to errors, reducing the robustness of the resulting maps and hampering robot operation. In this work, we propose Voxeland, a probabilistic framework for incrementally building instance-aware semantic maps. Inspired by the Theory of Evidence, Voxeland treats neural network predictions as subjective opinions regarding map instances at both geometric and semantic levels. These opinions are aggregated over time to form evidences, which are formalized through a probabilistic model. This enables us to quantify uncertainty in the reconstruction process, facilitating the identification of map areas requiring improvement (e.g. reobservation or reclassification). As one strategy to exploit this, we incorporate a Large Vision-Language Model (LVLM) to perform semantic level disambiguation for instances with high uncertainty. Results from the standard benchmarking on the publicly available SceneNN dataset demonstrate that Voxeland outperforms state-of-the-art methods, highlighting the benefits of incorporating and leveraging both instance- and semantic-level uncertainties to enhance reconstruction robustness. This is further validated through qualitative experiments conducted on the real-world ScanNet dataset.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08862",
        "abstract url": "https://arxiv.org/abs/2411.08862",
        "title": "LLMStinger: Jailbreaking LLMs using RL fine-tuned LLMs",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "We introduce LLMStinger, a novel approach that leverages Large Language Models (LLMs) to automatically generate adversarial suffixes for jailbreak attacks. Unlike traditional methods, which require complex prompt engineering or white-box access, LLMStinger uses a reinforcement learning (RL) loop to fine-tune an attacker LLM, generating new suffixes based on existing attacks for harmful questions from the HarmBench benchmark. Our method significantly outperforms existing red-teaming approaches (we compared against 15 of the latest methods), achieving a +57.2% improvement in Attack Success Rate (ASR) on LLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, both models known for their extensive safety measures. Additionally, we achieved a 94.97% ASR on GPT-3.5 and 99.4% on Gemma-2B-it, demonstrating the robustness and adaptability of LLMStinger across open and closed-source models.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "Accepted at AAAI 2025"
    },
    {
        "paper id": "2411.08933",
        "abstract url": "https://arxiv.org/abs/2411.08933",
        "title": "Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for Certified Robustness",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The remarkable advances in deep learning have led to the emergence of many off-the-shelf classifiers, e.g., large pre-trained models. However, since they are typically trained on clean data, they remain vulnerable to adversarial attacks. Despite this vulnerability, their superior performance and transferability make off-the-shelf classifiers still valuable in practice, demanding further work to provide adversarial robustness for them in a post-hoc manner. A recently proposed method, denoised smoothing, leverages a denoiser model in front of the classifier to obtain provable robustness without additional training. However, the denoiser often creates hallucination, i.e., images that have lost the semantics of their originally assigned class, leading to a drop in robustness. Furthermore, its noise-and-denoise procedure introduces a significant distribution shift from the original distribution, causing the denoised smoothing framework to achieve sub-optimal robustness. In this paper, we introduce Fine-Tuning with Confidence-Aware Denoised Image Selection (FT-CADIS), a novel fine-tuning scheme to enhance the certified robustness of off-the-shelf classifiers. FT-CADIS is inspired by the observation that the confidence of off-the-shelf classifiers can effectively identify hallucinated images during denoised smoothing. Based on this, we develop a confidence-aware training objective to handle such hallucinated images and improve the stability of fine-tuning from denoised images. In this way, the classifier can be fine-tuned using only images that are beneficial for adversarial robustness. We also find that such a fine-tuning can be done by updating a small fraction of parameters of the classifier. Extensive experiments demonstrate that FT-CADIS has established the state-of-the-art certified robustness among denoised smoothing methods across all $\\ell_2$-adversary radius in various benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "comment": "26 pages; TMLR 2024; Code is available at https://github.com/suhyeok24/FT-CADIS"
    },
    {
        "paper id": "2411.08954",
        "abstract url": "https://arxiv.org/abs/2411.08954",
        "title": "Inconsistencies In Consistency Models: Better ODE Solving Does Not Imply Better Samples",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Although diffusion models can generate remarkably high-quality samples, they are intrinsically bottlenecked by their expensive iterative sampling procedure. Consistency models (CMs) have recently emerged as a promising diffusion model distillation method, reducing the cost of sampling by generating high-fidelity samples in just a few iterations. Consistency model distillation aims to solve the probability flow ordinary differential equation (ODE) defined by an existing diffusion model. CMs are not directly trained to minimize error against an ODE solver, rather they use a more computationally tractable objective. As a way to study how effectively CMs solve the probability flow ODE, and the effect that any induced error has on the quality of generated samples, we introduce Direct CMs, which \\textit{directly} minimize this error. Intriguingly, we find that Direct CMs reduce the ODE solving error compared to CMs but also result in significantly worse sample quality, calling into question why exactly CMs work well in the first place. Full code is available at: https://github.com/layer6ai-labs/direct-cms.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "NeurIPS 2024 ATTRIB Workshop"
    },
    {
        "paper id": "2411.09022",
        "abstract url": "https://arxiv.org/abs/2411.09022",
        "title": "DART-LLM: Dependency-Aware Multi-Robot Task Decomposition and Execution using Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language",
                "VLM"
            ],
            [
                "Robot"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated significant reasoning capabilities in robotic systems. However, their deployment in multi-robot systems remains fragmented and struggles to handle complex task dependencies and parallel execution. This study introduces the DART-LLM (Dependency-Aware Multi-Robot Task Decomposition and Execution using Large Language Models) system, designed to address these challenges. DART-LLM utilizes LLMs to parse natural language instructions, decomposing them into multiple subtasks with dependencies to establish complex task sequences, thereby enhancing efficient coordination and parallel execution in multi-robot systems. The system includes the QA LLM module, Breakdown Function modules, Actuation module, and a Vision-Language Model (VLM)-based object detection module, enabling task decomposition and execution from natural language instructions to robotic actions. Experimental results demonstrate that DART-LLM excels in handling long-horizon tasks and collaborative tasks with complex dependencies. Even when using smaller models like Llama 3.1 8B, the system achieves good performance, highlighting DART-LLM's robustness in terms of model size. Please refer to the project website \\url{https://wyd0817.github.io/project-dart-llm/} for videos and code.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to the 2025 IEEE International Conference on Robotics & Automation on September 15, 2024"
    },
    {
        "paper id": "2411.09066",
        "abstract url": "https://arxiv.org/abs/2411.09066",
        "title": "A multidimensional measurement of photorealistic avatar quality of experience",
        "rating": "0",
        "keywords": [
            [
                "avatar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Photorealistic avatars are human avatars that look, move, and talk like real people. The performance of photorealistic avatars has significantly improved recently based on objective metrics such as PSNR, SSIM, LPIPS, FID, and FVD. However, recent photorealistic avatar publications do not provide subjective tests of the avatars to measure human usability factors. We provide an open source test framework to subjectively measure photorealistic avatar performance in ten dimensions: realism, trust, comfortableness using, comfortableness interacting with, appropriateness for work, creepiness, formality, affinity, resemblance to the person, and emotion accuracy. We show that the correlation of nine of these subjective metrics with PSNR, SSIM, LPIPS, FID, and FVD is weak, and moderate for emotion accuracy. The crowdsourced subjective test framework is highly reproducible and accurate when compared to a panel of experts. We analyze a wide range of avatars from photorealistic to cartoon-like and show that some photorealistic avatars are approaching real video performance based on these dimensions. We also find that for avatars above a certain level of realism, eight of these measured dimensions are strongly correlated. In particular, for photorealistic avatars there is a linear relationship between avatar affinity and realism; in other words, there is no uncanny valley effect for photorealistic avatars in the telecommunication scenario. We provide several extensions of this test framework for future work and discuss design implications for telecommunication systems. The test framework is available at https://github.com/microsoft/P.910.",
        "subjects": [
            "cs.HC",
            "cs.CV",
            "cs.GR"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2204.06784"
    },
    {
        "paper id": "2411.09101",
        "abstract url": "https://arxiv.org/abs/2411.09101",
        "title": "Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery",
        "rating": "0",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Vision Transformers (ViT) have recently brought a new wave of research in the field of computer vision. These models have done particularly well in the field of image classification and segmentation. Research on semantic and instance segmentation has emerged to accelerate with the inception of the new architecture, with over 80\\% of the top 20 benchmarks for the iSAID dataset being either based on the ViT architecture or the attention mechanism behind its success. This paper focuses on the heuristic comparison of three key factors of using (or not using) ViT for semantic segmentation of remote sensing aerial images on the iSAID. The experimental results observed during the course of the research were under the scrutinization of the following objectives: 1. Use of weighted fused loss function for the maximum mean Intersection over Union (mIoU) score, Dice score, and minimization or conservation of entropy or class representation, 2. Comparison of transfer learning on Meta's MaskFormer, a ViT-based semantic segmentation model, against generic UNet Convolutional Neural Networks (CNNs) judged over mIoU, Dice scores, training efficiency, and inference time, and 3. What do we lose for what we gain? i.e., the comparison of the two models against current state-of-art segmentation models. We show the use of the novel combined weighted loss function significantly boosts the CNN model's performance capacities as compared to transfer learning the ViT. The code for this implementation can be found on \\url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation}.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09125",
        "abstract url": "https://arxiv.org/abs/2411.09125",
        "title": "DROJ: A Prompt-Driven Attack against Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Attack"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities across various natural language processing tasks. Due to their training on internet-sourced datasets, LLMs can sometimes generate objectionable content, necessitating extensive alignment with human feedback to avoid such outputs. Despite massive alignment efforts, LLMs remain susceptible to adversarial jailbreak attacks, which usually are manipulated prompts designed to circumvent safety mechanisms and elicit harmful responses. Here, we introduce a novel approach, Directed Rrepresentation Optimization Jailbreak (DROJ), which optimizes jailbreak prompts at the embedding level to shift the hidden representations of harmful queries towards directions that are more likely to elicit affirmative responses from the model. Our evaluations on LLaMA-2-7b-chat model show that DROJ achieves a 100\\% keyword-based Attack Success Rate (ASR), effectively preventing direct refusals. However, the model occasionally produces repetitive and non-informative responses. To mitigate this, we introduce a helpfulness system prompt that enhances the utility of the model's responses. Our code is available at https://github.com/Leon-Leyang/LLM-Safeguard.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09156",
        "abstract url": "https://arxiv.org/abs/2411.09156",
        "title": "DyGASR: Dynamic Generalized Exponential Splatting with Surface Alignment for Accelerated 3D Mesh Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "point cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in 3D Gaussian Splatting (3DGS), which lead to high-quality novel view synthesis and accelerated rendering, have remarkably improved the quality of radiance field reconstruction. However, the extraction of mesh from a massive number of minute 3D Gaussian points remains great challenge due to the large volume of Gaussians and difficulty of representation of sharp signals caused by their inherent low-pass characteristics. To address this issue, we propose DyGASR, which utilizes generalized exponential function instead of traditional 3D Gaussian to decrease the number of particles and dynamically optimize the representation of the captured signal. In addition, it is observed that reconstructing mesh with Generalized Exponential Splatting(GES) without modifications frequently leads to failures since the generalized exponential distribution centroids may not precisely align with the scene surface. To overcome this, we adopt Sugar's approach and introduce Generalized Surface Regularization (GSR), which reduces the smallest scaling vector of each point cloud to zero and ensures normal alignment perpendicular to the surface, facilitating subsequent Poisson surface mesh reconstruction. Additionally, we propose a dynamic resolution adjustment strategy that utilizes a cosine schedule to gradually increase image resolution from low to high during the training stage, thus avoiding constant full resolution, which significantly boosts the reconstruction speed. Our approach surpasses existing 3DGS-based mesh reconstruction methods, as evidenced by extensive evaluations on various scene datasets, demonstrating a 25\\% increase in speed, and a 30\\% reduction in memory usage.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09167",
        "abstract url": "https://arxiv.org/abs/2411.09167",
        "title": "Robust AI-Synthesized Speech Detection Using Feature Decomposition Learning and Synthesizer Feature Augmentation",
        "rating": "0",
        "keywords": [
            [
                "deepfake"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "AI-synthesized speech, also known as deepfake speech, has recently raised significant concerns due to the rapid advancement of speech synthesis and speech conversion techniques. Previous works often rely on distinguishing synthesizer artifacts to identify deepfake speech. However, excessive reliance on these specific synthesizer artifacts may result in unsatisfactory performance when addressing speech signals created by unseen synthesizers. In this paper, we propose a robust deepfake speech detection method that employs feature decomposition to learn synthesizer-independent content features as complementary for detection. Specifically, we propose a dual-stream feature decomposition learning strategy that decomposes the learned speech representation using a synthesizer stream and a content stream. The synthesizer stream specializes in learning synthesizer features through supervised training with synthesizer labels. Meanwhile, the content stream focuses on learning synthesizer-independent content features, enabled by a pseudo-labeling-based supervised learning method. This method randomly transforms speech to generate speed and compression labels for training. Additionally, we employ an adversarial learning technique to reduce the synthesizer-related components in the content stream. The final classification is determined by concatenating the synthesizer and content features. To enhance the model's robustness to different synthesizer characteristics, we further propose a synthesizer feature augmentation strategy that randomly blends the characteristic styles within real and fake audio features and randomly shuffles the synthesizer features with the content features. This strategy effectively enhances the feature diversity and simulates more feature combinations.",
        "subjects": [
            "cs.SD",
            "cs.CR",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09174",
        "abstract url": "https://arxiv.org/abs/2411.09174",
        "title": "Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Recent advances in image generation, particularly via diffusion models, have led to impressive improvements in image synthesis quality. Despite this, diffusion models are still challenged by model-induced artifacts and limited stability in image fidelity. In this work, we hypothesize that the primary cause of this issue is the improper resampling operation that introduces aliasing in the diffusion model and a careful alias-free resampling dictated by image processing theory can improve the model's performance in image synthesis. We propose the integration of alias-free resampling layers into the UNet architecture of diffusion models without adding extra trainable parameters, thereby maintaining computational efficiency. We then assess whether these theory-driven modifications enhance image quality and rotational equivariance. Our experimental results on benchmark datasets, including CIFAR-10, MNIST, and MNIST-M, reveal consistent gains in image quality, particularly in terms of FID and KID scores. Furthermore, we propose a modified diffusion process that enables user-controlled rotation of generated images without requiring additional training. Our findings highlight the potential of theory-driven enhancements such as alias-free resampling in generative models to improve image quality while maintaining model efficiency and pioneer future research directions to incorporate them into video-generating diffusion models, enabling deeper exploration of the applications of alias-free resampling in generative modeling.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "13 pages, 7 figures"
    },
    {
        "paper id": "2411.09180",
        "abstract url": "https://arxiv.org/abs/2411.09180",
        "title": "LEAP:D -- A Novel Prompt-based Approach for Domain-Generalized Aerial Object Detection",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "Drone"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Drone-captured images present significant challenges in object detection due to varying shooting conditions, which can alter object appearance and shape. Factors such as drone altitude, angle, and weather cause these variations, influencing the performance of object detection algorithms. To tackle these challenges, we introduce an innovative vision-language approach using learnable prompts. This shift from conventional manual prompts aims to reduce domain-specific knowledge interference, ultimately improving object detection capabilities. Furthermore, we streamline the training process with a one-step approach, updating the learnable prompt concurrently with model training, enhancing efficiency without compromising performance. Our study contributes to domain-generalized object detection by leveraging learnable prompts and optimizing training processes. This enhances model robustness and adaptability across diverse environments, leading to more effective aerial object detection.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "ICIP 2024 Workshop accepted paper"
    },
    {
        "paper id": "2411.08341",
        "abstract url": "https://arxiv.org/abs/2411.08341",
        "title": "Generative AI for Data Augmentation in Wireless Networks: Analysis, Applications, and Case Study",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Data augmentation is a powerful technique to mitigate data scarcity. However, owing to fundamental differences in wireless data structures, traditional data augmentation techniques may not be suitable for wireless data. Fortunately, Generative Artificial Intelligence (GenAI) can be an effective alternative to wireless data augmentation due to its excellent data generation capability. This article systemically explores the potential and effectiveness of GenAI-driven data augmentation in wireless networks. We first briefly review data augmentation techniques, discuss their limitations in wireless networks, and introduce generative data augmentation, including reviewing GenAI models and their applications in data augmentation. We then explore the application prospects of GenAI-driven data augmentation in wireless networks from the physical, network, and application layers, which provides a GenAI-driven data augmentation architecture for each application. Subsequently, we propose a general generative diffusion model-based data augmentation framework for Wi-Fi gesture recognition, which uses transformer-based diffusion models to generate high-quality channel state information data. Furthermore, we develop residual neural network models for Wi-Fi gesture recognition to evaluate the role of augmented data and conduct a case study based on a real dataset. Simulation results demonstrate the effectiveness of the proposed framework. Finally, we discuss research directions for generative data augmentation.",
        "subjects": [
            "cs.NI",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08355",
        "abstract url": "https://arxiv.org/abs/2411.08355",
        "title": "Communication Efficient Decentralization for Smoothed Online Convex Optimization",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem, where $N$ agents interact through a communication graph. In each round, each agent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online fashion and selects an action $x^i_t \\in \\mathbb{R}^d$. The objective is to minimize the global cumulative cost, which includes the sum of individual hitting costs $f^i_t(x^i_t)$, a temporal \"switching cost\" for changing decisions, and a spatial \"dissimilarity cost\" that penalizes deviations in decisions among neighboring agents. We propose the first decentralized algorithm for multi-agent SOCO and prove its asymptotic optimality. Our approach allows each agent to operate using only local information from its immediate neighbors in the graph. For finite-time performance, we establish that the optimality gap in competitive ratio decreases with the time horizon $T$ and can be conveniently tuned based on the per-round computation available to each agent. Moreover, our results hold even when the communication graph changes arbitrarily and adaptively over time. Finally, we establish that the computational complexity per round depends only logarithmically on the number of agents and almost linearly on their degree within the graph, ensuring scalability for large-system implementations.",
        "subjects": [
            "math.OC",
            "cs.DS",
            "cs.LG"
        ],
        "comment": "39 pages"
    },
    {
        "paper id": "2411.08360",
        "abstract url": "https://arxiv.org/abs/2411.08360",
        "title": "Coverage Analysis for Digital Cousin Selection -- Improving Multi-Environment Q-Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Q-learning is widely employed for optimizing various large-dimensional networks with unknown system dynamics. Recent advancements include multi-environment mixed Q-learning (MEMQ) algorithms, which utilize multiple independent Q-learning algorithms across multiple, structurally related but distinct environments and outperform several state-of-the-art Q-learning algorithms in terms of accuracy, complexity, and robustness. We herein conduct a comprehensive probabilistic coverage analysis to ensure optimal data coverage conditions for MEMQ algorithms. First, we derive upper and lower bounds on the expectation and variance of different coverage coefficients (CC) for MEMQ algorithms. Leveraging these bounds, we develop a simple way of comparing the utilities of multiple environments in MEMQ algorithms. This approach appears to be near optimal versus our previously proposed partial ordering approach. We also present a novel CC-based MEMQ algorithm to improve the accuracy and complexity of existing MEMQ algorithms. Numerical experiments are conducted using random network graphs with four different graph properties. Our algorithm can reduce the average policy error (APE) by 65% compared to partial ordering and is 95% faster than the exhaustive search. It also achieves 60% less APE than several state-of-the-art reinforcement learning and prior MEMQ algorithms. Additionally, we numerically verify the theoretical results and show their scalability with the action-space size.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.08374",
        "abstract url": "https://arxiv.org/abs/2411.08374",
        "title": "Federated Graph Learning with Graphless Clients",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Federated Graph Learning (FGL) is tasked with training machine learning models, such as Graph Neural Networks (GNNs), for multiple clients, each with its own graph data. Existing methods usually assume that each client has both node features and graph structure of its graph data. In real-world scenarios, however, there exist federated systems where only a part of the clients have such data while other clients (i.e. graphless clients) may only have node features. This naturally leads to a novel problem in FGL: how to jointly train a model over distributed graph data with graphless clients? In this paper, we propose a novel framework FedGLS to tackle the problem in FGL with graphless clients. In FedGLS, we devise a local graph learner on each graphless client which learns the local graph structure with the structure knowledge transferred from other clients. To enable structure knowledge transfer, we design a GNN model and a feature encoder on each client. During local training, the feature encoder retains the local graph structure knowledge together with the GNN model via knowledge distillation, and the structure knowledge is transferred among clients in global update. Our extensive experiments demonstrate the superiority of the proposed FedGLS over five baselines.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": "Accepted by Transactions on Machine Learning Research (TMLR)"
    },
    {
        "paper id": "2411.08561",
        "abstract url": "https://arxiv.org/abs/2411.08561",
        "title": "LogLLM: Log-based Anomaly Detection Using Large Language Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Software systems often record important runtime information in logs to help with troubleshooting. Log-based anomaly detection has become a key research area that aims to identify system issues through log data, ultimately enhancing the reliability of software systems. Traditional deep learning methods often struggle to capture the semantic information embedded in log data, which is typically organized in natural language. In this paper, we propose LogLLM, a log-based anomaly detection framework that leverages large language models (LLMs). LogLLM employs BERT for extracting semantic vectors from log messages, while utilizing Llama, a transformer decoder-based model, for classifying log sequences. Additionally, we introduce a projector to align the vector representation spaces of BERT and Llama, ensuring a cohesive understanding of log semantics. Unlike conventional methods that require log parsers to extract templates, LogLLM preprocesses log messages with regular expressions, streamlining the entire process. Our framework is trained through a novel three-stage procedure designed to enhance performance and adaptability. Experimental results across four public datasets demonstrate that LogLLM outperforms state-of-the-art methods. Even when handling unstable logs, it effectively captures the semantic meaning of log messages and detects anomalies accurately.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08562",
        "abstract url": "https://arxiv.org/abs/2411.08562",
        "title": "Neural Corrective Machine Unranking",
        "rating": "-0.5",
        "keywords": [
            [
                "unlearning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Machine unlearning in neural information retrieval (IR) systems requires removing specific data whilst maintaining model performance. Applying existing machine unlearning methods to IR may compromise retrieval effectiveness or inadvertently expose unlearning actions due to the removal of particular items from the retrieved results presented to users. We formalise corrective unranking, which extends machine unlearning in (neural) IR context by integrating substitute documents to preserve ranking integrity, and propose a novel teacher-student framework, Corrective unRanking Distillation (CuRD), for this task. CuRD (1) facilitates forgetting by adjusting the (trained) neural IR model such that its output relevance scores of to-be-forgotten samples mimic those of low-ranking, non-retrievable samples; (2) enables correction by fine-tuning the relevance scores for the substitute samples to match those of corresponding to-be-forgotten samples closely; (3) seeks to preserve performance on samples that are not targeted for forgetting. We evaluate CuRD on four neural IR models (BERTcat, BERTdot, ColBERT, PARADE) using MS MARCO and TREC CAR datasets. Experiments with forget set sizes from 1 % and 20 % of the training dataset demonstrate that CuRD outperforms seven state-of-the-art baselines in terms of forgetting and correction while maintaining model retention and generalisation capabilities.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": "submitted to Information Sciences"
    },
    {
        "paper id": "2411.08566",
        "abstract url": "https://arxiv.org/abs/2411.08566",
        "title": "Grammarization-Based Grasping with Deep Multi-Autoencoder Latent Space Exploration by Reinforcement Learning Agent",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Grasping by a robot in unstructured environments is deemed a critical challenge because of the requirement for effective adaptation to a wide variation in object geometries, material properties, and other environmental factors. In this paper, we propose a novel framework for robotic grasping based on the idea of compressing high-dimensional target and gripper features in a common latent space using a set of autoencoders. Our approach simplifies grasping by using three autoencoders dedicated to the target, the gripper, and a third one that fuses their latent representations. This allows the RL agent to achieve higher learning rates at the initial stages of exploration of a new environment, as well as at non-zero shot grasp attempts. The agent explores the latent space of the third autoencoder for better quality grasp without explicit reconstruction of objects. By implementing the PoWER algorithm into the RL training process, updates on the agent's policy will be made through the perturbation in the reward-weighted latent space. The successful exploration efficiently constrains both position and pose integrity for feasible executions of grasps. We evaluate our system on a diverse set of objects, demonstrating the high success rate in grasping with minimum computational overhead. We found that approach enhances the adaptation of the RL agent by more than 35 % in simulation experiments.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "Submitted for review at IEEE ICRA 2025"
    },
    {
        "paper id": "2411.08605",
        "abstract url": "https://arxiv.org/abs/2411.08605",
        "title": "Lo-MARVE: A Low Cost Autonomous Underwater Vehicle for Marine Exploration",
        "rating": "-0.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents Low-cost Marine Autonomous Robotic Vehicle Explorer (Lo-MARVE), a novel autonomous underwater vehicle (AUV) designed to provide a low cost solution for underwater exploration and environmental monitoring in shallow water environments. Lo-MARVE offers a cost-effective alternative to existing AUVs, featuring a modular design, low-cost sensors, and wireless communication capabilities. The total cost of Lo-MARVE is approximately EUR 500. Lo-MARVE is developed using the Raspberry Pi 4B microprocessor, with control software written in Python. The proposed AUV was validated through field testing outside of a laboratory setting, in the freshwater environment of the River Corrib in Galway, Ireland. This demonstrates its ability to navigate autonomously, collect data, and communicate effectively outside of a controlled laboratory setting. The successful deployment of Lo-MARVE in a real-world environment validates its proof of concept.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "This paper was presented at the 12th International Conference on Control, Mechatronics and Automation (ICCMA 2024), held in London, UK, from November 11-13, 2024"
    },
    {
        "paper id": "2411.08622",
        "abstract url": "https://arxiv.org/abs/2411.08622",
        "title": "Precision-Focused Reinforcement Learning Model for Robotic Object Pushing",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Non-prehensile manipulation, such as pushing objects to a desired target position, is an important skill for robots to assist humans in everyday situations. However, the task is challenging due to the large variety of objects with different and sometimes unknown physical properties, such as shape, size, mass, and friction. This can lead to the object overshooting its target position, requiring fast corrective movements of the robot around the object, especially in cases where objects need to be precisely pushed. In this paper, we improve the state-of-the-art by introducing a new memory-based vision-proprioception RL model to push objects more precisely to target positions using fewer corrective movements.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08637",
        "abstract url": "https://arxiv.org/abs/2411.08637",
        "title": "Robot See, Robot Do: Imitation Reward for Noisy Financial Environments",
        "rating": "-0.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The sequential nature of decision-making in financial asset trading aligns naturally with the reinforcement learning (RL) framework, making RL a common approach in this domain. However, the low signal-to-noise ratio in financial markets results in noisy estimates of environment components, including the reward function, which hinders effective policy learning by RL agents. Given the critical importance of reward function design in RL problems, this paper introduces a novel and more robust reward function by leveraging imitation learning, where a trend labeling algorithm acts as an expert. We integrate imitation (expert's) feedback with reinforcement (agent's) feedback in a model-free RL algorithm, effectively embedding the imitation learning problem within the RL paradigm to handle the stochasticity of reward signals. Empirical results demonstrate that this novel approach improves financial performance metrics compared to traditional benchmarks and RL agents trained solely using reinforcement feedback.",
        "subjects": [
            "cs.LG",
            "cs.RO",
            "q-fin.TR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08638",
        "abstract url": "https://arxiv.org/abs/2411.08638",
        "title": "Gaussian Mixture Models Based Augmentation Enhances GNN Generalization",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have shown great promise in tasks like node and graph classification, but they often struggle to generalize, particularly to unseen or out-of-distribution (OOD) data. These challenges are exacerbated when training data is limited in size or diversity. To address these issues, we introduce a theoretical framework using Rademacher complexity to compute a regret bound on the generalization error and then characterize the effect of data augmentation. This framework informs the design of GMM-GDA, an efficient graph data augmentation (GDA) algorithm leveraging the capability of Gaussian Mixture Models (GMMs) to approximate any distribution. Our approach not only outperforms existing augmentation techniques in terms of generalization but also offers improved time complexity, making it highly suitable for real-world applications.",
        "subjects": [
            "cs.LG",
            "cs.SI",
            "stat.AP",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08687",
        "abstract url": "https://arxiv.org/abs/2411.08687",
        "title": "Measuring similarity between embedding spaces using induced neighborhood graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Deep Learning techniques have excelled at generating embedding spaces that capture semantic similarities between items. Often these representations are paired, enabling experiments with analogies (pairs within the same domain) and cross-modality (pairs across domains). These experiments are based on specific assumptions about the geometry of embedding spaces, which allow finding paired items by extrapolating the positional relationships between embedding pairs in the training dataset, allowing for tasks such as finding new analogies, and multimodal zero-shot classification. In this work, we propose a metric to evaluate the similarity between paired item representations. Our proposal is built from the structural similarity between the nearest-neighbors induced graphs of each representation, and can be configured to compare spaces based on different distance metrics and on different neighborhood sizes. We demonstrate that our proposal can be used to identify similar structures at different scales, which is hard to achieve with kernel methods such as Centered Kernel Alignment (CKA). We further illustrate our method with two case studies: an analogy task using GloVe embeddings, and zero-shot classification in the CIFAR-100 dataset using CLIP embeddings. Our results show that accuracy in both analogy and zero-shot classification tasks correlates with the embedding similarity. These findings can help explain performance differences in these tasks, and may lead to improved design of paired-embedding models in the future.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08696",
        "abstract url": "https://arxiv.org/abs/2411.08696",
        "title": "Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata using LLMs",
        "rating": "-0.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Several initiatives have been undertaken to conceptually model the domain of scholarly data using ontologies and to create respective Knowledge Graphs. Yet, the full potential seems unleashed, as automated means for automatic population of said ontologies are lacking, and respective initiatives from the Semantic Web community are not necessarily connected: we propose to make scholarly data more sustainably accessible by leveraging Wikidata's infrastructure and automating its population in a sustainable manner through LLMs by tapping into unstructured sources like conference Web sites and proceedings texts as well as already existing structured conference datasets. While an initial analysis shows that Semantic Web conferences are only minimally represented in Wikidata, we argue that our methodology can help to populate, evolve and maintain scholarly data as a community within Wikidata. Our main contributions include (a) an analysis of ontologies for representing scholarly data to identify gaps and relevant entities/properties in Wikidata, (b) semi-automated extraction -- requiring (minimal) manual validation -- of conference metadata (e.g., acceptance rates, organizer roles, programme committee members, best paper awards, keynotes, and sponsors) from websites and proceedings texts using LLMs. Finally, we discuss (c) extensions to visualization tools in the Wikidata context for data exploration of the generated scholarly data. Our study focuses on data from 105 Semantic Web-related conferences and extends/adds more than 6000 entities in Wikidata. It is important to note that the method can be more generally applicable beyond Semantic Web-related conferences for enhancing Wikidata's utility as a comprehensive scholarly resource. Source Repository: https://github.com/scholarly-wikidata/ DOI: https://doi.org/10.5281/zenodo.10989709 License: Creative Commons CC0 (Data), MIT (Code)",
        "subjects": [
            "cs.DL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "17 pages, accepted at EKAW-24"
    },
    {
        "paper id": "2411.08758",
        "abstract url": "https://arxiv.org/abs/2411.08758",
        "title": "ScaleNet: Scale Invariance Learning in Directed Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "GNNs",
                "Graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have advanced relational data analysis but lack invariance learning techniques common in image classification. In node classification with GNNs, it is actually the ego-graph of the center node that is classified. This research extends the scale invariance concept to node classification by drawing an analogy to image processing: just as scale invariance being used in image classification to capture multi-scale features, we propose the concept of ``scaled ego-graphs''. Scaled ego-graphs generalize traditional ego-graphs by replacing undirected single-edges with ``scaled-edges'', which are ordered sequences of multiple directed edges. We empirically assess the performance of the proposed scale invariance in graphs on seven benchmark datasets, across both homophilic and heterophilic structures. Our scale-invariance-based graph learning outperforms inception models derived from random walks by being simpler, faster, and more accurate. The scale invariance explains inception models' success on homophilic graphs and limitations on heterophilic graphs. To ensure applicability of inception model to heterophilic graphs as well, we further present ScaleNet, an architecture that leverages multi-scaled features. ScaleNet achieves state-of-the-art results on five out of seven datasets (four homophilic and one heterophilic) and matches top performance on the remaining two, demonstrating its excellent applicability. This represents a significant advance in graph learning, offering a unified framework that enhances node classification across various graph types. Our code is available at https://github.com/Qin87/ScaleNet/tree/July25.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Scale invariance in node classification is demonstrated and applied in graph transformation to develop ScaleNet, which achieves state-of-the-art performance on both homophilic and heterophilic directed graphs"
    },
    {
        "paper id": "2411.08764",
        "abstract url": "https://arxiv.org/abs/2411.08764",
        "title": "Flow reconstruction in time-varying geometries using graph neural networks",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The paper presents a Graph Attention Convolutional Network (GACN) for flow reconstruction from very sparse data in time-varying geometries. The model incorporates a feature propagation algorithm as a preprocessing step to handle extremely sparse inputs, leveraging information from neighboring nodes to initialize missing features. In addition, a binary indicator is introduced as a validity mask to distinguish between the original and propagated data points, enabling more effective learning from sparse inputs. Trained on a unique data set of Direct Numerical Simulations (DNS) of a motored engine at a technically relevant operating condition, the GACN shows robust performance across different resolutions and domain sizes and can effectively handle unstructured data and variable input sizes. The model is tested on previously unseen DNS data as well as on an experimental data set from Particle Image Velocimetry (PIV) measurements that were not considered during training. A comparative analysis shows that the GACN consistently outperforms both a conventional Convolutional Neural Network (CNN) and cubic interpolation methods on the DNS and PIV test sets by achieving lower reconstruction errors and better capturing fine-scale turbulent structures. In particular, the GACN effectively reconstructs flow fields from domains up to 14 times larger than those observed during training, with the performance advantage increasing for larger domains.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "physics.flu-dyn"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08832",
        "abstract url": "https://arxiv.org/abs/2411.08832",
        "title": "Offline Adaptation of Quadruped Locomotion using Diffusion Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We present a diffusion-based approach to quadrupedal locomotion that simultaneously addresses the limitations of learning and interpolating between multiple skills and of (modes) offline adapting to new locomotion behaviours after training. This is the first framework to apply classifier-free guided diffusion to quadruped locomotion and demonstrate its efficacy by extracting goal-conditioned behaviour from an originally unlabelled dataset. We show that these capabilities are compatible with a multi-skill policy and can be applied with little modification and minimal compute overhead, i.e., running entirely on the robots onboard CPU. We verify the validity of our approach with hardware experiments on the ANYmal quadruped platform.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08879",
        "abstract url": "https://arxiv.org/abs/2411.08879",
        "title": "4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "depth"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Novel view synthesis of dynamic scenes is becoming important in various applications, including augmented and virtual reality. We propose a novel 4D Gaussian Splatting (4DGS) algorithm for dynamic scenes from casually recorded monocular videos. To overcome the overfitting problem of existing work for these real-world videos, we introduce an uncertainty-aware regularization that identifies uncertain regions with few observations and selectively imposes additional priors based on diffusion models and depth smoothness on such regions. This approach improves both the performance of novel view synthesis and the quality of training image reconstruction. We also identify the initialization problem of 4DGS in fast-moving dynamic regions, where the Structure from Motion (SfM) algorithm fails to provide reliable 3D landmarks. To initialize Gaussian primitives in such regions, we present a dynamic region densification method using the estimated depth maps and scene flow. Our experiments show that the proposed method improves the performance of 4DGS reconstruction from a video captured by a handheld monocular camera and also exhibits promising results in few-shot static scene reconstruction.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2411.09117",
        "abstract url": "https://arxiv.org/abs/2411.09117",
        "title": "Efficiently learning and sampling multimodal distributions with data-based initialization",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider the problem of sampling a multimodal distribution with a Markov chain given a small number of samples from the stationary measure. Although mixing can be arbitrarily slow, we show that if the Markov chain has a $k$th order spectral gap, initialization from a set of $\\tilde O(k/\\varepsilon^2)$ samples from the stationary distribution will, with high probability over the samples, efficiently generate a sample whose conditional law is $\\varepsilon$-close in TV distance to the stationary measure. In particular, this applies to mixtures of $k$ distributions satisfying a Poincar\u00e9 inequality, with faster convergence when they satisfy a log-Sobolev inequality. Our bounds are stable to perturbations to the Markov chain, and in particular work for Langevin diffusion over $\\mathbb R^d$ with score estimation error, as well as Glauber dynamics combined with approximation error from pseudolikelihood estimation. This justifies the success of data-based initialization for score matching methods despite slow mixing for the data distribution, and improves and generalizes the results of Koehler and Vuong (2023) to have linear, rather than exponential, dependence on $k$ and apply to arbitrary semigroups. As a consequence of our results, we show for the first time that a natural class of low-complexity Ising measures can be efficiently learned from samples.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "math.PR",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09158",
        "abstract url": "https://arxiv.org/abs/2411.09158",
        "title": "The \\emph{Optimist}: Towards Fully Automated Graph Theory Research",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces the \\emph{Optimist}, an autonomous system developed to advance automated conjecture generation in graph theory. Leveraging mixed-integer programming (MIP) and heuristic methods, the \\emph{Optimist} generates conjectures that both rediscover established theorems and propose novel inequalities. Through a combination of memory-based computation and agent-like adaptability, the \\emph{Optimist} iteratively refines its conjectures by integrating new data, enabling a feedback process with minimal human (\\emph{or machine}) intervention. Initial experiments reveal the \\emph{Optimist}'s potential to uncover foundational results in graph theory, as well as to produce conjectures of interest for future exploration. This work also outlines the \\emph{Optimist}'s evolving integration with a counterpart agent, the \\emph{Pessimist} (a human \\emph{or machine} agent), to establish a dueling system that will drive fully automated graph theory research.",
        "subjects": [
            "cs.AI",
            "math.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10481",
        "abstract url": "https://arxiv.org/abs/2411.10481",
        "title": "Boolean-aware Boolean Circuit Classification: A Comprehensive Study on Graph Neural Network",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Boolean circuit is a computational graph that consists of the dynamic directed graph structure and static functionality. The commonly used logic optimization and Boolean matching-based transformation can change the behavior of the Boolean circuit for its graph structure and functionality in logic synthesis. The graph structure-based Boolean circuit classification can be grouped into the graph classification task, however, the functionality-based Boolean circuit classification remains an open problem for further research. In this paper, we first define the proposed matching-equivalent class based on its ``Boolean-aware'' property. The Boolean circuits in the proposed class can be transformed into each other. Then, we present a commonly study framework based on graph neural network~(GNN) to analyze the key factors that can affect the Boolean-aware Boolean circuit classification. The empirical experiment results verify the proposed analysis, and it also shows the direction and opportunity to improve the proposed problem. The code and dataset will be released after acceptance.",
        "subjects": [
            "cs.LG",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08344",
        "abstract url": "https://arxiv.org/abs/2411.08344",
        "title": "Bangla Grammatical Error Detection Leveraging Transformer-based Token Classification",
        "rating": "-1",
        "keywords": [
            [
                "grammar",
                "Grammatical"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Bangla is the seventh most spoken language by a total number of speakers in the world, and yet the development of an automated grammar checker in this language is an understudied problem. Bangla grammatical error detection is a task of detecting sub-strings of a Bangla text that contain grammatical, punctuation, or spelling errors, which is crucial for developing an automated Bangla typing assistant. Our approach involves breaking down the task as a token classification problem and utilizing state-of-the-art transformer-based models. Finally, we combine the output of these models and apply rule-based post-processing to generate a more reliable and comprehensive result. Our system is evaluated on a dataset consisting of over 25,000 texts from various sources. Our best model achieves a Levenshtein distance score of 1.04. Finally, we provide a detailed analysis of different components of our system.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08347",
        "abstract url": "https://arxiv.org/abs/2411.08347",
        "title": "A Chinese Multi-label Affective Computing Dataset Based on Social Media Network Users",
        "rating": "-1",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.AI",
                "cs.CY",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Emotion and personality are central elements in understanding human psychological states. Emotions reflect an individual subjective experiences, while personality reveals relatively stable behavioral and cognitive patterns. Existing affective computing datasets often annotate emotion and personality traits separately, lacking fine-grained labeling of micro-emotions and emotion intensity in both single-label and multi-label classifications. Chinese emotion datasets are extremely scarce, and datasets capturing Chinese user personality traits are even more limited. To address these gaps, this study collected data from the major social media platform Weibo, screening 11,338 valid users from over 50,000 individuals with diverse MBTI personality labels and acquiring 566,900 posts along with the user MBTI personality tags. Using the EQN method, we compiled a multi-label Chinese affective computing dataset that integrates the same user's personality traits with six emotions and micro-emotions, each annotated with intensity levels. Validation results across multiple NLP classification models demonstrate the dataset strong utility. This dataset is designed to advance machine recognition of complex human emotions and provide data support for research in psychology, education, marketing, finance, and politics.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08371",
        "abstract url": "https://arxiv.org/abs/2411.08371",
        "title": "Multiscale Graph Construction Using Non-local Cluster Features",
        "rating": "-1",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "Graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a multiscale graph construction method using both graph and signal features. Multiscale graph is a hierarchical representation of the graph, where a node at each level indicates a cluster in a finer resolution. To obtain the hierarchical clusters, existing methods often use graph clustering; however, they may ignore signal variations. As a result, these methods could fail to detect the clusters having similar features on nodes. In this paper, we consider graph and node-wise features simultaneously for multiscale clustering of a graph. With given clusters of the graph, the clusters are merged hierarchically in three steps: 1) Feature vectors in the clusters are extracted. 2) Similarities among cluster features are calculated using optimal transport. 3) A variable $k$-nearest neighbor graph (V$k$NNG) is constructed and graph spectral clustering is applied to the V$k$NNG to obtain clusters at a coarser scale. Additionally, the multiscale graph in this paper has \\textit{non-local} characteristics: Nodes with similar features are merged even if they are spatially separated. In experiments on multiscale image and point cloud segmentation, we demonstrate the effectiveness of the proposed method.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08389",
        "abstract url": "https://arxiv.org/abs/2411.08389",
        "title": "Integrative Wrapping System for a Dual-Arm Humanoid Robot",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Flexible object manipulation of paper and cloth is a major research challenge in robot manipulation. Although there have been efforts to develop hardware that enables specific actions and to realize a single action of paper folding using sim-to-real and learning, there have been few proposals for humanoid robots and systems that enable continuous, multi-step actions of flexible materials. Wrapping an object with paper and tape is more complex and diverse than traditional manipulation research due to the increased number of objects that need to be handled, as well as the three-dimensionality of the operation. In this research, necessary information is organized and coded based on the characteristics of each object handled in wrapping. We also generalize the hardware configuration, manipulation method, and recognition system that enable humanoid wrapping operations. The system will include manipulation with admittance control focusing on paper tension and state evaluation using point clouds to handle three-dimensional flexible objects. Finally, wrapping objects with different shapes is experimented with to show the generality and effectiveness of the proposed system.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted Humanoids2024"
    },
    {
        "paper id": "2411.08411",
        "abstract url": "https://arxiv.org/abs/2411.08411",
        "title": "Modeling and Optimization for Rotatable Antenna Enabled Wireless Communication",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Fluid antenna system (FAS)/movable antenna (MA) has emerged as a promising technology to fully exploit the spatial degrees of freedom (DoFs). In this paper, we propose a new rotatable antenna (RA) model, as a simplified implementation of six-dimensional movable antenna (6DMA), to improve the performance of wireless communication systems. Different from conventional fixed-position antenna (FPA), the proposed RA system can independently and flexibly change the three-dimensional (3D) orientation of each antenna by adjusting its declination angles to achieve desired channel realizations. Specifically, we study an RA-enabled uplink communication system, where the receive beamforming and the declination angles of all RAs are jointly optimized to maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the users. In the special single-user and free-space propagation setup, the optimal declination angles are derived in closed form with the maximum-ratio combining (MRC) beamformer applied at the base station (BS). In the general multi-user and multi-path setup, we propose an alternating optimization (AO) algorithm to alternately optimize the receive beamforming and the declination angles in an iterative manner. Simulation results are provided to demonstrate that the proposed RA-enabled system can significantly outperform other benchmark schemes.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2411.08436",
        "abstract url": "https://arxiv.org/abs/2411.08436",
        "title": "Robust performance for switched systems with constrained switching and its application to weakly hard real-time control systems",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Many cyber-physical systems can naturally be formulated as switched systems with constrained switching. This includes systems where one of the signals in the feedback loop may be lost. Possible sources for losses are shared or unreliable communication media in networked control systems, or signals which are discarded, e.g., when using a shared computation device such as a processor in real-time control applications. The use of switched systems with constrained switching is not limited to cyber-physical systems but, includes many other relevant applications such as power systems and modeling virus mutations. In this chapter, we introduce a framework for analyzing and designing controllers which guarantee robust quadratic performance for switched systems with constrained switching. The possible switching sequences are described by the language of a labeled graph where the labels are linked to the different subsystems. The subsystems are allowed to have different input and output dimensions, and their state-space representations can be affected by a broad class of uncertainties in a rational way. The proposed framework exploits ideas from dissipativity-based linear control theory to derive analysis and synthesis inequalities given by linear matrix inequalities. We demonstrate how the proposed framework can be applied to the design of controllers for uncertain weakly hard real-time control systems - a system class naturally appearing in networked and real-time control.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08482",
        "abstract url": "https://arxiv.org/abs/2411.08482",
        "title": "Methodology for a Statistical Analysis of Influencing Factors on 3D Object Detection Performance",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In autonomous driving, object detection is an essential task to perceive the environment by localizing and classifying objects. Most object detection algorithms rely on deep learning for their superior performance. However, their black box nature makes it challenging to ensure safety. In this paper, we propose a first-of-its-kind methodology for statistical analysis of the influence of various factors related to the objects to detect or the environment on the detection performance of both LiDAR- and camera-based 3D object detectors. We perform a univariate analysis between each of the factors and the detection error in order to compare the strength of influence. To better identify potential sources of detection errors, we also analyze the performance in dependency of the influencing factors and examine the interdependencies between the different influencing factors. Recognizing the factors that influence detection performance helps identify robustness issues in the trained object detector and supports the safety approval of object detection systems.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08488",
        "abstract url": "https://arxiv.org/abs/2411.08488",
        "title": "UNSCT-HRNet: Modeling Anatomical Uncertainty for Landmark Detection in Total Hip Arthroplasty",
        "rating": "-1",
        "keywords": [
            [
                "surgical",
                "CT"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Total hip arthroplasty (THA) relies on accurate landmark detection from radiographic images, but unstructured data caused by irregular patient postures or occluded anatomical markers pose significant challenges for existing methods. To address this, we propose UNSCT-HRNet (Unstructured CT - High-Resolution Net), a deep learning-based framework that integrates a Spatial Relationship Fusion (SRF) module and an Uncertainty Estimation (UE) module. The SRF module, utilizing coordinate convolution and polarized attention, enhances the model's ability to capture complex spatial relationships. Meanwhile, the UE module which based on entropy ensures predictions are anatomically relevant. For unstructured data, the proposed method can predict landmarks without relying on the fixed number of points, which shows higher accuracy and better robustness comparing with the existing methods. Our UNSCT-HRNet demonstrates over a 60% improvement across multiple metrics in unstructured data. The experimental results also reveal that our approach maintains good performance on the structured dataset. Overall, the proposed UNSCT-HRNet has the potential to be used as a new reliable, automated solution for THA surgical planning and postoperative monitoring.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08490",
        "abstract url": "https://arxiv.org/abs/2411.08490",
        "title": "Impact of Iris Pigmentation on Performance Bias in Visible Iris Verification Systems: A Comparative Study",
        "rating": "-1",
        "keywords": [
            [
                "biometric"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Iris recognition technology plays a critical role in biometric identification systems, but their performance can be affected by variations in iris pigmentation. In this work, we investigate the impact of iris pigmentation on the efficacy of biometric recognition systems, focusing on a comparative analysis of blue and dark irises. Data sets were collected using multiple devices, including P1, P2, and P3 smartphones [4], to assess the robustness of the systems in different capture environments [19]. Both traditional machine learning techniques and deep learning models were used, namely Open-Iris, ViT-b, and ResNet50, to evaluate performance metrics such as Equal Error Rate (EER) and True Match Rate (TMR). Our results indicate that iris recognition systems generally exhibit higher accuracy for blue irises compared to dark irises. Furthermore, we examined the generalization capabilities of these systems across different iris colors and devices, finding that while training on diverse datasets enhances recognition performance, the degree of improvement is contingent on the specific model and device used. Our analysis also identifies inherent biases in recognition performance related to iris color and cross-device variability. These findings underscore the need for more inclusive dataset collection and model refinement to reduce bias and promote equitable biometric recognition across varying iris pigmentation and device configurations.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 5 figures, 5 Tables"
    },
    {
        "paper id": "2411.08516",
        "abstract url": "https://arxiv.org/abs/2411.08516",
        "title": "Tree-of-Table: Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding",
        "rating": "-1",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The ubiquity and value of tables as semi-structured data across various domains necessitate advanced methods for understanding their complexity and vast amounts of information. Despite the impressive capabilities of large language models (LLMs) in advancing the natural language understanding frontier, their application to large-scale tabular data presents significant challenges, specifically regarding table size and complex intricate relationships. Existing works have shown promise with small-scale tables but often flounder when tasked with the complex reasoning required by larger, interconnected tables found in real-world scenarios. To address this gap, we introduce \"Tree-of-Table\", a novel approach designed to enhance LLMs' reasoning capabilities over large and complex tables. Our method employs Table Condensation and Decomposition to distill and reorganize relevant data into a manageable format, followed by the construction of a hierarchical Table-Tree that facilitates tree-structured reasoning. Through a meticulous Table-Tree Execution process, we systematically unravel the tree-structured reasoning chain to derive the solutions. Experiments across diverse datasets, including WikiTQ, TableFact, FeTaQA, and BIRD, demonstrate that Tree-of-Table sets a new benchmark with superior performance, showcasing remarkable efficiency and generalization capabilities in large-scale table reasoning.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08520",
        "abstract url": "https://arxiv.org/abs/2411.08520",
        "title": "On the Design of Variable Modulation and Adaptive Modulation for Uplink Sparse Code Multiple Access",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Sparse code multiple access (SCMA) is a promising non-orthogonal multiple access scheme for enabling massive connectivity in next generation wireless networks. However, current SCMA codebooks are designed with the same size, leading to inflexibility of user grouping and supporting diverse data rates. To address this issue, we propose a variable modulation SCMA (VM-SCMA) that allows users to employ codebooks with different modulation orders. To guide the VM-SCMA design, a VM matrix (VMM) that assigns modulation orders based on the SCMA factor graph is first introduced. We formulate the VM-SCMA design using the proposed average inverse product distance and the asymptotic upper bound of sum-rate, and jointly optimize the VMM, VM codebooks, power and codebook allocations. The proposed VM-SCMA not only enables diverse date rates but also supports different modulation order combinations for each rate. Leveraging these distinct advantages, we further propose an adaptive VM-SCMA (AVM-SCMA) scheme which adaptively selects the rate and the corresponding VM codebooks to adapt to the users' channel conditions by maximizing the proposed effective throughput. Simulation results show that the overall designs are able to simultaneously achieve a high-level system flexibility, enhanced error rate results, and significantly improved throughput performance, when compared to conventional SCMA schemes.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08530",
        "abstract url": "https://arxiv.org/abs/2411.08530",
        "title": "Efficient Whole Slide Image Classification through Fisher Vector Representation",
        "rating": "-1",
        "keywords": [
            [
                "Whole Slide",
                "pathological"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The advancement of digital pathology, particularly through computational analysis of whole slide images (WSI), is poised to significantly enhance diagnostic precision and efficiency. However, the large size and complexity of WSIs make it difficult to analyze and classify them using computers. This study introduces a novel method for WSI classification by automating the identification and examination of the most informative patches, thus eliminating the need to process the entire slide. Our method involves two-stages: firstly, it extracts only a few patches from the WSIs based on their pathological significance; and secondly, it employs Fisher vectors (FVs) for representing features extracted from these patches, which is known for its robustness in capturing fine-grained details. This approach not only accentuates key pathological features within the WSI representation but also significantly reduces computational overhead, thus making the process more efficient and scalable. We have rigorously evaluated the proposed method across multiple datasets to benchmark its performance against comprehensive WSI analysis and contemporary weakly-supervised learning methodologies. The empirical results indicate that our focused analysis of select patches, combined with Fisher vector representation, not only aligns with, but at times surpasses, the classification accuracy of standard practices. Moreover, this strategy notably diminishes computational load and resource expenditure, thereby establishing an efficient and precise framework for WSI analysis in the realm of digital pathology.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08531",
        "abstract url": "https://arxiv.org/abs/2411.08531",
        "title": "Classification and Morphological Analysis of DLBCL Subtypes in H\\&E-Stained Slides",
        "rating": "-1",
        "keywords": [
            [
                "biological",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We address the challenge of automated classification of diffuse large B-cell lymphoma (DLBCL) into its two primary subtypes: activated B-cell-like (ABC) and germinal center B-cell-like (GCB). Accurate classification between these subtypes is essential for determining the appropriate therapeutic strategy, given their distinct molecular profiles and treatment responses. Our proposed deep learning model demonstrates robust performance, achieving an average area under the curve (AUC) of (87.4 pm 5.7)\\% during cross-validation. It shows a high positive predictive value (PPV), highlighting its potential for clinical application, such as triaging for molecular testing. To gain biological insights, we performed an analysis of morphological features of ABC and GCB subtypes. We segmented cell nuclei using a pre-trained deep neural network and compared the statistics of geometric and color features for ABC and GCB. We found that the distributions of these features were not very different for the two subtypes, which suggests that the visual differences between them are more subtle. These results underscore the potential of our method to assist in more precise subtype classification and can contribute to improved treatment management and outcomes for patients of DLBCL.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08537",
        "abstract url": "https://arxiv.org/abs/2411.08537",
        "title": "MLV$^2$-Net: Rater-Based Majority-Label Voting for Consistent Meningeal Lymphatic Vessel Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "MRI",
                "disease"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Meningeal lymphatic vessels (MLVs) are responsible for the drainage of waste products from the human brain. An impairment in their functionality has been associated with aging as well as brain disorders like multiple sclerosis and Alzheimer's disease. However, MLVs have only recently been described for the first time in magnetic resonance imaging (MRI), and their ramified structure renders manual segmentation particularly difficult. Further, as there is no consistent notion of their appearance, human-annotated MLV structures contain a high inter-rater variability that most automatic segmentation methods cannot take into account. In this work, we propose a new rater-aware training scheme for the popular nnU-Net model, and we explore rater-based ensembling strategies for accurate and consistent segmentation of MLVs. This enables us to boost nnU-Net's performance while obtaining explicit predictions in different annotation styles and a rater-based uncertainty estimation. Our final model, MLV$^2$-Net, achieves a Dice similarity coefficient of 0.806 with respect to the human reference standard. The model further matches the human inter-rater reliability and replicates age-related associations with MLV volume.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "ML4H 2024"
    },
    {
        "paper id": "2411.08588",
        "abstract url": "https://arxiv.org/abs/2411.08588",
        "title": "I Can Embrace and Avoid Vagueness Myself: Supporting the Design Process by Balancing Vagueness through Text-to-Image Generative AI",
        "rating": "-1",
        "keywords": [
            [
                "Text-to-Image"
            ]
        ],
        "abstract": "This study examines the role of vagueness in the design process and its strategic management for the effective human-AI interaction. While vagueness in the generation of design ideas promotes diverse interpretations and prevents fixation, excessive vagueness can lead to scattered results. Designers attempt to use image search tools or generative AIs (e.g., Dall-E) for their work but often fail to achieve satisfactory results because the level of vagueness is not properly managed in these technologies. In this work, we identified how designers coordinate vagueness in their design process and applied key components of the process to the design of CLAY, an interactive system that balances vagueness through iterative prompt refinement by integrating the strengths of text-to-image generative AI. Results from our user study with 10 fashion designers showed that CLAY effectively supported their design process, reducing design time, and expanding creative possibilities compared to their existing practice, by allowing them to both embrace and avoid vagueness as needed. Our study highlights the importance of identifying key characteristics of the target user and domain, and exploring ways to incorporate them into the design of an AI-based interactive tool.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "18 pages, 13 figures, 3 tables"
    },
    {
        "paper id": "2411.08618",
        "abstract url": "https://arxiv.org/abs/2411.08618",
        "title": "Robust Optimal Power Flow Against Adversarial Attacks: A Tri-Level Optimization Approach",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "In power systems, unpredictable events like extreme weather, equipment failures, and cyberattacks present significant challenges to ensuring safety and reliability. Ensuring resilience in the face of these uncertainties is crucial for reliable and efficient operations. This paper presents a tri-level optimization approach for robust power system operations that effectively address worst-case attacks. The first stage focuses on optimizing economic dispatch under normal operating conditions, aiming to minimize generation costs while maintaining the supply-demand balance. The second stage introduces an adversarial attack model, identifying worst-case scenarios that maximize the system's vulnerability by targeting distributed generation (DG). In the third stage, mitigation strategies are developed using fast-response energy storage systems (ESS) to minimize disruptions caused by these attacks. By integrating economic dispatch, vulnerability assessment, and mitigation into a unified framework, this approach provides a robust solution for enhancing power system resilience and safety against evolving adversarial threats. The approach is validated using the IEEE-33 node distribution system to demonstrate its effectiveness in achieving both cost efficiency and system resilience.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "This work has been submitted for possible publication"
    },
    {
        "paper id": "2411.08629",
        "abstract url": "https://arxiv.org/abs/2411.08629",
        "title": "Zero-shot capability of SAM-family models for bone segmentation in CT scans",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "CT",
                "clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The Segment Anything Model (SAM) and similar models build a family of promptable foundation models (FMs) for image and video segmentation. The object of interest is identified using prompts, such as bounding boxes or points. With these FMs becoming part of medical image segmentation, extensive evaluation studies are required to assess their strengths and weaknesses in clinical setting. Since the performance is highly dependent on the chosen prompting strategy, it is important to investigate different prompting techniques to define optimal guidelines that ensure effective use in medical image segmentation. Currently, no dedicated evaluation studies exist specifically for bone segmentation in CT scans, leaving a gap in understanding the performance for this task. Thus, we use non-iterative, ``optimal'' prompting strategies composed of bounding box, points and combinations to test the zero-shot capability of SAM-family models for bone CT segmentation on three different skeletal regions. Our results show that the best settings depend on the model type and size, dataset characteristics and objective to optimize. Overall, SAM and SAM2 prompted with a bounding box in combination with the center point for all the components of an object yield the best results across all tested settings. As the results depend on multiple factors, we provide a guideline for informed decision-making in 2D prompting with non-interactive, ''optimal'' prompts.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08642",
        "abstract url": "https://arxiv.org/abs/2411.08642",
        "title": "Towards More Accurate Fake Detection on Images Generated from Advanced Generative and Neural Rendering Models",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian splatting",
                "Radiance Fields"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "The remarkable progress in neural-network-driven visual data generation, especially with neural rendering techniques like Neural Radiance Fields and 3D Gaussian splatting, offers a powerful alternative to GANs and diffusion models. These methods can produce high-fidelity images and lifelike avatars, highlighting the need for robust detection methods. In response, an unsupervised training technique is proposed that enables the model to extract comprehensive features from the Fourier spectrum magnitude, thereby overcoming the challenges of reconstructing the spectrum due to its centrosymmetric properties. By leveraging the spectral domain and dynamically combining it with spatial domain information, we create a robust multimodal detector that demonstrates superior generalization capabilities in identifying challenging synthetic images generated by the latest image synthesis techniques. To address the absence of a 3D neural rendering-based fake image database, we develop a comprehensive database that includes images generated by diverse neural rendering techniques, providing a robust foundation for evaluating and advancing detection methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "13 pages, 8 Figures"
    },
    {
        "paper id": "2411.08661",
        "abstract url": "https://arxiv.org/abs/2411.08661",
        "title": "Energy Optimal Traversal Between Hover Waypoints for Lift+Cruise Electric Powered Aircraft",
        "rating": "-1",
        "keywords": [
            [
                "trajectory",
                "flight"
            ]
        ],
        "abstract": "Advanced Air Mobility aircraft require energy efficient flight plans to be economically viable. This paper defines minimum energy direct trajectories between waypoints for Lift+Cruise electric Vertical Take-Off and Landing (eVTOL) aircraft. Energy consumption is optimized over accelerated and cruise flight profiles with consideration of mode transitions. Because eVTOL operations start and end in hover for vertical take-off and landing, hover waypoints are utilized. Energy consumption is modeled as a function of airspeed for each flight mode, providing the basis to prove energy optimality for multi-mode traversal. Wind magnitude and direction dictate feasibility of straight-line traversal because Lift+Cruise aircraft point into the relative wind direction while hovering but also have a maximum heading rate constraint. Energy and power use for an experimentally validated QuadPlane small eVTOL aircraft are characterized with respect to airspeed and acceleration in all flight modes. Optimal QuadPlane traversals are presented. Constraints on acceleration and wind are derived for straight-line QuadPlane traversal. Results show an optimal QuadPlane $500m$ traversal between hover waypoints saves $71\\%$ energy compared to pure vertical flight traversal for a representative case study with a direct $4m/s$ crosswind. Energy optimal eVTOL direct trajectory definition with transitions to and from hover is novel to this work. Future work should model three-dimensional flight and wind as well as optimize maneuver primitives when required.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "34 pages, 17 figures and 5 tables"
    },
    {
        "paper id": "2411.08671",
        "abstract url": "https://arxiv.org/abs/2411.08671",
        "title": "Theoretical Analysis of Byte-Pair Encoding",
        "rating": "-1",
        "keywords": [
            [
                "grammar"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Byte-Pair Encoding (BPE) is a widely used method for subword tokenization, with origins in grammar-based text compression. It is employed in a variety of language processing tasks such as machine translation or large language model (LLM) pretraining, to create a token dictionary of a prescribed size. Most evaluations of BPE to date are empirical, and the reasons for its good practical performance are not well understood. In this paper we focus on the optimization problem underlying BPE: finding a pair encoding that achieves optimal compression utility. We show that this problem is APX-complete, indicating that it is unlikely to admit a polynomial-time approximation scheme. This answers, in a stronger form, a question recently raised by Zouhar et al. On the positive side, we show that BPE approximates the compression utility of the optimal pair encoding to a worst-case factor between $0.333$ and $0.625$. Our results aim to explain the ongoing success of BPE and are, to our knowledge, the first rigorous guarantees on its compression utility that hold for all inputs.",
        "subjects": [
            "cs.DS",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08685",
        "abstract url": "https://arxiv.org/abs/2411.08685",
        "title": "Long induced paths in sparse graphs and graphs with forbidden patterns",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "Consider a graph $G$ with a path $P$ of order $n$. What conditions force $G$ to also have a long induced path? As complete bipartite graphs have long paths but no long induced paths, a natural restriction is to forbid some fixed complete bipartite graph $K_{t,t}$ as a subgraph. In this case we show that $G$ has an induced path of order $(\\log \\log n)^{1/5-o(1)}$. This is an exponential improvement over a result of Galvin, Rival, and Sands (1982) and comes close to a recent upper bound of order $O((\\log \\log n)^2)$. Another way to approach this problem is by viewing $G$ as an ordered graph (where the vertices are ordered according to their position on the path $P$). From this point of view it is most natural to consider which ordered subgraphs need to be forbidden in order to force the existence of a long induced path. Focusing on the exclusion of ordered matchings, we improve or recover a number of existing results with much simpler proofs, in a unified way. We also show that if some forbidden ordered subgraph forces the existence of a long induced path in $G$, then this induced path has size at least $\u03a9((\\log \\log \\log n)^{1/3})$, and can be chosen to be increasing with respect to $P$.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "26 pages, 8 figures. Comments welcome !"
    },
    {
        "paper id": "2411.08701",
        "abstract url": "https://arxiv.org/abs/2411.08701",
        "title": "TRACE: Transformer-based Risk Assessment for Clinical Evaluation",
        "rating": "-1",
        "keywords": [
            [
                "Clinical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation), a novel method for clinical risk assessment based on clinical data, leveraging the self-attention mechanism for enhanced feature interaction and result interpretation. Our approach is able to handle different data modalities, including continuous, categorical and multiple-choice (checkbox) attributes. The proposed architecture features a shared representation of the clinical data obtained by integrating specialized embeddings of each data modality, enabling the detection of high-risk individuals using Transformer encoder layers. To assess the effectiveness of the proposed method, a strong baseline based on non-negative multi-layer perceptrons (MLPs) is introduced. The proposed method outperforms various baselines widely used in the domain of clinical risk assessment, while effectively handling missing values. In terms of explainability, our Transformer-based method offers easily interpretable results via attention weights, further enhancing the clinicians' decision-making process.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08755",
        "abstract url": "https://arxiv.org/abs/2411.08755",
        "title": "Weakly-Supervised Anomaly Detection in Surveillance Videos Based on Two-Stream I3D Convolution Network",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The widespread implementation of urban surveillance systems has necessitated more sophisticated techniques for anomaly detection to ensure enhanced public safety. This paper presents a significant advancement in the field of anomaly detection through the application of Two-Stream Inflated 3D (I3D) Convolutional Networks. These networks substantially outperform traditional 3D Convolutional Networks (C3D) by more effectively extracting spatial and temporal features from surveillance videos, thus improving the precision of anomaly detection. Our research advances the field by implementing a weakly supervised learning framework based on Multiple Instance Learning (MIL), which uniquely conceptualizes surveillance videos as collections of 'bags' that contain instances (video clips). Each instance is innovatively processed through a ranking mechanism that prioritizes clips based on their potential to display anomalies. This novel strategy not only enhances the accuracy and precision of anomaly detection but also significantly diminishes the dependency on extensive manual annotations. Moreover, through meticulous optimization of model settings, including the choice of optimizer, our approach not only establishes new benchmarks in the performance of anomaly detection systems but also offers a scalable and efficient solution for real-world surveillance applications. This paper contributes significantly to the field of computer vision by delivering a more adaptable, efficient, and context-aware anomaly detection system, which is poised to redefine practices in urban surveillance.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "11 pages, 8 figures"
    },
    {
        "paper id": "2411.08761",
        "abstract url": "https://arxiv.org/abs/2411.08761",
        "title": "AI-Enhanced Inverter Fault and Anomaly Detection System for Distributed Energy Resources in Microgrids",
        "rating": "-1",
        "keywords": [
            [
                "Anomaly Detection"
            ]
        ],
        "abstract": "The integration of Distributed Energy Resources (DERs) into power distribution systems has made microgrids foundational to grid modernization. These DERs, connected through power electronic inverters, create power electronics dominated grid architecture, introducing unique challenges for fault detection. While external line faults are widely studied, inverter faults remain a critical yet underexplored issue. This paper proposes various data mining techniques for the effective detection and localization of inverter faults-essential for preventing catastrophic grid failures. Furthermore, the difficulty of differentiating between system anomalies and internal inverter faults within Power Electronics-Driven Grids (PEDGs) is addressed. To enhance grid resilience, this work applies advanced artificial intelligence methods to distinguish anomalies from true internal faults, identifying the specific malfunctioning switch. The proposed FaultNet-ML methodology is validated on a 9-bus system dominated by inverters, illustrating its robustness in a PEDG environment.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "5 pages, 2 figures, submitted to 2025 IEEE Power and Energy Society General Meeting (PESGM 2025), Austin, TX"
    },
    {
        "paper id": "2411.08805",
        "abstract url": "https://arxiv.org/abs/2411.08805",
        "title": "Stochastic Matching via In-n-Out Local Computation Algorithms",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "Consider the following stochastic matching problem. Given a graph $G=(V, E)$, an unknown subgraph $G_p = (V, E_p)$ is realized where $E_p$ includes every edge of $E$ independently with some probability $p \\in (0, 1]$. The goal is to query a sparse subgraph $H$ of $G$, such that the realized edges in $H$ include an approximate maximum matching of $G_p$. This problem has been studied extensively over the last decade due to its numerous applications in kidney exchange, online dating, and online labor markets. For any fixed $\u03b5> 0$, [BDH STOC'20] showed that any graph $G$ has a subgraph $H$ with $\\text{quasipoly}(1/p) = (1/p)^{\\text{poly}(\\log(1/p))}$ maximum degree, achieving a $(1-\u03b5)$-approximation. A major open question is the best approximation achievable with $\\text{poly}(1/p)$-degree subgraphs. A long line of work has progressively improved the approximation in the $\\text{poly}(1/p)$-degree regime from .5 [BDH+ EC'15] to .501 [AKL EC'17], .656 [BHFR SODA'19], .666 [AB SOSA'19], .731 [BBD SODA'22] (bipartite graphs), and most recently to .68 [DS '24]. In this work, we show that a $\\text{poly}(1/p)$-degree subgraph can obtain a $(1-\u03b5)$-approximation for any desirably small fixed $\u03b5> 0$, achieving the best of both worlds. Beyond its quantitative improvement, a key conceptual contribution of our work is to connect local computation algorithms (LCAs) to the stochastic matching problem for the first time. While prior work on LCAs mainly focuses on their out-queries (the number of vertices probed to produce the output of a given vertex), our analysis also bounds the in-queries (the number of vertices that probe a given vertex). We prove that the outputs of LCAs with bounded in- and out-queries (in-n-out LCAs for short) have limited correlation, a property that our analysis crucially relies on and might find applications beyond stochastic matchings.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08835",
        "abstract url": "https://arxiv.org/abs/2411.08835",
        "title": "Goal-oriented Semantic Communication for Robot Arm Reconstruction in Digital Twin: Feature and Temporal Selections",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "As one of the most promising technologies in industry, the Digital Twin (DT) facilitates real-time monitoring and predictive analysis for real-world systems by precisely reconstructing virtual replicas of physical entities. However, this reconstruction faces unprecedented challenges due to the everincreasing communication overhead, especially for digital robot arm reconstruction. To this end, we propose a novel goal-oriented semantic communication (GSC) framework to extract the GSC information for the robot arm reconstruction task in the DT, with the aim of minimising the communication load under the strict and relaxed reconstruction error constraints. Unlike the traditional reconstruction framework that periodically transmits a reconstruction message for real-time DT reconstruction, our framework implements a feature selection (FS) algorithm to extract the semantic information from the reconstruction message, and a deep reinforcement learning-based temporal selection algorithm to selectively transmit the semantic information over time. We validate our proposed GSC framework through both Pybullet simulations and lab experiments based on the Franka Research 3 robot arm. For a range of distinct robotic tasks, simulation results show that our framework can reduce the communication load by at least 59.5% under strict reconstruction error constraints and 80% under relaxed reconstruction error constraints, compared with traditional communication framework. Also, experimental results confirm the effectiveness of our framework, where the communication load is reduced by 53% in strict constraint case and 74% in relaxed constraint case. The demo is available at: https://youtu.be/2OdeHKxcgnk.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": "Submitted to IEEE for potential publication"
    },
    {
        "paper id": "2411.08839",
        "abstract url": "https://arxiv.org/abs/2411.08839",
        "title": "Sparser Abelian High Dimensional Expanders",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We present two new explicit constructions of Cayley high dimensional expanders (HDXs) over the abelian group $\\mathbb{F}_2^n$. Our expansion proofs use only linear algebra and combinatorial arguments. The first construction gives local spectral HDXs of any constant dimension and subpolynomial degree $\\exp(n^\u03b5)$ for every $\u03b5>0$, improving on a construction by Golowich [Gol23] which achieves $\u03b5=1/2$. [Gol23] derives these HDXs by sparsifying the complete Grassmann poset of subspaces. The novelty in our construction is the ability to sparsify any expanding Grassmannian posets, leading to iterated sparsification and much smaller degrees. The sparse Grassmannian (which is of independent interest in the theory of HDXs) serves as the generating set of the Cayley graph. Our second construction gives a 2-dimensional HDXs of any polynomial degree $\\exp(\u03b5n$) for any constant $\u03b5> 0$, which is simultaneously a spectral expander and a coboundary expander. To the best of our knowledge, this is the first such non-trivial construction. We name it the Johnson complex, as it is derived from the classical Johnson scheme, whose vertices serve as the generating set of this Cayley graph. This construction may be viewed as a derandomization of the recent random geometric complexes of [LMSY23]. Establishing coboundary expansion through Gromov's \"cone method\" and the associated isoperimetric inequalities is the most intricate aspect of this construction. While these two constructions are quite different, we show that they both share a common structure, resembling the intersection patterns of vectors in the Hadamard code. We propose a general framework of such \"Hadamard-like\" constructions in the hope that it will yield new HDXs.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08851",
        "abstract url": "https://arxiv.org/abs/2411.08851",
        "title": "Experience-based Subproblem Planning for Multi-Robot Motion Planning",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Multi-robot systems enhance efficiency and productivity across various applications, from manufacturing to surveillance. While single-robot motion planning has improved by using databases of prior solutions, extending this approach to multi-robot motion planning (MRMP) presents challenges due to the increased complexity and diversity of tasks and configurations. Recent discrete methods have attempted to address this by focusing on relevant lower-dimensional subproblems, but they are inadequate for complex scenarios like those involving manipulator robots. To overcome this, we propose a novel approach that %leverages experience-based planning by constructs and utilizes databases of solutions for smaller sub-problems. By focusing on interactions between fewer robots, our method reduces the need for exhaustive database growth, allowing for efficient handling of more complex MRMP scenarios. We validate our approach with experiments involving both mobile and manipulator robots, demonstrating significant improvements over existing methods in scalability and planning efficiency. Our contributions include a rapidly constructed database for low-dimensional MRMP problems, a framework for applying these solutions to larger problems, and experimental validation with up to 32 mobile and 16 manipulator robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08868",
        "abstract url": "https://arxiv.org/abs/2411.08868",
        "title": "CamemBERT 2.0: A Smarter French Language Model Aged to Perfection",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "French language models, such as CamemBERT, have been widely adopted across industries for natural language processing (NLP) tasks, with models like CamemBERT seeing over 4 million downloads per month. However, these models face challenges due to temporal concept drift, where outdated training data leads to a decline in performance, especially when encountering new topics and terminology. This issue emphasizes the need for updated models that reflect current linguistic trends. In this paper, we introduce two new versions of the CamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these challenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use of the Replaced Token Detection (RTD) objective for better contextual understanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked Language Modeling (MLM) objective. Both models are trained on a significantly larger and more recent dataset with longer context length and an updated tokenizer that enhances tokenization performance for French. We evaluate the performance of these models on both general-domain NLP tasks and domain-specific applications, such as medical field tasks, demonstrating their versatility and effectiveness across a range of use cases. Our results show that these updated models vastly outperform their predecessors, making them valuable tools for modern NLP systems. All our new models, as well as intermediate checkpoints, are made openly available on Huggingface.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08934",
        "abstract url": "https://arxiv.org/abs/2411.08934",
        "title": "Predicting household socioeconomic position in Mozambique using satellite and household imagery",
        "rating": "-1",
        "keywords": [
            [
                "satellite"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Many studies have predicted SocioEconomic Position (SEP) for aggregated spatial units such as villages using satellite data, but SEP prediction at the household level and other sources of imagery have not been yet explored. We assembled a dataset of 975 households in a semi-rural district in southern Mozambique, consisting of self-reported asset, expenditure, and income SEP data, as well as multimodal imagery including satellite images and a ground-based photograph survey of 11 household elements. We fine-tuned a convolutional neural network to extract feature vectors from the images, which we then used in regression analyzes to model household SEP using different sets of image types. The best prediction performance was found when modeling asset-based SEP using random forest models with all image types, while the performance for expenditure- and income-based SEP was lower. Using SHAP, we observed clear differences between the images with the largest positive and negative effects, as well as identified the most relevant household elements in the predictions. Finally, we fitted an additional reduced model using only the identified relevant household elements, which had an only slightly lower performance compared to models using all images. Our results show how ground-based household photographs allow to zoom in from an area-level to an individual household prediction while minimizing the data collection effort by using explainable machine learning. The developed workflow can be potentially integrated into routine household surveys, where the collected household imagery could be used for other purposes, such as refined asset characterization and environmental exposure assessment.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08935",
        "abstract url": "https://arxiv.org/abs/2411.08935",
        "title": "Classification of Keratitis from Eye Corneal Photographs using Deep Learning",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Keratitis is an inflammatory corneal condition responsible for 10% of visual impairment in low- and middle-income countries (LMICs), with bacteria, fungi, or amoeba as the most common infection etiologies. While an accurate and timely diagnosis is crucial for the selected treatment and the patients' sight outcomes, due to the high cost and limited availability of laboratory diagnostics in LMICs, diagnosis is often made by clinical observation alone, despite its lower accuracy. In this study, we investigate and compare different deep learning approaches to diagnose the source of infection: 1) three separate binary models for infection type predictions; 2) a multitask model with a shared backbone and three parallel classification layers (Multitask V1); and, 3) a multitask model with a shared backbone and a multi-head classification layer (Multitask V2). We used a private Brazilian cornea dataset to conduct the empirical evaluation. We achieved the best results with Multitask V2, with an area under the receiver operating characteristic curve (AUROC) confidence intervals of 0.7413-0.7740 (bacteria), 0.8395-0.8725 (fungi), and 0.9448-0.9616 (amoeba). A statistical analysis of the impact of patient features on models' performance revealed that sex significantly affects amoeba infection prediction, and age seems to affect fungi and bacteria predictions.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "6 pages; Accepted at IEEE's International Conference on Bioinformatics and Biomedicine (2024)"
    },
    {
        "paper id": "2411.08936",
        "abstract url": "https://arxiv.org/abs/2411.08936",
        "title": "Clustered Patch Embeddings for Permutation-Invariant Classification of Whole Slide Images",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "Whole Slide",
                "pathological"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Whole Slide Imaging (WSI) is a cornerstone of digital pathology, offering detailed insights critical for diagnosis and research. Yet, the gigapixel size of WSIs imposes significant computational challenges, limiting their practical utility. Our novel approach addresses these challenges by leveraging various encoders for intelligent data reduction and employing a different classification model to ensure robust, permutation-invariant representations of WSIs. A key innovation of our method is the ability to distill the complex information of an entire WSI into a single vector, effectively capturing the essential features needed for accurate analysis. This approach significantly enhances the computational efficiency of WSI analysis, enabling more accurate pathological assessments without the need for extensive computational resources. This breakthrough equips us with the capability to effectively address the challenges posed by large image resolutions in whole-slide imaging, paving the way for more scalable and effective utilization of WSIs in medical diagnostics and research, marking a significant advancement in the field.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2411.08530"
    },
    {
        "paper id": "2411.08975",
        "abstract url": "https://arxiv.org/abs/2411.08975",
        "title": "Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion",
        "rating": "-1",
        "keywords": [
            [
                "biology",
                "whole slide",
                "cancer"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Though multiple instance learning (MIL) has been a foundational strategy in computational pathology for processing whole slide images (WSIs), current approaches are designed for traditional hematoxylin and eosin (H&E) slides rather than emerging multiplexed technologies. Here, we present an MIL strategy, the Fluoroformer module, that is specifically tailored to multiplexed WSIs by leveraging scaled dot-product attention (SDPA) to interpretably fuse information across disparate channels. On a cohort of 434 non-small cell lung cancer (NSCLC) samples, we show that the Fluoroformer both obtains strong prognostic performance and recapitulates immuno-oncological hallmarks of NSCLC. Our technique thereby provides a path for adapting state-of-the-art AI techniques to emerging spatial biology assays.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Findings paper presented at Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024, Vancouver, Canada, 14 pages"
    },
    {
        "paper id": "2411.09007",
        "abstract url": "https://arxiv.org/abs/2411.09007",
        "title": "Scale Contrastive Learning with Selective Attentions for Blind Image Quality Assessment",
        "rating": "-1",
        "keywords": [
            [
                "Quality Assessment"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Blind image quality assessment (BIQA) serves as a fundamental task in computer vision, yet it often fails to consistently align with human subjective perception. Recent advances show that multi-scale evaluation strategies are promising due to their ability to replicate the hierarchical structure of human vision. However, the effectiveness of these strategies is limited by a lack of understanding of how different image scales influence perceived quality. This paper addresses two primary challenges: the significant redundancy of information across different scales, and the confusion caused by combining features from these scales, which may vary widely in quality. To this end, a new multi-scale BIQA framework is proposed, namely Contrast-Constrained Scale-Focused IQA Framework (CSFIQA). CSFIQA features a selective focus attention mechanism to minimize information redundancy and highlight critical quality-related information. Additionally, CSFIQA includes a scale-level contrastive learning module equipped with a noise sample matching mechanism to identify quality discrepancies across the same image content at different scales. By exploring the intrinsic relationship between image scales and the perceived quality, the proposed CSFIQA achieves leading performance on eight benchmark datasets, e.g., achieving SRCC values of 0.967 (versus 0.947 in CSIQ) and 0.905 (versus 0.876 in LIVEC).",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09026",
        "abstract url": "https://arxiv.org/abs/2411.09026",
        "title": "On the Complexity of Hazard-Free Formulas",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ]
        ],
        "abstract": "This paper studies the hazard-free formula complexity of Boolean functions. As our main result, we prove that unate functions are the only Boolean functions for which the monotone formula complexity of the hazard-derivative equals the hazard-free formula complexity of the function itself. Consequently, every non-unate function breaks the so-called monotone barrier, as introduced and discussed by Ikenmeyer, Komarath, and Saurabh (ITCS 2023). Our second main result shows that the hazard-free formula complexity of random Boolean functions is at most $2^{(1+o(1))n}$. Prior to this, no better upper bound than $O(3^n)$ was known. Notably, unlike in the general case of Boolean circuits and formulas, where the typical complexity matches that of the multiplexer function, the hazard-free formula complexity is smaller than the optimal hazard-free formula for the multiplexer by an exponential factor in $n$. Additionally, we explore the hazard-free formula complexity of block composition of Boolean functions and obtain a result in the hazard-free setting that is analogous to a result of Karchmer, Raz, and Wigderson (Computational Complexity, 1995) in the monotone setting. We demonstrate that our result implies a lower bound on the hazard-free formula depth of the block composition of the set covering function with the multiplexer function, which breaks the monotone barrier.",
        "subjects": [
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09027",
        "abstract url": "https://arxiv.org/abs/2411.09027",
        "title": "Transformer-based Time-Series Biomarker Discovery for COPD Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "Biomarker",
                "medical",
                "Diagnosis",
                "disease",
                "clinical"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Chronic Obstructive Pulmonary Disorder (COPD) is an irreversible and progressive disease which is highly heritable. Clinically, COPD is defined using the summary measures derived from a spirometry test but these are not always adequate. Here we show that using the high-dimensional raw spirogram can provide a richer signal compared to just using the summary measures. We design a transformer-based deep learning technique to process the raw spirogram values along with demographic information and predict clinically-relevant endpoints related to COPD. Our method is able to perform better than prior works while being more computationally efficient. Using the weights learned by the model, we make the framework more interpretable by identifying parts of the spirogram that are important for the model predictions. Pairing up with a board-certified pulmonologist, we also provide clinical insights into the different aspects of the spirogram and show that the explanations obtained from the model align with underlying medical knowledge.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted as a workshop paper to NeurIPS 2024"
    },
    {
        "paper id": "2411.09037",
        "abstract url": "https://arxiv.org/abs/2411.09037",
        "title": "A Transformer-Based Visual Piano Transcription Algorithm",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatic music transcription (AMT) for musical performances is a long standing problem in the field of Music Information Retrieval (MIR). Visual piano transcription (VPT) is a multimodal subproblem of AMT which focuses on extracting a symbolic representation of a piano performance from visual information only (e.g., from a top-down video of the piano keyboard). Inspired by the success of Transformers for audio-based AMT, as well as their recent successes in other computer vision tasks, in this paper we present a Transformer based architecture for VPT. The proposed VPT system combines a piano bounding box detection model with an onset and pitch detection model, allowing our system to perform well in more naturalistic conditions like imperfect image crops around the piano and slightly tilted images.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "9 pages, 2 figures"
    },
    {
        "paper id": "2411.09077",
        "abstract url": "https://arxiv.org/abs/2411.09077",
        "title": "Drone Detection using Deep Neural Networks Trained on Pure Synthetic Data",
        "rating": "-1",
        "keywords": [
            [
                "Drone"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Drone detection has benefited from improvements in deep neural networks, but like many other applications, suffers from the availability of accurate data for training. Synthetic data provides a potential for low-cost data generation and has been shown to improve data availability and quality. However, models trained on synthetic datasets need to prove their ability to perform on real-world data, known as the problem of sim-to-real transferability. Here, we present a drone detection Faster-RCNN model trained on a purely synthetic dataset that transfers to real-world data. We found that it achieves an AP_50 of 97.0% when evaluated on the MAV-Vid - a real dataset of flying drones - compared with 97.8% for an equivalent model trained on real-world data. Our results show that using synthetic data for drone detection has the potential to reduce data collection costs and improve labelling quality. These findings could be a starting point for more elaborate synthetic drone datasets. For example, realistic recreations of specific scenarios could de-risk the dataset generation of safety-critical applications such as the detection of drones at airports. Further, synthetic data may enable reliable drone detection systems, which could benefit other areas, such as unmanned traffic management systems. The code is available https://github.com/mazqtpopx/cranfield-synthetic-drone-detection alongside the datasets https://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "12 pages, 8 figures"
    },
    {
        "paper id": "2411.09104",
        "abstract url": "https://arxiv.org/abs/2411.09104",
        "title": "Deep Learning for Beamforming in Multi-User Continuous Aperture Array (CAPA) Systems",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "A DeepCAPA (Deep Learning for Continuous Aperture Array (CAPA)) framework is proposed to learn beamforming in CAPA systems. The beamforming optimization problem is firstly formulated, and it is mathematically proved that the optimal beamforming lies in the subspace spanned by users' conjugate channel responses. Two challenges are encountered when directly applying deep neural networks (DNNs) for solving the formulated problem, i) both the input and output spaces are infinite-dimensional, which are not compatible with DNNs. The finite-dimensional representations of inputs and outputs are derived to address this challenge. ii) A closed-form loss function is unavailable for training the DNN. To tackle this challenge, two additional DNNs are trained to approximate the operations without closed-form expressions for expediting gradient back-propagation. To improve learning performance and reduce training complexity, the permutation equivariance properties of the mappings to be learned are mathematically proved. As a further advance, the DNNs are designed as graph neural networks to leverage the properties. Numerical results demonstrate that: i) the proposed DeepCAPA framework achieves higher spectral efficiency and lower inference complexity compared to match-filtering and state-of-art Fourier-based discretization method, and ii) DeepCAPA approaches the performance upper bound of optimizing beamforming in the spatially discrete array-based system as the number of antennas in a fixed-sized area tends toward infinity.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages, 11 figures. arXiv admin note: text overlap with arXiv:2408.11230"
    },
    {
        "paper id": "2411.09133",
        "abstract url": "https://arxiv.org/abs/2411.09133",
        "title": "Computational metaoptics for imaging",
        "rating": "-1",
        "keywords": [
            [
                "quantum"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Metasurfaces -- ultrathin structures composed of subwavelength optical elements -- have revolutionized light manipulation by enabling precise control over electromagnetic waves' amplitude, phase, polarization, and spectral properties. Concurrently, computational imaging leverages algorithms to reconstruct images from optically processed signals, overcoming limitations of traditional imaging systems. This review explores the synergistic integration of metaoptics and computational imaging, \"computational metaoptics,\" which combines the physical wavefront shaping ability of metasurfaces with advanced computational algorithms to enhance imaging performance beyond conventional limits. We discuss how computational metaoptics addresses the inherent limitations of single-layer metasurfaces in achieving multifunctionality without compromising efficiency. By treating metasurfaces as physical preconditioners and co-designing them with reconstruction algorithms through end-to-end (inverse) design, it is possible to jointly optimize the optical hardware and computational software. This holistic approach allows for the automatic discovery of optimal metasurface designs and reconstruction methods that significantly improve imaging capabilities. Advanced applications enabled by computational metaoptics are highlighted, including phase imaging and quantum state measurement, which benefit from the metasurfaces' ability to manipulate complex light fields and the computational algorithms' capacity to reconstruct high-dimensional information. We also examine performance evaluation challenges, emphasizing the need for new metrics that account for the combined optical and computational nature of these systems. Finally, we identify new frontiers in computational metaoptics which point toward a future where computational metaoptics may play a central role in advancing imaging science and technology.",
        "subjects": [
            "physics.optics",
            "cs.CV",
            "physics.comp-ph",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09140",
        "abstract url": "https://arxiv.org/abs/2411.09140",
        "title": "Adversarial Vessel-Unveiling Semi-Supervised Segmentation for Retinopathy of Prematurity Diagnosis",
        "rating": "-1",
        "keywords": [
            [
                "biomarker",
                "Diagnosis",
                "clinical",
                "retinal"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurate segmentation of retinal images plays a crucial role in aiding ophthalmologists in diagnosing retinopathy of prematurity (ROP) and assessing its severity. However, due to their underdeveloped, thinner vessels, manual annotation in infant fundus images is very complex, and this presents challenges for fully supervised learning. To address the scarcity of annotations, we propose a semi supervised segmentation framework designed to advance ROP studies without the need for extensive manual vessel annotation. Unlike previous methods that rely solely on limited labeled data, our approach leverages teacher student learning by integrating two powerful components: an uncertainty weighted vessel unveiling module and domain adversarial learning. The vessel unveiling module helps the model effectively reveal obscured and hard to detect vessel structures, while adversarial training aligns feature representations across different domains, ensuring robust and generalizable vessel segmentations. We validate our approach on public datasets (CHASEDB, STARE) and an in-house ROP dataset, demonstrating its superior performance across multiple evaluation metrics. Additionally, we extend the model's utility to a downstream task of ROP multi-stage classification, where vessel masks extracted by our segmentation model improve diagnostic accuracy. The promising results in classification underscore the model's potential for clinical application, particularly in early-stage ROP diagnosis and intervention. Overall, our work offers a scalable solution for leveraging unlabeled data in pediatric ophthalmology, opening new avenues for biomarker discovery and clinical research.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 5 figures"
    },
    {
        "paper id": "2411.09145",
        "abstract url": "https://arxiv.org/abs/2411.09145",
        "title": "UniHOI: Learning Fast, Dense and Generalizable 4D Reconstruction for Egocentric Hand Object Interaction Videos",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Egocentric Hand Object Interaction (HOI) videos provide valuable insights into human interactions with the physical world, attracting growing interest from the computer vision and robotics communities. A key task in fully understanding the geometry and dynamics of HOI scenes is dense pointclouds sequence reconstruction. However, the inherent motion of both hands and the camera makes this challenging. Current methods often rely on time-consuming test-time optimization, making them impractical for reconstructing internet-scale videos. To address this, we introduce UniHOI, a model that unifies the estimation of all variables necessary for dense 4D reconstruction, including camera intrinsic, camera poses, and video depth, for egocentric HOI scene in a fast feed-forward manner. We end-to-end optimize all these variables to improve their consistency in 3D space. Furthermore, our model could be trained solely on large-scale monocular video dataset, overcoming the limitation of scarce labeled HOI data. We evaluate UniHOI with both in-domain and zero-shot generalization setting, surpassing all baselines in pointclouds sequence reconstruction and long-term 3D scene flow recovery. UniHOI is the first approach to offer fast, dense, and generalizable monocular egocentric HOI scene reconstruction in the presence of motion. Code and trained model will be released in the future.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09151",
        "abstract url": "https://arxiv.org/abs/2411.09151",
        "title": "Mono2Stereo: Monocular Knowledge Transfer for Enhanced Stereo Matching",
        "rating": "-1",
        "keywords": [
            [
                "depth"
            ],
            [
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The generalization and performance of stereo matching networks are limited due to the domain gap of the existing synthetic datasets and the sparseness of GT labels in the real datasets. In contrast, monocular depth estimation has achieved significant advancements, benefiting from large-scale depth datasets and self-supervised strategies. To bridge the performance gap between monocular depth estimation and stereo matching, we propose leveraging monocular knowledge transfer to enhance stereo matching, namely Mono2Stereo. We introduce knowledge transfer with a two-stage training process, comprising synthetic data pre-training and real-world data fine-tuning. In the pre-training stage, we design a data generation pipeline that synthesizes stereo training data from monocular images. This pipeline utilizes monocular depth for warping and novel view synthesis and employs our proposed Edge-Aware (EA) inpainting module to fill in missing contents in the generated images. In the fine-tuning stage, we introduce a Sparse-to-Dense Knowledge Distillation (S2DKD) strategy encouraging the distributions of predictions to align with dense monocular depths. This strategy mitigates issues with edge blurring in sparse real-world labels and enhances overall consistency. Experimental results demonstrate that our pre-trained model exhibits strong zero-shot generalization capabilities. Furthermore, domain-specific fine-tuning using our pre-trained model and S2DKD strategy significantly increments in-domain performance. The code will be made available soon.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 6 figures"
    },
    {
        "paper id": "2411.09154",
        "abstract url": "https://arxiv.org/abs/2411.09154",
        "title": "STAR-RIS Enabled ISAC Systems: Joint Rate Splitting and Beamforming Optimization",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "This paper delves into an integrated sensing and communication (ISAC) system bolstered by a simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). Within this system, a base station (BS) is equipped with communication and radar capabilities, enabling it to communicate with ground terminals (GTs) and concurrently probe for echo signals from a target of interest. Moreover, to manage interference and improve communication quality, the rate splitting multiple access (RSMA) scheme is incorporated into the system. The signal-to-interference-plus-noise ratio (SINR) of the received sensing echo signals is a measure of sensing performance. We formulate a joint optimization problem of common rates, transmit beamforming at the BS, and passive beamforming vectors of the STAR-RIS. The objective is to maximize sensing SINR while guaranteeing the communication rate requirements for each GT. We present an iterative algorithm to address the non-convex problem by invoking Dinkelbach's transform, semidefinite relaxation (SDR), majorization-minimization, and sequential rank-one constraint relaxation (SROCR) theories. Simulation results manifest that the performance of the studied ISAC network enhanced by the STAR-RIS and RSMA surpasses other benchmarks considerably. The results evidently indicate the superior performance improvement of the ISAC system with the proposed RSMA-based transmission strategy design and the dynamic optimization of both transmission and reflection beamforming at STAR-RIS.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "13 pages, 9 figures"
    },
    {
        "paper id": "2411.10484",
        "abstract url": "https://arxiv.org/abs/2411.10484",
        "title": "iFlow: An Interactive Max-Flow/Min-Cut Algorithms Visualizer",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The Max-Flow/Min-Cut problem is a fundamental tool in graph theory, with applications in many domains, including data mining, image segmentation, transportation planning, and many types of assignment problems, in addition to being an essential building block for many other algorithms. The Ford-Fulkerson Algorithm for Max-Flow/Min-Cut and its variants are therefore commonly taught in undergraduate and beginning graduate algorithms classes. However, these algorithms -- and in particular the so-called residual graphs they utilize -- often pose significant challenges for students. To help students achieve a deeper understanding, we developed iFlow, an interactive visualization tool for the Ford-Fulkerson Algorithm and its variants. iFlow lets users design or import flow networks, and execute the algorithm by hand. In particular, the user can select an augmentation path and amount, and then update the residual graph. The user is given detailed feedback on mistakes, and can also have iFlow auto-complete each step, to use it as a demonstration tool while still in the initial learning stages. iFlow has been made publicly available and open-sourced. We deployed iFlow in an undergraduate algorithms class, and collected students' self-reported learning benefits via an optional survey. All respondents considered the tool at least somewhat useful and engaging, with most rating it either as useful/engaging or very useful/engaging. Students also generally reported a significant increase in understanding of the algorithm.",
        "subjects": [
            "cs.HC",
            "cs.DS"
        ],
        "comment": "This paper is accepted by SIGCSE 2025 TS. Due to the page limit we can not include the appendix in the SIGCSE version. So we decide to include them on arXiv so that the SIGCSE version can point to the arXiv version. Since the final SIGCSE version is due by Nov. 17, it would be really helpful if this submission can go online as soon as possible. Thanks!"
    },
    {
        "paper id": "2411.08404",
        "abstract url": "https://arxiv.org/abs/2411.08404",
        "title": "Quantifying Qualitative Insights: Leveraging LLMs to Market Predict",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advancements in Large Language Models (LLMs) have the potential to transform financial analytics by integrating numerical and textual data. However, challenges such as insufficient context when fusing multimodal information and the difficulty in measuring the utility of qualitative outputs, which LLMs generate as text, have limited their effectiveness in tasks such as financial forecasting. This study addresses these challenges by leveraging daily reports from securities firms to create high-quality contextual information. The reports are segmented into text-based key factors and combined with numerical data, such as price information, to form context sets. By dynamically updating few-shot examples based on the query time, the sets incorporate the latest information, forming a highly relevant set closely aligned with the query point. Additionally, a crafted prompt is designed to assign scores to the key factors, converting qualitative insights into quantitative results. The derived scores undergo a scaling process, transforming them into real-world values that are used for prediction. Our experiments demonstrate that LLMs outperform time-series models in market forecasting, though challenges such as imperfect reproducibility and limited explainability remain.",
        "subjects": [
            "q-fin.CP",
            "cs.LG"
        ],
        "comment": "7 pages, 4 figures"
    },
    {
        "paper id": "2411.08433",
        "abstract url": "https://arxiv.org/abs/2411.08433",
        "title": "3D Multi-Object Tracking with Semi-Supervised GRU-Kalman Filter",
        "rating": "-1.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "autonomous driving"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "3D Multi-Object Tracking (MOT), a fundamental component of environmental perception, is essential for intelligent systems like autonomous driving and robotic sensing. Although Tracking-by-Detection frameworks have demonstrated excellent performance in recent years, their application in real-world scenarios faces significant challenges. Object movement in complex environments is often highly nonlinear, while existing methods typically rely on linear approximations of motion. Furthermore, system noise is frequently modeled as a Gaussian distribution, which fails to capture the true complexity of the noise dynamics. These oversimplified modeling assumptions can lead to significant reductions in tracking precision. To address this, we propose a GRU-based MOT method, which introduces a learnable Kalman filter into the motion module. This approach is able to learn object motion characteristics through data-driven learning, thereby avoiding the need for manual model design and model error. At the same time, to avoid abnormal supervision caused by the wrong association between annotations and trajectories, we design a semi-supervised learning strategy to accelerate the convergence speed and improve the robustness of the model. Evaluation experiment on the nuScenes and Argoverse2 datasets demonstrates that our system exhibits superior performance and significant potential compared to traditional TBD methods.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08469",
        "abstract url": "https://arxiv.org/abs/2411.08469",
        "title": "Building Trustworthy AI: Transparent AI Systems via Large Language Models, Ontologies, and Logical Reasoning (TranspNet)",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Growing concerns over the lack of transparency in AI, particularly in high-stakes fields like healthcare and finance, drive the need for explainable and trustworthy systems. While Large Language Models (LLMs) perform exceptionally well in generating accurate outputs, their \"black box\" nature poses significant challenges to transparency and trust. To address this, the paper proposes the TranspNet pipeline, which integrates symbolic AI with LLMs. By leveraging domain expert knowledge, retrieval-augmented generation (RAG), and formal reasoning frameworks like Answer Set Programming (ASP), TranspNet enhances LLM outputs with structured reasoning and verification. This approach ensures that AI systems deliver not only accurate but also explainable and trustworthy results, meeting regulatory demands for transparency and accountability. TranspNet provides a comprehensive solution for developing AI systems that are reliable and interpretable, making it suitable for real-world applications where trust is critical.",
        "subjects": [
            "cs.AI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08526",
        "abstract url": "https://arxiv.org/abs/2411.08526",
        "title": "Gendered Words and Grant Rates: A Textual Analysis of Disparate Outcomes in the Patent System",
        "rating": "-1.5",
        "keywords": [
            [
                "Patent"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "This study examines gender disparities in patent law by analyzing the textual content of patent applications. While prior research has primarily focused on the study of metadata (i.e., filing year or technological class), we employ machine learning and natural language processing techniques to derive latent information from patent texts. In particular, these methods are used to predict inventor gender based on textual characteristics. We find that gender can be identified with notable accuracy - even without knowing the inventor's name. This ability to discern gender through text suggests that anonymized patent examination - often proposed as a solution to mitigate disparities in patent grant rate - may not fully address gender-specific outcomes in securing a patent. Our analysis additionally identifies gendered differences in textual choices within patent documents and the fields in which inventors choose to work. These findings highlight the complex interaction between textual choices, gender, and success in securing a patent. As discussed herein, this raises critical questions about the efficacy of current proposals aimed at achieving gender parity and efficiency in the patent system.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08552",
        "abstract url": "https://arxiv.org/abs/2411.08552",
        "title": "Leveraging Pre-Trained Neural Networks to Enhance Machine Learning with Variational Quantum Circuits",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Quantum Machine Learning (QML) offers tremendous potential but is currently limited by the availability of qubits. We introduce an innovative approach that utilizes pre-trained neural networks to enhance Variational Quantum Circuits (VQC). This technique effectively separates approximation error from qubit count and removes the need for restrictive conditions, making QML more viable for real-world applications. Our method significantly improves parameter optimization for VQC while delivering notable gains in representation and generalization capabilities, as evidenced by rigorous theoretical analysis and extensive empirical testing on quantum dot classification tasks. Moreover, our results extend to applications such as human genome analysis, demonstrating the broad applicability of our approach. By addressing the constraints of current quantum hardware, our work paves the way for a new era of advanced QML applications, unlocking the full potential of quantum computing in fields such as machine learning, materials science, medicine, mimetics, and various interdisciplinary areas.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "quant-ph"
        ],
        "comment": "In submission"
    },
    {
        "paper id": "2411.08583",
        "abstract url": "https://arxiv.org/abs/2411.08583",
        "title": "An Empirical Examination of the Evaluative AI Framework",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This study empirically examines the \"Evaluative AI\" framework, which aims to enhance the decision-making process for AI users by transitioning from a recommendation-based approach to a hypothesis-driven one. Rather than offering direct recommendations, this framework presents users pro and con evidence for hypotheses to support more informed decisions. However, findings from the current behavioral experiment reveal no significant improvement in decision-making performance and limited user engagement with the evidence provided, resulting in cognitive processes similar to those observed in traditional AI systems. Despite these results, the framework still holds promise for further exploration in future research.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08586",
        "abstract url": "https://arxiv.org/abs/2411.08586",
        "title": "Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "Clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Summarizing patient clinical notes is vital for reducing documentation burdens. Current manual summarization makes medical staff struggle. We propose an automatic method using LLMs, but long inputs cause LLMs to lose context, reducing output quality especially in small size model. We used a 7B model, open-calm-7b, enhanced with Native Bayes Context Extend and a redesigned decoding mechanism to reference one sentence at a time, keeping inputs within context windows, 2048 tokens. Our improved model achieved near parity with Google's over 175B Gemini on ROUGE-L metrics with 200 samples, indicating strong performance using less resources, enhancing automated EMR summarization feasibility.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08608",
        "abstract url": "https://arxiv.org/abs/2411.08608",
        "title": "Comparative study of random walks with one-step memory on complex networks",
        "rating": "-1.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "graph"
            ],
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "We investigate searching efficiency of different kinds of random walk on complex networks which rely on local information and one-step memory. For the studied navigation strategies we obtained theoretical and numerical values for the graph mean first passage times as an indicator for the searching efficiency. The experiments with generated and real networks show that biasing based on inverse degree, persistence and local two-hop paths can lead to smaller searching times. Moreover, these biasing approaches can be combined to achieve a more robust random search strategy. Our findings can be applied in the modeling and solution of various real-world problems.",
        "subjects": [
            "cs.CY",
            "cs.SI",
            "physics.soc-ph"
        ],
        "comment": "12 pages, 4 figures, 1 table, conference"
    },
    {
        "paper id": "2411.08700",
        "abstract url": "https://arxiv.org/abs/2411.08700",
        "title": "Rethinking negative sampling in content-based news recommendation",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "News recommender systems are hindered by the brief lifespan of articles, as they undergo rapid relevance decay. Recent studies have demonstrated the potential of content-based neural techniques in tackling this problem. However, these models often involve complex neural architectures and often lack consideration for negative examples. In this study, we posit that the careful sampling of negative examples has a big impact on the model's outcome. We devise a negative sampling technique that not only improves the accuracy of the model but also facilitates the decentralization of the recommendation system. The experimental results obtained using the MIND dataset demonstrate that the accuracy of the method under consideration can compete with that of State-of-the-Art models. The utilization of the sampling technique is essential in reducing model complexity and accelerating the training process, while maintaining a high level of accuracy. Finally, we discuss how decentralized models can help improve privacy and scalability.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08750",
        "abstract url": "https://arxiv.org/abs/2411.08750",
        "title": "Optimal Transport-Based Displacement Interpolation with Data Augmentation for Reduced Order Modeling of Nonlinear Dynamical Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a novel reduced-order Model (ROM) that leverages optimal transport (OT) theory and displacement interpolation to enhance the representation of nonlinear dynamics in complex systems. While traditional ROM techniques face challenges in this scenario, especially when data (i.e., observational snapshots) is limited, our method addresses these issues by introducing a data augmentation strategy based on OT principles. The proposed framework generates interpolated solutions tracing geodesic paths in the space of probability distributions, enriching the training dataset for the ROM. A key feature of our approach is its ability to provide a continuous representation of the solution's dynamics by exploiting a virtual-to-real time mapping. This enables the reconstruction of solutions at finer temporal scales than those provided by the original data. To further improve prediction accuracy, we employ Gaussian Process Regression to learn the residual and correct the representation between the interpolated snapshots and the physical solution. We demonstrate the effectiveness of our methodology with atmospheric mesoscale benchmarks characterized by highly nonlinear, advection-dominated dynamics. Our results show improved accuracy and efficiency in predicting complex system behaviors, indicating the potential of this approach for a wide range of applications in computational physics and engineering.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08760",
        "abstract url": "https://arxiv.org/abs/2411.08760",
        "title": "Energy Dissipation Preserving Physics Informed Neural Network for Allen-Cahn Equations",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper investigates a numerical solution of Allen-Cahn equation with constant and degenerate mobility, with polynomial and logarithmic energy functionals, with deterministic and random initial functions, and with advective term in one, two, and three spatial dimensions, based on the physics-informed neural network (PINN). To improve the learning capacity of the PINN, we incorporate the energy dissipation property of the Allen-Cahn equation as a penalty term into the loss function of the network. To facilitate the learning process of random initials, we employ a continuous analogue of the initial random condition by utilizing the Fourier series expansion. Adaptive methods from traditional numerical analysis are also integrated to enhance the effectiveness of the proposed PINN. Numerical results indicate a consistent decrease in the discrete energy, while also revealing phenomena such as phase separation and metastability.",
        "subjects": [
            "math.NA",
            "cs.LG",
            "physics.comp-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08766",
        "abstract url": "https://arxiv.org/abs/2411.08766",
        "title": "Mapping Methane -- The Impact of Dairy Farm Practices on Emissions Through Satellite Data and Machine Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Satellite"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study investigates the correlation between dairy farm characteristics and methane concentrations as derived from satellite observations in Eastern Canada. Utilizing data from 11 dairy farms collected between January 2020 and December 2022, we integrated Sentinel-5P satellite methane data with critical farm-level attributes, including herd genetics, feeding practices, and management strategies. Initial analyses revealed significant correlations with methane concentrations, leading to the application of Variance Inflation Factor (VIF) and Principal Component Analysis (PCA) to address multicollinearity and enhance model stability. Subsequently, machine learning models - specifically Random Forest and Neural Networks - were employed to evaluate feature importance and predict methane emissions. Our findings indicate a strong negative correlation between the Estimated Breeding Value (EBV) for protein percentage and methane concentrations, suggesting that genetic selection for higher milk protein content could be an effective strategy for emissions reduction. The integration of atmospheric transport models with satellite data further refined our emission estimates, significantly enhancing accuracy and spatial resolution. This research underscores the potential of advanced satellite monitoring, machine learning techniques, and atmospheric modeling in improving methane emission assessments within the dairy sector. It emphasizes the critical role of farm-specific characteristics in developing effective mitigation strategies. Future investigations should focus on expanding the dataset and incorporating inversion modeling for more precise emission quantification. Balancing ecological impacts with economic viability will be essential for fostering sustainable dairy farming practices.",
        "subjects": [
            "cs.LG",
            "stat.AP"
        ],
        "comment": "16 pages, 5 figures"
    },
    {
        "paper id": "2411.08800",
        "abstract url": "https://arxiv.org/abs/2411.08800",
        "title": "Deep Learning Accelerated Quantum Transport Simulations in Nanoelectronics: From Break Junctions to Field-Effect Transistors",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum",
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Quantum transport calculations are essential for understanding and designing nanoelectronic devices, yet the trade-off between accuracy and computational efficiency has long limited their practical applications. We present a general framework that combines the deep learning tight-binding Hamiltonian (DeePTB) approach with the non-equilibrium Green's Function (NEGF) method, enabling efficient quantum transport calculations while maintaining first-principles accuracy. We demonstrate the capabilities of the DeePTB-NEGF framework through two representative applications: comprehensive simulation of break junction systems, where conductance histograms show good agreement with experimental measurements in both metallic contact and single-molecule junction cases; and simulation of carbon nanotube field effect transistors through self-consistent NEGF-Poisson calculations, capturing essential physics including the electrostatic potential and transfer characteristic curves under finite bias conditions. This framework bridges the gap between first-principles accuracy and computational efficiency, providing a powerful tool for high-throughput quantum transport simulations across different scales in nanoelectronics.",
        "subjects": [
            "cond-mat.mes-hall",
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": "10 pages, 4 figures"
    },
    {
        "paper id": "2411.08843",
        "abstract url": "https://arxiv.org/abs/2411.08843",
        "title": "Data-driven Surface Solar Irradiance Estimation using Neural Operators at Global Scale",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting",
                "satellite"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Accurate surface solar irradiance (SSI) forecasting is essential for optimizing renewable energy systems, particularly in the context of long-term energy planning on a global scale. This paper presents a pioneering approach to solar radiation forecasting that leverages recent advancements in numerical weather prediction (NWP) and data-driven machine learning weather models. These advances facilitate long, stable rollouts and enable large ensemble forecasts, enhancing the reliability of predictions. Our flexible model utilizes variables forecast by these NWP and AI weather models to estimate 6-hourly SSI at global scale. Developed using NVIDIA Modulus, our model represents the first adaptive global framework capable of providing long-term SSI forecasts. Furthermore, it can be fine-tuned using satellite data, which significantly enhances its performance in the fine-tuned regions, while maintaining accuracy elsewhere. The improved accuracy of these forecasts has substantial implications for the integration of solar energy into power grids, enabling more efficient energy management and contributing to the global transition to renewable energy sources.",
        "subjects": [
            "physics.ao-ph",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09055",
        "abstract url": "https://arxiv.org/abs/2411.09055",
        "title": "SAFELOC: Overcoming Data Poisoning Attacks in Heterogeneous Federated Machine Learning for Indoor Localization",
        "rating": "-1.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) based indoor localization solutions are critical for many emerging applications, yet their efficacy is often compromised by hardware/software variations across mobile devices (i.e., device heterogeneity) and the threat of ML data poisoning attacks. Conventional methods aimed at countering these challenges show limited resilience to the uncertainties created by these phenomena. In response, in this paper, we introduce SAFELOC, a novel framework that not only minimizes localization errors under these challenging conditions but also ensures model compactness for efficient mobile device deployment. Our framework targets a distributed and co-operative learning environment that uses federated learning (FL) to preserve user data privacy and assumes heterogeneous mobile devices carried by users (just like in most real-world scenarios). Within this heterogeneous FL context, SAFELOC introduces a novel fused neural network architecture that performs data poisoning detection and localization, with a low model footprint. Additionally, a dynamic saliency map-based aggregation strategy is designed to adapt based on the severity of the detected data poisoning scenario. Experimental evaluations demonstrate that SAFELOC achieves improvements of up to 5.9x in mean localization error, 7.8x in worst-case localization error, and a 2.1x reduction in model inference latency compared to state-of-the-art indoor localization frameworks, across diverse building floorplans, mobile devices, and ML data poisoning attack scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09065",
        "abstract url": "https://arxiv.org/abs/2411.09065",
        "title": "Language-Model Prior Overcomes Cold-Start Items",
        "rating": "-1.5",
        "keywords": [
            [
                "recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The growth of recommender systems (RecSys) is driven by digitization and the need for personalized content in areas such as e-commerce and video streaming. The content in these systems often changes rapidly and therefore they constantly face the ongoing cold-start problem, where new items lack interaction data and are hard to value. Existing solutions for the cold-start problem, such as content-based recommenders and hybrid methods, leverage item metadata to determine item similarities. The main challenge with these methods is their reliance on structured and informative metadata to capture detailed item similarities, which may not always be available. This paper introduces a novel approach for cold-start item recommendation that utilizes the language model (LM) to estimate item similarities, which are further integrated as a Bayesian prior with classic recommender systems. This approach is generic and able to boost the performance of various recommenders. Specifically, our experiments integrate it with both sequential and collaborative filtering-based recommender and evaluate it on two real-world datasets, demonstrating the enhanced performance of the proposed approach.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "This paper is dedicated to cold-start item recommendation using language-model priors"
    },
    {
        "paper id": "2411.09072",
        "abstract url": "https://arxiv.org/abs/2411.09072",
        "title": "Continuous GNN-based Anomaly Detection on Edge using Efficient Adaptive Knowledge Graph Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The increasing demand for robust security solutions across various industries has made Video Anomaly Detection (VAD) a critical task in applications such as intelligent surveillance, evidence investigation, and violence detection. Traditional approaches to VAD often rely on finetuning large pre-trained models, which can be computationally expensive and impractical for real-time or resource-constrained environments. To address this, MissionGNN introduced a more efficient method by training a graph neural network (GNN) using a fixed knowledge graph (KG) derived from large language models (LLMs) like GPT-4. While this approach demonstrated significant efficiency in computational power and memory, it faces limitations in dynamic environments where frequent updates to the KG are necessary due to evolving behavior trends and shifting data patterns. These updates typically require cloud-based computation, posing challenges for edge computing applications. In this paper, we propose a novel framework that facilitates continuous KG adaptation directly on edge devices, overcoming the limitations of cloud dependency. Our method dynamically modifies the KG through a three-phase process: pruning, alternating, and creating nodes, enabling real-time adaptation to changing data trends. This continuous learning approach enhances the robustness of anomaly detection models, making them more suitable for deployment in dynamic and resource-constrained environments.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to DATE 2025"
    },
    {
        "paper id": "2411.09153",
        "abstract url": "https://arxiv.org/abs/2411.09153",
        "title": "VidMan: Exploiting Implicit Dynamics from Video Diffusion Model for Effective Robot Manipulation",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "Robot"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Recent advancements utilizing large-scale video data for learning video generation models demonstrate significant potential in understanding complex physical dynamics. It suggests the feasibility of leveraging diverse robot trajectory data to develop a unified, dynamics-aware model to enhance robot manipulation. However, given the relatively small amount of available robot data, directly fitting data without considering the relationship between visual observations and actions could lead to suboptimal data utilization. To this end, we propose VidMan (Video Diffusion for Robot Manipulation), a novel framework that employs a two-stage training mechanism inspired by dual-process theory from neuroscience to enhance stability and improve data utilization efficiency. Specifically, in the first stage, VidMan is pre-trained on the Open X-Embodiment dataset (OXE) for predicting future visual trajectories in a video denoising diffusion manner, enabling the model to develop a long horizontal awareness of the environment's dynamics. In the second stage, a flexible yet effective layer-wise self-attention adapter is introduced to transform VidMan into an efficient inverse dynamics model that predicts action modulated by the implicit dynamics knowledge via parameter sharing. Our VidMan framework outperforms state-of-the-art baseline model GR-1 on the CALVIN benchmark, achieving a 11.7% relative improvement, and demonstrates over 9% precision gains on the OXE small-scale dataset. These results provide compelling evidence that world models can significantly enhance the precision of robot action prediction. Codes and models will be public.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": "Accepted to NeurIPS 2024"
    },
    {
        "paper id": "2411.09168",
        "abstract url": "https://arxiv.org/abs/2411.09168",
        "title": "Theory of Mind Enhances Collective Intelligence",
        "rating": "-1.5",
        "keywords": [
            [
                "psychological"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Collective Intelligence plays a central role in a large variety of fields, from economics and evolutionary theory to neural networks and eusocial insects, and it is also core to much of the work on emergence and self-organisation in complex systems theory. However, in human collective intelligence there is still much more to be understood in the relationship between specific psychological processes at the individual level and the emergence of self-organised structures at the social level. Previously psychological factors have played a relatively minor role in the study of collective intelligence as the principles are often quite general and applicable to humans just as readily as insects or other agents without sophisticated psychologies. In this article we emphasise, with examples from other complex adaptive systems, the broad applicability of collective intelligence principles while the mechanisms and time-scales differ significantly between examples. We contend that flexible collective intelligence in human social settings is improved by our use of a specific cognitive tool: our Theory of Mind. We identify several key characteristics of psychologically mediated collective intelligence and show that the development of a Theory of Mind is a crucial factor distinguishing social collective intelligence from general collective intelligence. We then place these capabilities in the context of the next steps in artificial intelligence embedded in a future that includes an effective human-AI hybrid social ecology.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.CY",
            "cs.GT",
            "nlin.AO"
        ],
        "comment": "20 pages, 2 figures, 1 table"
    },
    {
        "paper id": "2411.09170",
        "abstract url": "https://arxiv.org/abs/2411.09170",
        "title": "Towards Scalable Handwriting Communication via EEG Decoding and Latent Embedding Integration",
        "rating": "-1.5",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, brain-computer interfaces have made advances in decoding various motor-related tasks, including gesture recognition and movement classification, utilizing electroencephalogram (EEG) data. These developments are fundamental in exploring how neural signals can be interpreted to recognize specific physical actions. This study centers on a written alphabet classification task, where we aim to decode EEG signals associated with handwriting. To achieve this, we incorporate hand kinematics to guide the extraction of the consistent embeddings from high-dimensional neural recordings using auxiliary variables (CEBRA). These CEBRA embeddings, along with the EEG, are processed by a parallel convolutional neural network model that extracts features from both data sources simultaneously. The model classifies nine different handwritten characters, including symbols such as exclamation marks and commas, within the alphabet. We evaluate the model using a quantitative five-fold cross-validation approach and explore the structure of the embedding space through visualizations. Our approach achieves a classification accuracy of 91 % for the nine-class task, demonstrating the feasibility of fine-grained handwriting decoding from EEG.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "4 pages, 2 figures, 1 table, Name of Conference: International Conference on Brain-Computer Interface"
    },
    {
        "paper id": "2411.09184",
        "abstract url": "https://arxiv.org/abs/2411.09184",
        "title": "Dynamic technology impact analysis: A multi-task learning approach to patent citation prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "patent"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) models are valuable tools for analyzing the impact of technology using patent citation information. However, existing ML-based methods often struggle to account for the dynamic nature of the technology impact over time and the interdependencies of these impacts across different periods. This study proposes a multi-task learning (MTL) approach to enhance the prediction of technology impact across various time frames by leveraging knowledge sharing and simultaneously monitoring the evolution of technology impact. First, we quantify the technology impacts and identify patterns through citation analysis over distinct time periods. Next, we develop MTL models to predict citation counts using multiple patent indicators over time. Finally, we examine the changes in key input indicators and their patterns over different periods using the SHapley Additive exPlanation method. We also offer guidelines for validating and interpreting the results by employing statistical methods and natural language processing techniques. A case study on battery technologies demonstrates that our approach not only deepens the understanding of technology impact, but also improves prediction accuracy, yielding valuable insights for both academia and industry.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10483",
        "abstract url": "https://arxiv.org/abs/2411.10483",
        "title": "Physics-Informed Neural Networks for Electrical Circuit Analysis: Applications in Dielectric Material Modeling",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Scientific machine learning (SciML) represents a significant advancement in integrating machine learning (ML) with scientific methodologies. At the forefront of this development are Physics-Informed Neural Networks (PINNs), which offer a promising approach by incorporating physical laws directly into the learning process, thereby reducing the need for extensive datasets. However, when data is limited or the system becomes more complex, PINNs can face challenges, such as instability and difficulty in accurately fitting the training data. In this article, we explore the capabilities and limitations of the DeepXDE framework, a tool specifically designed for implementing PINNs, in addressing both forward and inverse problems related to dielectric properties. Using RC circuit models to represent dielectric materials in HVDC systems, we demonstrate the effectiveness of PINNs in analyzing and improving system performance. Additionally, we show that applying a logarithmic transformation to the current (ln(I)) significantly enhances the stability and accuracy of PINN predictions, especially in challenging scenarios with sparse data or complex models. In inverse mode, however, we faced challenges in estimating key system parameters, such as resistance and capacitance, in more complex scenarios with longer time domains. This highlights the potential for future work in improving PINNs through transformations or other methods to enhance performance in inverse problems. This article provides pedagogical insights for those looking to use PINNs in both forward and inverse modes, particularly within the DeepXDE framework.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10486",
        "abstract url": "https://arxiv.org/abs/2411.10486",
        "title": "Artificial Intelligence for Infectious Disease Prediction and Prevention: A Comprehensive Review",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "Health",
                "Disease"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) and infectious diseases prediction have recently experienced a common development and advancement. Machine learning (ML) apparition, along with deep learning (DL) emergence, extended many approaches against diseases apparition and their spread. And despite their outstanding results in predicting infectious diseases, conflicts appeared regarding the types of data used and how they can be studied, analyzed, and exploited using various emerging methods. This has led to some ongoing discussions in the field. This research aims not only to provide an overview of what has been accomplished, but also to highlight the difficulties related to the types of data used, and the learning methods applied for each research objective. It categorizes these contributions into three areas: predictions using Public Health Data to prevent the spread of a transmissible disease within a region; predictions using Patients' Medical Data to detect whether a person is infected by a transmissible disease; and predictions using both Public and patient medical data to estimate the extent of disease spread in a population. The paper also critically assesses the potential of AI and outlines its limitations in infectious disease management.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.PE"
        ],
        "comment": "31 pages, 5 figures, this manuscript has been accepted for publication in ACTA UNIVERSITATIS SAPIENTIAE, Informatica"
    },
    {
        "paper id": "2411.17709",
        "abstract url": "https://arxiv.org/abs/2411.17709",
        "title": "Quantity versus Diversity: Influence of Data on Detecting EEG Pathology with Advanced ML Models",
        "rating": "-1.5",
        "keywords": [
            [
                "Biosignals",
                "EEG",
                "pathological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study investigates the impact of quantity and diversity of data on the performance of various machine-learning models for detecting general EEG pathology. We utilized an EEG dataset of 2,993 recordings from Temple University Hospital and a dataset of 55,787 recordings from Elmiko Biosignals sp. z o.o. The latter contains data from 39 hospitals and a diverse patient set with varied conditions. Thus, we introduce the Elmiko dataset - the largest publicly available EEG corpus. Our findings show that small and consistent datasets enable a wide range of models to achieve high accuracy; however, variations in pathological conditions, recording protocols, and labeling standards lead to significant performance degradation. Nonetheless, increasing the number of available recordings improves predictive accuracy and may even compensate for data diversity, particularly in neural networks based on attention mechanism or transformer architecture. A meta-model that combined these networks with a gradient-boosting approach using handcrafted features demonstrated superior performance across varied datasets.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "comment": "20 pages, 17 figures"
    },
    {
        "paper id": "2411.08353",
        "abstract url": "https://arxiv.org/abs/2411.08353",
        "title": "Everything You Wanted to Know About Consumer Light Management in Smart Energy",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "Consumer lighting plays a significant role in the development of smart cities and smart villages. With the advancement of (IoT) technology, smart lighting solutions have become more prevalent in residential areas as well. These solutions provide consumers with increased energy efficiency, added convenience, and improved security. On the other hand, the growing number of IoT devices has become a global concern due to the carbon footprint and carbon emissions associated with these devices. The overuse of batteries increases maintenance and cost to IoT devices and simultaneously possesses adverse environmental effects, ultimately exacerbating the pace of climate change. Therefore, in tandom with the principles of Industry 4.0, it has become crucial for manufacturing and research industries to prioritize sustainable measures adhering to smart energy as a prevention to the negative impacts. Consequently, it has undoubtedly garnered global interest from scientists, researchers, and industrialists to integrate state-of-the-art technologies in order to solve the current issues in consumer light management systems making it a complete sustainable, and smart solution for consumer lighting application. This manuscript provides a thorough investigation of various methods as well as techniques to design a state-of-the-art IoT-enabled consumer light management system. It critically reviews the existing works done in consumer light management systems, emphasizing the significant limitations and the need for sustainability. The top-down approach of developing sustainable computing frameworks for IoT-enabled consumer light management has been reviewed based on the multidisciplinary technologies involved and state-of-the-art works in the respective domains. Lastly, this article concludes by highlighting possible avenues for future research.",
        "subjects": [
            "cs.AR",
            "cs.ET"
        ],
        "comment": "39 pages, 21 Figures excluding authors' biography"
    },
    {
        "paper id": "2411.08359",
        "abstract url": "https://arxiv.org/abs/2411.08359",
        "title": "MultiKG: Multi-Source Threat Intelligence Aggregation for High-Quality Knowledge Graph Representation of Attack Techniques",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Attack"
            ]
        ],
        "abstract": "The construction of attack technique knowledge graphs aims to transform various types of attack knowledge into structured representations for more effective attack procedure modeling. Existing methods typically rely on textual data, such as Cyber Threat Intelligence (CTI) reports, which are often coarse-grained and unstructured, resulting in incomplete and inaccurate knowledge graphs. To address these issues, we expand attack knowledge sources by incorporating audit logs and static code analysis alongside CTI reports, providing finer-grained data for constructing attack technique knowledge graphs. We propose MultiKG, a fully automated framework that integrates multiple threat knowledge sources. MultiKG processes data from CTI reports, dynamic logs, and static code separately, then merges them into a unified attack knowledge graph. Through system design and the utilization of the Large Language Model (LLM), MultiKG automates the analysis, construction, and merging of attack graphs across these sources, producing a fine-grained, multi-source attack knowledge graph. We implemented MultiKG and evaluated it using 1,015 real attack techniques and 9,006 attack intelligence entries from CTI reports. Results show that MultiKG effectively extracts attack knowledge graphs from diverse sources and aggregates them into accurate, comprehensive representations. Through case studies, we demonstrate that our approach directly benefits security tasks such as attack reconstruction and detection.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "21 pages, 15 figures, 8 tables"
    },
    {
        "paper id": "2411.08373",
        "abstract url": "https://arxiv.org/abs/2411.08373",
        "title": "DG-SLAM: Robust Dynamic Gaussian Splatting SLAM with Hybrid Pose Optimization",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "SLAM"
            ]
        ],
        "abstract": "Achieving robust and precise pose estimation in dynamic scenes is a significant research challenge in Visual Simultaneous Localization and Mapping (SLAM). Recent advancements integrating Gaussian Splatting into SLAM systems have proven effective in creating high-quality renderings using explicit 3D Gaussian models, significantly improving environmental reconstruction fidelity. However, these approaches depend on a static environment assumption and face challenges in dynamic environments due to inconsistent observations of geometry and photometry. To address this problem, we propose DG-SLAM, the first robust dynamic visual SLAM system grounded in 3D Gaussians, which provides precise camera pose estimation alongside high-fidelity reconstructions. Specifically, we propose effective strategies, including motion mask generation, adaptive Gaussian point management, and a hybrid camera tracking algorithm to improve the accuracy and robustness of pose estimation. Extensive experiments demonstrate that DG-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and novel-view synthesis in dynamic scenes, outperforming existing methods meanwhile preserving real-time rendering ability.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08376",
        "abstract url": "https://arxiv.org/abs/2411.08376",
        "title": "Transfer Learning Guided Noise Reduction for Automatic Modulation Classification",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Automatic modulation classification (AMC) has emerged as a key technique in cognitive radio networks in sixth-generation (6G) communications. AMC enables effective data transmission without requiring prior knowledge of modulation schemes. However, the low classification accuracy under the condition of low signal-to-noise ratio (SNR) limits the implementation of AMC techniques under the rapidly changing physical channels in 6G and beyond. This paper investigates the AMC technique for the signals with dynamic and varying SNRs, and a deep learning based noise reduction network is proposed to reduce the noise introduced by the wireless channel and the receiving equipment. In particular, a transfer learning guided learning framework (TNR-AMC) is proposed to utilize the scarce annotated modulation signals and improve the classification accuracy for low SNR modulation signals. The numerical results show that the proposed noise reduction network achieves an accuracy improvement of over 20\\% in low SNR scenarios, and the TNR-AMC framework can improve the classification accuracy under unstable SNRs.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Submitted to ICC 2025"
    },
    {
        "paper id": "2411.08402",
        "abstract url": "https://arxiv.org/abs/2411.08402",
        "title": "V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "LiDAR",
                "Radar",
                "Vehicle"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current Vehicle-to-Everything (V2X) systems have significantly enhanced 3D object detection using LiDAR and camera data. However, these methods suffer from performance degradation in adverse weather conditions. The weatherrobust 4D radar provides Doppler and additional geometric information, raising the possibility of addressing this challenge. To this end, we present V2X-R, the first simulated V2X dataset incorporating LiDAR, camera, and 4D radar. V2X-R contains 12,079 scenarios with 37,727 frames of LiDAR and 4D radar point clouds, 150,908 images, and 170,859 annotated 3D vehicle bounding boxes. Subsequently, we propose a novel cooperative LiDAR-4D radar fusion pipeline for 3D object detection and implement it with various fusion strategies. To achieve weather-robust detection, we additionally propose a Multi-modal Denoising Diffusion (MDD) module in our fusion pipeline. MDD utilizes weather-robust 4D radar feature as a condition to prompt the diffusion model to denoise noisy LiDAR features. Experiments show that our LiDAR-4D radar fusion pipeline demonstrates superior performance in the V2X-R dataset. Over and above this, our MDD module further improved the performance of basic fusion model by up to 5.73%/6.70% in foggy/snowy conditions with barely disrupting normal performance. The dataset and code will be publicly available at: https://github.com/ylwhxht/V2X-R.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08405",
        "abstract url": "https://arxiv.org/abs/2411.08405",
        "title": "An Ising Machine Formulation for Design Updates in Topology Optimization of Flow Channels",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Topology optimization is an essential tool in computational engineering, for example, to improve the design and efficiency of flow channels. At the same time, Ising machines, including digital or quantum annealers, have been used as efficient solvers for combinatorial optimization problems. Beyond combinatorial optimization, recent works have demonstrated applicability to other engineering tasks by tailoring corresponding problem formulations. In this study, we present a novel Ising machine formulation for computing design updates during topology optimization with the goal of minimizing dissipation energy in flow channels. We explore the potential of this approach to improve the efficiency and performance of the optimization process. To this end, we conduct experiments to study the impact of various factors within the novel formulation. Additionally, we compare it to a classical method using the number of optimization steps and the final values of the objective function as indicators of the time intensity of the optimization and the performance of the resulting designs, respectively. Our findings show that the proposed update strategy can accelerate the topology optimization process while producing comparable designs. However, it tends to be less exploratory, which may lead to lower performance of the designs. These results highlight the potential of incorporating Ising formulations for optimization tasks but also show their limitations when used to compute design updates in an iterative optimization process. In conclusion, this work provides an efficient alternative for design updates in topology optimization and enhances the understanding of integrating Ising machine formulations in engineering optimization.",
        "subjects": [
            "cs.CE",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08413",
        "abstract url": "https://arxiv.org/abs/2411.08413",
        "title": "Inference-Aware State Reconstruction for Industrial Metaverse under Synchronous/Asynchronous Short-Packet Transmission",
        "rating": "-2",
        "keywords": [
            [
                "Industrial"
            ]
        ],
        "abstract": "We consider a real-time state reconstruction system for industrial metaverse. The time-varying physical process states in real space are captured by multiple sensors via wireless links, and then reconstructed in virtual space. In this paper, we use the spatial-temporal correlation of the sensor data of interest to infer the real-time data of the target sensor to reduce the mean squared error (MSE) of reconstruction for industrial metaverse under short-packet transmission (SPT). Both synchronous and asynchronous transmission modes for multiple sensors are considered. It is proved that the average MSE of reconstruction and average block error probability (BLEP) have a positive correlation under inference with synchronous transmission scheme, and they have a negative correlation in some conditions under inference with asynchronous transmission scheme. Also, it is proved that the average MSE of reconstruction with inference can be significantly lower than that without inference, even under weak mean squared spatial correlation (MSSC). In addition, closed-form MSSC thresholds are derived for the superiority regions of the inference with synchronous transmission and inference with asynchronous transmission schemes, respectively. Adaptations of blocklength and time shift of asynchronous transmission are conducted to minimize the average MSE of reconstruction. Simulation results show that the two schemes significantly outperform the no inference case, with an average MSE reduction of more than 50%.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08449",
        "abstract url": "https://arxiv.org/abs/2411.08449",
        "title": "Towards Evaluating Large Language Models for Graph Query Generation",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "SQL"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) are revolutionizing the landscape of Generative Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging rapidly. However, when applied to database technologies, specifically query generation for graph databases and Knowledge Graphs (KGs), LLMs still face significant challenges. While research on LLM-driven query generation for Structured Query Language (SQL) exists, similar systems for graph databases remain underdeveloped. This paper presents a comparative study addressing the challenge of generating Cypher queries a powerful language for interacting with graph databases using open-access LLMs. We rigorously evaluate several LLM agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT) reasoning. Our empirical analysis of query generation accuracy reveals that Claude Sonnet 3.5 outperforms its counterparts in this specific domain. Further, we highlight promising future research directions to address the identified limitations and advance LLM-driven query generation for graph databases.",
        "subjects": [
            "cs.ET",
            "cs.CL"
        ],
        "comment": "Paper accepted and will be presented at CSCI2024 in December 2024, Later will be published at Springer LNCS"
    },
    {
        "paper id": "2411.08474",
        "abstract url": "https://arxiv.org/abs/2411.08474",
        "title": "A Cost-effective, Stand-alone, and Real-time TinyML-Based Gait Diagnosis Unit Aimed at Lower-limb Robotic Prostheses and Exoskeletons",
        "rating": "-2",
        "keywords": [
            [
                "medical",
                "Diagnosis"
            ]
        ],
        "abstract": "Robotic prostheses and exoskeletons can do wonders compared to their non-robotic counterpart. However, in a cost-soaring world where 1 in every 10 patients has access to normal medical prostheses, access to advanced ones is, unfortunately, extremely limited especially due to their high cost, a significant portion of which is contributed to by the diagnosis and controlling units. However, affordability is often not a major concern for developing such devices as with cost reduction, performance is also found to be deducted due to the cost vs. performance trade-off. Considering the gravity of such circumstances, the goal of this research was to propose an affordable wearable real-time gait diagnosis unit (GDU) aimed at robotic prostheses and exoskeletons. As a proof of concept, it has also developed the GDU prototype which leveraged TinyML to run two parallel quantized int8 models into an ESP32 NodeMCU development board (7.30 USD) to effectively classify five gait scenarios (idle, walk, run, hopping, and skip) and generate an anomaly score based on acceleration data received from two attached IMUs. The developed wearable gait diagnosis stand-alone unit could be fitted to any prosthesis or exoskeleton and could effectively classify the gait scenarios with an overall accuracy of 92% and provide anomaly scores within 95-96 ms with only 3 seconds of gait data in real-time.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08487",
        "abstract url": "https://arxiv.org/abs/2411.08487",
        "title": "Peak Age of Incorrect Information of Reactive ALOHA Reporting Under Imperfect Feedback",
        "rating": "-2",
        "keywords": [
            [
                "medical"
            ]
        ],
        "abstract": "Age of Incorrect Information (AoII) is particularly relevant in systems where real time responses to anomalies are required, such as natural disaster alerts, cybersecurity warnings, or medical emergency notifications. Keeping system control with wrong information for too long can lead to inappropriate responses. In this paper, we study the Peak AoII (PAoII) for multi-source status reporting by independent devices over a collision channel, following a zero-threshold ALOHA access where nodes observing an anomaly immediately start transmitting about it. If a collision occurs, nodes reduce the transmission probability to allow for a resolution. Finally, wrong or lost feedback messages may lead a node that successfully updated the destination to believe a collision happened. The PAoII for this scenario is computed in closed-form. We are eventually able to derive interesting results concerning the minimization of PAoII, which can be traded against the overall goodput and energy efficiency, but may push the system to the edge of congestion collapse.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Submitted for publication to the IEEE International Conference on Communications (ICC) 2025"
    },
    {
        "paper id": "2411.08529",
        "abstract url": "https://arxiv.org/abs/2411.08529",
        "title": "Towards Practical Deep Schedulers for Allocating Cellular Radio Resources",
        "rating": "-2",
        "keywords": [
            [
                "5G"
            ]
        ],
        "abstract": "Machine learning methods are often suggested to address wireless network functions, such as radio packet scheduling. However, a feasible 3GPP-compliant scheduler capable of delivering fair throughput across users, while keeping a low computational complexity for 5G and beyond is still missing. To address this, we first take a critical look at previous deep scheduler efforts. Secondly, we enhance State-of-the-Art (SoTA) deep Reinforcement Learning (RL) algorithms and adapt them to train our deep scheduler. In particular, we propose novel training techniques for Proximal Policy Optimization (PPO) and a new Distributional Soft Actor-Critic Discrete (DSACD) algorithm, which outperformed other tested variants. These improvements were achieved while maintaining minimal actor network complexity, making them suitable for real-time computing environments. Additionally, the entropy learning in SACD was fine-tuned to accommodate resource allocation action spaces of varying sizes. Our proposed deep schedulers exhibited strong generalization across different bandwidths, number of MU-MIMO layers, and traffic models. Ultimately, we show that our pre-trained deep schedulers outperform their heuristic rivals in realistic and standard-compliant 5G system-level simulations.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08570",
        "abstract url": "https://arxiv.org/abs/2411.08570",
        "title": "Electromagnetic Modeling and Capacity Analysis of Rydberg Atom-Based MIMO System",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Rydberg atom-based antennas exploit the quantum properties of highly excited Rydberg atoms, providing unique advantages over classical antennas, such as high sensitivity, broad frequency range, and compact size. Despite the increasing interests in their applications in antenna and communication engineering, two key properties, involving the lack of polarization multiplexing and isotropic reception without mutual coupling, remain unexplored in the analysis of Rydberg atom-based spatial multiplexing, i.e., multiple-input and multiple-output (MIMO), communications. Generally, the design considerations for any antenna, even for atomic ones, can be extracted to factors such as radiation patterns, efficiency, and polarization, allowing them to be seamlessly integrated into existing system models. In this letter, we extract the antenna properties from relevant quantum characteristics, enabling electromagnetic modeling and capacity analysis of Rydberg MIMO systems in both far-field and near-field scenarios. By employing ray-based method for far-field analysis and dyadic Green's function for near-field calculation, our results indicate that Rydberg atom-based antenna arrays offer specific advantages over classical dipole-type arrays in single-polarization MIMO communications.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08579",
        "abstract url": "https://arxiv.org/abs/2411.08579",
        "title": "NavAgent: Multi-scale Urban Street View Fusion For UAV Embodied Vision-and-Language Navigation",
        "rating": "-2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "robot",
                "Navigation"
            ],
            [
                "Graph"
            ],
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Vision-and-Language Navigation (VLN), as a widely discussed research direction in embodied intelligence, aims to enable embodied agents to navigate in complicated visual environments through natural language commands. Most existing VLN methods focus on indoor ground robot scenarios. However, when applied to UAV VLN in outdoor urban scenes, it faces two significant challenges. First, urban scenes contain numerous objects, which makes it challenging to match fine-grained landmarks in images with complex textual descriptions of these landmarks. Second, overall environmental information encompasses multiple modal dimensions, and the diversity of representations significantly increases the complexity of the encoding process. To address these challenges, we propose NavAgent, the first urban UAV embodied navigation model driven by a large Vision-Language Model. NavAgent undertakes navigation tasks by synthesizing multi-scale environmental information, including topological maps (global), panoramas (medium), and fine-grained landmarks (local). Specifically, we utilize GLIP to build a visual recognizer for landmark capable of identifying and linguisticizing fine-grained landmarks. Subsequently, we develop dynamically growing scene topology map that integrate environmental information and employ Graph Convolutional Networks to encode global environmental data. In addition, to train the visual recognizer for landmark, we develop NavAgent-Landmark2K, the first fine-grained landmark dataset for real urban street scenes. In experiments conducted on the Touchdown and Map2seq datasets, NavAgent outperforms strong baseline models. The code and dataset will be released to the community to facilitate the exploration and development of outdoor VLN.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08592",
        "abstract url": "https://arxiv.org/abs/2411.08592",
        "title": "Slender Object Scene Segmentation in Remote Sensing Image Based on Learnable Morphological Skeleton with Segment Anything Model",
        "rating": "-2",
        "keywords": [
            [
                "Skeleton"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Morphological methods play a crucial role in remote sensing image processing, due to their ability to capture and preserve small structural details. However, most of the existing deep learning models for semantic segmentation are based on the encoder-decoder architecture including U-net and Segment Anything Model (SAM), where the downsampling process tends to discard fine details. In this paper, we propose a new approach that integrates learnable morphological skeleton prior into deep neural networks using the variational method. To address the difficulty in backpropagation in neural networks caused by the non-differentiability presented in classical morphological operations, we provide a smooth representation of the morphological skeleton and design a variational segmentation model integrating morphological skeleton prior by employing operator splitting and dual methods. Then, we integrate this model into the network architecture of SAM, which is achieved by adding a token to mask decoder and modifying the final sigmoid layer, ensuring the final segmentation results preserve the skeleton structure as much as possible. Experimental results on remote sensing datasets, including buildings and roads, demonstrate that our method outperforms the original SAM on slender object segmentation and exhibits better generalization capability.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08616",
        "abstract url": "https://arxiv.org/abs/2411.08616",
        "title": "Multiplexed bi-layered realization of fault-tolerant quantum computation over optically networked trapped-ion modules",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We study an architecture for fault-tolerant measurement-based quantum computation (FT-MBQC) over optically-networked trapped-ion modules. The architecture is implemented with a finite number of modules and ions per module, and leverages photonic interactions for generating remote entanglement between modules and local Coulomb interactions for intra-modular entangling gates. We focus on generating the topologically protected Raussendorf-Harrington-Goyal (RHG) lattice cluster state, which is known to be robust against lattice bond failures and qubit noise, with the modules acting as lattice sites. To ensure that the remote entanglement generation rates surpass the bond-failure tolerance threshold of the RHG lattice, we employ spatial and temporal multiplexing. For realistic system timing parameters, we estimate the code cycle time of the RHG lattice and the ion resources required in a bi-layered implementation, where the number of modules matches the number of sites in two lattice layers, and qubits are reinitialized after measurement. For large distances between modules, we incorporate quantum repeaters between sites and analyze the benefits in terms of cumulative resource requirements. Finally, we derive and analyze a qubit noise-tolerance threshold inequality for the RHG lattice generation in the proposed architecture that accounts for noise from various sources. This includes the depolarizing noise arising from the photonically-mediated remote entanglement generation between modules due to finite optical detection efficiency, limited visibility, and the presence of dark clicks, in addition to the noise from imperfect gates and measurements, and memory decoherence with time. Our work thus underscores the hardware and channel threshold requirements to realize distributed FT-MBQC in a leading qubit platform today -- trapped ions.",
        "subjects": [
            "quant-ph",
            "cs.DC"
        ],
        "comment": "20 pages, 19 figures"
    },
    {
        "paper id": "2411.08648",
        "abstract url": "https://arxiv.org/abs/2411.08648",
        "title": "Diagnosing Refactoring Dangers",
        "rating": "-2",
        "keywords": [
            [
                "Diagnosing"
            ]
        ],
        "abstract": "This report investigates the relationship between software refactoring and behavior preservation. Existing behavior preservation analyses often lack comprehensive insights into refactoring rejections and do not provide actionable solutions. To address these issues, we developed a conceptual model to detect refactoring dangers, and created an Eclipse plugin based upon this model, called ReFD. Every refactoring can be partitioned in microsteps, each of which carries potential risks. ReFD evaluates a given code context to identify if these potential risks are present, making them actual risks, and employs a verdict mechanism to reduce false positives. To facilitate the risk detection, several components called detectors and subdetectors are defined, which can be reused for multiple refactorings. The tool was validated by implementing the detection for multiple refactorings, which produce the expected information about the risks detected. This information leads a developer to actively think about solutions to the problems a refactoring might cause within an actual codebase.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "35 pages, 19 figures"
    },
    {
        "paper id": "2411.08663",
        "abstract url": "https://arxiv.org/abs/2411.08663",
        "title": "Toward Human Understanding with Controllable Synthesis",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Training methods to perform robust 3D human pose and shape (HPS) estimation requires diverse training images with accurate ground truth. While BEDLAM demonstrates the potential of traditional procedural graphics to generate such data, the training images are clearly synthetic. In contrast, generative image models produce highly realistic images but without ground truth. Putting these methods together seems straightforward: use a generative model with the body ground truth as controlling signal. However, we find that, the more realistic the generated images, the more they deviate from the ground truth, making them inappropriate for training and evaluation. Enhancements of realistic details, such as clothing and facial expressions, can lead to subtle yet significant deviations from the ground truth, potentially misleading training models. We empirically verify that this misalignment causes the accuracy of HPS networks to decline when trained with generated images. To address this, we design a controllable synthesis method that effectively balances image realism with precise ground truth. We use this to create the Generative BEDLAM (Gen-B) dataset, which improves the realism of the existing synthetic BEDLAM dataset while preserving ground truth accuracy. We perform extensive experiments, with various noise-conditioning strategies, to evaluate the tradeoff between visual realism and HPS accuracy. We show, for the first time, that generative image models can be controlled by traditional graphics methods to produce training data that increases the accuracy of HPS methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08665",
        "abstract url": "https://arxiv.org/abs/2411.08665",
        "title": "OSMLoc: Single Image-Based Visual Localization in OpenStreetMap with Geometric and Semantic Guidances",
        "rating": "-2",
        "keywords": [
            [
                "depth"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "OpenStreetMap (OSM), an online and versatile source of volunteered geographic information (VGI), is widely used for human self-localization by matching nearby visual observations with vectorized map data. However, due to the divergence in modalities and views, image-to-OSM (I2O) matching and localization remain challenging for robots, preventing the full utilization of VGI data in the unmanned ground vehicles and logistic industry. Inspired by the fact that the human brain relies on geometric and semantic understanding of sensory information for spatial localization tasks, we propose the OSMLoc in this paper. OSMLoc is a brain-inspired single-image visual localization method with semantic and geometric guidance to improve accuracy, robustness, and generalization ability. First, we equip the OSMLoc with the visual foundational model to extract powerful image features. Second, a geometry-guided depth distribution adapter is proposed to bridge the monocular depth estimation and camera-to-BEV transform. Thirdly, the semantic embeddings from the OSM data are utilized as auxiliary guidance for image-to-OSM feature matching. To validate the proposed OSMLoc, we collect a worldwide cross-area and cross-condition (CC) benchmark for extensive evaluation. Experiments on the MGL dataset, CC validation benchmark, and KITTI dataset have demonstrated the superiority of our method. Code, pre-trained models, CC validation benchmark, and additional results are available on: https://github.com/WHU-USI3DV/OSMLoc",
        "subjects": [
            "cs.CV"
        ],
        "comment": "15 pages, technical report"
    },
    {
        "paper id": "2411.08712",
        "abstract url": "https://arxiv.org/abs/2411.08712",
        "title": "High-resolution optical and acoustic remote sensing datasets of the Puck Lagoon, Southern Baltic",
        "rating": "-2",
        "keywords": [
            [
                "LiDAR"
            ],
            [
                "remote sensing",
                "satellite",
                "seafloor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The very shallow marine basin of Puck Lagoon in the southern Baltic Sea, on the Northern coast of Poland, hosts valuable benthic habitats and cultural heritage sites. These include, among others, protected Zostera marina meadows, one of the Baltic's major medieval harbours, a ship graveyard, and likely other submerged features that are yet to be discovered. Prior to this project, no comprehensive high-resolution remote sensing data were available for this area. This article describes the first Digital Elevation Models (DEMs) derived from a combination of airborne bathymetric LiDAR, multibeam echosounder, airborne photogrammetry and satellite imagery. These datasets also include multibeam echosounder backscatter and LiDAR intensity, allowing determination of the character and properties of the seafloor. Combined, these datasets are a vital resource for assessing and understanding seafloor morphology, benthic habitats, cultural heritage, and submerged landscapes. Given the significance of Puck Lagoon's hydrographical, ecological, geological, and archaeological environs, the high-resolution bathymetry, acquired by our project, can provide the foundation for sustainable management and informed decision-making for this area of interest.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08777",
        "abstract url": "https://arxiv.org/abs/2411.08777",
        "title": "LUDO: Low-Latency Understanding of Highly Deformable Objects using Point Cloud Occupancy Functions",
        "rating": "-2",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "biopsies",
                "medical",
                "surgical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurately determining the shape and location of internal structures within deformable objects is crucial for medical tasks that require precise targeting, such as robotic biopsies. We introduce LUDO, a method for accurate low-latency understanding of deformable objects. LUDO reconstructs objects in their deformed state, including their internal structures, from a single-view point cloud observation in under 30 ms using occupancy networks. We demonstrate LUDO's abilities for autonomous targeting of internal regions of interest (ROIs) in highly deformable objects. Additionally, LUDO provides uncertainty estimates and explainability for its predictions, both of which are important in safety-critical applications such as surgical interventions. We evaluate LUDO in real-world robotic experiments, achieving a success rate of 98.9% for puncturing various ROIs inside highly deformable objects. LUDO demonstrates the potential to interact with deformable objects without the need for deformable registration methods.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08792",
        "abstract url": "https://arxiv.org/abs/2411.08792",
        "title": "An alignment problem",
        "rating": "-2",
        "keywords": [
            [
                "disease"
            ]
        ],
        "abstract": "This work concerns an alignment problem that has applications in many geospatial problems such as resource allocation and building reliable disease maps. Here, we introduce the problem of optimally aligning $k$ collections of $m$ spatial supports over $n$ spatial units in a $d$-dimensional Euclidean space. We show that the 1-dimensional case is solvable in time polynomial in $k$, $m$ and $n$. We then show that the 2-dimensional case is NP-hard for 2 collections of 2 supports. Finally, we devise a heuristic for aligning a set of collections in the 2-dimensional case.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08819",
        "abstract url": "https://arxiv.org/abs/2411.08819",
        "title": "Bilateral Signal Warping for Left Ventricular Hypertrophy Diagnosis",
        "rating": "-2",
        "keywords": [
            [
                "Diagnosis",
                "clinical",
                "cardiac"
            ]
        ],
        "abstract": "Left Ventricular Hypertrophy (LVH) is a major cardiovascular risk factor, linked to heart failure, arrhythmia, and sudden cardiac death, often resulting from chronic stress like hypertension. Electrocardiography (ECG), while varying in sensitivity, is widely accessible and cost-effective for detecting LVH-related morphological changes. This work introduces a bilateral signal warping (BSW) approach to improve ECG-based LVH diagnosis. Our method creates a library of heartbeat prototypes from patients with consistent ECG patterns. After preprocessing to eliminate baseline wander and detect R peaks, we apply BSW to cluster heartbeats, generating prototypes for both normal and LVH classes. We compare each new record to these references to support diagnosis. Experimental results show promising potential for practical application in clinical settings.",
        "subjects": [
            "eess.SP",
            "physics.med-ph"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2411.08822",
        "abstract url": "https://arxiv.org/abs/2411.08822",
        "title": "A probabilistic reduced-order modeling framework for patient-specific cardio-mechanical analysis",
        "rating": "-2",
        "keywords": [
            [
                "clinical",
                "cardiac"
            ]
        ],
        "abstract": "Cardio-mechanical models can be used to support clinical decision-making. Unfortunately, the substantial computational effort involved in many cardiac models hinders their application in the clinic, despite the fact that they may provide valuable information. In this work, we present a probabilistic reduced-order modeling (ROM) framework to dramatically reduce the computational effort of such models while providing a credibility interval. In the online stage, a fast-to-evaluate generalized one-fiber model is considered. This generalized one-fiber model incorporates correction factors to emulate patient-specific attributes, such as local geometry variations. In the offline stage, Bayesian inference is used to calibrate these correction factors on training data generated using a full-order isogeometric cardiac model (FOM). A Gaussian process is used in the online stage to predict the correction factors for geometries that are not in the training data. The proposed framework is demonstrated using two examples. The first example considers idealized left-ventricle geometries, for which the behavior of the ROM framework can be studied in detail. In the second example, the ROM framework is applied to scan-based geometries, based on which the application of the ROM framework in the clinical setting is discussed. The results for the two examples convey that the ROM framework can provide accurate online predictions, provided that adequate FOM training data is available. The uncertainty bands provided by the ROM framework give insight into the trustworthiness of its results. Large uncertainty bands can be considered as an indicator for the further population of the training data set.",
        "subjects": [
            "cs.CE",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08860",
        "abstract url": "https://arxiv.org/abs/2411.08860",
        "title": "How NOT to Fool the Masses When Giving Performance Results for Quantum Computers",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "In 1991, David Bailey wrote an article describing techniques for overstating the performance of massively parallel computers. Intended as a lighthearted protest against the practice of inflating benchmark results in order to ``fool the masses\" and boost sales, the paper sparked development of procedural standards that help benchmarkers avoid methodological errors leading to unjustified and misleading conclusions. Now that quantum computers are starting to realize their potential as viable alternatives to classical computers, we can see the mistakes of three decades ago being repeated by a new batch of researchers who are unfamiliar with this history and these standards. Inspired by Bailey's model, this paper presents four suggestions for newcomers to quantum performance benchmarking, about how not to do it. They are: (1) Don't claim superior performance without mentioning runtimes; (2) Don't report optimized results without mentioning the tuning time needed to optimize those results; (3) Don't claim faster runtimes for (or in comparison to) solvers running on imaginary platforms; and (4) No cherry-picking (without justification and qualification). Suggestions for improving current practice appear in the last section.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": "14 pages; 17 pages including references"
    },
    {
        "paper id": "2411.09020",
        "abstract url": "https://arxiv.org/abs/2411.09020",
        "title": "Predictive Visuo-Tactile Interactive Perception Framework for Object Properties Inference",
        "rating": "-2",
        "keywords": [
            [
                "robot"
            ],
            [
                "Graph"
            ]
        ],
        "abstract": "Interactive exploration of the unknown physical properties of objects such as stiffness, mass, center of mass, friction coefficient, and shape is crucial for autonomous robotic systems operating continuously in unstructured environments. Precise identification of these properties is essential to manipulate objects in a stable and controlled way, and is also required to anticipate the outcomes of (prehensile or non-prehensile) manipulation actions such as pushing, pulling, lifting, etc. Our study focuses on autonomously inferring the physical properties of a diverse set of various homogeneous, heterogeneous, and articulated objects utilizing a robotic system equipped with vision and tactile sensors. We propose a novel predictive perception framework for identifying object properties of the diverse objects by leveraging versatile exploratory actions: non-prehensile pushing and prehensile pulling. As part of the framework, we propose a novel active shape perception to seamlessly initiate exploration. Our innovative dual differentiable filtering with Graph Neural Networks learns the object-robot interaction and performs consistent inference of indirectly observable time-invariant object properties. In addition, we formulate a $N$-step information gain approach to actively select the most informative actions for efficient learning and inference. Extensive real-robot experiments with planar objects show that our predictive perception framework results in better performance than the state-of-the-art baseline and demonstrate our framework in three major applications for i) object tracking, ii) goal-driven task, and iii) change in environment detection.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09023",
        "abstract url": "https://arxiv.org/abs/2411.09023",
        "title": "CoMiX: Cross-Modal Fusion with Deformable Convolutions for HSI-X Semantic Segmentation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "hyperspectral image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Improving hyperspectral image (HSI) semantic segmentation by exploiting complementary information from a supplementary data type (referred to X-modality) is promising but challenging due to differences in imaging sensors, image content, and resolution. Current techniques struggle to enhance modality-specific and modality-shared information, as well as to capture dynamic interaction and fusion between different modalities. In response, this study proposes CoMiX, an asymmetric encoder-decoder architecture with deformable convolutions (DCNs) for HSI-X semantic segmentation. CoMiX is designed to extract, calibrate, and fuse information from HSI and X data. Its pipeline includes an encoder with two parallel and interacting backbones and a lightweight all-multilayer perceptron (ALL-MLP) decoder. The encoder consists of four stages, each incorporating 2D DCN blocks for the X model to accommodate geometric variations and 3D DCN blocks for HSIs to adaptively aggregate spatial-spectral features. Additionally, each stage includes a Cross-Modality Feature enhancement and eXchange (CMFeX) module and a feature fusion module (FFM). CMFeX is designed to exploit spatial-spectral correlations from different modalities to recalibrate and enhance modality-specific and modality-shared features while adaptively exchanging complementary information between them. Outputs from CMFeX are fed into the FFM for fusion and passed to the next stage for further information learning. Finally, the outputs from each FFM are integrated by the ALL-MLP decoder for final prediction. Extensive experiments demonstrate that our CoMiX achieves superior performance and generalizes well to various multimodal recognition tasks. The CoMiX code will be released.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09062",
        "abstract url": "https://arxiv.org/abs/2411.09062",
        "title": "Multimodal Object Detection using Depth and Image Data for Manufacturing Parts",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "point cloud",
                "Depth"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Manufacturing requires reliable object detection methods for precise picking and handling of diverse types of manufacturing parts and components. Traditional object detection methods utilize either only 2D images from cameras or 3D data from lidars or similar 3D sensors. However, each of these sensors have weaknesses and limitations. Cameras do not have depth perception and 3D sensors typically do not carry color information. These weaknesses can undermine the reliability and robustness of industrial manufacturing systems. To address these challenges, this work proposes a multi-sensor system combining an red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are calibrated for precise alignment of the multimodal data captured from the two hardware devices. A novel multimodal object detection method is developed to process both RGB and depth data. This object detector is based on the Faster R-CNN baseline that was originally designed to process only camera images. The results show that the multimodal model significantly outperforms the depth-only and RGB-only baselines on established object detection metrics. More specifically, the multimodal model improves mAP by 13% and raises Mean Precision by 11.8% in comparison to the RGB-only baseline. Compared to the depth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%. Hence, this method facilitates more reliable and robust object detection in service to smart manufacturing applications.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09121",
        "abstract url": "https://arxiv.org/abs/2411.09121",
        "title": "AutoQ 2.0: From Verification of Quantum Circuits to Verification of Quantum Programs",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "We present a verifier of quantum programs called AutoQ 2.0. Quantum programs extend quantum circuits (the domain of AutoQ 1.0) by classical control flow constructs, which enable users to describe advanced quantum algorithms in a formal and precise manner. The extension is highly non-trivial, as we needed to tackle both theoretical challenges (such as the treatment of measurement, the normalization problem, and lifting techniques for verification of classical programs with loops to the quantum world), and engineering issues (such as extending the input format with a~support for specifying loop invariants). We have successfully used AutoQ 2.0 to verify two types of advanced quantum programs that cannot be expressed using only quantum circuits: the \\emph{repeat-until-success} (RUS) algorithm and the weak-measurement-based version of Grover's search algorithm. AutoQ 2.0 can efficiently verify all our benchmarks: all RUS algorithms were verified instantly and, for the weak-measurement-based version of Grover's search, we were able to handle the case of 100 qubits in $\\sim$20 minutes.",
        "subjects": [
            "cs.LO",
            "cs.FL"
        ],
        "comment": "regular tool paper submitted to TACAS 2025"
    },
    {
        "paper id": "2411.09128",
        "abstract url": "https://arxiv.org/abs/2411.09128",
        "title": "Performance Analysis of uRLLC in scalable Cell-free RAN System",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "As an essential part of mobile communication systems that beyond the fifth generation (B5G) and sixth generation (6G), ultra reliable low latency communication (uRLLC) places strict requirements on latency and reliability. In recent years, with the improvement of mobile communication network performance, centralized and distributed processing of cell-free mMIMO has been widely studied, and wireless access networks (RAN) have also become a widely studied topic in academia. This paper analyzes the performance of a novel scalable cell-free RAN (CF-RAN) architecture with multiple edge distributed units (EDUs) in the scenario of finite block length. The upper and lower bounds on its spectral efficiency (SE) performance are derived, and the complete set's formula and distributed processing can be used as their two exceptional cases, respectively. Secondly, the paper further considers the distribution of users and large-scale fading models and studies the position distribution of remote radio units (RRUs). It is found that a uniform distribution of RRUs is beneficial for improving the SE of finite block length under specific error rate performance, and RRUs need to be interwoven as much as possible under multiple EDUs. This is different from traditional multi-node clustering centralized collaborative processing. The paper compares the performance of Monte Carlo simulation and multi-RRU clustering group collaborative processing. At the same time, this article verifies the accuracy of the space-time exchange theory in the CF-RAN scenario. Through scalable EDU deployment, a trade-off between latency and reliability can be achieved in practical systems and exchanged with spatial degrees of freedom. This implementation can be seen as a distributed and scalable implementation of the space-time exchange theory.",
        "subjects": [
            "cs.IT",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09130",
        "abstract url": "https://arxiv.org/abs/2411.09130",
        "title": "Analysis and Optimization of Multiple-STAR-RIS Assisted MIMO-NOMA with GSVD Precoding: An Operator-Valued Free Probability Approach",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Among the key enabling 6G techniques, multiple-input multiple-output (MIMO) and non-orthogonal multiple-access (NOMA) play an important role in enhancing the spectral efficiency of the wireless communication systems. To further extend the coverage and the capacity, the simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) has recently emerged out as a cost-effective technology. To exploit the benefit of STAR-RIS in the MIMO-NOMA systems, in this paper, we investigate the analysis and optimization of the downlink dual-user MIMO-NOMA systems assisted by multiple STAR-RISs under the generalized singular value decomposition (GSVD) precoding scheme, in which the channel is assumed to be Rician faded with the Weichselberger's correlation structure. To analyze the asymptotic information rate of the users, we apply the operator-valued free probability theory to obtain the Cauchy transform of the generalized singular values (GSVs) of the MIMO-NOMA channel matrices, which can be used to obtain the information rate by Riemann integral. Then, considering the special case when the channels between the BS and the STAR-RISs are deterministic, we obtain the closed-form expression for the asymptotic information rates of the users. Furthermore, a projected gradient ascent method (PGAM) is proposed with the derived closed-form expression to design the STAR-RISs thereby maximizing the sum rate based on the statistical channel state information. The numerical results show the accuracy of the asymptotic expression compared to the Monte Carlo simulations and the superiority of the proposed PGAM algorithm.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09155",
        "abstract url": "https://arxiv.org/abs/2411.09155",
        "title": "Performance Boundaries and Tradeoffs in Super-Resolution Imaging Technologies for Space Targets",
        "rating": "-2",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "radar"
            ]
        ],
        "abstract": "Inverse synthetic aperture radar (ISAR) super-resolution imaging technology is widely applied in space target imaging. However, the performance limits of super-resolution imaging algorithms remain a rarely explored issue. This paper investigates these limits by analyzing the boundaries of super-resolution algorithms for space targets and examines the relationships between key contributing factors. In particular, drawing on the established mathematical theory of computational resolution limits (CRL) for line spectrum reconstruction, we derive mathematical expressions for the upper and lower bounds of cross-range super-resolution imaging, based on ISAR imaging model transformations. Leveraging the explicit expressions, we first explore influencing factors of these bounds, such as the traditional Rayleigh limit, the number of scatterers, and the peak signal-to-noise ratio (PSNR) of scatterers. Then we elucidate the minimum resource requirements in ISAR imaging imposed by the CRL theory to meet the desired cross-range resolution, without which studying super-resolution algorithms becomes unnecessary in practice. Furthermore, the tradeoffs between the cumulative rotation angle, the radar transmit energy, and other contributing factors in optimizing the resolution are analyzed. Simulations are conducted to demonstrate these tradeoffs across various ISAR imaging scenarios, revealing their high dependence on specific imaging targets.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09173",
        "abstract url": "https://arxiv.org/abs/2411.09173",
        "title": "Correction of circuit faults in a stacked quantum memory using rank-metric codes",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "We introduce a model for a stacked quantum memory made with multi-qubit cells, inspired by multi-level flash cells in classical solid-state drive, and we design quantum error correction codes for this model by generalizing rank-metric codes to the quantum setting. Rank-metric codes are used to correct faulty links in classical communication networks. We propose a quantum generalization of Gabidulin codes, which is one of the most popular family of rank-metric codes, and we design a protocol to correct faults in Clifford circuits applied to a stacked quantum memory based on these codes. We envision potential applications to the optimization of stabilizer states and magic states factories, and to variational quantum algorithms. Further work is needed to make this protocol practical. It requires a hardware platform capable of hosting multi-qubit cells with low crosstalk between cells, a fault-tolerant syndrome extraction circuit for rank-metric codes and an associated efficient decoder.",
        "subjects": [
            "quant-ph",
            "cs.IT"
        ],
        "comment": "6 pages, 1 figure"
    },
    {
        "paper id": "2411.09177",
        "abstract url": "https://arxiv.org/abs/2411.09177",
        "title": "Enhancing reinforcement learning for population setpoint tracking in co-cultures",
        "rating": "-2",
        "keywords": [
            [
                "biotechnological"
            ]
        ],
        "abstract": "Efficient multiple setpoint tracking can enable advanced biotechnological applications, such as maintaining desired population levels in co-cultures for optimal metabolic division of labor. In this study, we employ reinforcement learning as a control method for population setpoint tracking in co-cultures, focusing on policy-gradient techniques where the control policy is parameterized by neural networks. However, achieving accurate tracking across multiple setpoints is a significant challenge in reinforcement learning, as the agent must effectively balance the contributions of various setpoints to maximize the expected system performance. Traditional return functions, such as those based on a quadratic cost, often yield suboptimal performance due to their inability to efficiently guide the agent toward the simultaneous satisfaction of all setpoints. To overcome this, we propose a novel return function that rewards the simultaneous satisfaction of multiple setpoints and diminishes overall reward gains otherwise, accounting for both stage and terminal system performance. This return function includes parameters to fine-tune the desired smoothness and steepness of the learning process. We demonstrate our approach considering an $\\textit{Escherichia coli}$ co-culture in a chemostat with optogenetic control over amino acid synthesis pathways, leveraging auxotrophies to modulate growth.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09433",
        "abstract url": "https://arxiv.org/abs/2411.09433",
        "title": "Field-based Security Testing of SDN configuration Updates",
        "rating": "-2",
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "Software-defined systems revolutionized the management of hardware devices but introduced quality assurance challenges that remain to be tackled. For example, software defined networks (SDNs) became a key technology for the prompt reconfigurations of network services in many sectors including telecommunications, data centers, financial services, cloud providers, and manufacturing industry. Unfortunately, reconfigurations may lead to mistakes that compromise the dependability of the provided services. In this paper, we focus on the reconfigurations of network services in the satellite communication sector, and target security requirements, which are often hard to verify; for example, although connectivity may function properly, confidentiality may be broken by packets forwarded to a wrong destination. We propose an approach for FIeld-based Security Testing of SDN Configurations Updates (FISTS). First, it probes the network before and after configuration updates. Then, using the collected data, it relies on unsupervised machine learning algorithms to prioritize the inspection of suspicious node responses, after identifying the network nodes that likely match across the two configurations. Our empirical evaluation has been conducted with network data from simulated and real SDN configuration updates for our industry partner, a world-leading satellite operator. Our results show that, when combined with K-Nearest Neighbour, FISTS leads to best results (up to 0.95 precision and 1.00 recall). Further, we demonstrated its scalability.",
        "subjects": [
            "cs.SE",
            "cs.NI"
        ],
        "comment": "9 Figures, 6 Tables, 1 Algorithm"
    },
    {
        "paper id": "2411.10485",
        "abstract url": "https://arxiv.org/abs/2411.10485",
        "title": "Gait Kinematics in Healthy Participants: A Motion Capture Dataset Under Weight Load and Knee Brace Conditions",
        "rating": "-2",
        "keywords": [
            [
                "health",
                "clinical"
            ]
        ],
        "abstract": "The objective assessment of gait kinematics is crucial in evaluating human movement, informing clinical decisions, and advancing rehabilitation and assistive technologies. Assessing gait symmetry, in particular, holds significant importance in clinical rehabilitation, as it reflects the intricate coordination between nerves and muscles during human walking. In this research, a dataset has been compiled to improve the understanding of gait kinematics. The dataset encompasses motion capture data of the walking patterns of eleven healthy participants who were tasked with completing various activities on a circular path. These activities included normal walking, walking with a weighted dominant hand, walking with a braced dominant leg, and walking with both weight and brace. The walking tasks involving weight and brace were designed to emulate the asymmetry associated with common health conditions, shedding light on irregularities in individuals' walking patterns and reflecting the coordination between nerves and muscles. All tasks were performed at regular and fast speeds, offering valuable insights into upper and lower body kinematics. The dataset comprises raw sensor data, providing information on joint dynamics, angular velocities, and orientation changes during walking, as well as analyzed data, including processed data, Euler angles, and joint kinematics spanning various body segments. This dataset will serve as a valuable resource for researchers, clinicians, and engineers, facilitating the analysis of gait patterns and extracting relevant indices on mobility and balance.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "All datasets generated during the current study are publicly available on figshare (doi:10.6084/m9.figshare.26090200.v1.)"
    },
    {
        "paper id": "2411.08378",
        "abstract url": "https://arxiv.org/abs/2411.08378",
        "title": "Physics Informed Distillation for Diffusion Models",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Diffusion models have recently emerged as a potent tool in generative modeling. However, their inherent iterative nature often results in sluggish image generation due to the requirement for multiple model evaluations. Recent progress has unveiled the intrinsic link between diffusion models and Probability Flow Ordinary Differential Equations (ODEs), thus enabling us to conceptualize diffusion models as ODE systems. Simultaneously, Physics Informed Neural Networks (PINNs) have substantiated their effectiveness in solving intricate differential equations through implicit modeling of their solutions. Building upon these foundational insights, we introduce Physics Informed Distillation (PID), which employs a student model to represent the solution of the ODE system corresponding to the teacher diffusion model, akin to the principles employed in PINNs. Through experiments on CIFAR 10 and ImageNet 64x64, we observe that PID achieves performance comparable to recent distillation methods. Notably, it demonstrates predictable trends concerning method-specific hyperparameters and eliminates the need for synthetic dataset generation during the distillation process. Both of which contribute to its easy-to-use nature as a distillation approach for Diffusion Models. Our code and pre-trained checkpoint are publicly available at: https://github.com/pantheon5100/pid_diffusion.git.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08392",
        "abstract url": "https://arxiv.org/abs/2411.08392",
        "title": "RLInspect: An Interactive Visual Approach to Assess Reinforcement Learning Algorithm",
        "rating": "-2.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Reinforcement Learning (RL) is a rapidly growing area of machine learning that finds its application in a broad range of domains, from finance and healthcare to robotics and gaming. Compared to other machine learning techniques, RL agents learn from their own experiences using trial and error, and improve their performance over time. However, assessing RL models can be challenging, which makes it difficult to interpret their behaviour. While reward is a widely used metric to evaluate RL models, it may not always provide an accurate measure of training performance. In some cases, the reward may seem increasing while the model's performance is actually decreasing, leading to misleading conclusions about the effectiveness of the training. To overcome this limitation, we have developed RLInspect - an interactive visual analytic tool, that takes into account different components of the RL model - state, action, agent architecture and reward, and provides a more comprehensive view of the RL training. By using RLInspect, users can gain insights into the model's behaviour, identify issues during training, and potentially correct them effectively, leading to a more robust and reliable RL system.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08409",
        "abstract url": "https://arxiv.org/abs/2411.08409",
        "title": "DiVR: incorporating context from diverse VR scenes for human trajectory prediction",
        "rating": "-2.5",
        "keywords": [
            [
                "point cloud"
            ],
            [
                "trajectory"
            ],
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Virtual environments provide a rich and controlled setting for collecting detailed data on human behavior, offering unique opportunities for predicting human trajectories in dynamic scenes. However, most existing approaches have overlooked the potential of these environments, focusing instead on static contexts without considering userspecific factors. Employing the CREATTIVE3D dataset, our work models trajectories recorded in virtual reality (VR) scenes for diverse situations including road-crossing tasks with user interactions and simulated visual impairments. We propose Diverse Context VR Human Motion Prediction (DiVR), a cross-modal transformer based on the Perceiver architecture that integrates both static and dynamic scene context using a heterogeneous graph convolution network. We conduct extensive experiments comparing DiVR against existing architectures including MLP, LSTM, and transformers with gaze and point cloud context. Additionally, we also stress test our model's generalizability across different users, tasks, and scenes. Results show that DiVR achieves higher accuracy and adaptability compared to other models and to static graphs. This work highlights the advantages of using VR datasets for context-aware human trajectory modeling, with potential applications in enhancing user experiences in the metaverse. Our source code is publicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model.",
        "subjects": [
            "cs.AI",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08414",
        "abstract url": "https://arxiv.org/abs/2411.08414",
        "title": "Material Property Prediction with Element Attribute Knowledge Graphs and Multimodal Representation Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning has become a crucial tool for predicting the properties of crystalline materials. However, existing methods primarily represent material information by constructing multi-edge graphs of crystal structures, often overlooking the chemical and physical properties of elements (such as atomic radius, electronegativity, melting point, and ionization energy), which have a significant impact on material performance. To address this limitation, we first constructed an element property knowledge graph and utilized an embedding model to encode the element attributes within the knowledge graph. Furthermore, we propose a multimodal fusion framework, ESNet, which integrates element property features with crystal structure features to generate joint multimodal representations. This provides a more comprehensive perspective for predicting the performance of crystalline materials, enabling the model to consider both microstructural composition and chemical characteristics of the materials. We conducted experiments on the Materials Project benchmark dataset, which showed leading performance in the bandgap prediction task and achieved results on a par with existing benchmarks in the formation energy prediction task.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08664",
        "abstract url": "https://arxiv.org/abs/2411.08664",
        "title": "UniMat: Unifying Materials Embeddings through Multi-modal Learning",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "X-ray"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Materials science datasets are inherently heterogeneous and are available in different modalities such as characterization spectra, atomic structures, microscopic images, and text-based synthesis conditions. The advancements in multi-modal learning, particularly in vision and language models, have opened new avenues for integrating data in different forms. In this work, we evaluate common techniques in multi-modal learning (alignment and fusion) in unifying some of the most important modalities in materials science: atomic structure, X-ray diffraction patterns (XRD), and composition. We show that structure graph modality can be enhanced by aligning with XRD patterns. Additionally, we show that aligning and fusing more experimentally accessible data formats, such as XRD patterns and compositions, can create more robust joint embeddings than individual modalities across various tasks. This lays the groundwork for future studies aiming to exploit the full potential of multi-modal data in materials science, facilitating more informed decision-making in materials design and discovery.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08699",
        "abstract url": "https://arxiv.org/abs/2411.08699",
        "title": "FedSub: Introducing class-aware Subnetworks Fusion to Enhance Personalized Federated Learning in Ubiquitous Systems",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Personalized Federated Learning is essential in AI-driven ubiquitous systems, supporting the distributed development of models able to adapt to diverse and evolving user behaviors while safeguarding privacy. Despite addressing heterogeneous user data distributions in collaborative model training, existing methods often face limitations balancing personalization and generalization, oversimplifying user similarities, or relying heavily on global models. In this paper, we propose FedSub, a novel federated approach designed to enhance personalization through the use of class-aware prototypes and model subnetworks. Prototypes serve as compact representations of user data, clustered on the server to identify similarities based on specific label patterns. Concurrently, subnetworks -- model components necessary to process each class -- are extracted locally and fused by the server according to these clusters, producing highly tailored model updates for each user. This fine-grained, class-specific aggregation of clients' models allows FedSub to capture the unique characteristics of individual user data patterns. The effectiveness of FedSub is validated in three real-world scenarios characterized by high data heterogeneity, derived from human activity recognition and mobile health applications. Experimental evaluations demonstrate FedSub's performance improvements with respect to the state-of-the-art and significant advancements in personalization for ubiquitous systems based on personal mobile and wearable devices.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Submitted to Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT)"
    },
    {
        "paper id": "2411.08703",
        "abstract url": "https://arxiv.org/abs/2411.08703",
        "title": "MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "biological",
                "disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The distinct characteristics of multiomics data, including complex interactions within and across biological layers and disease heterogeneity (e.g., heterogeneity in etiology and clinical symptoms), drive us to develop novel designs to address unique challenges in multiomics prediction. In this paper, we propose the multi-view knowledge transfer learning (MVKTrans) framework, which transfers intra- and inter-omics knowledge in an adaptive manner by reviewing data heterogeneity and suppressing bias transfer, thereby enhancing classification performance. Specifically, we design a graph contrastive module that is trained on unlabeled data to effectively learn and transfer the underlying intra-omics patterns to the supervised task. This unsupervised pretraining promotes learning general and unbiased representations for each modality, regardless of the downstream tasks. In light of the varying discriminative capacities of modalities across different diseases and/or samples, we introduce an adaptive and bi-directional cross-omics distillation module. This module automatically identifies richer modalities and facilitates dynamic knowledge transfer from more informative to less informative omics, thereby enabling a more robust and generalized integration. Extensive experiments on four real biomedical datasets demonstrate the superior performance and robustness of MVKTrans compared to the state-of-the-art. Code and data are available at https://github.com/Yaolab-fantastic/MVKTrans.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08842",
        "abstract url": "https://arxiv.org/abs/2411.08842",
        "title": "AstroM$^3$: A self-supervised multimodal model for astronomy",
        "rating": "-2.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "astronomy"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "While machine-learned models are now routinely employed to facilitate astronomical inquiry, model inputs tend to be limited to a primary data source (namely images or time series) and, in the more advanced approaches, some metadata. Yet with the growing use of wide-field, multiplexed observational resources, individual sources of interest often have a broad range of observational modes available. Here we construct an astronomical multimodal dataset and propose AstroM$^3$, a self-supervised pre-training approach that enables a model to learn from multiple modalities simultaneously. Specifically, we extend the CLIP (Contrastive Language-Image Pretraining) model to a trimodal setting, allowing the integration of time-series photometry data, spectra, and astrophysical metadata. In a fine-tuning supervised setting, our results demonstrate that CLIP pre-training improves classification performance for time-series photometry, where accuracy increases from 84.6% to 91.5%. Furthermore, CLIP boosts classification accuracy by up to 12.6% when the availability of labeled data is limited, showing the effectiveness of leveraging larger corpora of unlabeled data. In addition to fine-tuned classification, we can use the trained model in other downstream tasks that are not explicitly contemplated during the construction of the self-supervised model. In particular we show the efficacy of using the learned embeddings for misclassifications identification, similarity search, and anomaly detection. One surprising highlight is the \"rediscovery\" of Mira subtypes and two Rotational variable subclasses using manifold learning and dimension reduction algorithm. To our knowledge this is the first construction of an $n>2$ mode model in astronomy. Extensions to $n>3$ modes is naturally anticipated with this approach.",
        "subjects": [
            "astro-ph.IM",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08993",
        "abstract url": "https://arxiv.org/abs/2411.08993",
        "title": "Parameter Inference via Differentiable Diffusion Bridge Importance Sampling",
        "rating": "-2.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce a methodology for performing parameter inference in high-dimensional, non-linear diffusion processes. We illustrate its applicability for obtaining insights into the evolution of and relationships between species, including ancestral state reconstruction. Estimation is performed by utilising score matching to approximate diffusion bridges, which are subsequently used in an importance sampler to estimate log-likelihoods. The entire setup is differentiable, allowing gradient ascent on approximated log-likelihoods. This allows both parameter inference and diffusion mean estimation. This novel, numerically stable, score matching-based parameter inference framework is presented and demonstrated on biological two- and three-dimensional morphometry data.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09047",
        "abstract url": "https://arxiv.org/abs/2411.09047",
        "title": "Anomaly Detection in Large-Scale Cloud Systems: An Industry Case and Dataset",
        "rating": "-2.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "health"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As Large-Scale Cloud Systems (LCS) become increasingly complex, effective anomaly detection is critical for ensuring system reliability and performance. However, there is a shortage of large-scale, real-world datasets available for benchmarking anomaly detection methods. To address this gap, we introduce a new high-dimensional dataset from IBM Cloud, collected over 4.5 months from the IBM Cloud Console. This dataset comprises 39,365 rows and 117,448 columns of telemetry data. Additionally, we demonstrate the application of machine learning models for anomaly detection and discuss the key challenges faced in this process. This study and the accompanying dataset provide a resource for researchers and practitioners in cloud system monitoring. It facilitates more efficient testing of anomaly detection methods in real-world data, helping to advance the development of robust solutions to maintain the health and performance of large-scale cloud infrastructures.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09100",
        "abstract url": "https://arxiv.org/abs/2411.09100",
        "title": "General linear threshold models with application to influence maximization",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "health"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "A number of models have been developed for information spread through networks, often for solving the Influence Maximization (IM) problem. IM is the task of choosing a fixed number of nodes to \"seed\" with information in order to maximize the spread of this information through the network, with applications in areas such as marketing and public health. Most methods for this problem rely heavily on the assumption of known strength of connections between network members (edge weights), which is often unrealistic. In this paper, we develop a likelihood-based approach to estimate edge weights from the fully and partially observed information diffusion paths. We also introduce a broad class of information diffusion models, the general linear threshold (GLT) model, which generalizes the well-known linear threshold (LT) model by allowing arbitrary distributions of node activation thresholds. We then show our weight estimator is consistent under the GLT and some mild assumptions. For the special case of the standard LT model, we also present a much faster expectation-maximization approach for weight estimation. Finally, we prove that for the GLT models, the IM problem can be solved by a natural greedy algorithm with standard optimality guarantees if all node threshold distributions have concave cumulative distribution functions. Extensive experiments on synthetic and real-world networks demonstrate that the flexibility in the choice of threshold distribution combined with the estimation of edge weights significantly improves the quality of IM solutions, spread prediction, and the estimates of the node activation probabilities.",
        "subjects": [
            "cs.SI",
            "stat.ME"
        ],
        "comment": "30 pages, 10 figures"
    },
    {
        "paper id": "2411.09120",
        "abstract url": "https://arxiv.org/abs/2411.09120",
        "title": "Neural Graph Simulator for Complex Systems",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Numerical simulation is a predominant tool for studying the dynamics in complex systems, but large-scale simulations are often intractable due to computational limitations. Here, we introduce the Neural Graph Simulator (NGS) for simulating time-invariant autonomous systems on graphs. Utilizing a graph neural network, the NGS provides a unified framework to simulate diverse dynamical systems with varying topologies and sizes without constraints on evaluation times through its non-uniform time step and autoregressive approach. The NGS offers significant advantages over numerical solvers by not requiring prior knowledge of governing equations and effectively handling noisy or missing data with a robust training scheme. It demonstrates superior computational efficiency over conventional methods, improving performance by over $10^5$ times in stiff problems. Furthermore, it is applied to real traffic data, forecasting traffic flow with state-of-the-art accuracy. The versatility of the NGS extends beyond the presented cases, offering numerous potential avenues for enhancement.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09152",
        "abstract url": "https://arxiv.org/abs/2411.09152",
        "title": "GRAINRec: Graph and Attention Integrated Approach for Real-Time Session-Based Item Recommendations",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Recent advancements in session-based recommendation models using deep learning techniques have demonstrated significant performance improvements. While they can enhance model sophistication and improve the relevance of recommendations, they also make it challenging to implement a scalable real-time solution. To addressing this challenge, we propose GRAINRec: a Graph and Attention Integrated session-based recommendation model that generates recommendations in real-time. Our scope of work is item recommendations in online retail where a session is defined as an ordered sequence of digital guest actions, such as page views or adds to cart. The proposed model generates recommendations by considering the importance of all items in the session together, letting us predict relevant recommendations dynamically as the session evolves. We also propose a heuristic approach to implement real-time inferencing that meets Target platform's service level agreement (SLA). The proposed architecture lets us predict relevant recommendations dynamically as the session evolves, rather than relying on pre-computed recommendations for each item. Evaluation results of the proposed model show an average improvement of 1.5% across all offline evaluation metrics. A/B tests done over a 2 week duration showed an increase of 10% in click through rate and 9% increase in attributable demand. Extensive ablation studies are also done to understand our model performance for different parameters.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted to the 2024 IEEE International Conference on Big Data (IEEE BigData 2024)"
    },
    {
        "paper id": "2411.09181",
        "abstract url": "https://arxiv.org/abs/2411.09181",
        "title": "DeBaTeR: Denoising Bipartite Temporal Graph for Recommendation",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Due to the difficulty of acquiring large-scale explicit user feedback, implicit feedback (e.g., clicks or other interactions) is widely applied as an alternative source of data, where user-item interactions can be modeled as a bipartite graph. Due to the noisy and biased nature of implicit real-world user-item interactions, identifying and rectifying noisy interactions are vital to enhance model performance and robustness. Previous works on purifying user-item interactions in collaborative filtering mainly focus on mining the correlation between user/item embeddings and noisy interactions, neglecting the benefit of temporal patterns in determining noisy interactions. Time information, while enhancing the model utility, also bears its natural advantage in helping to determine noisy edges, e.g., if someone usually watches horror movies at night and talk shows in the morning, a record of watching a horror movie in the morning is more likely to be noisy interaction. Armed with this observation, we introduce a simple yet effective mechanism for generating time-aware user/item embeddings and propose two strategies for denoising bipartite temporal graph in recommender systems (DeBaTeR): the first is through reweighting the adjacency matrix (DeBaTeR-A), where a reliability score is defined to reweight the edges through both soft assignment and hard assignment; the second is through reweighting the loss function (DeBaTeR-L), where weights are generated to reweight user-item samples in the losses. Extensive experiments have been conducted to demonstrate the efficacy of our methods and illustrate how time information indeed helps identifying noisy edges.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09714",
        "abstract url": "https://arxiv.org/abs/2411.09714",
        "title": "Machine learning approaches to explore important features behind bird flight modes",
        "rating": "-2.5",
        "keywords": [
            [
                "flight"
            ],
            [
                "biologically",
                "physiological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Birds exhibit a variety of flight styles, primarily classified as flapping, which is characterized by rapid up-and-down wing movements, and soaring, which involves gliding with wings outstretched. Each species usually performs specific flight styles, and this has been argued in terms of morphological and physiological adaptation. However, it remains a challenge to evaluate the contribution of each factor to the difference in flight styles. In this study, using phenotypic data from 635 migratory bird species, such as body mass, wing length, and breeding periods, we quantified the relative importance of each feature using Feature Importance and SHAP values, and used them to construct weighted L1 distance matrices and construct NJ trees. Comparison with traditional phylogenetic logistic regression revealed similarity in top-ranked features, but also differences in overall weight distributions and clustering patterns in NJ trees. Our results highlight the complexity of constructing a biologically useful distance matrix from correlated phenotypic features, while the complementary nature of these weighting methods suggests the potential utility of multi-faceted approaches to assessing feature contributions.",
        "subjects": [
            "q-bio.QM",
            "cs.LG"
        ],
        "comment": "6 pages, 5 figures"
    },
    {
        "paper id": "2411.08424",
        "abstract url": "https://arxiv.org/abs/2411.08424",
        "title": "A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "Diagnosis",
                "fMRI",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Brain connectivity alternations associated with brain disorders have been widely reported in resting-state functional imaging (rs-fMRI) and diffusion tensor imaging (DTI). While many dual-modal fusion methods based on graph neural networks (GNNs) have been proposed, they generally follow homogenous fusion ways ignoring rich heterogeneity of dual-modal information. To address this issue, we propose a novel method that integrates functional and structural connectivity based on heterogeneous graph neural networks (HGNNs) to better leverage the rich heterogeneity in dual-modal images. We firstly use blood oxygen level dependency and whiter matter structure information provided by rs-fMRI and DTI to establish homo-meta-path, capturing node relationships within the same modality. At the same time, we propose to establish hetero-meta-path based on structure-function coupling and brain community searching to capture relations among cross-modal nodes. Secondly, we further introduce a heterogeneous graph pooling strategy that automatically balances homo- and hetero-meta-path, effectively leveraging heterogeneous information and preventing feature confusion after pooling. Thirdly, based on the flexibility of heterogeneous graphs, we propose a heterogeneous graph data augmentation approach that can conveniently address the sample imbalance issue commonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset for mild cognitive impairment (MCI) diagnosis. Experimental results indicate the proposed method is effective and superior to other algorithms, with a mean classification accuracy of 93.3%.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08472",
        "abstract url": "https://arxiv.org/abs/2411.08472",
        "title": "A survey on Graph Deep Representation Learning for Facial Expression Recognition",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Graph"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This comprehensive review delves deeply into the various methodologies applied to facial expression recognition (FER) through the lens of graph representation learning (GRL). Initially, we introduce the task of FER and the concepts of graph representation and GRL. Afterward, we discuss some of the most prevalent and valuable databases for this task. We explore promising approaches for graph representation in FER, including graph diffusion, spatio-temporal graphs, and multi-stream architectures. Finally, we identify future research opportunities and provide concluding remarks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08499",
        "abstract url": "https://arxiv.org/abs/2411.08499",
        "title": "Learning Robust Grasping Strategy Through Tactile Sensing and Adaption Skill",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Robust grasping represents an essential task in robotics, necessitating tactile feedback and reactive grasping adjustments for robust grasping of objects. Previous research has extensively combined tactile sensing with grasping, primarily relying on rule-based approaches, frequently neglecting post-grasping difficulties such as external disruptions or inherent uncertainties of the object's physics and geometry. To address these limitations, this paper introduces an human-demonstration-based adaptive grasping policy base on tactile, which aims to achieve robust gripping while resisting disturbances to maintain grasp stability. Our trained model generalizes to daily objects with seven different sizes, shapes, and textures. Experimental results demonstrate that our method performs well in dynamic and force interaction tasks and exhibits excellent generalization ability.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08599",
        "abstract url": "https://arxiv.org/abs/2411.08599",
        "title": "XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL",
        "rating": "-3",
        "keywords": [
            [
                "named entity recognition"
            ],
            [
                "SQL"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "To tackle the challenges of large language model performance in natural language to SQL tasks, we introduce XiYan-SQL, an innovative framework that employs a multi-generator ensemble strategy to improve candidate generation. We introduce M-Schema, a semi-structured schema representation method designed to enhance the understanding of database structures. To enhance the quality and diversity of generated candidate SQL queries, XiYan-SQL integrates the significant potential of in-context learning (ICL) with the precise control of supervised fine-tuning. On one hand, we propose a series of training strategies to fine-tune models to generate high-quality candidates with diverse preferences. On the other hand, we implement the ICL approach with an example selection method based on named entity recognition to prevent overemphasis on entities. The refiner optimizes each candidate by correcting logical or syntactical errors. To address the challenge of identifying the best candidate, we fine-tune a selection model to distinguish nuances of candidate SQL queries. The experimental results on multiple dialect datasets demonstrate the robustness of XiYan-SQL in addressing challenges across different scenarios. Overall, our proposed XiYan-SQL achieves the state-of-the-art execution accuracy of 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on NL2GQL, and a competitive score of 72.23% on the Bird development benchmark. The proposed framework not only enhances the quality and diversity of SQL queries but also outperforms previous methods.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.DB",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08607",
        "abstract url": "https://arxiv.org/abs/2411.08607",
        "title": "Time-constrained Federated Learning (FL) in Push-Pull IoT Wireless Access",
        "rating": "-3",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "Training a high-quality Federated Learning (FL) model at the network edge is challenged by limited transmission resources. Although various device scheduling strategies have been proposed, it remains unclear how scheduling decisions affect the FL model performance under temporal constraints. This is pronounced when the wireless medium is shared to enable the participation of heterogeneous Internet of Things (IoT) devices with distinct communication modes: (1) a scheduling (pull) scheme, that selects devices with valuable updates, and (2) random access (push), in which interested devices transmit model parameters. The motivation for pushing data is the improved representation of own data distribution within the trained FL model and thereby better generalization. The scheduling strategy affects the transmission opportunities for push-based communication during the access phase, extending the number of communication rounds required for model convergence. This work investigates the interplay of push-pull interactions in a time-constrained FL setting, where the communication opportunities are finite, with a utility-based analytical model. Using real-world datasets, we provide a performance tradeoff analysis that validates the significance of strategic device scheduling under push-pull wireless access for several practical settings. The simulation results elucidate the impact of the device sampling strategy on learning efficiency under timing constraints.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08628",
        "abstract url": "https://arxiv.org/abs/2411.08628",
        "title": "TDGCN-Based Mobile Multiuser Physical-Layer Authentication for EI-Enabled IIoT",
        "rating": "-3",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "Industrial"
            ]
        ],
        "abstract": "Physical-Layer Authentication (PLA) offers endogenous security, lightweight implementation, and high reliability, making it a promising complement to upper-layer security methods in Edge Intelligence (EI)-empowered Industrial Internet of Things (IIoT). However, state-of-the-art Channel State Information (CSI)-based PLA schemes face challenges in recognizing mobile multi-users due to the limited reliability of CSI fingerprints in low Signal-to-Noise Ratio (SNR) environments and the constantly shifting CSI distributions with user movements. To address these issues, we propose a Temporal Dynamic Graph Convolutional Network (TDGCN)-based PLA scheme. This scheme harnesses Intelligent Reflecting Surfaces (IRSs) to refine CSI fingerprint precision and employs Graph Neural Networks (GNNs) to capture the spatio-temporal dynamics induced by user movements and IRS deployments. Specifically, we partition hierarchical CSI fingerprints into multivariate time series and utilize dynamic GNNs to capture their associations. Additionally, Temporal Convolutional Networks (TCNs) handle temporal dependencies within each CSI fingerprint dimension. Dynamic Graph Isomorphism Networks (GINs) and cascade node clustering pooling further enable efficient information aggregation and reduced computational complexity. Simulations demonstrate the proposed scheme's superior authentication accuracy compared to seven baseline schemes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "9 pages, 12 figures"
    },
    {
        "paper id": "2411.08680",
        "abstract url": "https://arxiv.org/abs/2411.08680",
        "title": "Integrated Precoder and Trajectory Design for MIMO UAV-Assisted Relay System With Finite-Alphabet Inputs",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory",
                "flight"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Unmanned aerial vehicles (UAVs) are gaining widespread use in wireless relay systems due to their exceptional flexibility and cost-effectiveness. This paper focuses on the integrated design of UAV trajectories and the precoders at both the transmitter and UAV in a UAV-assisted relay communication system, accounting for transmit power constraints and UAV flight limitations. Unlike previous works that primarily address multiple-input single-output (MISO) systems with Gaussian inputs, we investigate a more realistic scenario involving multiple-input multiple-output (MIMO) systems with finite-alphabet inputs. To tackle the challenging and inherently non-convex problem, we propose an efficient solution algorithm that leverages successive convex approximation and alternating optimization techniques. Simulation results validate the effectiveness of the proposed algorithm, demonstrating its capability to optimize system performance.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08730",
        "abstract url": "https://arxiv.org/abs/2411.08730",
        "title": "3D Modelling to Address Pandemic Challenges: A Project-Based Learning Methodology",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "medical",
                "health",
                "surgical"
            ]
        ],
        "abstract": "The use of 3D modelling in medical education is a revolutionary tool during the learning process. In fact, this type of technology enables a more interactive teaching approach, making information retention more effective and enhancing students' understanding. 3D modelling allows for the creation of precise representations of the human body, as well as interaction with three-dimensional models, giving students a better spatial understanding of the different organs and systems and enabling simulations of surgical and technical procedures. This way, medical education is enriched with a more realistic and safe educational experience. The goal is to understand whether, when students and schools are challenged, they play an important role in addressing health issues in their community. School-led projects are directed towards educational scenarios that emphasize STEM education, tackling relevant public health problems through open-school initiatives. By implementing an educational scenario focused on 3D modelling and leveraging technology, we aim to raise community awareness on public health issues.",
        "subjects": [
            "cs.MM",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08767",
        "abstract url": "https://arxiv.org/abs/2411.08767",
        "title": "SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory"
            ],
            [
                "5G"
            ],
            [
                "cs.AI"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Wireless ray-tracing (RT) is emerging as a key tool for three-dimensional (3D) wireless channel modeling, driven by advances in graphical rendering. Current approaches struggle to accurately model beyond 5G (B5G) network signaling, which often operates at higher frequencies and is more susceptible to environmental conditions and changes. Existing online learning solutions require real-time environmental supervision during training, which is both costly and incompatible with GPU-based processing. In response, we propose a novel approach that redefines ray trajectory generation as a sequential decision-making problem, leveraging generative models to jointly learn the optical, physical, and signal properties within each designated environment. Our work introduces the Scene-Aware Neural Decision Wireless Channel Raytracing Hierarchy (SANDWICH), an innovative offline, fully differentiable approach that can be trained entirely on GPUs. SANDWICH offers superior performance compared to existing online learning methods, outperforms the baseline by 4e^-2 radian in RT accuracy, and only fades 0.5 dB away from toplined channel gain estimation.",
        "subjects": [
            "cs.NI",
            "cs.AI"
        ],
        "comment": "Submitted in ICASSP 2025"
    },
    {
        "paper id": "2411.09080",
        "abstract url": "https://arxiv.org/abs/2411.09080",
        "title": "Language Models for Music Medicine Generation",
        "rating": "-3",
        "keywords": [
            [
                "health"
            ],
            [
                "Music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Music therapy has been shown in recent years to provide multiple health benefits related to emotional wellness. In turn, maintaining a healthy emotional state has proven to be effective for patients undergoing treatment, such as Parkinson's patients or patients suffering from stress and anxiety. We propose fine-tuning MusicGen, a music-generating transformer model, to create short musical clips that assist patients in transitioning from negative to desired emotional states. Using low-rank decomposition fine-tuning on the MTG-Jamendo Dataset with emotion tags, we generate 30-second clips that adhere to the iso principle, guiding patients through intermediate states in the valence-arousal circumplex. The generated music is evaluated using a music emotion recognition model to ensure alignment with intended emotions. By concatenating these clips, we produce a 15-minute \"music medicine\" resembling a music therapy session. Our approach is the first model to leverage Language Models to generate music medicine. Ultimately, the output is intended to be used as a temporary relief between music therapy sessions with a board-certified therapist.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Late-Breaking / Demo Session Extended Abstract, ISMIR 2024 Conference"
    },
    {
        "paper id": "2411.09114",
        "abstract url": "https://arxiv.org/abs/2411.09114",
        "title": "Comparative genomics with succinct colored de Bruijn graphs",
        "rating": "-3",
        "keywords": [
            [
                "graphs"
            ],
            [
                "DNA"
            ]
        ],
        "abstract": "DNA technologies have evolved significantly in the past years enabling the sequencing of a large number of genomes in a short time. Nevertheless, the underlying computational problem is hard, and many technical factors and limitations complicate obtaining the complete sequence of a genome. Many genomes are left in a draft state, in which each chromosome is represented by a set of sequences with partial information on their relative order. Recently, some approaches have been proposed to compare draft genomes by comparing paths in de Bruijn graphs, which are constructed by many practical genome assemblers. In this article we introduce gcBB, a method for comparing genomes represented as succinct colored de Bruijn graphs directly, without resorting to sequence alignments, by means of the entropy and expectation measures based on the Burrows-Wheeler Similarity Distribution. We also introduce an improved version of gcBB, called mgcBB, that improves the time performance considerably through the selection of different data structures. We have compared phylogenies of genomes obtained by other methods to those obtained with gcBB, achieving promising results.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08447",
        "abstract url": "https://arxiv.org/abs/2411.08447",
        "title": "Learning Dynamic Cognitive Map with Autonomous Navigation",
        "rating": "-3.5",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "Graph"
            ],
            [
                "biologically"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Inspired by animal navigation strategies, we introduce a novel computational model to navigate and map a space rooted in biologically inspired principles. Animals exhibit extraordinary navigation prowess, harnessing memory, imagination, and strategic decision-making to traverse complex and aliased environments adeptly. Our model aims to replicate these capabilities by incorporating a dynamically expanding cognitive map over predicted poses within an Active Inference framework, enhancing our agent's generative model plasticity to novelty and environmental changes. Through structure learning and active inference navigation, our model demonstrates efficient exploration and exploitation, dynamically expanding its model capacity in response to anticipated novel un-visited locations and updating the map given new evidence contradicting previous beliefs. Comparative analyses in mini-grid environments with the Clone-Structured Cognitive Graph model (CSCG), which shares similar objectives, highlight our model's ability to rapidly learn environmental structures within a single episode, with minimal navigation overlap. Our model achieves this without prior knowledge of observation and world dimensions, underscoring its robustness and efficacy in navigating intricate environments.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "under submission at Frontiers Computer Neuroscience"
    },
    {
        "paper id": "2411.08463",
        "abstract url": "https://arxiv.org/abs/2411.08463",
        "title": "Symbolic-AI-Fusion Deep Learning (SAIF-DL): Encoding Knowledge into Training with Answer Set Programming Loss Penalties by a Novel Loss Function Approach",
        "rating": "-3.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents a hybrid methodology that enhances the training process of deep learning (DL) models by embedding domain expert knowledge using ontologies and answer set programming (ASP). By integrating these symbolic AI methods, we encode domain-specific constraints, rules, and logical reasoning directly into the model's learning process, thereby improving both performance and trustworthiness. The proposed approach is flexible and applicable to both regression and classification tasks, demonstrating generalizability across various fields such as healthcare, autonomous systems, engineering, and battery manufacturing applications. Unlike other state-of-the-art methods, the strength of our approach lies in its scalability across different domains. The design allows for the automation of the loss function by simply updating the ASP rules, making the system highly scalable and user-friendly. This facilitates seamless adaptation to new domains without significant redesign, offering a practical solution for integrating expert knowledge into DL models in industrial settings such as battery manufacturing.",
        "subjects": [
            "cs.AI",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08521",
        "abstract url": "https://arxiv.org/abs/2411.08521",
        "title": "SAD-TIME: a Spatiotemporal-fused network for depression detection with Automated multi-scale Depth-wise and TIME-interval-related common feature extractor",
        "rating": "-3.5",
        "keywords": [
            [
                "Depth"
            ],
            [
                "graph"
            ],
            [
                "diagnosis",
                "EEG"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Background and Objective: Depression is a severe mental disorder, and accurate diagnosis is pivotal to the cure and rehabilitation of people with depression. However, the current questionnaire-based diagnostic methods could bring subjective biases and may be denied by subjects. In search of a more objective means of diagnosis, researchers have begun to experiment with deep learning-based methods for identifying depressive disorders in recent years. Methods: In this study, a novel Spatiotemporal-fused network with Automated multi-scale Depth-wise and TIME-interval-related common feature extractor (SAD-TIME) is proposed. SAD-TIME incorporates an automated nodes' common features extractor (CFE), a spatial sector (SpS), a modified temporal sector (TeS), and a domain adversarial learner (DAL). The CFE includes a multi-scale depth-wise 1D-convolutional neural network and a time-interval embedding generator, where the unique information of each channel is preserved. The SpS fuses the functional connectivity with the distance-based connectivity containing spatial position of EEG electrodes. A multi-head-attention graph convolutional network is also applied in the SpS to fuse the features from different EEG channels. The TeS is based on long short-term memory and graph transformer networks, where the temporal information of different time-windows is fused. Moreover, the DAL is used after the SpS to obtain the domain-invariant feature. Results: Experimental results under tenfold cross-validation show that the proposed SAD-TIME method achieves 92.00% and 94.00% depression classification accuracies on two datasets, respectively, in cross-subject mode. Conclusion: SAD-TIME is a robust depression detection model, where the automatedly-generated features, the SpS and the TeS assist the classification performance with the fusion of the innate spatiotemporal information in the EEG signals.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "21pages, 7 figures"
    },
    {
        "paper id": "2411.08533",
        "abstract url": "https://arxiv.org/abs/2411.08533",
        "title": "ACROSS: A Deformation-Based Cross-Modal Representation for Robotic Tactile Perception",
        "rating": "-3.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotics"
            ],
            [
                "BioTac"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Tactile perception is essential for human interaction with the environment and is becoming increasingly crucial in robotics. Tactile sensors like the BioTac mimic human fingertips and provide detailed interaction data. Despite its utility in applications like slip detection and object identification, this sensor is now deprecated, making many existing valuable datasets obsolete. However, recreating similar datasets with newer sensor technologies is both tedious and time-consuming. Therefore, it is crucial to adapt these existing datasets for use with new setups and modalities. In response, we introduce ACROSS, a novel framework for translating data between tactile sensors by exploiting sensor deformation information. We demonstrate the approach by translating BioTac signals into the DIGIT sensor. Our framework consists of first converting the input signals into 3D deformation meshes. We then transition from the 3D deformation mesh of one sensor to the mesh of another, and finally convert the generated 3D deformation mesh into the corresponding output space. We demonstrate our approach to the most challenging problem of going from a low-dimensional tactile representation to a high-dimensional one. In particular, we transfer the tactile signals of a BioTac sensor to DIGIT tactile images. Our approach enables the continued use of valuable datasets and the exchange of data between groups with different setups.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": "Paper Submitted to ICRA2025. arXiv admin note: text overlap with arXiv:2410.14310"
    },
    {
        "paper id": "2411.08550",
        "abstract url": "https://arxiv.org/abs/2411.08550",
        "title": "Graph Neural Networks in Supply Chain Analytics and Optimization: Concepts, Perspectives, Dataset and Benchmarks",
        "rating": "-3.5",
        "keywords": [
            [
                "GNNs",
                "Graph"
            ],
            [
                "anomaly detection"
            ],
            [
                "bioinformatics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Graph Neural Networks (GNNs) have recently gained traction in transportation, bioinformatics, language and image processing, but research on their application to supply chain management remains limited. Supply chains are inherently graph-like, making them ideal for GNN methodologies, which can optimize and solve complex problems. The barriers include a lack of proper conceptual foundations, familiarity with graph applications in SCM, and real-world benchmark datasets for GNN-based supply chain research. To address this, we discuss and connect supply chains with graph structures for effective GNN application, providing detailed formulations, examples, mathematical definitions, and task guidelines. Additionally, we present a multi-perspective real-world benchmark dataset from a leading FMCG company in Bangladesh, focusing on supply chain planning. We discuss various supply chain tasks using GNNs and benchmark several state-of-the-art models on homogeneous and heterogeneous graphs across six supply chain analytics tasks. Our analysis shows that GNN-based models consistently outperform statistical Machine Learning and other Deep Learning models by around 10-30% in regression, 10-30% in classification and detection tasks, and 15-40% in anomaly detection tasks on designated metrics. With this work, we lay the groundwork for solving supply chain problems using GNNs, supported by conceptual discussions, methodological insights, and a comprehensive dataset.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "stat.ML"
        ],
        "comment": "27 Pages. Extended journal version of SupplyGraph (arXiv:2401.15299). In Review"
    },
    {
        "paper id": "2411.08728",
        "abstract url": "https://arxiv.org/abs/2411.08728",
        "title": "Polymetis:Large Language Modeling for Multiple Material Domains",
        "rating": "-3.5",
        "keywords": [
            [
                "biology"
            ],
            [
                "alloy",
                "chemistry"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "As the application of large language models in various fields continues to expand, materials science also ushers in opportunities for AI-driven innovation. The traditional way of relying on manual search for materials science-related information is now using artificial intelligence technology as an auxiliary tool to improve the efficiency of materials science research. To accelerate researchers' knowledge acquisition and intelligent decision-making support in materials science research, this paper proposes a large language model Polymetis model for a variety of materials fields, aiming to provide highly professional knowledge answers in the field of materials, covering energy materials, functional materials, alloy materials, physical chemistry, biology, and other material directions. The model uses a dataset of about 2 million material knowledge instructions, and in the process of building the dataset, we developed the Intelligent Extraction Large Model (IELM), which is specially used to extract and form structured knowledge from scientific texts, avoiding a large number of costs that need to be manually annotated, and improving efficiency. We inject this data into the GLM4-9B model for learning to enhance its inference capabilities in a variety of material domains. In addition, we have introduced enhanced prompt strategies to ensure that the answers to the model are more organized and comprehensive, providing efficient and comprehensive intelligent support for the diverse needs of materials science exploration, and promoting the development of material science.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08734",
        "abstract url": "https://arxiv.org/abs/2411.08734",
        "title": "Recommender systems and reinforcement learning for building control and occupant interaction: A text-mining driven review of scientific literature",
        "rating": "-3.5",
        "keywords": [
            [
                "health"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The indoor environment greatly affects health and well-being; enhancing health and reducing energy use in these settings is a key research focus. With advancing Information and Communication Technology (ICT), recommendation systems and reinforcement learning have emerged as promising methods to induce behavioral changes that improve indoor environments and building energy efficiency. This study employs text-mining and Natural Language Processing (NLP) to examine these approaches in building control and occupant interaction. Analyzing approximately 27,000 articles from the ScienceDirect database, we found extensive use of recommendation systems and reinforcement learning for space optimization, location recommendations, and personalized control suggestions. Despite broad applications, their use in optimizing indoor environments and energy efficiency is limited. Traditional recommendation algorithms are commonly used, but optimizing indoor conditions and energy efficiency often requires advanced machine learning techniques like reinforcement and deep learning. This review highlights the potential for expanding recommender systems and reinforcement learning applications in buildings and indoor environments. Areas for innovation include predictive maintenance, building-related product recommendations, and optimizing environments for specific needs like sleep and productivity enhancements based on user feedback.",
        "subjects": [
            "eess.SY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08453",
        "abstract url": "https://arxiv.org/abs/2411.08453",
        "title": "Biomass phenotyping of oilseed rape through UAV multi-view oblique imaging with 3DGS and SAM model",
        "rating": "-4",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "point cloud",
                "NeRF",
                "Radiance Fields"
            ],
            [
                "Biomass"
            ],
            [
                "UAV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Biomass estimation of oilseed rape is crucial for optimizing crop productivity and breeding strategies. While UAV-based imaging has advanced high-throughput phenotyping, current methods often rely on orthophoto images, which struggle with overlapping leaves and incomplete structural information in complex field environments. This study integrates 3D Gaussian Splatting (3DGS) with the Segment Anything Model (SAM) for precise 3D reconstruction and biomass estimation of oilseed rape. UAV multi-view oblique images from 36 angles were used to perform 3D reconstruction, with the SAM module enhancing point cloud segmentation. The segmented point clouds were then converted into point cloud volumes, which were fitted to ground-measured biomass using linear regression. The results showed that 3DGS (7k and 30k iterations) provided high accuracy, with peak signal-to-noise ratios (PSNR) of 27.43 and 29.53 and training times of 7 and 49 minutes, respectively. This performance exceeded that of structure from motion (SfM) and mipmap Neural Radiance Fields (Mip-NeRF), demonstrating superior efficiency. The SAM module achieved high segmentation accuracy, with a mean intersection over union (mIoU) of 0.961 and an F1-score of 0.980. Additionally, a comparison of biomass extraction models found the point cloud volume model to be the most accurate, with an determination coefficient (R2) of 0.976, root mean square error (RMSE) of 2.92 g/plant, and mean absolute percentage error (MAPE) of 6.81%, outperforming both the plot crop volume and individual crop volume models. This study highlights the potential of combining 3DGS with multi-view UAV imaging for improved biomass phenotyping.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08666",
        "abstract url": "https://arxiv.org/abs/2411.08666",
        "title": "A Survey on Vision Autoregressive Model",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "image editing"
            ],
            [
                "robotic manipulation"
            ],
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Autoregressive models have demonstrated great performance in natural language processing (NLP) with impressive scalability, adaptability and generalizability. Inspired by their notable success in NLP field, autoregressive models have been intensively investigated recently for computer vision, which perform next-token predictions by representing visual data as visual tokens and enables autoregressive modelling for a wide range of vision tasks, ranging from visual generation and visual understanding to the very recent multimodal generation that unifies visual generation and understanding with a single autoregressive model. This paper provides a systematic review of vision autoregressive models, including the development of a taxonomy of existing methods and highlighting their major contributions, strengths, and limitations, covering various vision tasks such as image generation, video generation, image editing, motion generation, medical image analysis, 3D generation, robotic manipulation, unified multimodal generation, etc. Besides, we investigate and analyze the latest advancements in autoregressive models, including thorough benchmarking and discussion of existing methods across various evaluation datasets. Finally, we outline key challenges and promising directions for future research, offering a roadmap to guide further advancements in vision autoregressive models.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "This work will be integrated into another project"
    },
    {
        "paper id": "2411.08370",
        "abstract url": "https://arxiv.org/abs/2411.08370",
        "title": "A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants",
        "rating": "-4.5",
        "keywords": [
            [
                "anomaly detection"
            ],
            [
                "Health"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Early fault detection and timely maintenance scheduling can significantly mitigate operational risks in NPPs and enhance the reliability of operator decision-making. Therefore, it is necessary to develop an efficient Prognostics and Health Management (PHM) multi-step prediction model for predicting of system health status and prompt execution of maintenance operations. In this study, we propose a novel predictive model that integrates reinforcement learning with Long Short-Term Memory (LSTM) neural networks and the Expert Fuzzy Evaluation Method. The model is validated using parameter data for 20 different breach sizes in the Main Steam Line Break (MSLB) accident condition of the CPR1000 pressurized water reactor simulation model and it demonstrates a remarkable capability in accurately forecasting NPP parameter changes up to 128 steps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds), thereby satisfying the temporal advance requirement for fault prognostics in NPPs. Furthermore, this method provides an effective reference solution for PHM applications such as anomaly detection and remaining useful life prediction.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08582",
        "abstract url": "https://arxiv.org/abs/2411.08582",
        "title": "Intelligent Algorithms For Signature Diagnostics Of Three-Phase Motors",
        "rating": "-5.5",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "industrial"
            ],
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The application of machine learning (ML) algorithms in the intelligent diagnosis of three-phase engines has the potential to significantly enhance diagnostic performance and accuracy. Traditional methods largely rely on signature analysis, which, despite being a standard practice, can benefit from the integration of advanced ML techniques. In our study, we innovate by combining state of the art algorithms with a novel unsupervised anomaly generation methodology that takes into account physics model of the engine. This hybrid approach leverages the strengths of both supervised ML and unsupervised signature analysis, achieving superior diagnostic accuracy and reliability along with a wide industrial application. Our experimental results demonstrate that this method significantly outperforms existing ML and non-ML state-of-the-art approaches while retaining the practical advantages of an unsupervised methodology. The findings highlight the potential of our approach to significantly contribute to the field of engine diagnostics, offering a robust and efficient solution for real-world applications.",
        "subjects": [
            "eess.SP",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08383",
        "abstract url": "https://arxiv.org/abs/2411.08383",
        "title": "FAS-Driven Spectrum Sensing for Cognitive Radio Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cognitive radio (CR) networks face significant challenges in spectrum sensing, especially under spectrum scarcity. Fluid antenna systems (FAS) can offer an unorthodox solution due to their ability to dynamically adjust antenna positions for improved channel gain. In this letter, we study a FAS-driven CR setup where a secondary user (SU) adjusts the positions of fluid antennas to detect signals from the primary user (PU). We aim to maximize the detection probability under the constraints of the false alarm probability and the received beamforming of the SU. To address this problem, we first derive a closed-form expression for the optimal detection threshold and reformulate the problem to find its solution. Then an alternating optimization (AO) scheme is proposed to decompose the problem into several sub-problems, addressing both the received beamforming and the antenna positions at the SU. The beamforming subproblem is addressed using a closed-form solution, while the fluid antenna positions are solved by successive convex approximation (SCA). Simulation results reveal that the proposed algorithm provides significant improvements over traditional fixed-position antenna (FPA) schemes in terms of spectrum sensing performance.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08386",
        "abstract url": "https://arxiv.org/abs/2411.08386",
        "title": "A Secure Beamforming Design: When Fluid Antenna Meets NOMA",
        "rating": "-10",
        "keywords": [],
        "abstract": "This letter proposes a secure beamforming design for downlink non-orthogonal multiple access (NOMA) systems utilizing fluid antenna systems (FAS). We consider a setup where a base station (BS) with $M$ fluid antennas (FAs) communicates to a cell-center user (CU) and a cell-edge user (CEU), each with a FA. The CU is the intended recipient while the CEU is regarded as a potential eavesdropper. Our aim is to maximize the achievable secrecy rate by jointly optimizing the secure beamforming vectors and the positions of FAs. To tackle this, we adopt an alternating optimization (AO) algorithm that optimizes secure beamforming and the positions of the FAs iteratively while keeping the other variables fixed. Numerical results illustrate that when FAs meet NOMA, the proposed scheme greatly enhances the secrecy rate compared to conventional multiple-input single-output (MISO) fixed antenna NOMA systems and other benchmark schemes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08388",
        "abstract url": "https://arxiv.org/abs/2411.08388",
        "title": "Multi-Lingual Development & Programming Languages Interoperability: An Empirical Study",
        "rating": "-10",
        "keywords": [],
        "abstract": "As part of a research on a novel in-process multiprogramming-language interoperability system, this study investigates the interoperability and usage of multiple programming languages within a large dataset of GitHub projects and Stack Overflow Q\\&A. It addresses existing multi-lingual development practices and interactions between programming languages, focusing on in-process multi-programming language interoperability. The research examines a dataset of 414,486 GitHub repositories, 22,156,001 Stack Overflow questions from 2008-2021 and 173 interoperability tools. The paper's contributions include a comprehensive dataset, large-scale analysis, and insights into the prevalence, dominant languages, interoperability tools, and related issues in multi-language programming. The paper presents the research results, shows that C is a central pillar in programming language interoperability, and outlines \\emph{simple interoperability} guidelines. These findings and guidelines contribute to our multi-programming language interoperability system research, also laying the groundwork for other systems and tools by suggesting key features for future interoperability tools.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "26 pages, includes supplement"
    },
    {
        "paper id": "2411.08401",
        "abstract url": "https://arxiv.org/abs/2411.08401",
        "title": "Reducing Dynamic Range in Bistatic Backscatter Communication via Beamforming Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Considering the exponential growth of Internet-of-Things devices and the goals toward sustainable networks, the complexity should be focused on the infrastructure side. For a massive number of passive devices, backscatter communication (BC) is a promising technology that reduces cost and increases energy efficiency by enabling transmitting information by backscattering radio frequency signals. Two main limitations that restrict the performance of BC are the round-trip path loss effect and the direct link interference (DLI) from the carrier emitter (CE). To circumvent this, we propose a novel transmit beamforming design for a multiple antenna bistatic BC (BiBC) system that realizes both purposes: mitigation of the DLI and increasing the power towards the backscatter device (BD). Additionally, we provide a detector design and the performance is evaluated in terms of the probability of error, for which we also provide a closed-form expression. Finally, simulation results show the superiority of the proposed beamforming design in decreasing DLI over a benchmark scenario that considers maximum-ratio transmission.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "6 pages, 6 figures"
    },
    {
        "paper id": "2411.08421",
        "abstract url": "https://arxiv.org/abs/2411.08421",
        "title": "Modest Sets are Equivalent to PERs",
        "rating": "-10",
        "keywords": [],
        "abstract": "The aim of this article is to give an expository account of the equivalence between modest sets and partial equivalence relations. Our proof is entirely self-contained in that we do not assume any knowledge of categorical realizability. At the heart of the equivalence lies the subquotient construction on a partial equivalence relation. The subquotient construction embeds the category of partial equivalence relations into the category of modest sets. We show that this embedding is a split essentially surjective functor, and thereby, an equivalence of categories. Our development is both constructive and predicative, and employs the language of homotopy type theory. All the mathematics presented in this article has been mechanised in Cubical Agda.",
        "subjects": [
            "math.CT",
            "cs.LO"
        ],
        "comment": "14 pages; Expository article"
    },
    {
        "paper id": "2411.08434",
        "abstract url": "https://arxiv.org/abs/2411.08434",
        "title": "Anonymous Distributed Localisation via Spatial Population Protocols",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the distributed localization problem (DLP), n anonymous robots (agents) A0, A1, ..., A(n-1) begin at arbitrary positions p0, ..., p(n-1) in S, where S is a Euclidean space. The primary goal in DLP is for agents to reach a consensus on a unified coordinate system that accurately reflects the relative positions of all points, p0, ... , p(n-1), in S. Extensive research on DLP has primarily focused on the feasibility and complexity of achieving consensus when agents have limited access to inter-agent distances, often due to missing or imprecise data. In this paper, however, we examine a minimalist, computationally efficient model of distributed computing in which agents have access to all pairwise distances, if needed. Specifically, we introduce a novel variant of population protocols, referred to as the spatial population protocols model. In this variant each agent can memorise one or a fixed number of coordinates, and when agents A(i) and A(j) interact, they can not only exchange their current knowledge but also either determine the distance d(i,j) between them in S (distance query model) or obtain the vector v(i,j) spanning points p(i) and p(j) (vector query model). We examine three DLP scenarios: - Self-stabilising localisation protocol with distance queries We propose and analyse self-stabilising localisation protocol based on pairwise distance adjustment. We also discuss several hard instances in this scenario, and suggest possible improvements for the considered protocol, - Leader-based localisation protocol with distance queries We propose and analyse several leader-based protocols which stabilise in o(n) parallel time. These protocols rely on efficient solution to multi-contact epidemic, and - Self-stabilising localisation protocol with vector queries We propose and analyse superfast self-stabilising DLP protocol which stabilises in O(log n) parallel time.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08437",
        "abstract url": "https://arxiv.org/abs/2411.08437",
        "title": "Evolutionary Algorithm with Detection Region Method for Constrained Multi-Objective Problems with Binary Constraints",
        "rating": "-10",
        "keywords": [],
        "abstract": "Solving constrained multi-objective optimization problems (CMOPs) is a challenging task. While many practical algorithms have been developed to tackle CMOPs, real-world scenarios often present cases where the constraint functions are unknown or unquantifiable, resulting in only binary outcomes (feasible or infeasible). This limitation reduces the effectiveness of constraint violation guidance, which can negatively impact the performance of existing algorithms that rely on this approach. Such challenges are particularly detrimental for algorithms employing the epsilon-based method, as they hinder effective relaxation of the feasible region. To address these challenges, this paper proposes a novel algorithm called DRMCMO based on the detection region method. In DRMCMO, detection regions dynamic monitor feasible solutions to enhance convergence, helping the population escape local optima. Additionally, these regions collaborate with the neighbor pairing strategy to improve population diversity within narrow feasible areas. We have modified three existing test suites to serve as benchmark test problems for CMOPs with binary constraints(CMOP/BC) and conducted comprehensive comparative experiments with state-of-the-art algorithms on these test suites and real-world problems. The results demonstrate the strong competitiveness of DRMCMO against state-of-the-art algorithms. Given the limited research on CMOP/BC, our study offers a new perspective for advancing this field.",
        "subjects": [
            "cs.NE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08439",
        "abstract url": "https://arxiv.org/abs/2411.08439",
        "title": "A Fully Local Last-Generated Rule in a Blockchain",
        "rating": "-10",
        "keywords": [],
        "abstract": "An effective method for suppressing intentional forks in a blockchain is the last-generated rule, which selects the most recent chain as the main chain in the event of a chain tie. This rule helps invalidate blocks that are withheld by adversaries for a certain period. However, existing last-generated rules face an issue in that their applications to the system are not fully localized. In conservative cryptocurrency systems such as Bitcoin, it is desirable for methods to be applied in a fully local manner. In this paper, we propose a locally applicable last-generated rule. Our method is straightforward and is based on a relative time reference. By conservatively setting the upper bound for the clock skews $\u0394_{O_i}$ to 200 s, our proposed method reduces the proportion $\u03b3$ of honest miners following the attacker during chain ties by more than 40% compared to existing local methods.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08448",
        "abstract url": "https://arxiv.org/abs/2411.08448",
        "title": "In Serverless, OS Scheduler Choice Costs Money: A Hybrid Scheduling Approach for Cheaper FaaS",
        "rating": "-10",
        "keywords": [],
        "abstract": "In Function-as-a-Service (FaaS) serverless, large applications are split into short-lived stateless functions. Deploying functions is mutually profitable: users need not be concerned with resource management, while providers can keep their servers at high utilization rates running thousands of functions concurrently on a single machine. It is exactly this high concurrency that comes at a cost. The standard Linux Completely Fair Scheduler (CFS) switches often between tasks, which leads to prolonged execution times. We present evidence that relying on the default Linux CFS scheduler increases serverless workloads cost by up to 10X. In this article, we raise awareness and make a case for rethinking the OS-level scheduling in Linux for serverless workloads composed of many short-lived processes. To make serverless more affordable we introduce a hybrid two-level scheduling approach that relies on FaaS characteristics. Short-running functions are executed in FIFO fashion without preemption, while longer-running functions are passed to CFS after a certain time period. We show that tailor-made OS scheduling is able to significantly reduce user-facing costs without adding any provider-facing overhead.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Accepted at Middleware 2024, author draft made available for timely dissemination"
    },
    {
        "paper id": "2411.08473",
        "abstract url": "https://arxiv.org/abs/2411.08473",
        "title": "Fractional Fourier Domain PAPR Reduction",
        "rating": "-10",
        "keywords": [],
        "abstract": "High peak-to-average power ratio (PAPR) has long posed a challenge for multi-carrier systems, impacting amplifier efficiency and overall system performance. This paper introduces dynamic angle fractional Fourier division multiplexing (DA-FrFDM), an innovative multi-carrier system that effectively reduces PAPR for both QAM and Gaussian signals with minimal signaling overhead. DA-FrFDM leverages the fractional Fourier domain to balance PAPR characteristics between the time and frequency domains, achieving significant PAPR reduction while preserving signal quality. Furthermore, DA-FrFDM refines signal processing and enables one-tap equalization in the fractional Fourier domain through the simple multiplication of time-domain signals by a quadratic phase sequence. Our results show that DA-FrFDM not only outperforms existing PAPR reduction techniques but also retains efficient inter-carrier interference (ICI) mitigation capabilities in doubly dispersive channels.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08481",
        "abstract url": "https://arxiv.org/abs/2411.08481",
        "title": "Variable-Length Feedback Codes via Deep Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "Variable-length feedback coding has the potential to significantly enhance communication reliability in finite block length scenarios by adapting coding strategies based on real-time receiver feedback. Designing such codes, however, is challenging. While deep learning (DL) has been employed to design sophisticated feedback codes, existing DL-aided feedback codes are predominantly fixed-length and suffer performance degradation in the high code rate regime, limiting their adaptability and efficiency. This paper introduces deep variable-length feedback (DeepVLF) code, a novel DL-aided variable-length feedback coding scheme. By segmenting messages into multiple bit groups and employing a threshold-based decoding mechanism for independent decoding of each bit group across successive communication rounds, DeepVLF outperforms existing DL-based feedback codes and establishes a new benchmark in feedback channel coding.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08493",
        "abstract url": "https://arxiv.org/abs/2411.08493",
        "title": "Advanced Nonlinear SCMA Codebook Design Based on Lattice Constellations",
        "rating": "-10",
        "keywords": [],
        "abstract": "The design of efficient sparse codebooks in sparse code multiple access (SCMA) system have attracted tremendous research attention in the past few years. This paper proposes a novel nonlinear SCMA (NL-SCMA) that can subsume the conventional SCMA system which is referred to as linear SCMA, as special cases for downlink channels. This innovative approach allows a direct mapping of users' messages to a superimposed codeword for transmission, eliminating the need of a codebook for each user. This mapping is referred to as nonlinear mapping (codebook) in this paper. Hence, the primary objective is to design the nonlinear mapping, rather than the linear codebook for each user. We leverage the Lattice constellation to design the superimposed constellation due to its advantages such as the minimum Euclidean distance (MED), constellation volume, design flexibility and shape gain. Then, by analyzing the error patterns of the Lattice-designed superimposed codewords with the aid of the pair-wise error probability, it is found that the MED of the proposed nonlinear codebook is lower bounded by the ``single error pattern''. To this end, an error pattern-inspired codebook design is proposed, which can achieve large MEDs of the nonlinear codebooks. Numerical results show that the proposed codebooks can achieve lower error rate performance over both Gaussian and Rayleigh fading channels than the-state-of-the-art linear codebooks.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08494",
        "abstract url": "https://arxiv.org/abs/2411.08494",
        "title": "Achieving Consistent and Comparable CPU Evaluation Outcomes",
        "rating": "-10",
        "keywords": [],
        "abstract": "The SPEC CPU2017 benchmark suite is an industry standard for accessing CPU performance. It adheres strictly to some workload and system configurations - arbitrary specificity - while leaving other system configurations undefined - arbitrary ambiguity. This article reveals: (1) Arbitrary specificity proves not meaningful, obscuring many scenarios, as evidenced by significant performance variations, a 74.49x performance difference observed on the same CPU. (2) Arbitrary ambiguity is unfair as it fails to establish the same configurations for comparing different CPUs. We propose an innovative CPU evaluation methodology. It considers all workload and system configurations valid and mandates each configuration to be well-defined to avoid arbitrary specificity and ambiguity. To reduce the evaluation cost, a sampling approach is proposed to select a subset of the configurations. To expose CPU performance under different scenarios, it treats all outcomes under each configuration as equally important. Finally, it utilizes confidence level and confidence interval to report the outcomes to avoid bias.",
        "subjects": [
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08507",
        "abstract url": "https://arxiv.org/abs/2411.08507",
        "title": "TimeLess: A Vision for the Next Generation of Software Development",
        "rating": "-10",
        "keywords": [],
        "abstract": "Present-day software development faces three major challenges: complexity, time consumption, and high costs. Developing large software systems often requires battalions of teams and considerable time for meetings, which end without any action, resulting in unproductive cycles, delayed progress, and increased cost. What if, instead of large meetings with no immediate results, the software product is completed by the end of the meeting? In response, we present a vision for a system called TimeLess, designed to reshape the software development process by enabling immediate action during meetings. The goal is to shift meetings from planning discussions to productive, action-oriented sessions. This approach minimizes the time and effort required for development, allowing teams to focus on critical decision-making while AI agents execute development tasks based on the meeting discussions. We will employ multiple AI agents that work collaboratively to capture human discussions and execute development tasks in real time. This represents a step toward next-generation software development environments, where human expertise drives strategy and AI accelerates task execution.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "5 pages, 4 figure, and 1 table"
    },
    {
        "paper id": "2411.08509",
        "abstract url": "https://arxiv.org/abs/2411.08509",
        "title": "Sum Rate Maximization for Movable Antenna-Aided Downlink RSMA Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Rate splitting multiple access (RSMA) is regarded as a crucial and powerful physical layer (PHY) paradigm for next-generation communication systems. Particularly, users employ successive interference cancellation (SIC) to decode part of the interference while treating the remainder as noise. However, conventional RSMA systems rely on fixed-position antenna arrays, limiting their ability to fully exploit spatial diversity. This constraint reduces beamforming gain and significantly impairs RSMA performance. To address this problem, we propose a movable antenna (MA)-aided RSMA scheme that allows the antennas at the base station (BS) to dynamically adjust their positions. Our objective is to maximize the system sum rate of common and private messages by jointly optimizing the MA positions, beamforming matrix, and common rate allocation. To tackle the formulated non-convex problem, we apply fractional programming (FP) and develop an efficient two-stage, coarse-to-fine-grained searching (CFGS) algorithm to obtain high-quality solutions. Numerical results demonstrate that, with optimized antenna adjustments, the MA-enabled system achieves substantial performance and reliability improvements in RSMA over fixed-position antenna setups.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08510",
        "abstract url": "https://arxiv.org/abs/2411.08510",
        "title": "CorrectBench: Automatic Testbench Generation with Functional Self-Correction using LLMs for HDL Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Functional simulation is an essential step in digital hardware design. Recently, there has been a growing interest in leveraging Large Language Models (LLMs) for hardware testbench generation tasks. However, the inherent instability associated with LLMs often leads to functional errors in the generated testbenches. Previous methods do not incorporate automatic functional correction mechanisms without human intervention and still suffer from low success rates, especially for sequential tasks. To address this issue, we propose CorrectBench, an automatic testbench generation framework with functional self-validation and self-correction. Utilizing only the RTL specification in natural language, the proposed approach can validate the correctness of the generated testbenches with a success rate of 88.85%. Furthermore, the proposed LLM-based corrector employs bug information obtained during the self-validation process to perform functional self-correction on the generated testbenches. The comparative analysis demonstrates that our method achieves a pass ratio of 70.13% across all evaluated tasks, compared with the previous LLM-based testbench generation framework's 52.18% and a direct LLM-based generation method's 33.33%. Specifically in sequential circuits, our work's performance is 62.18% higher than previous work in sequential tasks and almost 5 times the pass ratio of the direct method. The codes and experimental results are open-sourced at the link: https://github.com/AutoBench/CorrectBench",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08523",
        "abstract url": "https://arxiv.org/abs/2411.08523",
        "title": "The Word Problem for $(\u03c9- 1)$-Terms over $\\mathrm{DAb}$",
        "rating": "-10",
        "keywords": [],
        "abstract": "We give a ranker-based description using finite-index congruences for the variety $\\boldsymbol{\\mathrm{DAb}}$ of finite monoids whose regular $\\mathcal{D}$-classes form Abelian groups. This combinatorial description yields a normal form for general pseudowords over $\\boldsymbol{\\mathrm{DAb}}$. For $(\u03c9- 1)$-terms, this normal form is computable, which yields an algorithm for the word problem for $(\u03c9- 1)$-terms of $\\boldsymbol{\\mathrm{DAb}}$.",
        "subjects": [
            "cs.FL",
            "math.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08535",
        "abstract url": "https://arxiv.org/abs/2411.08535",
        "title": "The EU AI Act is a good start but falls short",
        "rating": "-10",
        "keywords": [],
        "abstract": "The EU AI Act was created to ensure ethical and safe Artificial Intelligence (AI) development and deployment across the EU. This study aims to identify key challenges and strategies for helping enterprises focus on resources effectively. To achieve this aim, we conducted a Multivocal Literature Review (MLR) to explore the sentiments of both the industry and the academia. From 130 articles, 56 met the criteria. Our key findings are three-fold. First, liability. Second, discrimination. Third, tool adequacy. Additionally, some negative sentiments were expressed by industry and academia regarding regulatory interpretations, specific requirements, and transparency issues. Next, our findings are three essential themes for enterprises. First, risk-based regulatory compliance. Second, ethical frameworks and principles in technology development. Third, policies and systems for regulatory risk management. These results identify the key challenges and strategies and provide less commonly discussed themes, enabling enterprises to align with the requirements and minimize their distance from the EU market.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "18 pages, 4 figures, 1 table"
    },
    {
        "paper id": "2411.08538",
        "abstract url": "https://arxiv.org/abs/2411.08538",
        "title": "Intelligent Adaptive Metasurface in Complex Wireless Environments",
        "rating": "-10",
        "keywords": [],
        "abstract": "The programmable metasurface is regarded as one of the most promising transformative technologies for next-generation wireless system applications. Due to the lack of effective perception ability of the external electromagnetic environment, there are numerous challenges in the intelligent regulation of wireless channels, and it still relies on external sensors to reshape electromagnetic environment as desired. To address that problem, we propose an adaptive metasurface (AMS) which integrates the capabilities of acquiring wireless environment information and manipulating reflected electromagnetic (EM) waves in a programmable manner. The proposed design endows the metasurfaces with excellent capabilities to sense the complex electromagnetic field distributions around them and then dynamically manipulate the waves and signals in real time under the guidance of the sensed information, eliminating the need for prior knowledge or external inputs about the wireless environment. For verification, a prototype of the proposed AMS is constructed, and its dual capabilities of sensing and manipulation are experimentally validated. Additionally, different integrated sensing and communication (ISAC) scenarios with and without the aid of the AMS are established. The effectiveness of the AMS in enhancing communication quality is well demonstrated in complex electromagnetic environments, highlighting its beneficial application potential in future wireless systems.",
        "subjects": [
            "physics.app-ph",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08549",
        "abstract url": "https://arxiv.org/abs/2411.08549",
        "title": "A Framework for Robust Lossy Compression of Heavy-Tailed Sources",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the rate-distortion problem for both scalar and vector memoryless heavy-tailed $\u03b1$-stable sources ($0 < \u03b1< 2$). Using a recently defined notion of ``strength\" as a power measure, we derive the rate-distortion function for $\u03b1$-stable sources subject to a constraint on the strength of the error, and show it to be logarithmic in the strength-to-distortion ratio. We showcase how our framework paves the way to finding optimal quantizers for $\u03b1$-stable sources and more generally to heavy-tailed ones. In addition, we study high-rate scalar quantizers and show that uniform ones are asymptotically optimal under the strength measure. We compare uniform Gaussian and Cauchy quantizers and show that more representation points for the Cauchy source are required to guarantee the same quantization quality. Our findings generalize the well-known rate-distortion and quantization results of Gaussian sources ($\u03b1= 2$) under a quadratic distortion measure.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "28 pages, 6 figures"
    },
    {
        "paper id": "2411.08574",
        "abstract url": "https://arxiv.org/abs/2411.08574",
        "title": "Practitioners' Discussions on Building LLM-based Applications for Production",
        "rating": "-10",
        "keywords": [],
        "abstract": "\\textit{Background}: Large language models (LLMs) have become a paramount interest of researchers and practitioners alike, yet a comprehensive overview of key considerations for those developing LLM-based systems is lacking. This study addresses this gap by collecting and mapping the topics practitioners discuss online, offering practical insights into where priorities lie in developing LLM-based applications. \\textit{Method}: We collected 189 videos from 2022 to 2024 from practitioners actively developing such systems and discussing various aspects they encounter during development and deployment of LLMs in production. We analyzed the transcripts using BERTopic, then manually sorted and merged the generated topics into themes, leading to a total of 20 topics in 8 themes. \\textit{Results}: The most prevalent topics fall within the theme Design \\& Architecture, with a strong focus on retrieval-augmented generation (RAG) systems. Other frequently discussed topics include model capabilities and enhancement techniques (e.g., fine-tuning, prompt engineering), infrastructure and tooling, and risks and ethical challenges. \\textit{Implications}: Our results highlight current discussions and challenges in deploying LLMs in production. This way, we provide a systematic overview of key aspects practitioners should be aware of when developing LLM-based applications. We further pale off topics of interest for academics where further research is needed.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08576",
        "abstract url": "https://arxiv.org/abs/2411.08576",
        "title": "Future state prediction based on observer for missile system",
        "rating": "-10",
        "keywords": [],
        "abstract": "Guided missile accuracy and precision is negatively impacted by seeker delay, more specifically by the delay introduced by a mechanical seeker gimbal and the computational time taken to process the raw data. To meet the demands and expectations of modern missiles systems, the impact of this hardware limitation must be reduced. This paper presents a new observer design that predicts the future state of a seeker signal, augmenting the guidance system to mitigate the effects of this delay. The design is based on a novel two-step differentiator, which produces the estimated future time derivatives of the signal. The input signal can be nonlinear and provides for simple integration into existing systems. A bespoke numerical guided missile simulation is used to demonstrate the performance of the observer within a missile guidance system. Both non-manoeuvring and randomly manoeuvring target engagement scenarios are considered.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08621",
        "abstract url": "https://arxiv.org/abs/2411.08621",
        "title": "Thought Experiments in Design Fiction for Visualization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Thought experiments are considered valuable tools in science, enabling the exploration of hypotheses and the examination of complex ideas in a conceptual, non-empirical framework. These thought experiments can be useful in design fiction for speculating future possibilities, examining existing and alternate scenarios in new ways or challenging current paradigms. In visualization, speculating future possibilities or exploring new ways of interpreting existing scenarios can provoke critical reflection and envision novel approaches. In this paper we present such thought experiments for visualization. We conceptualize and define a thought experiment to consist of a situation, a story, and a scenario. Situations are derived from different tools of thought experiments and visualization practice; a story is an AI-generated fiction based on the situation and the scenario is the grounding of the situation and story in visualization research. We present ten such thought experiments and demonstrate their utility in visualization by deriving critiques from them.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08626",
        "abstract url": "https://arxiv.org/abs/2411.08626",
        "title": "Learning-Guided Fuzzing for Testing Stateful SDN Controllers",
        "rating": "-10",
        "keywords": [],
        "abstract": "Controllers for software-defined networks (SDNs) are centralised software components that enable advanced network functionalities, such as dynamic traffic engineering and network virtualisation. However, these functionalities increase the complexity of SDN controllers, making thorough testing crucial. SDN controllers are stateful, interacting with multiple network devices through sequences of control messages. Identifying stateful failures in an SDN controller is challenging due to the infinite possible sequences of control messages, which result in an unbounded number of stateful interactions between the controller and network devices. In this article, we propose SeqFuzzSDN, a learning-guided fuzzing method for testing stateful SDN controllers. SeqFuzzSDN aims to (1) efficiently explore the state space of the SDN controller under test, (2) generate effective and diverse tests (i.e., control message sequences) to uncover failures, and (3) infer accurate failure-inducing models that characterise the message sequences leading to failures. In addition, we compare SeqFuzzSDN with three extensions of state-of-the-art (SOTA) methods for fuzzing SDNs. Our findings show that, compared to the extended SOTA methods, SeqFuzzSDN (1) generates more diverse message sequences that lead to failures within the same time budget, and (2) produces more accurate failure-inducing models, significantly outperforming the other extended SOTA methods in terms of sensitivity.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08634",
        "abstract url": "https://arxiv.org/abs/2411.08634",
        "title": "On the Application of Model Predictive Control to a Weighted Coverage Path Planning Problem",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper considers the application of Model Predictive Control (MPC) to a weighted coverage path planning (WCPP) problem. The problem appears in a wide range of practical applications, such as search and rescue (SAR) missions. The basic setup is that one (or multiple) agents can move around a given search space and collect rewards from a given spatial distribution. Unlike an artificial potential field, each reward can only be collected once. In contrast to a Traveling Salesman Problem (TSP), the agent moves in a continuous space. Moreover, he is not obliged to cover all locations and/or may return to previously visited locations. The WCPP problem is tackled by a new Model Predictive Control (MPC) formulation with so-called Coverage Constraints (CCs). It is shown that the solution becomes more effective if the solver is initialized with a TSP-based heuristic. With and without this initialization, the proposed MPC approach clearly outperforms a naive MPC formulation, as demonstrated in a small simulation study.",
        "subjects": [
            "eess.SY",
            "cs.MA",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08635",
        "abstract url": "https://arxiv.org/abs/2411.08635",
        "title": "Synthesis with Privacy Against an Observer",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study automatic synthesis of systems that interact with their environment and maintain privacy against an observer to the interaction. The system and the environment interact via sets $I$ and $O$ of input and output signals. The input to the synthesis problem contains, in addition to a specification, also a list of secrets, a function $cost: I\\cup O\\rightarrow\\mathbb{N}$, which maps each signal to the cost of hiding it, and a bound $b\\in\\mathbb{N}$ on the budget that the system may use for hiding of signals. The desired output is an $(I/O)$-transducer $T$ and a set $H\\subseteq I\\cup O$ of signals that respects the bound on the budget, thus $\\sum_{s\\in H} cost(s)\\leq b$, such that for every possible interaction of $T$, the generated computation satisfies the specification, yet an observer, from whom the signals in $H$ are hidden, cannot evaluate the secrets. We first show that the problem's complexity is 2EXPTIME-complete for specifications and secrets in LTL, making it no harder than synthesis without privacy requirements. We then analyze the complexity further, isolating the two aspects that do not exist in traditional synthesis: the need to hide secret values and the need to choose the set $H$. We do this by studying settings in which traditional synthesis is solvable in polynomial time -- when the specification formalism is deterministic automata and when the system is closed -- and show that each of these aspects adds an exponential blow-up in complexity. We continue and study bounded synthesis with privacy, where the input includes a bound on the synthesized transducer size, as well as a variant of the problem in which the observer has knowledge, either about the specification or about the system, which can be helpful in evaluating the secrets. Additionally, we study certified privacy, where the synthesis algorithm provides certification that the secrets remain hidden.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08647",
        "abstract url": "https://arxiv.org/abs/2411.08647",
        "title": "The Galactica database: an open, generic and versatile tool for the dissemination of simulation data in astrophysics",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Galactica simulation database is a platform designed to assist computational astrophysicists with their open science approach based on FAIR (Findable, Accessible, Interoperable, Reusable) principles. It offers the means to publish their numerical simulation projects, whatever their field of application or research theme and provides access to reduced datasets and object catalogs online. The application implements the Simulation Datamodel IVOA standard. To provide the scientific community indirect access to raw simulation data, Galactica can generate, on an \"on-demand\" basis, custom high-level data products to meet specific user requirements. These data products, accessible through online WebServices, are produced remotely from the raw simulation datasets. To that end, the Galactica central web application communicates with a high-scalability ecosystem of data-processing servers called Terminus by means of an industry-proven asynchronous task management system. Each Terminus node, hosted in a research institute, a regional or national supercomputing facility, contributes to the ecosystem by providing both the storage and the computational resources required to store the massive simulation datasets and post-process them to create the data products requested on Galactica, hence guaranteeing fine-grained sovereignty over data and resources. This distributed architecture is very versatile, it can be interfaced with any kind of data-processing software, written in any language, handling raw data produced by every type of simulation code used in the field of computational astrophysics. Its generality and versatility, together with its excellent scalability makes it a powerful tool for the scientific community to disseminate numerical models in astrophysics in the exascale era.",
        "subjects": [
            "astro-ph.IM",
            "cs.CE",
            "cs.DB"
        ],
        "comment": "5 pages, 2 figures, submitted to IAU Proceedings Series"
    },
    {
        "paper id": "2411.08672",
        "abstract url": "https://arxiv.org/abs/2411.08672",
        "title": "Joint Model Caching and Resource Allocation in Generative AI-Enabled Wireless Edge Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the rapid advancement of artificial intelligence (AI), generative AI (GenAI) has emerged as a transformative tool, enabling customized and personalized AI-generated content (AIGC) services. However, GenAI models with billions of parameters require substantial memory capacity and computational power for deployment and execution, presenting significant challenges to resource-limited edge networks. In this paper, we address the joint model caching and resource allocation problem in GenAI-enabled wireless edge networks. Our objective is to balance the trade-off between delivering high-quality AIGC and minimizing the delay in AIGC service provisioning. To tackle this problem, we employ a deep deterministic policy gradient (DDPG)-based reinforcement learning approach, capable of efficiently determining optimal model caching and resource allocation decisions for AIGC services in response to user mobility and time-varying channel conditions. Numerical results demonstrate that DDPG achieves a higher model hit ratio and provides superior-quality, lower-latency AIGC services compared to other benchmark solutions.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": "conference paper with 6 pages and 5 figures. arXiv admin note: text overlap with arXiv:2411.01458"
    },
    {
        "paper id": "2411.08673",
        "abstract url": "https://arxiv.org/abs/2411.08673",
        "title": "ScribGen: Generating Scribble Art Through Metaheuristics",
        "rating": "-10",
        "keywords": [],
        "abstract": "Art has long been a medium for individuals to engage with the world. Scribble art, a form of abstract visual expression, features spontaneous, gestural strokes made with pens or brushes. These dynamic and expressive compositions, created quickly and impulsively, reveal intricate patterns and hidden meanings upon closer inspection. While scribble art is often associated with spontaneous expression and experimentation, it can also be planned and intentional. Some artists use scribble techniques as a starting point for their creative process, exploring the possibilities of line, shape, and texture before refining their work into more polished compositions. From ancient cave paintings to modern abstract sketches and doodles, scribble art has evolved with civilizations, reflecting diverse artistic movements and cultural influences. This evolution highlights its universal appeal, transcending language and cultural barriers and connecting people through the shared experience of creating art.",
        "subjects": [
            "cs.GR"
        ],
        "comment": "SIGGRAPH Asia 2024"
    },
    {
        "paper id": "2411.08674",
        "abstract url": "https://arxiv.org/abs/2411.08674",
        "title": "Reducing ADC Front-end Costs During Training of On-sensor Printed Multilayer Perceptrons",
        "rating": "-10",
        "keywords": [],
        "abstract": "Printed electronics technology offers a cost-effectiveand fully-customizable solution to computational needs beyondthe capabilities of traditional silicon technologies, offering ad-vantages such as on-demand manufacturing and conformal, low-cost hardware. However, the low-resolution fabrication of printedelectronics, which results in large feature sizes, poses a challengefor integrating complex designs like those of machine learn-ing (ML) classification systems. Current literature optimizes onlythe Multilayer Perceptron (MLP) circuit within the classificationsystem, while the cost of analog-to-digital converters (ADCs)is overlooked. Printed applications frequently require on-sensorprocessing, yet while the digital classifier has been extensivelyoptimized, the analog-to-digital interfacing, specifically the ADCs,dominates the total area and energy consumption. In this work,we target digital printed MLP classifiers and we propose thedesign of customized ADCs per MLP's input which involvesminimizing the distinct represented numbers for each input,simplifying thus the ADC's circuitry. Incorporating this ADCoptimization in the MLP training, enables eliminating ADC levelsand the respective comparators, while still maintaining highclassification accuracy. Our approach achieves 11.2x lower ADCarea for less than 5% accuracy drop across varying MLPs.",
        "subjects": [
            "cs.AR",
            "cs.NE"
        ],
        "comment": "This article is accepted for publication in IEEE Embedded Systems Letters"
    },
    {
        "paper id": "2411.08678",
        "abstract url": "https://arxiv.org/abs/2411.08678",
        "title": "Identification of Power Systems with Droop-Controlled Units Using Neural Ordinary Differential Equations",
        "rating": "-10",
        "keywords": [],
        "abstract": "In future power systems, the detailed structure and dynamics may not always be fully known. This is due to an increasing number of distributed energy resources, such as photovoltaic generators, battery storage systems, heat pumps and electric vehicles, as well as a shift towards active distribution grids. Obtaining physically-based models for simulation and control synthesis can therefore become challenging. Differential equations, where the right-hand side is represented by a neural network, i.e., neural ordinary differential equations (NODEs), have a great potential to serve as a data-driven black-box model to overcome this challenge. This paper explores their use in identifying the dynamics of droop-controlled grid-forming units based on inputs and state measurements. In numerical studies, various NODE structures used with different numerical solvers are trained and evaluated. Moreover, they are compared to the sparse identification of nonlinear dynamics (SINDy) method. The results demonstrate that even though SINDy yields more accurate models, NODEs achieve good prediction performance without prior knowledge about the system's nonlinearities which SINDy requires to work best.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08693",
        "abstract url": "https://arxiv.org/abs/2411.08693",
        "title": "Human-Centered AI Transformation: Exploring Behavioral Dynamics in Software Engineering",
        "rating": "-10",
        "keywords": [],
        "abstract": "As Artificial Intelligence (AI) becomes integral to software development, understanding the social and cooperative dynamics that affect AI-driven organizational change is important. Yet, despite AI's rapid progress and influence, the human and cooperative facets of these shifts in software organizations remain relatively less explored. This study uses Behavioral Software Engineering (BSE) as a lens to examine these often-overlooked dimensions of AI transformation. Through a qualitative approach involving ten semi-structured interviews across four organizations that are undergoing AI transformations, we performed a thematic analysis that revealed numerous sub-themes linked to twelve BSE concepts across individual, group, and organizational levels. Since the organizations are at an early stage of transformation we found more emphasis on the individual level. Our findings further reveal six key challenges tied to these BSE aspects that the organizations face during their AI transformation. Aligned with change management literature, we emphasize that effective communication, proactive leadership, and resistance management are essential for successful AI integration. However, we also identify ethical considerations as critical in the AI context-an area largely overlooked in previous research. Furthermore, a narrative analysis illustrates how different roles within an organization experience the AI transition in unique ways. These insights underscore that AI transformation extends beyond technical solutions; it requires a thoughtful approach that balances technological and human factors.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "11 pages, 1 figure, 7 tables. Submitted to a conference"
    },
    {
        "paper id": "2411.08735",
        "abstract url": "https://arxiv.org/abs/2411.08735",
        "title": "New advances in universal approximation with neural networks of minimal width",
        "rating": "-10",
        "keywords": [],
        "abstract": "Deep neural networks have achieved remarkable success in diverse applications, prompting the need for a solid theoretical foundation. Recent research has identified the minimal width $\\max\\{2,d_x,d_y\\}$ required for neural networks with input dimensions $d_x$ and output dimension $d_y$ that use leaky ReLU activations to universally approximate $L^p(\\mathbb{R}^{d_x},\\mathbb{R}^{d_y})$ on compacta. Here, we present an alternative proof for the minimal width of such neural networks, by directly constructing approximating networks using a coding scheme that leverages the properties of leaky ReLUs and standard $L^p$ results. The obtained construction has a minimal interior dimension of $1$, independent of input and output dimensions, which allows us to show that autoencoders with leaky ReLU activations are universal approximators of $L^p$ functions. Furthermore, we demonstrate that the normalizing flow LU-Net serves as a distributional universal approximator. We broaden our results to show that smooth invertible neural networks can approximate $L^p(\\mathbb{R}^{d},\\mathbb{R}^{d})$ on compacta when the dimension $d\\geq 2$, which provides a constructive proof of a classical theorem of Brenier and Gangbo. In addition, we use a topological argument to establish that for FNNs with monotone Lipschitz continuous activations, $d_x+1$ is a lower bound on the minimal width required for the uniform universal approximation of continuous functions $C^0(\\mathbb{R}^{d_x},\\mathbb{R}^{d_y})$ on compacta when $d_x\\geq d_y$.",
        "subjects": [
            "cs.NE",
            "math.FA"
        ],
        "comment": "56 pages in the main text, 70 pages with Appendix"
    },
    {
        "paper id": "2411.08754",
        "abstract url": "https://arxiv.org/abs/2411.08754",
        "title": "Logic-based Knowledge Awareness for Autonomous Agents in Continuous Spaces",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a step towards a formal controller design method for autonomous agents based on knowledge awareness to improve decision-making. Our approach is to first create an organized repository of information (a knowledge base) for autonomous agents which can be accessed and then translated into temporal specifications. Secondly, to develop a controller with formal guarantees that meets a combination of mission-specific objective and the specification from the knowledge base, we utilize an abstraction-based controller design (ABCD) approach, capable of managing both nonlinear dynamics and temporal requirements. Unlike the conventional offline ABCD approach, our method dynamically updates the controller whenever the knowledge base prompts changes in the specifications. A three-dimensional nonlinear car model navigating an urban road scenario with traffic signs and obstacles is considered for validation. Results show the effectiveness of the method in guiding the autonomous agents to the target while complying with the knowledge base and the mission-specific objective.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08759",
        "abstract url": "https://arxiv.org/abs/2411.08759",
        "title": "Clutter-Aware Target Detection for ISAC in a Millimeter-Wave Cell-Free Massive MIMO System",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we investigate the performance of an integrated sensing and communication (ISAC) system within a cell-free massive multiple-input multiple-output (MIMO) system. Each access point (AP) operates in the millimeter-wave (mmWave) frequency band. The APs jointly serve the user equipments (UEs) in the downlink while simultaneously detecting a target through dedicated sensing beams, which are directed toward a reconfigurable intelligent surface (RIS). Although the AP-RIS, RIS-target, and AP-target channels have both line-of-sight (LoS) and non-line-of-sight (NLoS) parts, it is assumed only knowledge of the LoS paths is available. A key contribution of this study is the consideration of clutter, which degrades the target detection if not handled. We propose an algorithm to alternatively optimize the transmit power allocation and the RIS phase-shift matrix, maximizing the target signal-to-clutter-plus-noise ratio (SCNR) while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for the UEs. Numerical results demonstrate that exploiting clutter subspace significantly enhances detection probability, particularly at high clutter-to-noise ratios, and reveal that an increased number of transmit side clusters impair detection performance. Finally, we highlight the performance gains achieved using a dedicated sensing stream.",
        "subjects": [
            "eess.SP",
            "eess.SY"
        ],
        "comment": "submitted to IEEE ICC25"
    },
    {
        "paper id": "2411.08765",
        "abstract url": "https://arxiv.org/abs/2411.08765",
        "title": "Tolerant Testing of Stabilizer States with Mixed State Inputs",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem of tolerant testing of stabilizer states. In particular, we give the first such algorithm that accepts mixed state inputs. Formally, given a mixed state $\u03c1$ that either has fidelity at least $\\varepsilon_1$ with some stabilizer pure state or fidelity at most $\\varepsilon_2$ with all such states, where $\\varepsilon_2 \\leq \\varepsilon_1^{O(1)}$, our algorithm distinguishes the two cases with sample complexity $\\text{poly}(1/\\varepsilon_1)$ and time complexity $O(n \\cdot \\text{poly}(1/\\varepsilon_1))$.",
        "subjects": [
            "quant-ph",
            "cs.DS"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2411.08770",
        "abstract url": "https://arxiv.org/abs/2411.08770",
        "title": "On Kleisli liftings and decorated trace semantics",
        "rating": "-10",
        "keywords": [],
        "abstract": "It is well known that Kleisli categories provide a natural language to model side effects. For instance, in the theory of coalgebras, behavioural equivalence coincides with language equivalence (instead of bisimilarity) when nondeterministic automata are modelled as coalgebras living in the Kleisli category of the powerset monad. In this paper, our aim is to establish decorated trace semantics based on language and ready equivalences for conditional transition systems (CTSs) with/without upgrades. To this end, we model CTSs as coalgebras living in the Kleisli category of a relative monad. Our results are twofold. First, we reduce the problem of defining a Kleisli lifting for the machine endofunctor in the context of a relative monad to the classical notion of Kleisli lifting. Second, we provide a recipe based on indexed categories to construct a Kleisli lifting for general endofunctors.",
        "subjects": [
            "cs.LO"
        ],
        "comment": "40th Conference on Mathematical Foundations of Programming Semantics (MFPS)"
    },
    {
        "paper id": "2411.08781",
        "abstract url": "https://arxiv.org/abs/2411.08781",
        "title": "SoK: Towards a Common Understanding of Cryptographic Agility",
        "rating": "-10",
        "keywords": [],
        "abstract": "Cryptographic agility is gaining attention due to its crucial role in maintaining cryptographic security in a rapidly evolving technological landscape. However, despite its increasing importance, the term cryptographic agility remains vaguely defined and there is no clear consensus on its exact meaning. This lack of clarity poses a challenge since the need for agility becomes more urgent as new cryptographic vulnerabilities and advanced computing threats emerge, emphasizing the need for a systematic approach to clarify and refine the notion on cryptographic agility. In this paper, we systematize the concept of cryptographic agility by providing three research contributions. First, we review current definitions across academic and gray literature, identifying six distinct categories to differentiate every aspect within the definitions. Second, we synthesize these insights to establish a comprehensive, canonical definition of cryptographic agility. Third, we explore the relationship between cryptographic agility and the related concepts cryptographic versatility and interoperability. In our discussion, we examine the relevance of cryptographic agility, highlight its trade-offs with complexity, assess its individual applicability, and illustrate its various contexts by offering an additional application-specific definition. Our work provides a new perspective on cryptographic agility and related concepts, based on systematical research to clarify and enhance its future use.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "18 pages, 1 figure"
    },
    {
        "paper id": "2411.08784",
        "abstract url": "https://arxiv.org/abs/2411.08784",
        "title": "Towards Fair and Efficient Public Transportation: A Bus Stop Model",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider a stylized formal model of public transportation, where a set of agents need to travel along a given road, and there is a bus that runs the length of this road. Each agent has a left terminal and a right terminal between which they wish to travel; they can walk all the way, or walk to/from the nearest stop and use the bus for the rest of their journey. The bus can make a fixed number of stops, and the planner needs to select locations for these stops. We study notions of efficiency and fairness for this setting. First, we give a polynomial-time algorithm for computing a solution that minimizes the total travel time; our approach can capture further extensions of the base model, such as more general cost functions or existing infrastructure. Second, we develop a polynomial-time algorithm that outputs solutions with provable fairness guarantees (such as a variant of the justified representation axiom or $2$-approximate core) as long as the agents' costs only depend on the distance they need to walk. Our simulations indicate that our algorithm almost always outputs fair solutions, even for parameter regimes that do not admit theoretical guarantees.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08815",
        "abstract url": "https://arxiv.org/abs/2411.08815",
        "title": "Learning real-time one-counter automata using polynomially many queries",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we introduce a novel method for active learning of deterministic real-time one-counter automata (DROCA). The existing techniques for learning DROCA rely on observing the behaviour of the DROCA up to exponentially large counter-values. Our algorithm eliminates this need and requires only a polynomial number of queries. Additionally, our method differs from existing techniques as we learn a minimal counter-synchronous DROCA, resulting in much smaller counter-examples on equivalence queries. Learning a minimal counter-synchronous DROCA cannot be done in polynomial time unless P = NP, even in the case of visibly one-counter automata. We use a SAT solver to overcome this difficulty. The solver is used to compute a minimal separating DFA from a given set of positive and negative samples. We prove that the equivalence of two counter-synchronous DROCAs can be checked significantly faster than that of general DROCAs. For visibly one-counter automata, we have discovered an even faster algorithm for equivalence checking. We implemented the proposed learning algorithm and tested it on randomly generated DROCAs. Our evaluations show that the proposed method outperforms the existing techniques on the test set.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08818",
        "abstract url": "https://arxiv.org/abs/2411.08818",
        "title": "On integer sequences for rendering limit sets of Kleinian groups",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a technique for rendering limit sets for kleinian groups, based upon the base transformation of integers and which aims at saving memory resources and being faster than the traditional dictionary based approach.",
        "subjects": [
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08833",
        "abstract url": "https://arxiv.org/abs/2411.08833",
        "title": "Advanced OOP and new syntax patterns for Javascript",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present OBJS, a new transpiler project featuring the implementation of typified variables and functions call management in Javascript, as well as several new operators and syntax patterns that could make coding more agile and versatile. The goal is to empower this language. According to this point of view, this transpiler aims at implementing Object Oriented Programming paradigms into Javascript. The author opines that this would be likely the best evolution of this language in ways that should be proper to the original syntax, that is, by adopting native C++standards, so that there would be no promiscuity between old and new patterns, benefiting those who come from similar languages.",
        "subjects": [
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08847",
        "abstract url": "https://arxiv.org/abs/2411.08847",
        "title": "Proof Nets for the \u03c0-Calculus",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we establish the foundations of a novel logical framework for the \u03c0-calculus, based on the deduction-as-computation paradigm. Following the standard proof-theoretic interpretation of logic programming, we represent processes as formulas, and we interpret proofs as computations. For this purpose, we define a cut-free sequent calculus for an extension of first-order multiplicative and additive linear logic. This extension includes a non-commutative and non-associative connective to faithfully model the prefix operator, and nominal quantifiers to represent name restriction. Finally, we design proof nets providing canonical representatives of derivations up to local rule permutations.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08859",
        "abstract url": "https://arxiv.org/abs/2411.08859",
        "title": "Designing a Virtual Reality Training Apprenticeship for Cold Spray Advanced Manufacturing",
        "rating": "-10",
        "keywords": [],
        "abstract": "Apprenticeship and training programs in advanced manufacturing frequently encounter safety and accessibility concerns due to using heavy machinery. Virtual Reality (VR) training addresses such constraints while maintaining the spatial and procedural learning requirements of such training. However, designing effective VR training is challenging because advanced manufacturing processes are complex and require experts to train novices for a long time. This paper presents a VR Training Apprenticeship (VRTA) tailored for cold spray, which we carefully designed to teach novices step-by-step this particular advanced manufacturing process. To assess its effectiveness, we conducted an exploratory study ($n = 22$). We evaluated user experience (UX) measures in the form of quantitative scales, users' qualitative insights, and task performance with real-world machinery after the VR training. We discuss how the VRTA design contributed to the effectiveness and the challenges of considering VR training for advanced manufacturing.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08872",
        "abstract url": "https://arxiv.org/abs/2411.08872",
        "title": "Large Wireless Model (LWM): A Foundation Model for Wireless Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents the Large Wireless Model (LWM) -- the world's first foundation model for wireless channels. Designed as a task-agnostic model, LWM generates universal, rich, contextualized channel embeddings (features) that potentially enhance performance across a wide range of downstream tasks in wireless communication and sensing systems. Towards this objective, LWM, which has a transformer-based architecture, was pre-trained in a self-supervised manner on large-scale wireless channel datasets. Our results show consistent improvements in classification and regression tasks when using the LWM embeddings compared to raw channel representations, especially in scenarios with high-complexity machine learning tasks and limited training datasets. This LWM's ability to learn from large-scale wireless data opens a promising direction for intelligent systems that can efficiently adapt to diverse tasks with limited data, paving the way for addressing key challenges in wireless communication and sensing systems.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "The LWM model and relevant scripts are available on the LWM website: https://lwm-wireless.net/"
    },
    {
        "paper id": "2411.08874",
        "abstract url": "https://arxiv.org/abs/2411.08874",
        "title": "A Decidable Case of Query Determinacy: Project-Select Views",
        "rating": "-10",
        "keywords": [],
        "abstract": "Query determinacy is decidable for project-select views and a project-select-join query with no self joins, as long as the selection predicates are in a first-order theory for which satisfiability is decidable.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08972",
        "abstract url": "https://arxiv.org/abs/2411.08972",
        "title": "Designing Automated Market Makers for Combinatorial Securities: A Geometric Viewpoint",
        "rating": "-10",
        "keywords": [],
        "abstract": "Designing automated market makers (AMMs) for prediction markets on combinatorial securities over large outcome spaces poses significant computational challenges. Prior research has primarily focused on combinatorial prediction markets within specific set systems (e.g., intervals, permutations). We introduce a framework for designing AMMs on arbitrary set systems by building a novel connection to the range query problem in computational geometry. This connection enables the analysis of computational complexity and the design of efficient AMMs. We first demonstrate the equivalence between price queries and trade updates under the popular combinatorial logarithmic market scoring rule market and the range query and range update problem. Building on this equivalence, we construct sublinear time algorithms when the VC dimension of the set system is bounded and show the non-existence of such algorithms for unbounded VC dimension cases. We then extend this approach to AMMs for combinatorial prediction markets with quadratic and power scoring rules. Finally, we show that the multi-resolution market design can be naturally integrated into the partition-tree scheme. Additionally, we introduce the combinatorial swap operation problem for automated market makers in decentralized finance and show that it can be efficiently reduced to range update problems.",
        "subjects": [
            "cs.GT",
            "cs.CG",
            "cs.DS"
        ],
        "comment": "38 pages, 1 figure, accepted at SODA'25"
    },
    {
        "paper id": "2411.08989",
        "abstract url": "https://arxiv.org/abs/2411.08989",
        "title": "Nearly Tight Bounds on Testing of Metric Properties",
        "rating": "-10",
        "keywords": [],
        "abstract": "Given a non-negative $n \\times n$ matrix viewed as a set of distances between $n$ points, we consider the property testing problem of deciding if it is a metric. We also consider the same problem for two special classes of metrics, tree metrics and ultrametrics. For general metrics, our paper is the first to consider these questions. We prove an upper bound of $O(n^{2/3}/\u03b5^{4/3})$ on the query complexity for this problem. Our algorithm is simple, but the analysis requires great care in bounding the variance on the number of violating triangles in a sample. When $\u03b5$ is a slowly decreasing function of $n$ (rather than a constant, as is standard), we prove a lower bound of matching dependence on $n$ of $\u03a9(n^{2/3})$, ruling out any property testers with $o(n^{2/3})$ query complexity unless their dependence on $1/\u03b5$ is super-polynomial. Next, we turn to tree metrics and ultrametrics. While there were known upper and lower bounds, we considerably improve these bounds showing essentially tight bounds of $\\tilde{O}(1/\u03b5)$ on the sample complexity. We also show a lower bound of $\u03a9( 1/\u03b5^{4/3} )$ on the query complexity. Our upper bounds are derived by doing a more careful analysis of a natural, simple algorithm. For the lower bounds, we construct distributions on NO instances, where it is hard to find a witness showing that these are not ultrametrics.",
        "subjects": [
            "cs.DM",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08994",
        "abstract url": "https://arxiv.org/abs/2411.08994",
        "title": "A characterization of positive spanning sets with ties to strongly connected digraphs",
        "rating": "-10",
        "keywords": [],
        "abstract": "Positive spanning sets (PSSs) are families of vectors that span a given linear space through non-negative linear combinations. Despite certain classes of PSSs being well understood, a complete characterization of PSSs remains elusive. In this paper, we explore a relatively understudied relationship between positive spanning sets and strongly edge-connected digraphs, in that the former can be viewed as a generalization of the latter. We leverage this connection to define a decomposition structure for positive spanning sets inspired by the ear decomposition from digraph theory.",
        "subjects": [
            "cs.DM",
            "math.CO",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.08999",
        "abstract url": "https://arxiv.org/abs/2411.08999",
        "title": "Learning-Based Control Barrier Function with Provably Safe Guarantees: Reducing Conservatism with Heading-Aware Safety Margin",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a learning-based Control Barrier Function (CBF) to reduce conservatism in collision avoidance of car-like robots. Traditional CBFs often use Euclidean distance between robots' centers as safety margin, neglecting headings and simplifying geometries to circles. While this ensures smooth, differentiable safety functions required by CBFs, it can be overly conservative in tight environments. To address this limitation, we design a heading-aware safety margin that accounts for the robots' orientations, enabling a less conservative and more accurate estimation of safe regions. Since the function computing this safety margin is non-differentiable, we approximate it with a neural network to ensure differentiability and facilitate integration with CBFs. We describe how we achieve bounded learning error and incorporate the upper bound into the CBF to provide formal safety guarantees through forward invariance. We show that our CBF is a high-order CBF with relative degree two for a system with two robots whose dynamics are modeled by the nonlinear kinematic bicycle model. Experimental results in overtaking and bypassing scenarios reveal a 33.5 % reduction in conservatism compared to traditional methods, while maintaining safety. Code: https://github.com/bassamlab/sigmarl",
        "subjects": [
            "cs.RO",
            "cs.MA",
            "eess.SY"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2411.09004",
        "abstract url": "https://arxiv.org/abs/2411.09004",
        "title": "The geometry of the deep linear network",
        "rating": "-10",
        "keywords": [],
        "abstract": "This article provides an expository account of training dynamics in the Deep Linear Network (DLN) from the perspective of the geometric theory of dynamical systems. Rigorous results by several authors are unified into a thermodynamic framework for deep learning. The analysis begins with a characterization of the invariant manifolds and Riemannian geometry in the DLN. This is followed by exact formulas for a Boltzmann entropy, as well as stochastic gradient descent of free energy using a Riemannian Langevin Equation. Several links between the DLN and other areas of mathematics are discussed, along with some open questions.",
        "subjects": [
            "cs.NE",
            "math.DS",
            "math.PR",
            "nlin.AO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09053",
        "abstract url": "https://arxiv.org/abs/2411.09053",
        "title": "Information Need in Metaverse Recordings -- A Field Study",
        "rating": "-10",
        "keywords": [],
        "abstract": "Metaverse Recordings (MVRs) represent an emerging and underexplored media type within the field of Multimedia Information Retrieval (MMIR). This paper presents findings from a field study aimed at understanding the users information needs and search behaviors specific to MVR retrieval. By conducting and analyzing expert interviews, the study identifies application scenarios and highlights challenges in retrieving multimedia content from the metaverse. The results reveal existing application scenarios of MVRs and confirm the relevance of capturing time-series data from the graphical rendering process and related input-output devices, which are also highly relevant to user needs. Furthermore, the study provides a foundation for developing retrieval systems tailored to MVRs by defining use cases, user stereotypes, and specific requirements for MVR Retrieval systems. The findings contribute to a better understanding of information search behaviors in MVR Retrieval and pave the way for future research and system design in this field.",
        "subjects": [
            "cs.IR",
            "cs.MM"
        ],
        "comment": "12 pages, 3 Figures, 8 Tables"
    },
    {
        "paper id": "2411.09059",
        "abstract url": "https://arxiv.org/abs/2411.09059",
        "title": "Sublinear Metric Steiner Tree via Improved Bounds for Set Cover",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the metric Steiner tree problem in the sublinear query model. In this problem, for a set of $n$ points $V$ in a metric space given to us by means of query access to an $n\\times n$ matrix $w$, and a set of terminals $T\\subseteq V$, the goal is to find the minimum-weight subset of the edges that connects all the terminal vertices. Recently, Chen, Khanna and Tan [SODA'23] gave an algorithm that uses $\\widetilde{O}(n^{13/7})$ queries and outputs a $(2-\u03b7)$-estimate of the metric Steiner tree weight, where $\u03b7>0$ is a universal constant. A key component in their algorithm is a sublinear algorithm for a particular set cover problem where, given a set system $(U, F)$, the goal is to provide a multiplicative-additive estimate for $|U|-\\textsf{SC}(U, F)$. Here $U$ is the set of elements, $F$ is the collection of sets, and $\\textsf{SC}(U, F)$ denotes the optimal set cover size of $(U, F)$. In particular, their algorithm returns a $(1/4, \\varepsilon\\cdot|U|)$-multiplicative-additive estimate for this set cover problem using $\\widetilde{O}(|F|^{7/4})$ membership oracle queries (querying whether a set $S$ contains an $e$), where $\\varepsilon$ is a fixed constant. In this work, we improve the query complexity of $(2-\u03b7)$-estimating the metric Steiner tree weight to $\\widetilde{O}(n^{5/3})$ by showing a $(1/2, \\varepsilon \\cdot |U|)$-estimate for the above set cover problem using $\\widetilde{O}(|F|^{5/3})$ membership queries. To design our set cover algorithm, we estimate the size of a random greedy maximal matching for an auxiliary multigraph that the algorithm constructs implicitly, without access to its adjacency list or matrix.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09075",
        "abstract url": "https://arxiv.org/abs/2411.09075",
        "title": "Weak Poincar\u00e9 Inequalities, Simulated Annealing, and Sampling from Spherical Spin Glasses",
        "rating": "-10",
        "keywords": [],
        "abstract": "There has been a recent surge of powerful tools to show rapid mixing of Markov chains, via functional inequalities such as Poincar\u00e9 inequalities. In many situations, Markov chains fail to mix rapidly from a worst-case initialization, yet are expected to approximately sample from a random initialization. For example, this occurs if the target distribution has metastable states, small clusters accounting for a vanishing fraction of the mass that are essentially disconnected from the bulk of the measure. Under such conditions, a Poincar\u00e9 inequality cannot hold, necessitating new tools to prove sampling guarantees. We develop a framework to analyze simulated annealing, based on establishing so-called weak Poincar\u00e9 inequalities. These inequalities imply mixing from a suitably warm start, and simulated annealing provides a way to chain such warm starts together into a sampling algorithm. We further identify a local-to-global principle to prove weak Poincar\u00e9 inequalities, mirroring the spectral independence and localization schemes frameworks for analyzing mixing times of Markov chains. As our main application, we prove that simulated annealing samples from the Gibbs measure of a spherical spin glass for inverse temperatures up to a natural threshold, matching recent algorithms based on algorithmic stochastic localization. This provides the first Markov chain sampling guarantee that holds beyond the uniqueness threshold for spherical spin glasses, where mixing from a worst-case initialization is provably slow due to the presence of metastable states. As an ingredient in our proof, we prove bounds on the operator norm of the covariance matrix of spherical spin glasses in the full replica-symmetric regime. Additionally, we resolve a question related to sampling using data-based initializations.",
        "subjects": [
            "math.PR",
            "cond-mat.dis-nn",
            "cs.DS",
            "math-ph"
        ],
        "comment": "94 pages, removed an incorrect application to the ferromagnetic Potts model"
    },
    {
        "paper id": "2411.09110",
        "abstract url": "https://arxiv.org/abs/2411.09110",
        "title": "Information-Optimal Multi-Spacecraft Positioning for Interstellar Object Exploration",
        "rating": "-10",
        "keywords": [],
        "abstract": "Interstellar objects (ISOs), astronomical objects not gravitationally bound to the sun, could present valuable opportunities to advance our understanding of the universe's formation and composition. In response to the unpredictable nature of their discoveries that inherently come with large and rapidly changing uncertainty in their state, this paper proposes a novel multi-spacecraft framework for locally maximizing information to be gained through ISO encounters with formal probabilistic guarantees. Given some approximated control and estimation policies for fully autonomous spacecraft operations, we first construct an ellipsoid around its terminal position, where the ISO would be located with a finite probability. The large state uncertainty of the ISO is formally handled here through the hierarchical property in stochastically contracting nonlinear systems. We then propose a method to find the terminal positions of the multiple spacecraft optimally distributed around the ellipsoid, which locally maximizes the information we can get from all the points of interest (POIs). This utilizes a probabilistic information cost function that accounts for spacecraft positions, camera specifications, and ISO position uncertainty, where the information is defined as visual data collected by cameras. Numerical simulations demonstrate the efficacy of this approach using synthetic ISO candidates generated from quasi-realistic empirical populations. Our method allows each spacecraft to optimally select its terminal state and determine the ideal number of POIs to investigate, potentially enhancing the ability to study these rare and fleeting interstellar visitors while minimizing resource utilization.",
        "subjects": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "math.OC"
        ],
        "comment": "IEEE Aerospace Conference, Preprint Version, Accepted: November 2024"
    },
    {
        "paper id": "2411.09146",
        "abstract url": "https://arxiv.org/abs/2411.09146",
        "title": "Secrecy Energy Efficiency Maximization in IRS-Assisted VLC MISO Networks with RSMA: A DS-PPO approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper investigates intelligent reflecting surface (IRS)-assisted multiple-input single-output (MISO) visible light communication (VLC) networks utilizing the rate-splitting multiple access (RSMA) scheme. {In these networks,} an eavesdropper (Eve) attempts to eavesdrop on communications intended for legitimate users (LUs). To enhance information security and energy efficiency simultaneously, we formulate a secrecy energy efficiency (SEE) maximization problem. In the formulated problem, beamforming vectors, RSMA common rates, direct current (DC) bias, and IRS alignment matrices are jointly optimized subject to constraints on total power budget, quality of service (QoS) requirements, linear operating region of light emitting diodes (LEDs), and common information rate allocation. Due to the non-convex and NP-hard nature of the formulated problem, we propose a deep reinforcement learning (DRL)-based dual-sampling proximal policy optimization (DS-PPO) approach. {The approach leverages} dual sample strategies and generalized advantage estimation (GAE). In addition, to further simplify the design, we adopt the maximum ratio transmission (MRT) and zero-forcing (ZF) as beamforming vectors in the action space. Simulation results show that the proposed DS-PPO approach outperforms traditional baseline approaches in terms of achievable SEE and significantly improves convergence speed compared to the original PPO approach. Moreover, implementing the RSMA scheme and IRS contributes to overall system performance, {achieving approximately $19.67\\%$ improvement over traditional multiple access schemes and $25.74\\%$ improvement over networks without IRS deployment.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "13 pages, 10 figures"
    },
    {
        "paper id": "2411.09148",
        "abstract url": "https://arxiv.org/abs/2411.09148",
        "title": "Toward Democratized Generative AI in Next-Generation Mobile Edge Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "The rapid development of generative AI technologies, including large language models (LLMs), has brought transformative changes to various fields. However, deploying such advanced models on mobile and edge devices remains challenging due to their high computational, memory, communication, and energy requirements. To address these challenges, we propose a model-centric framework for democratizing generative AI deployment on mobile and edge networks. First, we comprehensively review key compact model strategies, such as quantization, model pruning, and knowledge distillation, and present key performance metrics to optimize generative AI for mobile deployment. Next, we provide a focused review of mobile and edge networks, emphasizing the specific challenges and requirements of these environments. We further conduct a case study demonstrating the effectiveness of these strategies by deploying LLMs on real mobile edge devices. Experimental results highlight the practicality of democratized LLMs, with significant improvements in generalization accuracy, hallucination rate, accessibility, and resource consumption. Finally, we discuss potential research directions to further advance the deployment of generative AI in resource-constrained environments.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "9 pages, 5 figures"
    },
    {
        "paper id": "2411.09159",
        "abstract url": "https://arxiv.org/abs/2411.09159",
        "title": "PIMCOMP: An End-to-End DNN Compiler for Processing-In-Memory Accelerators",
        "rating": "-10",
        "keywords": [],
        "abstract": "Various processing-in-memory (PIM) accelerators based on various devices, micro-architectures, and interfaces have been proposed to accelerate deep neural networks (DNNs). How to deploy DNNs onto PIM-based accelerators is the key to explore PIM's high performance and energy efficiency. The scale of DNN models, the diversity of PIM accelerators, and the complexity of deployment are far beyond the human deployment capability. Hence, an automatic deployment methodology is indispensable. In this work, we propose PIMCOMP, an end-to-end DNN compiler tailored for PIM accelerators, achieving efficient deployment of DNN models on PIM hardware. PIMCOMP can adapt to various PIM architectures by using an abstract configurable PIM accelerator template with a set of pseudo-instructions, which is a high-level abstraction of the hardware's fundamental functionalities. Through a generic multi-level optimization framework, PIMCOMP realizes an end-to-end conversion from a high-level DNN description to pseudo-instructions, which can be further converted to specific hardware intrinsics/primitives. The compilation addresses two critical issues in PIM-accelerated inference from a system perspective: resource utilization and dataflow scheduling. PIMCOMP adopts a flexible unfolding format to reshape and partition convolutional layers, adopts a weight-layout guided computation-storage-mapping approach to enhance resource utilization, and balances the system's computation, memory access, and communication characteristics. For dataflow scheduling, we design two scheduling algorithms with different inter-layer pipeline granularities to support varying application scenarios while ensuring high computational parallelism. Experiments demonstrate that PIMCOMP improves throughput, latency, and energy efficiency across various architectures. PIMCOMP is open-sourced at \\url{https://github.com/sunxt99/PIMCOMP-NN}.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09171",
        "abstract url": "https://arxiv.org/abs/2411.09171",
        "title": "Optimizing Metamorphic Testing: Prioritizing Relations Through Execution Profile Dissimilarity",
        "rating": "-10",
        "keywords": [],
        "abstract": "An oracle determines whether the output of a program for executed test cases is correct. For machine learning programs, such an oracle is often unavailable or impractical to apply. Metamorphic testing addresses this by using metamorphic relations (MRs), which are essential properties of the software under test, to verify program correctness. Prioritizing MRs enhances fault detection effectiveness and improves testing efficiency. However, fault-based MR prioritization is costly, and code coverage-based approaches often yield inaccurate results. To address these challenges, we propose a statement centrality-based prioritization approach that leverages diversity in the execution profiles of source and follow-up test cases. Our approach improves fault detection effectiveness by up to 31% compared to code coverage-based methods and reduces fault detection time by 29% compared to random MR execution. Overall, it increases the average fault detection rate, reduces fault detection time, and enhances testing efficiency.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2109.09798, arXiv:2209.00162"
    },
    {
        "paper id": "2411.10482",
        "abstract url": "https://arxiv.org/abs/2411.10482",
        "title": "The Noisy Work of Uncertainty Visualisation Research: A Review",
        "rating": "-10",
        "keywords": [],
        "abstract": "Uncertainty visualisation is quickly becomming a hot topic in information visualisation. Exisiting reviews in the field take the definition and purpose of an uncertainty visualisation to be self evident which results in a large amout of conflicting information. This conflict largely stems from a conflation between uncertainty visualisations designed for decision making and those designed to prevent false conclusions. We coin the term \"signal suppression\" to describe a visualisation that is designed for preventing false conclusions, as the approach demands that the signal (i.e. the collective take away of the estimates) is suppressed by the noise (i.e. the variance on those estimates). We argue that the current standards in visualisation suggest that uncertainty visualisations designed for decision making should not be considered uncertainty visualisations at all. Therefore, future work should focus on signal suppression. Effective signal suppression requires us to communicate the signal and the noise as a single \"validity of signal\" variable, and doing so proves to be difficult with current methods. We illustrate current approaches to uncertainty visualisation by showing how they would change the visual apprearance of a choropleth map. These maps allow us to see why some methods succeed at signal suppression, while others fall short. Evaluating visualisations on how well they perform signal suppression also proves to be difficult, as it involves measuring the effect of noise, a variable we typically try to ignore. We suggest authors use qualitative studies or compare uncertainty visualisations to the relevant hypothesis tests.",
        "subjects": [
            "cs.HC",
            "stat.AP"
        ],
        "comment": "52 pages with 7 figures"
    }
]