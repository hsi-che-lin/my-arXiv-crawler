[
    {
        "paper id": "2411.09273",
        "abstract url": "https://arxiv.org/abs/2411.09273",
        "title": "Cross-Modal Consistency in Multimodal Large Language Models",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent developments in multimodal methodologies have marked the beginning of an exciting era for models adept at processing diverse data types, encompassing text, audio, and visual content. Models like GPT-4V, which merge computer vision with advanced language processing, exhibit extraordinary proficiency in handling intricate tasks that require a simultaneous understanding of both textual and visual information. Prior research efforts have meticulously evaluated the efficacy of these Vision Large Language Models (VLLMs) in various domains, including object detection, image captioning, and other related fields. However, existing analyses have often suffered from limitations, primarily centering on the isolated evaluation of each modality's performance while neglecting to explore their intricate cross-modal interactions. Specifically, the question of whether these models achieve the same level of accuracy when confronted with identical task instances across different modalities remains unanswered. In this study, we take the initiative to delve into the interaction and comparison among these modalities of interest by introducing a novel concept termed cross-modal consistency. Furthermore, we propose a quantitative evaluation framework founded on this concept. Our experimental findings, drawn from a curated collection of parallel vision-language datasets developed by us, unveil a pronounced inconsistency between the vision and language modalities within GPT-4V, despite its portrayal as a unified multimodal model. Our research yields insights into the appropriate utilization of such models and hints at potential avenues for enhancing their design.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09587",
        "abstract url": "https://arxiv.org/abs/2411.09587",
        "title": "BabyLM Challenge: Exploring the Effect of Variation Sets on Language Model Training Efficiency",
        "rating": "2",
        "keywords": [
            [
                "Training Efficiency"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "While current large language models have achieved a remarkable success, their data efficiency remains a challenge to overcome. Recently it has been suggested that child-directed speech (CDS) can improve training data efficiency of modern language models based on Transformer neural networks. However, it is not yet understood which specific properties of CDS are effective for training these models. In the context of the BabyLM Challenge, we focus on Variation Sets (VSs), sets of consecutive utterances expressing a similar intent with slightly different words and structures, which are ubiquitous in CDS. To assess the impact of VSs on training data efficiency, we augment CDS data with different proportions of artificial VSs and use these datasets to train an auto-regressive model, GPT-2. We find that the best proportion of VSs depends on the evaluation benchmark: BLiMP and GLUE scores benefit from the presence of VSs, but EWOK scores do not. Additionally, the results vary depending on multiple factors such as the number of epochs and the order of utterance presentation. Taken together, these findings suggest that VSs can have a beneficial influence on language models, while leaving room for further investigation.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "This paper accepted BabyLM challenge 2024 at CONLL 2024"
    },
    {
        "paper id": "2411.09242",
        "abstract url": "https://arxiv.org/abs/2411.09242",
        "title": "FluidML: Fast and Memory Efficient Inference Optimization",
        "rating": "1.5",
        "keywords": [
            [
                "Memory Efficient"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning models deployed on edge devices have enabled numerous exciting new applications, such as humanoid robots, AR glasses, and autonomous vehicles. However, the computing resources available on these edge devices are not catching up with the ever-growing number of parameters in these models. As the models become bigger and more complicated, the novel yet sophisticated structure challenges the inference runtime optimization. We present FluidML, a generic runtime memory management and optimization framework that can flexibly transform the model execution blueprint to achieve faster and more memory-efficient inference. Evaluations across different platforms show that FluidML can consistently reduce the end-to-end inference latency by up to 25.38% for popular language models and reduce peak memory usage by up to 41.47%, compared to state-of-the-art approaches. FluidML is of ~30K line of codes, built for general-purpose usage, and will be released as an open-source inference runtime optimization framework to the community.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09317",
        "abstract url": "https://arxiv.org/abs/2411.09317",
        "title": "Pie: Pooling CPU Memory for LLM Inference",
        "rating": "1.5",
        "keywords": [
            [
                "GPU memory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The rapid growth of LLMs has revolutionized natural language processing and AI analysis, but their increasing size and memory demands present significant challenges. A common solution is to spill over to CPU memory; however, traditional GPU-CPU memory swapping often results in higher latency and lower throughput. This paper introduces Pie, an LLM inference framework that addresses these challenges with performance-transparent swapping and adaptive expansion. By leveraging predictable memory access patterns and the high bandwidth of modern hardware like the NVIDIA GH200 Grace Hopper Superchip, Pie enables concurrent data swapping without affecting foreground computation, expanding effective memory without added latency. Adaptive expansion dynamically adjusts CPU memory allocation based on real-time information, optimizing memory usage and performance under varying conditions. Pie maintains low computation latency, high throughput, and high elasticity. Our experimental evaluation demonstrates that Pie achieves optimal swapping policy during cache warmup and effectively balances increased memory capacity with negligible impact on computation. With its extended capacity, Pie outperforms vLLM by up to 1.9X in throughput and 2X in latency. Additionally, Pie can reduce GPU memory usage by up to 1.67X while maintaining the same performance. Compared to FlexGen, an offline profiling-based swapping solution, Pie achieves magnitudes lower latency and 9.4X higher throughput.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09453",
        "abstract url": "https://arxiv.org/abs/2411.09453",
        "title": "Long-Tailed Object Detection Pre-training: Dynamic Rebalancing Contrastive Learning with Dual Reconstruction",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Pre-training plays a vital role in various vision tasks, such as object recognition and detection. Commonly used pre-training methods, which typically rely on randomized approaches like uniform or Gaussian distributions to initialize model parameters, often fall short when confronted with long-tailed distributions, especially in detection tasks. This is largely due to extreme data imbalance and the issue of simplicity bias. In this paper, we introduce a novel pre-training framework for object detection, called Dynamic Rebalancing Contrastive Learning with Dual Reconstruction (2DRCL). Our method builds on a Holistic-Local Contrastive Learning mechanism, which aligns pre-training with object detection by capturing both global contextual semantics and detailed local patterns. To tackle the imbalance inherent in long-tailed data, we design a dynamic rebalancing strategy that adjusts the sampling of underrepresented instances throughout the pre-training process, ensuring better representation of tail classes. Moreover, Dual Reconstruction addresses simplicity bias by enforcing a reconstruction task aligned with the self-consistency principle, specifically benefiting underrepresented tail classes. Experiments on COCO and LVIS v1.0 datasets demonstrate the effectiveness of our method, particularly in improving the mAP/AP scores for tail classes.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by NeurIPS 2024"
    },
    {
        "paper id": "2411.09702",
        "abstract url": "https://arxiv.org/abs/2411.09702",
        "title": "On the Surprising Effectiveness of Attention Transfer for Vision Transformers",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Conventional wisdom suggests that pre-training Vision Transformers (ViT) improves downstream performance by learning useful representations. Is this actually true? We investigate this question and find that the features and representations learned during pre-training are not essential. Surprisingly, using only the attention patterns from pre-training (i.e., guiding how information flows between tokens) is sufficient for models to learn high quality features from scratch and achieve comparable downstream performance. We show this by introducing a simple method called attention transfer, where only the attention patterns from a pre-trained teacher ViT are transferred to a student, either by copying or distilling the attention maps. Since attention transfer lets the student learn its own features, ensembling it with a fine-tuned teacher also further improves accuracy on ImageNet. We systematically study various aspects of our findings on the sufficiency of attention maps, including distribution shift settings where they underperform fine-tuning. We hope our exploration provides a better understanding of what pre-training accomplishes and leads to a useful alternative to the standard practice of fine-tuning",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.NE"
        ],
        "comment": "NeurIPS 2024. Code: https://github.com/alexlioralexli/attention-transfer"
    },
    {
        "paper id": "2411.09827",
        "abstract url": "https://arxiv.org/abs/2411.09827",
        "title": "The Good, The Efficient and the Inductive Biases: Exploring Efficiency in Deep Learning Through the Use of Inductive Biases",
        "rating": "1.5",
        "keywords": [
            [
                "parameter efficiency"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The emergence of Deep Learning has marked a profound shift in machine learning, driven by numerous breakthroughs achieved in recent years. However, as Deep Learning becomes increasingly present in everyday tools and applications, there is a growing need to address unresolved challenges related to its efficiency and sustainability. This dissertation delves into the role of inductive biases -- particularly, continuous modeling and symmetry preservation -- as strategies to enhance the efficiency of Deep Learning. It is structured in two main parts. The first part investigates continuous modeling as a tool to improve the efficiency of Deep Learning algorithms. Continuous modeling involves the idea of parameterizing neural operations in a continuous space. The research presented here demonstrates substantial benefits for the (i) computational efficiency -- in time and memory, (ii) the parameter efficiency, and (iii) design efficiency -- the complexity of designing neural architectures for new datasets and tasks. The second focuses on the role of symmetry preservation on Deep Learning efficiency. Symmetry preservation involves designing neural operations that align with the inherent symmetries of data. The research presented in this part highlights significant gains both in data and parameter efficiency through the use of symmetry preservation. However, it also acknowledges a resulting trade-off of increased computational costs. The dissertation concludes with a critical evaluation of these findings, openly discussing their limitations and proposing strategies to address them, informed by literature and the author insights. It ends by identifying promising future research avenues in the exploration of inductive biases for efficiency, and their wider implications for Deep Learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "PhD Dissertation"
    },
    {
        "paper id": "2411.09189",
        "abstract url": "https://arxiv.org/abs/2411.09189",
        "title": "Improvement and Implementation of a Speech Emotion Recognition Model Based on Dual-Layer LSTM",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper builds upon an existing speech emotion recognition model by adding an additional LSTM layer to improve the accuracy and processing efficiency of emotion recognition from audio data. By capturing the long-term dependencies within audio sequences through a dual-layer LSTM network, the model can recognize and classify complex emotional patterns more accurately. Experiments conducted on the RAVDESS dataset validated this approach, showing that the modified dual layer LSTM model improves accuracy by 2% compared to the single-layer LSTM while significantly reducing recognition latency, thereby enhancing real-time performance. These results indicate that the dual-layer LSTM architecture is highly suitable for handling emotional features with long-term dependencies, providing a viable optimization for speech emotion recognition systems. This research provides a reference for practical applications in fields like intelligent customer service, sentiment analysis and human-computer interaction.",
        "subjects": [
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09214",
        "abstract url": "https://arxiv.org/abs/2411.09214",
        "title": "HateGPT: Unleashing GPT-3.5 Turbo to Combat Hate Speech on X",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The widespread use of social media platforms like Twitter and Facebook has enabled people of all ages to share their thoughts and experiences, leading to an immense accumulation of user-generated content. However, alongside the benefits, these platforms also face the challenge of managing hate speech and offensive content, which can undermine rational discourse and threaten democratic values. As a result, there is a growing need for automated methods to detect and mitigate such content, especially given the complexity of conversations that may require contextual analysis across multiple languages, including code-mixed languages like Hinglish, German-English, and Bangla. We participated in the English task where we have to classify English tweets into two categories namely Hate and Offensive and Non Hate-Offensive. In this work, we experiment with state-of-the-art large language models like GPT-3.5 Turbo via prompting to classify tweets into Hate and Offensive or Non Hate-Offensive. In this study, we evaluate the performance of a classification model using Macro-F1 scores across three distinct runs. The Macro-F1 score, which balances precision and recall across all classes, is used as the primary metric for model evaluation. The scores obtained are 0.756 for run 1, 0.751 for run 2, and 0.754 for run 3, indicating a high level of performance with minimal variance among the runs. The results suggest that the model consistently performs well in terms of precision and recall, with run 1 showing the highest performance. These findings highlight the robustness and reliability of the model across different runs.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at FIRE 2024 (Track: Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages (HASOC)). arXiv admin note: text overlap with arXiv:2411.05039, arXiv:2411.06946"
    },
    {
        "paper id": "2411.09219",
        "abstract url": "https://arxiv.org/abs/2411.09219",
        "title": "Harnessing Vision Foundation Models for High-Performance, Training-Free Open Vocabulary Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "While Contrastive Language-Image Pre-training (CLIP) has advanced open-vocabulary predictions, its performance on semantic segmentation remains suboptimal. This shortfall primarily stems from its spatial-invariant semantic features and constrained resolution. While previous adaptations addressed spatial invariance semantic by modifying the self-attention in CLIP's image encoder, the issue of limited resolution remains unexplored. Different from previous segment-then-splice methods that segment sub-images via a sliding window and splice the results, we introduce a splice-then-segment paradigm that incorporates Segment-Anything Model (SAM) to tackle the resolution issue since SAM excels at extracting fine-grained semantic correlations from high-resolution images. Specifically, we introduce Trident, a training-free framework that first splices features extracted by CLIP and DINO from sub-images, then leverages SAM's encoder to create a correlation matrix for global aggregation, enabling a broadened receptive field for effective segmentation. Besides, we propose a refinement strategy for CLIP's coarse segmentation outputs by transforming them into prompts for SAM, further enhancing the segmentation performance. Trident achieves a significant improvement in the mIoU across eight benchmarks compared with the current SOTA, increasing from 44.4 to 48.6.Code is available at https://github.com/YuHengsss/Trident.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 5 figures"
    },
    {
        "paper id": "2411.09222",
        "abstract url": "https://arxiv.org/abs/2411.09222",
        "title": "Toward Democracy Levels for AI",
        "rating": "1",
        "keywords": [
            [
                "cs.CY"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "There is increasing concern about the unilateral power of the organizations involved in the development, alignment, and governance of AI. Recent pilots - such as Meta's Community Forums and Anthropic's Collective Constitutional AI - have illustrated a promising direction, where democratic processes might be used to meaningfully improve public involvement and trust in critical decisions. However, there is no standard framework for evaluating such processes. In this paper, building on insights from the theory and practice of deliberative democracy, we provide a \"Democracy Levels\" framework for evaluating the degree to which decisions in a given domain are made democratically. The framework can be used (i) to define milestones in a roadmap for the democratic AI, pluralistic AI, and public AI ecosystems, (ii) to guide organizations that need to increase the legitimacy of their decisions on difficult AI governance questions, and (iii) as a rubric by those aiming to evaluate AI organizations and keep them accountable.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "11 pages. Accepted to the Workshop on Pluralistic Alignment at NeurIPS 2024"
    },
    {
        "paper id": "2411.09249",
        "abstract url": "https://arxiv.org/abs/2411.09249",
        "title": "Enhancing Financial Domain Adaptation of Language Models via Model Augmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The domain adaptation of language models, including large language models (LLMs), has become increasingly important as the use of such models continues to expand. This study demonstrates the effectiveness of Composition to Augment Language Models (CALM) in adapting to the financial domain. CALM is a model to extend the capabilities of existing models by introducing cross-attention between two LLMs with different functions. In our experiments, we developed a CALM to enhance the financial performance of an LLM with strong response capabilities by leveraging a financial-specialized LLM. Notably, the CALM was trained using a financial dataset different from the one used to train the financial-specialized LLM, confirming CALM's ability to adapt to various datasets. The models were evaluated through quantitative Japanese financial benchmarks and qualitative response comparisons, demonstrating that CALM enables superior responses with higher scores than the original models and baselines. Additionally, comparative experiments on connection points revealed that connecting the middle layers of the models is most effective in facilitating adaptation to the financial domain. These findings confirm that CALM is a practical approach for adapting LLMs to the financial domain.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09250",
        "abstract url": "https://arxiv.org/abs/2411.09250",
        "title": "Embedding Space Allocation with Angle-Norm Joint Classifiers for Few-Shot Class-Incremental Learning",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Few-shot class-incremental learning (FSCIL) aims to continually learn new classes from only a few samples without forgetting previous ones, requiring intelligent agents to adapt to dynamic environments. FSCIL combines the characteristics and challenges of class-incremental learning and few-shot learning: (i) Current classes occupy the entire feature space, which is detrimental to learning new classes. (ii) The small number of samples in incremental rounds is insufficient for fully training. In existing mainstream virtual class methods, for addressing the challenge (i), they attempt to use virtual classes as placeholders. However, new classes may not necessarily align with the virtual classes. For the challenge (ii), they replace trainable fully connected layers with Nearest Class Mean (NCM) classifiers based on cosine similarity, but NCM classifiers do not account for sample imbalance issues. To address these issues in previous methods, we propose the class-center guided embedding Space Allocation with Angle-Norm joint classifiers (SAAN) learning framework, which provides balanced space for all classes and leverages norm differences caused by sample imbalance to enhance classification criteria. Specifically, for challenge (i), SAAN divides the feature space into multiple subspaces and allocates a dedicated subspace for each session by guiding samples with the pre-set category centers. For challenge (ii), SAAN establishes a norm distribution for each class and generates angle-norm joint logits. Experiments demonstrate that SAAN can achieve state-of-the-art performance and it can be directly embedded into other SOTA methods as a plug-in, further enhancing their performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09263",
        "abstract url": "https://arxiv.org/abs/2411.09263",
        "title": "Rethinking Weight-Averaged Model-merging",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Weight-averaged model-merging has emerged as a powerful approach in deep learning, capable of enhancing model performance without fine-tuning or retraining. However, the underlying mechanisms that explain its effectiveness remain largely unexplored. In this paper, we investigate this technique from three novel perspectives to provide deeper insights into how and why weight-averaged model-merging works: (1) we examine the intrinsic patterns captured by the learning of the model weights, through the visualizations of their patterns on several datasets, showing that these weights often encode structured and interpretable patterns; (2) we investigate model ensemble merging strategies based on averaging on weights versus averaging on features, providing detailed analyses across diverse architectures and datasets; and (3) we explore the impact on model-merging prediction stability in terms of changing the parameter magnitude, revealing insights into the way of weight averaging works as regularization by showing the robustness across different parameter scales. Our findings shed light on the \"black box\" of weight-averaged model-merging, offering valuable insights and practical recommendations that advance the model-merging process.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09289",
        "abstract url": "https://arxiv.org/abs/2411.09289",
        "title": "StreamAdapter: Efficient Test Time Adaptation from Contextual Streams",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "In-context learning (ICL) allows large language models (LLMs) to adapt to new tasks directly from the given demonstrations without requiring gradient updates. While recent advances have expanded context windows to accommodate more demonstrations, this approach increases inference costs without necessarily improving performance. To mitigate these issues, We propose StreamAdapter, a novel approach that directly updates model parameters from context at test time, eliminating the need for explicit in-context demonstrations. StreamAdapter employs context mapping and weight absorption mechanisms to dynamically transform ICL demonstrations into parameter updates with minimal additional parameters. By reducing reliance on numerous in-context examples, StreamAdapter significantly reduce inference costs and allows for efficient inference with constant time complexity, regardless of demonstration count. Extensive experiments across diverse tasks and model architectures demonstrate that StreamAdapter achieves comparable or superior adaptation capability to ICL while requiring significantly fewer demonstrations. The superior task adaptation and context encoding capabilities of StreamAdapter on both language understanding and generation tasks provides a new perspective for adapting LLMs at test time using context, allowing for more efficient adaptation across scenarios and more cost-effective inference",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "22 Pages, 9 Figures"
    },
    {
        "paper id": "2411.09297",
        "abstract url": "https://arxiv.org/abs/2411.09297",
        "title": "DTELS: Towards Dynamic Granularity of Timeline Summarization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The rapid proliferation of online news has posed significant challenges in tracking the continuous development of news topics. Traditional timeline summarization constructs a chronological summary of the events but often lacks the flexibility to meet the diverse granularity needs. To overcome this limitation, we introduce a new paradigm, Dynamic-granularity TimELine Summarization, (DTELS), which aims to construct adaptive timelines based on user instructions or requirements. This paper establishes a comprehensive benchmark for DTLES that includes: (1) an evaluation framework grounded in journalistic standards to assess the timeline quality across four dimensions: Informativeness, Granular Consistency, Factuality, and Coherence; (2) a large-scale, multi-source dataset with multiple granularity timeline annotations based on a consensus process to facilitate authority; (3) extensive experiments and analysis with two proposed solutions based on Large Language Models (LLMs) and existing state-of-the-art TLS methods. The experimental results demonstrate the effectiveness of LLM-based solutions. However, even the most advanced LLMs struggle to consistently generate timelines that are both informative and granularly consistent, highlighting the challenges of the DTELS task.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Under review"
    },
    {
        "paper id": "2411.09308",
        "abstract url": "https://arxiv.org/abs/2411.09308",
        "title": "DT-JRD: Deep Transformer based Just Recognizable Difference Prediction Model for Video Coding for Machines",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Just Recognizable Difference (JRD) represents the minimum visual difference that is detectable by machine vision, which can be exploited to promote machine vision oriented visual signal processing. In this paper, we propose a Deep Transformer based JRD (DT-JRD) prediction model for Video Coding for Machines (VCM), where the accurately predicted JRD can be used reduce the coding bit rate while maintaining the accuracy of machine tasks. Firstly, we model the JRD prediction as a multi-class classification and propose a DT-JRD prediction model that integrates an improved embedding, a content and distortion feature extraction, a multi-class classification and a novel learning strategy. Secondly, inspired by the perception property that machine vision exhibits a similar response to distortions near JRD, we propose an asymptotic JRD loss by using Gaussian Distribution-based Soft Labels (GDSL), which significantly extends the number of training labels and relaxes classification boundaries. Finally, we propose a DT-JRD based VCM to reduce the coding bits while maintaining the accuracy of object detection. Extensive experimental results demonstrate that the mean absolute error of the predicted JRD by the DT-JRD is 5.574, outperforming the state-of-the-art JRD prediction model by 13.1%. Coding experiments shows that comparing with the VVC, the DT-JRD based VCM achieves an average of 29.58% bit rate reduction while maintaining the object detection accuracy.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Submitted to IEEE Transactions on Multimedia"
    },
    {
        "paper id": "2411.09318",
        "abstract url": "https://arxiv.org/abs/2411.09318",
        "title": "DriveThru: a Document Extraction Platform and Benchmark Datasets for Indonesian Local Language Archives",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Indonesia is one of the most diverse countries linguistically. However, despite this linguistic diversity, Indonesian languages remain underrepresented in Natural Language Processing (NLP) research and technologies. In the past two years, several efforts have been conducted to construct NLP resources for Indonesian languages. However, most of these efforts have been focused on creating manual resources thus difficult to scale to more languages. Although many Indonesian languages do not have a web presence, locally there are resources that document these languages well in printed forms such as books, magazines, and newspapers. Digitizing these existing resources will enable scaling of Indonesian language resource construction to many more languages. In this paper, we propose an alternative method of creating datasets by digitizing documents, which have not previously been used to build digital language resources in Indonesia. DriveThru is a platform for extracting document content utilizing Optical Character Recognition (OCR) techniques in its system to provide language resource building with less manual effort and cost. This paper also studies the utility of current state-of-the-art LLM for post-OCR correction to show the capability of increasing the character accuracy rate (CAR) and word accuracy rate (WAR) compared to off-the-shelf OCR.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "12 pages, 3 figures, 6 tables"
    },
    {
        "paper id": "2411.09371",
        "abstract url": "https://arxiv.org/abs/2411.09371",
        "title": "DSCformer: A Dual-Branch Network Integrating Enhanced Dynamic Snake Convolution and SegFormer for Crack Segmentation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "In construction quality monitoring, accurately detecting and segmenting cracks in concrete structures is paramount for safety and maintenance. Current convolutional neural networks (CNNs) have demonstrated strong performance in crack segmentation tasks, yet they often struggle with complex backgrounds and fail to capture fine-grained tubular structures fully. In contrast, Transformers excel at capturing global context but lack precision in detailed feature extraction. We introduce DSCformer, a novel hybrid model that integrates an enhanced Dynamic Snake Convolution (DSConv) with a Transformer architecture for crack segmentation to address these challenges. Our key contributions include the enhanced DSConv through a pyramid kernel for adaptive offset computation and a simultaneous bi-directional learnable offset iteration, significantly improving the model's performance to capture intricate crack patterns. Additionally, we propose a Weighted Convolutional Attention Module (WCAM), which refines channel attention, allowing for more precise and adaptive feature attention. We evaluate DSCformer on the Crack3238 and FIND datasets, achieving IoUs of 59.22\\% and 87.24\\%, respectively. The experimental results suggest that our DSCformer outperforms state-of-the-art methods across different datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09431",
        "abstract url": "https://arxiv.org/abs/2411.09431",
        "title": "Everyone deserves their voice to be heard: Analyzing Predictive Gender Bias in ASR Models Applied to Dutch Speech Data",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent research has shown that state-of-the-art (SotA) Automatic Speech Recognition (ASR) systems, such as Whisper, often exhibit predictive biases that disproportionately affect various demographic groups. This study focuses on identifying the performance disparities of Whisper models on Dutch speech data from the Common Voice dataset and the Dutch National Public Broadcasting organisation. We analyzed the word error rate, character error rate and a BERT-based semantic similarity across gender groups. We used the moral framework of Weerts et al. (2022) to assess quality of service harms and fairness, and to provide a nuanced discussion on the implications of these biases, particularly for automatic subtitling. Our findings reveal substantial disparities in word error rate (WER) among gender groups across all model sizes, with bias identified through statistical testing.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted at ECML PKDD 2024, 4th Workshop on Bias and Fairness in AI (BIAS)"
    },
    {
        "paper id": "2411.09439",
        "abstract url": "https://arxiv.org/abs/2411.09439",
        "title": "Spider: Any-to-Many Multimodal LLM",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal LLMs (MLLMs) have emerged as an extension of Large Language Models (LLMs), enabling the integration of various modalities. However, Any-to-Any MLLMs are limited to generating pairwise modalities 'Text + X' within a single response, such as Text + {Image or Audio or Video}. To address this limitation, we introduce Spider, a novel efficient Any-to-Many Modalities Generation (AMMG) framework, which can generate an arbitrary combination of modalities 'Text + Xs', such as Text + {Image and Audio and Video}. To achieve efficient AMMG, our Spider integrates three core components: a Base Model for basic X-to-X (i.e., Any-to-Any) modality processing, a novel Efficient Decoders-Controller for controlling multimodal Decoders to generate Xs (many-modal) contents, and an Any-to-Many Instruction Template designed for producing Xs signal prompts. To train Spider, we constructed a novel Text-formatted Many-Modal (TMM) dataset, which facilitates the learning of the X-to-Xs (i.e., Any-to-Many) capability necessary for AMMG. Ultimately, the well-trained Spider generates a pseudo X-to-Xs dataset, the first-ever X-to-Xs many-modal dataset, enhancing the potential for AMMG task in future research. Overall, this work not only pushes the boundary of multimodal interaction but also provides rich data support for advancing the field.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09468",
        "abstract url": "https://arxiv.org/abs/2411.09468",
        "title": "Harnessing Machine Learning for Single-Shot Measurement of Free Electron Laser Pulse Power",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Electron beam accelerators are essential in many scientific and technological fields. Their operation relies heavily on the stability and precision of the electron beam. Traditional diagnostic techniques encounter difficulties in addressing the complex and dynamic nature of electron beams. Particularly in the context of free-electron lasers (FELs), it is fundamentally impossible to measure the lasing-on and lasingoff electron power profiles for a single electron bunch. This is a crucial hurdle in the exact reconstruction of the photon pulse profile. To overcome this hurdle, we developed a machine learning model that predicts the temporal power profile of the electron bunch in the lasing-off regime using machine parameters that can be obtained when lasing is on. The model was statistically validated and showed superior predictions compared to the state-of-the-art batch calibrations. The work we present here is a critical element for a virtual pulse reconstruction diagnostic (VPRD) tool designed to reconstruct the power profile of individual photon pulses without requiring repeated measurements in the lasing-off regime. This promises to significantly enhance the diagnostic capabilities in FELs at large.",
        "subjects": [
            "cs.LG",
            "physics.acc-ph"
        ],
        "comment": "10 pages, 4 figures, Machine Learning and the Physical Sciences Workshop, NeurIPS 2024 https://neurips.cc/virtual/2024/100009"
    },
    {
        "paper id": "2411.09479",
        "abstract url": "https://arxiv.org/abs/2411.09479",
        "title": "An End-To-End Stuttering Detection Method Based On Conformer And BILSTM",
        "rating": "1",
        "keywords": [
            [
                "eess.AS"
            ]
        ],
        "abstract": "Stuttering is a neurodevelopmental speech disorder characterized by common speech symptoms such as pauses, exclamations, repetition, and prolongation. Speech-language pathologists typically assess the type and severity of stuttering by observing these symptoms. Many effective end-to-end methods exist for stuttering detection, but a commonly overlooked challenge is the uncertain relationship between tasks involved in this process. Using a suitable multi-task strategy could improve stuttering detection performance. This paper presents a novel stuttering event detection model designed to help speech-language pathologists assess both the type and severity of stuttering. First, the Conformer model extracts acoustic features from stuttered speech, followed by a Long Short-Term Memory (LSTM) network to capture contextual information. Finally, we explore multi-task learning for stuttering and propose an effective multi-task strategy. Experimental results show that our model outperforms current state-of-the-art methods for stuttering detection. In the SLT 2024 Stuttering Speech Challenge based on the AS-70 dataset [1], our model improved the mean F1 score by 24.8% compared to the baseline method and achieved first place. On this basis, we conducted relevant extensive experiments on LSTM and multi-task learning strategies respectively. The results show that our proposed method improved the mean F1 score by 39.8% compared to the baseline method.",
        "subjects": [
            "eess.AS"
        ],
        "comment": "7 pages, 3 figures, 7 tables"
    },
    {
        "paper id": "2411.09483",
        "abstract url": "https://arxiv.org/abs/2411.09483",
        "title": "Sparse Bayesian Generative Modeling for Compressive Sensing",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "eess.IV"
            ]
        ],
        "abstract": "This work addresses the fundamental linear inverse problem in compressive sensing (CS) by introducing a new type of regularizing generative prior. Our proposed method utilizes ideas from classical dictionary-based CS and, in particular, sparse Bayesian learning (SBL), to integrate a strong regularization towards sparse solutions. At the same time, by leveraging the notion of conditional Gaussianity, it also incorporates the adaptability from generative models to training data. However, unlike most state-of-the-art generative models, it is able to learn from a few compressed and noisy data samples and requires no optimization algorithm for solving the inverse problem. Additionally, similar to Dirichlet prior networks, our model parameterizes a conjugate prior enabling its application for uncertainty quantification. We support our approach theoretically through the concept of variational inference and validate it empirically using different types of compressible signals.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09484",
        "abstract url": "https://arxiv.org/abs/2411.09484",
        "title": "Image Matching Filtering and Refinement by Planes and Beyond",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper introduces a modular, non-deep learning method for filtering and refining sparse correspondences in image matching. Assuming that motion flow within the scene can be approximated by local homography transformations, matches are aggregated into overlapping clusters corresponding to virtual planes using an iterative RANSAC-based approach, with non-conforming correspondences discarded. Moreover, the underlying planar structural design provides an explicit map between local patches associated with the matches, enabling optional refinement of keypoint positions through cross-correlation template matching after patch reprojection. Finally, to enhance robustness and fault-tolerance against violations of the piece-wise planar approximation assumption, a further strategy is designed for minimizing relative patch distortion in the plane reprojection by introducing an intermediate homography that projects both patches into a common plane. The proposed method is extensively evaluated on standard datasets and image matching pipelines, and compared with state-of-the-art approaches. Unlike other current comparisons, the proposed benchmark also takes into account the more general, real, and practical cases where camera intrinsics are unavailable. Experimental results demonstrate that our proposed non-deep learning, geometry-based approach achieves performances that are either superior to or on par with recent state-of-the-art deep learning methods. Finally, this study suggests that there are still development potential in actual image matching solutions in the considered research direction, which could be in the future incorporated in novel deep image matching architectures.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "project page: https://github.com/fb82/MiHo"
    },
    {
        "paper id": "2411.09492",
        "abstract url": "https://arxiv.org/abs/2411.09492",
        "title": "MM-Eval: A Hierarchical Benchmark for Modern Mongolian Evaluation in LLMs",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) excel in high-resource languages but face notable challenges in low-resource languages like Mongolian. This paper addresses these challenges by categorizing capabilities into language abilities (syntax and semantics) and cognitive abilities (knowledge and reasoning). To systematically evaluate these areas, we developed MM-Eval, a specialized dataset based on Modern Mongolian Language Textbook I and enriched with WebQSP and MGSM datasets. Preliminary experiments on models including Qwen2-7B-Instruct, GLM4-9b-chat, Llama3.1-8B-Instruct, GPT-4, and DeepseekV2.5 revealed that: 1) all models performed better on syntactic tasks than semantic tasks, highlighting a gap in deeper language understanding; and 2) knowledge tasks showed a moderate decline, suggesting that models can transfer general knowledge from high-resource to low-resource contexts. The release of MM-Eval, comprising 569 syntax, 677 semantics, 344 knowledge, and 250 reasoning tasks, offers valuable insights for advancing NLP and LLMs in low-resource languages like Mongolian. The dataset is available at https://github.com/joenahm/MM-Eval.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09497",
        "abstract url": "https://arxiv.org/abs/2411.09497",
        "title": "The Use of Readability Metrics in Legal Text: A Systematic Literature Review",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Understanding the text in legal documents can be challenging due to their complex structure and the inclusion of domain-specific jargon. Laws and regulations are often crafted in such a manner that engagement with them requires formal training, potentially leading to vastly different interpretations of the same texts. Linguistic complexity is an important contributor to the difficulties experienced by readers. Simplifying texts could enhance comprehension across a broader audience, not just among trained professionals. Various metrics have been developed to measure document readability. Therefore, we adopted a systematic review approach to examine the linguistic and readability metrics currently employed for legal and regulatory texts. A total of 3566 initial papers were screened, with 34 relevant studies found and further assessed. Our primary objective was to identify which current metrics were applied for evaluating readability within the legal field. Sixteen different metrics were identified, with the Flesch-Kincaid Grade Level being the most frequently used method. The majority of studies (73.5%) were found in the domain of \"informed consent forms\". From the analysis, it is clear that not all legal domains are well represented in terms of readability metrics and that there is a further need to develop more consensus on which metrics should be applied for legal documents.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09510",
        "abstract url": "https://arxiv.org/abs/2411.09510",
        "title": "Communication Compression for Tensor Parallel LLM Inference",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have pushed the frontier of artificial intelligence but are comprised of hundreds of billions of parameters and operations. For faster inference latency, LLMs are deployed on multiple hardware accelerators through various Model Parallelism strategies. Our paper looks into the details on one such strategy - Tensor Parallel - and proposes to reduce latency by compressing inter-accelerator communication. We leverage fine grained quantization techniques to compress selected activations by 3.5 - 4.5x. Our proposed method leads up to 2x reduction of time-to-first-token (TTFT) with negligible model performance degradation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09515",
        "abstract url": "https://arxiv.org/abs/2411.09515",
        "title": "Application of signal separation to diffraction image compression and serial crystallography",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "We present here a real-time analysis of diffraction images acquired at high frame-rate (925 Hz) and its application to macromolecular serial crystallography. The software uses a new signal separation algorithm, able to distinguish the amorphous (or powder diffraction) component from the diffraction signal originating from single crystals. It relies on the ability to work efficiently in azimuthal space and derives from the work performed on pyFAI, the fast azimuthal integration library. Two applications are built upon this separation algorithm: a lossy compression algorithm and a peak-picking algorithm; the performances of both is assessed by comparing data quality after reduction with XDS and CrystFEL.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "eess.IV",
            "physics.optics"
        ],
        "comment": "43 pages, 12 figures"
    },
    {
        "paper id": "2411.09539",
        "abstract url": "https://arxiv.org/abs/2411.09539",
        "title": "A Practical Guide to Fine-tuning Language Models with Limited Data",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Employing pre-trained Large Language Models (LLMs) has become the de facto standard in Natural Language Processing (NLP) despite their extensive data requirements. Motivated by the recent surge in research focused on training LLMs with limited data, particularly in low-resource domains and languages, this paper surveys recent transfer learning approaches to optimize model performance in downstream tasks where data is scarce. We first address initial and continued pre-training strategies to better leverage prior knowledge in unseen domains and languages. We then examine how to maximize the utility of limited data during fine-tuning and few-shot learning. The final section takes a task-specific perspective, reviewing models and methods suited for different levels of data scarcity. Our goal is to provide practitioners with practical guidelines for overcoming the challenges posed by constrained data while also highlighting promising directions for future research.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09540",
        "abstract url": "https://arxiv.org/abs/2411.09540",
        "title": "Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Visual prompting (VP) is a new technique that adapts well-trained frozen models for source domain tasks to target domain tasks. This study examines VP's benefits for black-box model-level backdoor detection. The visual prompt in VP maps class subspaces between source and target domains. We identify a misalignment, termed class subspace inconsistency, between clean and poisoned datasets. Based on this, we introduce \\textsc{BProm}, a black-box model-level detection method to identify backdoors in suspicious models, if any. \\textsc{BProm} leverages the low classification accuracy of prompted models when backdoors are present. Extensive experiments confirm \\textsc{BProm}'s effectiveness.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09547",
        "abstract url": "https://arxiv.org/abs/2411.09547",
        "title": "Piecing It All Together: Verifying Multi-Hop Multimodal Claims",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Existing claim verification datasets often do not require systems to perform complex reasoning or effectively interpret multimodal evidence. To address this, we introduce a new task: multi-hop multimodal claim verification. This task challenges models to reason over multiple pieces of evidence from diverse sources, including text, images, and tables, and determine whether the combined multimodal evidence supports or refutes a given claim. To study this task, we construct MMCV, a large-scale dataset comprising 16k multi-hop claims paired with multimodal evidence, generated and refined using large language models, with additional input from human feedback. We show that MMCV is challenging even for the latest state-of-the-art multimodal large language models, especially as the number of reasoning hops increases. Additionally, we establish a human performance benchmark on a subset of MMCV. We hope this dataset and its evaluation task will encourage future research in multimodal multi-hop claim verification.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09555",
        "abstract url": "https://arxiv.org/abs/2411.09555",
        "title": "Image Processing for Motion Magnification",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Motion Magnification (MM) is a collection of relative recent techniques within the realm of Image Processing. The main motivation of introducing these techniques in to support the human visual system to capture relevant displacements of an object of interest; these motions can be in object color and in object location. In fact, the goal is to opportunely process a video sequence to obtain as output a new video in which motions are magnified and visible to the viewer. We propose a numerical technique using the Phase-Based Motion Magnification which analyses the video sequence in the Fourier Domain and rely on the Fourier Shifting Property. We describe the mathematical foundation of this method and the corresponding implementation in a numerical algorithm. We present preliminary experiments, focusing on some basic test made up using synthetic images.",
        "subjects": [
            "cs.CV",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09572",
        "abstract url": "https://arxiv.org/abs/2411.09572",
        "title": "Dynamic Reconstruction of Hand-Object Interaction with Distributed Force-aware Contact Representation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present ViTaM-D, a novel visual-tactile framework for dynamic hand-object interaction reconstruction, integrating distributed tactile sensing for more accurate contact modeling. While existing methods focus primarily on visual inputs, they struggle with capturing detailed contact interactions such as object deformation. Our approach leverages distributed tactile sensors to address this limitation by introducing DF-Field. This distributed force-aware contact representation models both kinetic and potential energy in hand-object interaction. ViTaM-D first reconstructs hand-object interactions using a visual-only network, VDT-Net, and then refines contact details through a force-aware optimization (FO) process, enhancing object deformation modeling. To benchmark our approach, we introduce the HOT dataset, which features 600 sequences of hand-object interactions, including deformable objects, built in a high-precision simulation environment. Extensive experiments on both the DexYCB and HOT datasets demonstrate significant improvements in accuracy over previous state-of-the-art methods such as gSDF and HOTrack. Our results highlight the superior performance of ViTaM-D in both rigid and deformable object reconstruction, as well as the effectiveness of DF-Field in refining hand poses. This work offers a comprehensive solution to dynamic hand-object interaction reconstruction by seamlessly integrating visual and tactile data. Codes, models, and datasets will be available.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09604",
        "abstract url": "https://arxiv.org/abs/2411.09604",
        "title": "Local-Global Attention: An Adaptive Mechanism for Multi-Scale Feature Integration",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, attention mechanisms have significantly enhanced the performance of object detection by focusing on key feature information. However, prevalent methods still encounter difficulties in effectively balancing local and global features. This imbalance hampers their ability to capture both fine-grained details and broader contextual information-two critical elements for achieving accurate object detection.To address these challenges, we propose a novel attention mechanism, termed Local-Global Attention, which is designed to better integrate both local and global contextual features. Specifically, our approach combines multi-scale convolutions with positional encoding, enabling the model to focus on local details while concurrently considering the broader global context. Additionally, we introduce a learnable parameters, which allow the model to dynamically adjust the relative importance of local and global attention, depending on the specific requirements of the task, thereby optimizing feature representations across multiple scales.We have thoroughly evaluated the Local-Global Attention mechanism on several widely used object detection and classification datasets. Our experimental results demonstrate that this approach significantly enhances the detection of objects at various scales, with particularly strong performance on multi-class and small object detection tasks. In comparison to existing attention mechanisms, Local-Global Attention consistently outperforms them across several key metrics, all while maintaining computational efficiency.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09607",
        "abstract url": "https://arxiv.org/abs/2411.09607",
        "title": "Initial Nugget Evaluation Results for the TREC 2024 RAG Track with the AutoNuggetizer Framework",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This report provides an initial look at partial results from the TREC 2024 Retrieval-Augmented Generation (RAG) Track. We have identified RAG evaluation as a barrier to continued progress in information access (and more broadly, natural language processing and artificial intelligence), and it is our hope that we can contribute to tackling the many challenges in this space. The central hypothesis we explore in this work is that the nugget evaluation methodology, originally developed for the TREC Question Answering Track in 2003, provides a solid foundation for evaluating RAG systems. As such, our efforts have focused on \"refactoring\" this methodology, specifically applying large language models to both automatically create nuggets and to automatically assign nuggets to system answers. We call this the AutoNuggetizer framework. Within the TREC setup, we are able to calibrate our fully automatic process against a manual process whereby nuggets are created by human assessors semi-manually and then assigned manually to system answers. Based on initial results across 21 topics from 45 runs, we observe a strong correlation between scores derived from a fully automatic nugget evaluation and a (mostly) manual nugget evaluation by human assessors. This suggests that our fully automatic evaluation process can be used to guide future iterations of RAG systems.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09612",
        "abstract url": "https://arxiv.org/abs/2411.09612",
        "title": "The Moral Foundations Weibo Corpus",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Moral sentiments expressed in natural language significantly influence both online and offline environments, shaping behavioral styles and interaction patterns, including social media selfpresentation, cyberbullying, adherence to social norms, and ethical decision-making. To effectively measure moral sentiments in natural language processing texts, it is crucial to utilize large, annotated datasets that provide nuanced understanding for accurate analysis and modeltraining. However, existing corpora, while valuable, often face linguistic limitations. To address this gap in the Chinese language domain,we introduce the Moral Foundation Weibo Corpus. This corpus consists of 25,671 Chinese comments on Weibo, encompassing six diverse topic areas. Each comment is manually annotated by at least three systematically trained annotators based on ten moral categories derived from a grounded theory of morality. To assess annotator reliability, we present the kappa testresults, a gold standard for measuring consistency. Additionally, we apply several the latest large language models to supplement the manual annotations, conducting analytical experiments to compare their performance and report baseline results for moral sentiment classification.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09642",
        "abstract url": "https://arxiv.org/abs/2411.09642",
        "title": "On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Specifying all desirable properties of a language model is challenging, but certain requirements seem essential. Given samples from an unknown language, the trained model should produce valid strings not seen in training and be expressive enough to capture the language's full richness. Otherwise, outputting invalid strings constitutes \"hallucination,\" and failing to capture the full range leads to \"mode collapse.\" We ask if a language model can meet both requirements. We investigate this within a statistical language generation setting building on Gold and Angluin. Here, the model receives random samples from a distribution over an unknown language K, which belongs to a possibly infinite collection of languages. The goal is to generate unseen strings from K. We say the model generates from K with consistency and breadth if, as training size increases, its output converges to all unseen strings in K. Kleinberg and Mullainathan [KM24] asked if consistency and breadth in language generation are possible. We answer this negatively: for a large class of language models, including next-token prediction models, this is impossible for most collections of candidate languages. This contrasts with [KM24]'s result, showing consistent generation without breadth is possible for any countable collection of languages. Our finding highlights that generation with breadth fundamentally differs from generation without breadth. As a byproduct, we establish near-tight bounds on the number of samples needed for generation with or without breadth. Finally, our results offer hope: consistent generation with breadth is achievable for any countable collection of languages when negative examples (strings outside K) are available alongside positive ones. This suggests that post-training feedback, which encodes negative examples, can be crucial in reducing hallucinations while limiting mode collapse.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.DS",
            "stat.ML"
        ],
        "comment": "Abstract shortened to fit arXiv limit"
    },
    {
        "paper id": "2411.09661",
        "abstract url": "https://arxiv.org/abs/2411.09661",
        "title": "Adaptive Decoding via Latent Preference Optimization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "During language model decoding, it is known that using higher temperature sampling gives more creative responses, while lower temperatures are more factually accurate. However, such models are commonly applied to general instruction following, which involves both creative and fact seeking tasks, using a single fixed temperature across all examples and tokens. In this work, we introduce Adaptive Decoding, a layer added to the model to select the sampling temperature dynamically at inference time, at either the token or example level, in order to optimize performance. To learn its parameters we introduce Latent Preference Optimization (LPO) a general approach to train discrete latent variables such as choices of temperature. Our method outperforms all fixed decoding temperatures across a range of tasks that require different temperatures, including UltraFeedback, Creative Story Writing, and GSM8K.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09688",
        "abstract url": "https://arxiv.org/abs/2411.09688",
        "title": "Squeezed Attention: Accelerating Long Context Length LLM Inference",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Emerging Large Language Model (LLM) applications require long input prompts to perform complex downstream tasks like document analysis and code generation. For these long context length applications, the length of the input prompt poses a significant challenge in terms of inference efficiency since the inference costs increase linearly with sequence length. However, for many of these applications, much of the context in the prompt is fixed across different user inputs, thereby providing the opportunity to perform offline optimizations to process user inputs quickly, as they are received. In this work, we propose Squeezed Attention as a mechanism to accelerate LLM applications where a large portion of the input prompt is fixed. We first leverage K-means clustering offline to group the keys for the fixed context based on semantic similarity and represent each cluster with a single centroid value. During inference, we compare query tokens from the user input with the centroids to predict which of the keys from the fixed context are semantically relevant and need to be loaded during inference. We then compute exact attention using only these important keys from the fixed context, thereby reducing bandwidth and computational costs. We also extend our method to use a hierarchical centroid lookup to identify important keys, which can reduce the complexity of attention from linear to logarithmic with respect to the context length. We implement optimized Triton kernels for centroid comparison and sparse FlashAttention with important keys, achieving more than 4x speedups during both the prefill and generation phases for long-context inference. Furthermore, we have extensively evaluated our method on various long-context benchmarks including LongBench, where it achieves a 3x reduction in KV cache budget without accuracy loss and up to an 8x reduction with <0.5 point accuracy gap for various models.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09689",
        "abstract url": "https://arxiv.org/abs/2411.09689",
        "title": "LLM Hallucination Reasoning with Zero-shot Knowledge Test",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "LLM hallucination, where LLMs occasionally generate unfaithful text, poses significant challenges for their practical applications. Most existing detection methods rely on external knowledge, LLM fine-tuning, or hallucination-labeled datasets, and they do not distinguish between different types of hallucinations, which are crucial for improving detection performance. We introduce a new task, Hallucination Reasoning, which classifies LLM-generated text into one of three categories: aligned, misaligned, and fabricated. Our novel zero-shot method assesses whether LLM has enough knowledge about a given prompt and text. Our experiments conducted on new datasets demonstrate the effectiveness of our method in hallucination reasoning and underscore its importance for enhancing detection performance.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "comment": "12 pages, 2 figures"
    },
    {
        "paper id": "2411.09691",
        "abstract url": "https://arxiv.org/abs/2411.09691",
        "title": "Advancing Fine-Grained Visual Understanding with Multi-Scale Alignment in Multi-Modal Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal large language models (MLLMs) have achieved remarkable success in fine-grained visual understanding across a range of tasks. However, they often encounter significant challenges due to inadequate alignment for fine-grained knowledge, which restricts their ability to accurately capture local details and attain a comprehensive global perception. While recent advancements have focused on aligning object expressions with grounding information, they typically lack explicit integration of object images, which contain affluent information beyond mere texts or coordinates. To bridge this gap, we introduce a novel fine-grained visual knowledge alignment method that effectively aligns and integrates multi-scale knowledge of objects, including texts, coordinates, and images. This innovative method is underpinned by our multi-scale fine-grained enhancement data synthesis pipeline, which provides over 300K essential training data to enhance alignment and improve overall performance. Furthermore, we present TinyGroundingGPT, a series of compact models optimized for high-level alignments. With a scale of approximately 3B parameters, TinyGroundingGPT achieves outstanding results in grounding tasks while delivering performance comparable to larger MLLMs in complex visual scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09694",
        "abstract url": "https://arxiv.org/abs/2411.09694",
        "title": "A Bayesian Optimization Approach to Machine Translation Reranking",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Reranking a list of candidates from a machine translation system with an external scoring model and returning the highest-scoring candidate remains a simple and effective method for improving the overall output quality. Translation scoring models continue to grow in size, with the best models being comparable to generation models. Thus, reranking can add substantial computational cost to the translation pipeline. In this work, we pose reranking as a Bayesian optimization (BayesOpt) problem. By strategically selecting candidates to score based on a balance of exploration and exploitation, we show that it is possible to find top-scoring candidates when scoring only a fraction of the candidate list. For instance, our method achieves the same CometKiwi score using only 70 scoring evaluations compared a baseline system using 180. We present a multi-fidelity setting for BayesOpt, where the candidates are first scored with a cheaper but noisier proxy scoring model, which further improves the cost-performance tradeoff when using smaller but well-trained distilled proxy scorers.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "v1: Preprint version"
    },
    {
        "paper id": "2411.09730",
        "abstract url": "https://arxiv.org/abs/2411.09730",
        "title": "SureMap: Simultaneous Mean Estimation for Single-Task and Multi-Task Disaggregated Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Disaggregated evaluation -- estimation of performance of a machine learning model on different subpopulations -- is a core task when assessing performance and group-fairness of AI systems. A key challenge is that evaluation data is scarce, and subpopulations arising from intersections of attributes (e.g., race, sex, age) are often tiny. Today, it is common for multiple clients to procure the same AI model from a model developer, and the task of disaggregated evaluation is faced by each customer individually. This gives rise to what we call the multi-task disaggregated evaluation problem, wherein multiple clients seek to conduct a disaggregated evaluation of a given model in their own data setting (task). In this work we develop a disaggregated evaluation method called SureMap that has high estimation accuracy for both multi-task and single-task disaggregated evaluations of blackbox models. SureMap's efficiency gains come from (1) transforming the problem into structured simultaneous Gaussian mean estimation and (2) incorporating external data, e.g., from the AI system creator or from their other clients. Our method combines maximum a posteriori (MAP) estimation using a well-chosen prior together with cross-validation-free tuning via Stein's unbiased risk estimate (SURE). We evaluate SureMap on disaggregated evaluation tasks in multiple domains, observing significant accuracy improvements over several strong competitors.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.AP",
            "stat.ML"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2411.09751",
        "abstract url": "https://arxiv.org/abs/2411.09751",
        "title": "Analyzing the AI Nudification Application Ecosystem",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Given a source image of a clothed person (an image subject), AI-based nudification applications can produce nude (undressed) images of that person. Moreover, not only do such applications exist, but there is ample evidence of the use of such applications in the real world and without the consent of an image subject. Still, despite the growing awareness of the existence of such applications and their potential to violate the rights of image subjects and cause downstream harms, there has been no systematic study of the nudification application ecosystem across multiple applications. We conduct such a study here, focusing on 20 popular and easy-to-find nudification websites. We study the positioning of these web applications (e.g., finding that most sites explicitly target the nudification of women, not all people), the features that they advertise (e.g., ranging from undressing-in-place to the rendering of image subjects in sexual positions, as well as differing user-privacy options), and their underlying monetization infrastructure (e.g., credit cards and cryptocurrencies). We believe this work will empower future, data-informed conversations -- within the scientific, technical, and policy communities -- on how to better protect individuals' rights and minimize harm in the face of modern (and future) AI-based nudification applications. Content warning: This paper includes descriptions of web applications that can be used to create synthetic non-consensual explicit AI-created imagery (SNEACI). This paper also includes an artistic rendering of a user interface for such an application.",
        "subjects": [
            "cs.HC",
            "cs.CV"
        ],
        "comment": "22 pages, 5 figures, 2 tables"
    },
    {
        "paper id": "2411.09758",
        "abstract url": "https://arxiv.org/abs/2411.09758",
        "title": "Partial Multi-View Clustering via Meta-Learning and Contrastive Feature Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Partial multi-view clustering (PVC) presents significant challenges practical research problem for data analysis in real-world applications, especially when some views of the data are partially missing. Existing clustering methods struggle to handle incomplete views effectively, leading to suboptimal clustering performance. In this paper, we propose a novel dual optimization framework based on contrastive learning, which aims to maximize the consistency of latent features in incomplete multi-view data and improve clustering performance through deep learning models. By combining a fine-tuned Vision Transformer and k-nearest neighbors (KNN), we fill in missing views and dynamically adjust view weights using self-supervised learning and meta-learning. Experimental results demonstrate that our framework outperforms state-of-the-art clustering models on the BDGP and HW datasets, particularly in handling complex and incomplete multi-view data.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09821",
        "abstract url": "https://arxiv.org/abs/2411.09821",
        "title": "Automatic Classification of General Movements in Newborns",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "General movements (GMs) are spontaneous, coordinated body movements in infants that offer valuable insights into the developing nervous system. Assessed through the Prechtl GM Assessment (GMA), GMs are reliable predictors for neurodevelopmental disorders. However, GMA requires specifically trained clinicians, who are limited in number. To scale up newborn screening, there is a need for an algorithm that can automatically classify GMs from infant video recordings. This data poses challenges, including variability in recording length, device type, and setting, with each video coarsely annotated for overall movement quality. In this work, we introduce a tool for extracting features from these recordings and explore various machine learning techniques for automated GM classification.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Findings paper presented at Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024, Vancouver, Canada, 6 pages"
    },
    {
        "paper id": "2411.09826",
        "abstract url": "https://arxiv.org/abs/2411.09826",
        "title": "Evaluating Gender Bias in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Gender bias in artificial intelligence has become an important issue, particularly in the context of language models used in communication-oriented applications. This study examines the extent to which Large Language Models (LLMs) exhibit gender bias in pronoun selection in occupational contexts. The analysis evaluates the models GPT-4, GPT-4o, PaLM 2 Text Bison and Gemini 1.0 Pro using a self-generated dataset. The jobs considered include a range of occupations, from those with a significant male presence to those with a notable female concentration, as well as jobs with a relatively equal gender distribution. Three different sentence processing methods were used to assess potential gender bias: masked tokens, unmasked sentences, and sentence completion. In addition, the LLMs suggested names of individuals in specific occupations, which were then examined for gender distribution. The results show a positive correlation between the models' pronoun choices and the gender distribution present in U.S. labor force data. Female pronouns were more often associated with female-dominated occupations, while male pronouns were more often associated with male-dominated occupations. Sentence completion showed the strongest correlation with actual gender distribution, while name generation resulted in a more balanced 'politically correct' gender distribution, albeit with notable variations in predominantly male or female occupations. Overall, the prompting method had a greater impact on gender distribution than the model selection itself, highlighting the complexity of addressing gender bias in LLMs. The findings highlight the importance of prompting in gender mapping.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "13 pages, 12 figures, 1 table"
    },
    {
        "paper id": "2411.09853",
        "abstract url": "https://arxiv.org/abs/2411.09853",
        "title": "KULCQ: An Unsupervised Keyword-based Utterance Level Clustering Quality Metric",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Intent discovery is crucial for both building new conversational agents and improving existing ones. While several approaches have been proposed for intent discovery, most rely on clustering to group similar utterances together. Traditional evaluation of these utterance clusters requires intent labels for each utterance, limiting scalability. Although some clustering quality metrics exist that do not require labeled data, they focus solely on cluster geometry while ignoring the linguistic nuances present in conversational transcripts. In this paper, we introduce Keyword-based Utterance Level Clustering Quality (KULCQ), an unsupervised metric that leverages keyword analysis to evaluate clustering quality. We demonstrate KULCQ's effectiveness by comparing it with existing unsupervised clustering metrics and validate its performance through comprehensive ablation studies. Our results show that KULCQ better captures semantic relationships in conversational data while maintaining consistency with geometric clustering principles.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09854",
        "abstract url": "https://arxiv.org/abs/2411.09854",
        "title": "Fair Secretaries with Unfair Predictions",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Algorithms with predictions is a recent framework for decision-making under uncertainty that leverages the power of machine-learned predictions without making any assumption about their quality. The goal in this framework is for algorithms to achieve an improved performance when the predictions are accurate while maintaining acceptable guarantees when the predictions are erroneous. A serious concern with algorithms that use predictions is that these predictions can be biased and, as a result, cause the algorithm to make decisions that are deemed unfair. We show that this concern manifests itself in the classical secretary problem in the learning-augmented setting -- the state-of-the-art algorithm can have zero probability of accepting the best candidate, which we deem unfair, despite promising to accept a candidate whose expected value is at least $\\max\\{\u03a9(1) , 1 - O(\u03b5)\\}$ times the optimal value, where $\u03b5$ is the prediction error. We show how to preserve this promise while also guaranteeing to accept the best candidate with probability $\u03a9(1)$. Our algorithm and analysis are based on a new \"pegging\" idea that diverges from existing works and simplifies/unifies some of their results. Finally, we extend to the $k$-secretary problem and complement our theoretical analysis with experiments.",
        "subjects": [
            "cs.LG",
            "cs.DS"
        ],
        "comment": "to appear at NeurIPS 2024"
    },
    {
        "paper id": "2411.09858",
        "abstract url": "https://arxiv.org/abs/2411.09858",
        "title": "Masked Image Contrastive Learning for Efficient Visual Conceptual Pre-training",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper proposes a scalable and straightforward pre-training paradigm for efficient visual conceptual representation called masked image contrastive learning (MiCL). Our MiCL approach is simple: we randomly mask patches to generate different views within an image and contrast them among a mini-batch of images. The core idea behind MiCL consists of two designs. First, masked tokens have the potential to significantly diminish the conceptual redundancy inherent in images, and create distinct views with substantial fine-grained differences on the semantic concept level instead of the instance level. Second, contrastive learning is adept at extracting high-level semantic conceptual features during the pre-training, circumventing the high-frequency interference and additional costs associated with image reconstruction. Importantly, MiCL learns highly semantic conceptual representations efficiently without relying on hand-crafted data augmentations or additional auxiliary modules. Empirically, MiCL demonstrates high scalability with Vision Transformers, as the ViT-L/16 can complete pre-training in 133 hours using only 4 A100 GPUs, achieving 85.8% accuracy in downstream fine-tuning tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2411.09871",
        "abstract url": "https://arxiv.org/abs/2411.09871",
        "title": "Content-Aware Preserving Image Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Remarkable progress has been achieved in image generation with the introduction of generative models. However, precisely controlling the content in generated images remains a challenging task due to their fundamental training objective. This paper addresses this challenge by proposing a novel image generation framework explicitly designed to incorporate desired content in output images. The framework utilizes advanced encoding techniques, integrating subnetworks called content fusion and frequency encoding modules. The frequency encoding module first captures features and structures of reference images by exclusively focusing on selected frequency components. Subsequently, the content fusion module generates a content-guiding vector that encapsulates desired content features. During the image generation process, content-guiding vectors from real images are fused with projected noise vectors. This ensures the production of generated images that not only maintain consistent content from guiding images but also exhibit diverse stylistic variations. To validate the effectiveness of the proposed framework in preserving content attributes, extensive experiments are conducted on widely used benchmark datasets, including Flickr-Faces-High Quality, Animal Faces High Quality, and Large-scale Scene Understanding datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "35 pages, 12 figures, 1 table, journal"
    },
    {
        "paper id": "2411.09921",
        "abstract url": "https://arxiv.org/abs/2411.09921",
        "title": "Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at Pixel Level",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we introduce Motion-Grounded Video Reasoning, a new motion understanding task that requires generating visual answers (video segmentation masks) according to the input question, and hence needs implicit spatiotemporal reasoning and grounding. This task extends existing spatiotemporal grounding work focusing on explicit action/motion grounding, to a more general format by enabling implicit reasoning via questions. To facilitate the development of the new task, we collect a large-scale dataset called GROUNDMORE, which comprises 1,715 video clips, 249K object masks that are deliberately designed with 4 question types (Causal, Sequential, Counterfactual, and Descriptive) for benchmarking deep and comprehensive motion reasoning abilities. GROUNDMORE uniquely requires models to generate visual answers, providing a more concrete and visually interpretable response than plain texts. It evaluates models on both spatiotemporal grounding and reasoning, fostering to address complex challenges in motion-related video reasoning, temporal perception, and pixel-level understanding. Furthermore, we introduce a novel baseline model named Motion-Grounded Video Reasoning Assistant (MORA). MORA incorporates the multimodal reasoning ability from the Multimodal LLM, the pixel-level perception capability from the grounding model (SAM), and the temporal perception ability from a lightweight localization head. MORA achieves respectable performance on GROUNDMORE outperforming the best existing visual grounding baseline model by an average of 21.5% relatively. We hope this novel and challenging task will pave the way for future advancements in robust and general motion understanding via video reasoning segmentation",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09936",
        "abstract url": "https://arxiv.org/abs/2411.09936",
        "title": "A Multi-Scale Spatial-Temporal Network for Wireless Video Transmission",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "Deep joint source-channel coding (DeepJSCC) has shown promise in wireless transmission of text, speech, and images within the realm of semantic communication. However, wireless video transmission presents greater challenges due to the difficulty of extracting and compactly representing both spatial and temporal features, as well as its significant bandwidth and computational resource requirements. In response, we propose a novel video DeepJSCC (VDJSCC) approach to enable end-to-end video transmission over a wireless channel. Our approach involves the design of a multi-scale vision Transformer encoder and decoder to effectively capture spatial-temporal representations over long-term frames. Additionally, we propose a dynamic token selection module to mask less semantically important tokens from spatial or temporal dimensions, allowing for content-adaptive variable-length video coding by adjusting the token keep ratio. Experimental results demonstrate the effectiveness of our VDJSCC approach compared to digital schemes that use separate source and channel codes, as well as other DeepJSCC schemes, in terms of reconstruction quality and bandwidth reduction.",
        "subjects": [
            "eess.IV"
        ],
        "comment": "2024 IEEE Global Communications Conference (GLOBECOM)"
    },
    {
        "paper id": "2411.09937",
        "abstract url": "https://arxiv.org/abs/2411.09937",
        "title": "Refined and Segmented Price Sentiment Indices from Survey Comments",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We aim to enhance a price sentiment index and to more precisely understand price trends from the perspective of not only consumers but also businesses. We extract comments related to prices from the Economy Watchers Survey conducted by the Cabinet Office of Japan and classify price trends using a large language model (LLM). We classify whether the survey sample reflects the perspective of consumers or businesses, and whether the comments pertain to goods or services by utilizing information on the fields of comments and the industries of respondents included in the Economy Watchers Survey. From these classified price-related comments, we construct price sentiment indices not only for a general purpose but also for more specific objectives by combining perspectives on consumers and prices, as well as goods and services. It becomes possible to achieve a more accurate classification of price directions by employing a LLM for classification. Furthermore, integrating the outputs of multiple LLMs suggests the potential for the better performance of the classification. The use of more accurately classified comments allows for the construction of an index with a higher correlation to existing indices than previous studies. We demonstrate that the correlation of the price index for consumers, which has a larger sample size, is further enhanced by selecting comments for aggregation based on the industry of the survey respondents.",
        "subjects": [
            "cs.CL",
            "q-fin.CP"
        ],
        "comment": "Accepted to IEEE BigData 2024. 9 pages, 11 tables, 1 figure"
    },
    {
        "paper id": "2411.09944",
        "abstract url": "https://arxiv.org/abs/2411.09944",
        "title": "SlimLM: An Efficient Small Language Model for On-Device Document Assistance",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "While small language models (SLMs) show promises for mobile deployment, their real-world performance and applications on smartphones remains underexplored. We present SlimLM, a series of SLMs optimized for document assistance tasks on mobile devices. Through extensive experiments on a Samsung Galaxy S24, we identify the optimal trade-offs between model size (ranging from 125M to 7B parameters), context length, and inference time for efficient on-device processing. SlimLM is pre-trained on SlimPajama-627B and fine-tuned on DocAssist, our constructed dataset for summarization, question answering and suggestion tasks. Our smallest model demonstrates efficient performance on S24, while larger variants offer enhanced capabilities within mobile constraints. We evaluate SlimLM against existing SLMs, showing comparable or superior performance and offering a benchmark for future research in on-device language models. We also provide an Android application, offering practical insights into SLM deployment. Our findings provide valuable insights and illuminate the capabilities of running advanced language models on high-end smartphones, potentially reducing server costs and enhancing privacy through on-device processing.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09205",
        "abstract url": "https://arxiv.org/abs/2411.09205",
        "title": "FlexFlood: Efficiently Updatable Learned Multi-dimensional Index",
        "rating": "0.5",
        "keywords": [
            [
                "NeurIPS"
            ]
        ],
        "abstract": "A learned multi-dimensional index is a data structure that efficiently answers multi-dimensional orthogonal queries by understanding the data distribution using machine learning models. One of the existing problems is that the search performance significantly decreases when the distribution of data stored in the data structure becomes skewed due to update operations. To overcome this problem, we propose FlexFlood, a flexible variant of Flood. FlexFlood partially reconstructs the internal structure when the data distribution becomes skewed. Moreover, FlexFlood is the first learned multi-dimensional index that guarantees the time complexity of the update operation. Through experiments using both artificial and real-world data, we demonstrate that the search performance when the data distribution becomes skewed is up to 10 times faster than existing methods. We also found that partial reconstruction takes only about twice as much time as naive data updating.",
        "subjects": [
            "cs.DS"
        ],
        "comment": "NeurIPS 2024 Workshop ML for Systems. Our code is available at https://github.com/mti-lab/FlexFlood"
    },
    {
        "paper id": "2411.09224",
        "abstract url": "https://arxiv.org/abs/2411.09224",
        "title": "Programming with AI: Evaluating ChatGPT, Gemini, AlphaCode, and GitHub Copilot for Programmers",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Our everyday lives now heavily rely on artificial intelligence (AI) powered large language models (LLMs). Like regular users, programmers are also benefiting from the newest large language models. In response to the critical role that AI models play in modern software development, this study presents a thorough evaluation of leading programming assistants, including ChatGPT, Gemini(Bard AI), AlphaCode, and GitHub Copilot. The evaluation is based on tasks like natural language processing and code generation accuracy in different programming languages like Java, Python and C++. Based on the results, it has emphasized their strengths and weaknesses and the importance of further modifications to increase the reliability and accuracy of the latest popular models. Although these AI assistants illustrate a high level of progress in language understanding and code generation, along with ethical considerations and responsible usage, they provoke a necessity for discussion. With time, developing more refined AI technology is essential for achieving advanced solutions in various fields, especially with the knowledge of the feature intricacies of these models and their implications. This study offers a comparison of different LLMs and provides essential feedback on the rapidly changing area of AI models. It also emphasizes the need for ethical developmental practices to actualize AI models' full potential.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2411.09238",
        "abstract url": "https://arxiv.org/abs/2411.09238",
        "title": "Rethinking the \"Heatmap + Monte Carlo Tree Search\" Paradigm for Solving Large Scale TSP",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Travelling Salesman Problem (TSP) remains a fundamental challenge in combinatorial optimization, inspiring diverse algorithmic strategies. This paper revisits the \"heatmap + Monte Carlo Tree Search (MCTS)\" paradigm that has recently gained traction for learning-based TSP solutions. Within this framework, heatmaps encode the likelihood of edges forming part of the optimal tour, and MCTS refines this probabilistic guidance to discover optimal solutions. Contemporary approaches have predominantly emphasized the refinement of heatmap generation through sophisticated learning models, inadvertently sidelining the critical role of MCTS. Our extensive empirical analysis reveals two pivotal insights: 1) The configuration of MCTS strategies profoundly influences the solution quality, demanding meticulous tuning to leverage their full potential; 2) Our findings demonstrate that a rudimentary and parameter-free heatmap, derived from the intrinsic $k$-nearest nature of TSP, can rival or even surpass the performance of complicated heatmaps, with strong generalizability across various scales. Empirical evaluations across various TSP scales underscore the efficacy of our approach, achieving competitive results. These observations challenge the prevailing focus on heatmap sophistication, advocating a reevaluation of the paradigm to harness both components synergistically. Our code is available at: https://github.com/LOGO-CUHKSZ/rethink_mcts_tsp.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09240",
        "abstract url": "https://arxiv.org/abs/2411.09240",
        "title": "Cybersecurity Study Programs: What's in a Name?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Improving cybersecurity education has become a priority for many countries and organizations worldwide. Computing societies and professional associations have recognized cybersecurity as a distinctive computing discipline and created specialized cybersecurity curricular guidelines. Higher education institutions are introducing new cybersecurity programs, attracting students to this expanding field. In this paper, we examined 101 study programs across 24 countries. Based on their analysis, we argue that top-ranked universities have not yet fully implemented the guidelines and offer programs that have \"cyber\" in their name but lack some essential elements of a cybersecurity program. In particular, most programs do not sufficiently cover non-technical components, such as law, policies, or risk management. Also, most programs teach knowledge and skills but do not expose students to experiential learning outside the traditional classroom (such as internships) to develop their competencies. As a result, graduates of these programs may not meet employer expectations and may require additional training. To help program directors and educators improve their programs and courses, this paper offers examples of effective practices from cybersecurity programs around the world and our teaching practice.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "comment": "Published in ACM SIGCSE 2025 conference proceedings, see https://doi.org/10.1145/3641554.3701976"
    },
    {
        "paper id": "2411.09261",
        "abstract url": "https://arxiv.org/abs/2411.09261",
        "title": "Automating Autograding: Large Language Models as Test Suite Generators for Introductory Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Automatically graded programming assignments provide instant feedback to students and significantly reduce manual grading time for instructors. However, creating comprehensive suites of test cases for programming problems within automatic graders can be time-consuming and complex. The effort needed to define test suites may deter some instructors from creating additional problems or lead to inadequate test coverage, potentially resulting in misleading feedback on student solutions. Such limitations may reduce student access to the well-documented benefits of timely feedback when learning programming. In this work, we evaluate the effectiveness of using Large Language Models (LLMs), as part of a larger workflow, to automatically generate test suites for CS1-level programming problems. Each problem's statement and reference solution are provided to GPT-4 to produce a test suite that can be used by an autograder. We evaluate our proposed approach using a sample of 26 problems, and more than 25,000 attempted solutions to those problems, submitted by students in an introductory programming course. We compare the performance of the LLM-generated test suites against the instructor-created test suites for each problem. Our findings reveal that LLM-generated test suites can correctly identify most valid solutions, and for most problems are at least as comprehensive as the instructor test suites. Additionally, the LLM-generated test suites exposed ambiguities in some problem statements, underscoring their potential to improve both autograding and instructional design.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "comment": "Submitted to Journal of Computer Assisted Learning; updated table refs"
    },
    {
        "paper id": "2411.09294",
        "abstract url": "https://arxiv.org/abs/2411.09294",
        "title": "Learning Hand State Estimation for a Light Exoskeleton",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We propose a machine learning-based estimator of the hand state for rehabilitation purposes, using light exoskeletons. These devices are easy to use and useful for delivering domestic and frequent therapies. We build a supervised approach using information from the muscular activity of the forearm and the motion of the exoskeleton to reconstruct the hand's opening degree and compliance level. Such information can be used to evaluate the therapy progress and develop adaptive control behaviors. Our approach is validated with a real light exoskeleton. The experiments demonstrate good predictive performance of our approach when trained on data coming from a single user and tested on the same user, even across different sessions. This generalization capability makes our system promising for practical use in real rehabilitation.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09311",
        "abstract url": "https://arxiv.org/abs/2411.09311",
        "title": "Compression Method for Solar Polarization Spectra Collected from Hinode SOT/SP Observations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The complex structure and extensive details of solar spectral data, combined with a recent surge in volume, present significant processing challenges. To address this, we propose a deep learning-based compression technique using deep autoencoder (DAE) and 1D-convolutional autoencoder (CAE) models developed with Hinode SOT/SP data. We focused on compressing Stokes I and V polarization spectra from the quiet Sun, as well as from active regions, providing a novel insight into comprehensive spectral analysis by incorporating spectra from extreme magnetic fields. The results indicate that the CAE model outperforms the DAE model in reconstructing Stokes profiles, demonstrating greater robustness and achieving reconstruction errors around the observational noise level. The proposed method has proven effective in compressing Stokes I and V spectra from both the quiet Sun and active regions, highlighting its potential for impactful applications in solar spectral analysis, such as detection of unusual spectral signals.",
        "subjects": [
            "cs.LG",
            "astro-ph.IM",
            "astro-ph.SR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09312",
        "abstract url": "https://arxiv.org/abs/2411.09312",
        "title": "Approximate Probabilistic Inference for Time-Series Data A Robust Latent Gaussian Model With Temporal Awareness",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The development of robust generative models for highly varied non-stationary time series data is a complex yet important problem. Traditional models for time series data prediction, such as Long Short-Term Memory (LSTM), are inefficient and generalize poorly as they cannot capture complex temporal relationships. In this paper, we present a probabilistic generative model that can be trained to capture temporal information, and that is robust to data errors. We call it Time Deep Latent Gaussian Model (tDLGM). Its novel architecture is inspired by Deep Latent Gaussian Model (DLGM). Our model is trained to minimize a loss function based on the negative log loss. One contributing factor to Time Deep Latent Gaussian Model (tDLGM) robustness is our regularizer, which accounts for data trends. Experiments conducted show that tDLGM is able to reconstruct and generate complex time series data, and that it is robust against to noise and faulty data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "New revision added a space between \"for\" and \"Time-Series\" in the title"
    },
    {
        "paper id": "2411.09313",
        "abstract url": "https://arxiv.org/abs/2411.09313",
        "title": "Socio-Economic Consequences of Generative AI: A Review of Methodological Approaches",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The widespread adoption of generative artificial intelligence (AI) has fundamentally transformed technological landscapes and societal structures in recent years. Our objective is to identify the primary methodologies that may be used to help predict the economic and social impacts of generative AI adoption. Through a comprehensive literature review, we uncover a range of methodologies poised to assess the multifaceted impacts of this technological revolution. We explore Agent-Based Simulation (ABS), Econometric Models, Input-Output Analysis, Reinforcement Learning (RL) for Decision-Making Agents, Surveys and Interviews, Scenario Analysis, Policy Analysis, and the Delphi Method. Our findings have allowed us to identify these approaches' main strengths and weaknesses and their adequacy in coping with uncertainty, robustness, and resource requirements.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09341",
        "abstract url": "https://arxiv.org/abs/2411.09341",
        "title": "Approximated Variational Bayesian Inverse Reinforcement Learning for Large Language Model Alignment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The alignment of large language models (LLMs) is crucial for generating helpful and harmless content. Existing approaches leverage preference-based human feedback data to learn the reward function and align the LLM with the feedback data. However, these approaches focus on modeling the reward difference between the chosen and rejected demonstrations, rather than directly modeling the true reward from each demonstration. Moreover, these approaches assume that the reward is only obtained at the end of the sentence, which overlooks the modeling of intermediate rewards. These issues lead to insufficient use of training signals in the feedback data, limiting the representation and generalization ability of the reward and potentially resulting in reward hacking. In this paper, we formulate LLM alignment as a Bayesian Inverse Reinforcement Learning (BIRL) problem and propose a novel training objective, Approximated Variational Alignment (AVA), to perform LLM alignment through Approximated Variational Reward Imitation Learning (AVRIL). The BIRL formulation facilitates intermediate reward modeling and direct reward modeling on each single demonstration, which enhances the utilization of training signals in the feedback data. Experiments show that AVA outperforms existing LLM alignment approaches in reward modeling, RL fine-tuning, and direct optimization.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09355",
        "abstract url": "https://arxiv.org/abs/2411.09355",
        "title": "Prices, Bids, Values: Everything, Everywhere, All at Once",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "We study the design of iterative combinatorial auctions (ICAs). The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most important information from bidders to maximize efficiency. The SOTA ML-based algorithms elicit bidders' preferences via value queries (i.e., \"What is your value for the bundle $\\{A,B\\}$?\"). However, the most popular iterative combinatorial auction in practice elicits information via more practical \\emph{demand queries} (i.e., \"At prices $p$, what is your most preferred bundle of items?\"). In this paper, we examine the advantages of value and demand queries from both an auction design and an ML perspective. We propose a novel ML algorithm that provably integrates the full information from both query types. As suggested by our theoretical analysis, our experimental results verify that combining demand and value queries results in significantly better learning performance. Building on these insights, we present MLHCA, the most efficient ICA ever designed. MLHCA substantially outperforms the previous SOTA in realistic auction settings, delivering large efficiency gains. Compared to the previous SOTA, MLHCA reduces efficiency loss by up to a factor of 10, and in the most challenging and realistic domain, MLHCA outperforms the previous SOTA using 30% fewer queries. Thus, MLHCA achieves efficiency improvements that translate to welfare gains of hundreds of millions of USD, while also reducing the cognitive load on the bidders, establishing a new benchmark both for practicability and for economic impact.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09365",
        "abstract url": "https://arxiv.org/abs/2411.09365",
        "title": "Stability and Generalization for Distributed SGDA",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Minimax optimization is gaining increasing attention in modern machine learning applications. Driven by large-scale models and massive volumes of data collected from edge devices, as well as the concern to preserve client privacy, communication-efficient distributed minimax optimization algorithms become popular, such as Local Stochastic Gradient Descent Ascent (Local-SGDA), and Local Decentralized SGDA (Local-DSGDA). While most existing research on distributed minimax algorithms focuses on convergence rates, computation complexity, and communication efficiency, the generalization performance remains underdeveloped, whereas generalization ability is a pivotal indicator for evaluating the holistic performance of a model when fed with unknown data. In this paper, we propose the stability-based generalization analytical framework for Distributed-SGDA, which unifies two popular distributed minimax algorithms including Local-SGDA and Local-DSGDA, and conduct a comprehensive analysis of stability error, generalization gap, and population risk across different metrics under various settings, e.g., (S)C-(S)C, PL-SC, and NC-NC cases. Our theoretical results reveal the trade-off between the generalization gap and optimization error and suggest hyperparameters choice to obtain the optimal population risk. Numerical experiments for Local-SGDA and Local-DSGDA validate the theoretical results.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09366",
        "abstract url": "https://arxiv.org/abs/2411.09366",
        "title": "LTLf+ and PPLTL+: Extending LTLf and PPLTL to Infinite Traces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce LTLf+ and PPLTL+, two logics to express properties of infinite traces, that are based on the linear-time temporal logics LTLf and PPLTL on finite traces. LTLf+/PPLTL+ use levels of Manna and Pnueli's LTL safety-progress hierarchy, and thus have the same expressive power as LTL. However, they also retain a crucial characteristic of the reactive synthesis problem for the base logics: the game arena for strategy extraction can be derived from deterministic finite automata (DFA). Consequently, these logics circumvent the notorious difficulties associated with determinizing infinite trace automata, typical of LTL reactive synthesis. We present DFA-based synthesis techniques for LTLf+/PPLTL+, and show that synthesis is 2EXPTIME-complete for LTLf+ (matching LTLf) and EXPTIME-complete for PPLTL+ (matching PPLTL). Notably, while PPLTL+ retains the full expressive power of LTL, reactive synthesis is EXPTIME-complete instead of 2EXPTIME-complete. The techniques are also adapted to optimally solve satisfiability, validity, and model-checking, to get EXPSPACE-complete for LTLf+ (extending a recent result for the guarantee level using LTLf), and PSPACE-complete for PPLTL+.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09393",
        "abstract url": "https://arxiv.org/abs/2411.09393",
        "title": "Inherently Interpretable and Uncertainty-Aware Models for Online Learning in Cyber-Security Problems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we address the critical need for interpretable and uncertainty-aware machine learning models in the context of online learning for high-risk industries, particularly cyber-security. While deep learning and other complex models have demonstrated impressive predictive capabilities, their opacity and lack of uncertainty quantification present significant questions about their trustworthiness. We propose a novel pipeline for online supervised learning problems in cyber-security, that harnesses the inherent interpretability and uncertainty awareness of Additive Gaussian Processes (AGPs) models. Our approach aims to balance predictive performance with transparency while improving the scalability of AGPs, which represents their main drawback, potentially enabling security analysts to better validate threat detection, troubleshoot and reduce false positives, and generally make trustworthy, informed decisions. This work contributes to the growing field of interpretable AI by proposing a class of models that can be significantly beneficial for high-stake decision problems such as the ones typical of the cyber-security domain. The source code is available.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09400",
        "abstract url": "https://arxiv.org/abs/2411.09400",
        "title": "Imagined Speech and Visual Imagery as Intuitive Paradigms for Brain-Computer Interfaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent advancements in brain-computer interface (BCI) technology have emphasized the promise of imagined speech and visual imagery as effective paradigms for intuitive communication. This study investigates the classification performance and brain connectivity patterns associated with these paradigms, focusing on decoding accuracy across selected word classes. Sixteen participants engaged in tasks involving thirteen imagined speech and visual imagery classes, revealing above-chance classification accuracy for both paradigms. Variability in classification accuracy across individual classes highlights the influence of sensory and motor associations in imagined speech and vivid visual associations in visual imagery. Connectivity analysis further demonstrated increased functional connectivity in language-related and sensory regions for imagined speech, whereas visual imagery activated spatial and visual processing networks. These findings suggest the potential of imagined speech and visual imagery as an intuitive and scalable paradigm for BCI communication when selecting optimal word classes. Further exploration of the decoding outcomes for these two paradigms could provide insights for practical BCI communication.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "4 pages"
    },
    {
        "paper id": "2411.09422",
        "abstract url": "https://arxiv.org/abs/2411.09422",
        "title": "OpenLS-DGF: An Adaptive Open-Source Dataset Generation Framework for Machine Learning Tasks in Logic Synthesis",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper introduces OpenLS-DGF, an adaptive logic synthesis dataset generation framework, to enhance machine learning~(ML) applications within the logic synthesis process. Previous dataset generation flows were tailored for specific tasks or lacked integrated machine learning capabilities. While OpenLS-DGF supports various machine learning tasks by encapsulating the three fundamental steps of logic synthesis: Boolean representation, logic optimization, and technology mapping. It preserves the original information in both Verilog and machine-learning-friendly GraphML formats. The verilog files offer semi-customizable capabilities, enabling researchers to insert additional steps and incrementally refine the generated dataset. Furthermore, OpenLS-DGF includes an adaptive circuit engine that facilitates the final dataset management and downstream tasks. The generated OpenLS-D-v1 dataset comprises 46 combinational designs from established benchmarks, totaling over 966,000 Boolean circuits. OpenLS-D-v1 supports integrating new data features, making it more versatile for new challenges. This paper demonstrates the versatility of OpenLS-D-v1 through four distinct downstream tasks: circuit classification, circuit ranking, quality of results (QoR) prediction, and probability prediction. Each task is chosen to represent essential steps of logic synthesis, and the experimental results show the generated dataset from OpenLS-DGF achieves prominent diversity and applicability. The source code and datasets are available at https://github.com/Logic-Factory/ACE/blob/master/OpenLS-DGF/readme.md.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2411.09429",
        "abstract url": "https://arxiv.org/abs/2411.09429",
        "title": "AI-driven inverse design of materials: Past, present and future",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The discovery of advanced materials is the cornerstone of human technological development and progress. The structures of materials and their corresponding properties are essentially the result of a complex interplay of multiple degrees of freedom such as lattice, charge, spin, symmetry, and topology. This poses significant challenges for the inverse design methods of materials. Humans have long explored new materials through a large number of experiments and proposed corresponding theoretical systems to predict new material properties and structures. With the improvement of computational power, researchers have gradually developed various electronic structure calculation methods, such as the density functional theory and high-throughput computational methods. Recently, the rapid development of artificial intelligence technology in the field of computer science has enabled the effective characterization of the implicit association between material properties and structures, thus opening up an efficient paradigm for the inverse design of functional materials. A significant progress has been made in inverse design of materials based on generative and discriminative models, attracting widespread attention from researchers. Considering this rapid technological progress, in this survey, we look back on the latest advancements in AI-driven inverse design of materials by introducing the background, key findings, and mainstream technological development routes. In addition, we summarize the remaining issues for future directions. This survey provides the latest overview of AI-driven inverse design of materials, which can serve as a useful resource for researchers.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cond-mat.supr-con",
            "cs.AI"
        ],
        "comment": "44 pages, 6 figures, 2 tables"
    },
    {
        "paper id": "2411.09444",
        "abstract url": "https://arxiv.org/abs/2411.09444",
        "title": "Learning efficient and provably convergent splitting methods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Splitting methods are widely used for solving initial value problems (IVPs) due to their ability to simplify complicated evolutions into more manageable subproblems which can be solved efficiently and accurately. Traditionally, these methods are derived using analytic and algebraic techniques from numerical analysis, including truncated Taylor series and their Lie algebraic analogue, the Baker--Campbell--Hausdorff formula. These tools enable the development of high-order numerical methods that provide exceptional accuracy for small timesteps. Moreover, these methods often (nearly) conserve important physical invariants, such as mass, unitarity, and energy. However, in many practical applications the computational resources are limited. Thus, it is crucial to identify methods that achieve the best accuracy within a fixed computational budget, which might require taking relatively large timesteps. In this regime, high-order methods derived with traditional methods often exhibit large errors since they are only designed to be asymptotically optimal. Machine Learning techniques offer a potential solution since they can be trained to efficiently solve a given IVP with less computational resources. However, they are often purely data-driven, come with limited convergence guarantees in the small-timestep regime and do not necessarily conserve physical invariants. In this work, we propose a framework for finding machine learned splitting methods that are computationally efficient for large timesteps and have provable convergence and conservation guarantees in the small-timestep limit. We demonstrate numerically that the learned methods, which by construction converge quadratically in the timestep size, can be significantly more efficient than established methods for the Schr\u00f6dinger equation if the computational budget is limited.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09475",
        "abstract url": "https://arxiv.org/abs/2411.09475",
        "title": "ResidualDroppath: Enhancing Feature Reuse over Residual Connections",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Residual connections are one of the most important components in neural network architectures for mitigating the vanishing gradient problem and facilitating the training of much deeper networks. One possible explanation for how residual connections aid deeper network training is by promoting feature reuse. However, we identify and analyze the limitations of feature reuse with vanilla residual connections. To address these limitations, we propose modifications in training methods. Specifically, we provide an additional opportunity for the model to learn feature reuse with residual connections through two types of iterations during training. The first type of iteration involves using droppath, which enforces feature reuse by randomly dropping a subset of layers. The second type of iteration focuses on training the dropped parts of the model while freezing the undropped parts. As a result, the dropped parts learn in a way that encourages feature reuse, as the model relies on the undropped parts with feature reuse in mind. Overall, we demonstrated performance improvements in models with residual connections for image classification in certain cases.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09481",
        "abstract url": "https://arxiv.org/abs/2411.09481",
        "title": "What makes a good BIM design: quantitative linking between design behavior and quality",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the Architecture Engineering & Construction (AEC) industry, how design behaviors impact design quality remains unclear. This study proposes a novel approach, which, for the first time, identifies and quantitatively describes the relationship between design behaviors and quality of design based on Building Information Modeling (BIM). Real-time collection and log mining are integrated to collect raw data of design behaviors. Feature engineering and various machine learning models are then utilized for quantitative modeling and interpretation. Results confirm an existing quantifiable relationship which can be learned by various models. The best-performing model using Extremely Random Trees achieved an R2 value of 0.88 on the test set. Behavioral features related to designer's skill level and changes of design intentions are identified to have significant impacts on design quality. These findings deepen our understanding of the design process and help forming BIM designs with better quality.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09507",
        "abstract url": "https://arxiv.org/abs/2411.09507",
        "title": "Toward a Cohesive AI and Simulation Software Ecosystem for Scientific Innovation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we discuss the need for an integrated software stack that unites artificial intelligence (AI) and modeling and simulation (ModSim) tools to advance scientific discovery. The authors advocate for a unified AI/ModSim software ecosystem that ensures compatibility across a wide range of software on diverse high-performance computing systems, promoting ease of deployment, version management, and binary distribution. Key challenges highlighted include balancing the distinct needs of AI and ModSim, especially in terms of software build practices, dependency management, and compatibility. The document underscores the importance of continuous integration, community-driven stewardship, and collaboration with the Department of Energy (DOE) to develop a portable and cohesive scientific software ecosystem. Recommendations focus on supporting standardized environments through initiatives like the Extreme-scale Scientific Software Stack (E4S) and Spack to foster interdisciplinary innovation and facilitate new scientific advancements.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "5 pages"
    },
    {
        "paper id": "2411.09517",
        "abstract url": "https://arxiv.org/abs/2411.09517",
        "title": "Randomized Truthful Auctions with Learning Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We study a setting where agents use no-regret learning algorithms to participate in repeated auctions. \\citet{kolumbus2022auctions} showed, rather surprisingly, that when bidders participate in second-price auctions using no-regret bidding algorithms, no matter how large the number of interactions $T$ is, the runner-up bidder may not converge to bidding truthfully. Our first result shows that this holds for \\emph{general deterministic} truthful auctions. We also show that the ratio of the learning rates of the bidders can \\emph{qualitatively} affect the convergence of the bidders. Next, we consider the problem of revenue maximization in this environment. In the setting with fully rational bidders, \\citet{myerson1981optimal} showed that revenue can be maximized by using a second-price auction with reserves.We show that, in stark contrast, in our setting with learning bidders, \\emph{randomized} auctions can have strictly better revenue guarantees than second-price auctions with reserves, when $T$ is large enough. Finally, we study revenue maximization in the non-asymptotic regime. We define a notion of {\\em auctioneer regret} comparing the revenue generated to the revenue of a second price auction with truthful bids. When the auctioneer has to use the same auction throughout the interaction, we show an (almost) tight regret bound of $\\smash{\\widetilde \u0398(T^{3/4})}.$ If the auctioneer can change auctions during the interaction, but in a way that is oblivious to the bids, we show an (almost) tight bound of $\\smash{\\widetilde \u0398(\\sqrt{T})}.$",
        "subjects": [
            "cs.GT",
            "cs.LG",
            "econ.TH"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09523",
        "abstract url": "https://arxiv.org/abs/2411.09523",
        "title": "Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "With the continuous development of large language models (LLMs), transformer-based models have made groundbreaking advances in numerous natural language processing (NLP) tasks, leading to the emergence of a series of agents that use LLMs as their control hub. While LLMs have achieved success in various tasks, they face numerous security and privacy threats, which become even more severe in the agent scenarios. To enhance the reliability of LLM-based applications, a range of research has emerged to assess and mitigate these risks from different perspectives. To help researchers gain a comprehensive understanding of various risks, this survey collects and analyzes the different threats faced by these agents. To address the challenges posed by previous taxonomies in handling cross-module and cross-stage threats, we propose a novel taxonomy framework based on the sources and impacts. Additionally, we identify six key features of LLM-based agents, based on which we summarize the current research progress and analyze their limitations. Subsequently, we select four representative agents as case studies to analyze the risks they may face in practical use. Finally, based on the aforementioned analyses, we propose future research directions from the perspectives of data, methodology, and policy, respectively.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09543",
        "abstract url": "https://arxiv.org/abs/2411.09543",
        "title": "OpenGeMM: A High-Utilization GeMM Accelerator Generator with Lightweight RISC-V Control and Tight Memory Coupling",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) face significant challenges when deployed on resource-constrained extreme edge devices due to their computational and data-intensive nature. While standalone accelerators tailored for specific application scenarios suffer from inflexible control and limited programmability, generic hardware acceleration platforms coupled with RISC-V CPUs can enable high reusability and flexibility, yet typically at the expense of system level efficiency and low utilization. To fill this gap, we propose OpenGeMM, an open-source acceleration platform, jointly demonstrating high efficiency and utilization, as well as ease of configurability and programmability. OpenGeMM encompasses a parameterized Chisel-coded GeMM accelerator, a lightweight RISC-V processor, and a tightly coupled multi-banked scratchpad memory. The GeMM core utilization and system efficiency are boosted through three mechanisms: configuration pre-loading, input pre-fetching with output buffering, and programmable strided memory access. Experimental results show that OpenGeMM can consistently achieve hardware utilization ranging from 81.89% to 99.34% across diverse CNN and Transformer workloads. Compared to the SotA open-source Gemmini accelerator, OpenGeMM demonstrates a 3.58x to 16.40x speedup on normalized throughput across a wide variety ofGeMM workloads, while achieving 4.68 TOPS/W system efficiency.",
        "subjects": [
            "cs.AR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09546",
        "abstract url": "https://arxiv.org/abs/2411.09546",
        "title": "Architectural Exploration of Application-Specific Resonant SRAM Compute-in-Memory (rCiM)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "While general-purpose computing follows Von Neumann's architecture, the data movement between memory and processor elements dictates the processor's performance. The evolving compute-in-memory (CiM) paradigm tackles this issue by facilitating simultaneous processing and storage within static random-access memory (SRAM) elements. Numerous design decisions taken at different levels of hierarchy affect the figure of merits (FoMs) of SRAM, such as power, performance, area, and yield. The absence of a rapid assessment mechanism for the impact of changes at different hierarchy levels on global FoMs poses a challenge to accurately evaluating innovative SRAM designs. This paper presents an automation tool designed to optimize the energy and latency of SRAM designs incorporating diverse implementation strategies for executing logic operations within the SRAM. The tool structure allows easy comparison across different array topologies and various design strategies to result in energy-efficient implementations. Our study involves a comprehensive comparison of over 6900+ distinct design implementation strategies for EPFL combinational benchmark circuits on the energy-recycling resonant compute-in-memory (rCiM) architecture designed using TSMC 28 nm technology. When provided with a combinational circuit, the tool aims to generate an energy-efficient implementation strategy tailored to the specified input memory and latency constraints. The tool reduces 80.9% of energy consumption on average across all benchmarks while using the six-topology implementation compared to baseline implementation of single-macro topology by considering the parallel processing capability of rCiM cache size ranging from 4KB to 192KB.",
        "subjects": [
            "cs.AR",
            "cs.CY",
            "cs.ET",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09551",
        "abstract url": "https://arxiv.org/abs/2411.09551",
        "title": "MFTIQ: Multi-Flow Tracker with Independent Matching Quality Estimation",
        "rating": "0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "In this work, we present MFTIQ, a novel dense long-term tracking model that advances the Multi-Flow Tracker (MFT) framework to address challenges in point-level visual tracking in video sequences. MFTIQ builds upon the flow-chaining concepts of MFT, integrating an Independent Quality (IQ) module that separates correspondence quality estimation from optical flow computations. This decoupling significantly enhances the accuracy and flexibility of the tracking process, allowing MFTIQ to maintain reliable trajectory predictions even in scenarios of prolonged occlusions and complex dynamics. Designed to be \"plug-and-play\", MFTIQ can be employed with any off-the-shelf optical flow method without the need for fine-tuning or architectural modifications. Experimental validations on the TAP-Vid Davis dataset show that MFTIQ with RoMa optical flow not only surpasses MFT but also performs comparably to state-of-the-art trackers while having substantially faster processing speed. Code and models available at https://github.com/serycjon/MFTIQ .",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted to WACV 2025"
    },
    {
        "paper id": "2411.09552",
        "abstract url": "https://arxiv.org/abs/2411.09552",
        "title": "Faster Differentially Private Top-$k$ Selection: A Joint Exponential Mechanism with Pruning",
        "rating": "0.5",
        "keywords": [
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We study the differentially private top-$k$ selection problem, aiming to identify a sequence of $k$ items with approximately the highest scores from $d$ items. Recent work by Gillenwater et al. (ICML '22) employs a direct sampling approach from the vast collection of $d^{\\,\u0398(k)}$ possible length-$k$ sequences, showing superior empirical accuracy compared to previous pure or approximate differentially private methods. Their algorithm has a time and space complexity of $\\tilde{O}(dk)$. In this paper, we present an improved algorithm with time and space complexity $O(d + k^2 / \u03b5\\cdot \\ln d)$, where $\u03b5$ denotes the privacy parameter. Experimental results show that our algorithm runs orders of magnitude faster than their approach, while achieving similar empirical accuracy.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2411.09558",
        "abstract url": "https://arxiv.org/abs/2411.09558",
        "title": "Adaptive Deviation Learning for Visual Anomaly Detection with Data Contamination",
        "rating": "0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Visual anomaly detection targets to detect images that notably differ from normal pattern, and it has found extensive application in identifying defective parts within the manufacturing industry. These anomaly detection paradigms predominantly focus on training detection models using only clean, unlabeled normal samples, assuming an absence of contamination; a condition often unmet in real-world scenarios. The performance of these methods significantly depends on the quality of the data and usually decreases when exposed to noise. We introduce a systematic adaptive method that employs deviation learning to compute anomaly scores end-to-end while addressing data contamination by assigning relative importance to the weights of individual instances. In this approach, the anomaly scores for normal instances are designed to approximate scalar scores obtained from the known prior distribution. Meanwhile, anomaly scores for anomaly examples are adjusted to exhibit statistically significant deviations from these reference scores. Our approach incorporates a constrained optimization problem within the deviation learning framework to update instance weights, resolving this problem for each mini-batch. Comprehensive experiments on the MVTec and VisA benchmark datasets indicate that our proposed method surpasses competing techniques and exhibits both stability and robustness in the presence of data contamination.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2025)"
    },
    {
        "paper id": "2411.09580",
        "abstract url": "https://arxiv.org/abs/2411.09580",
        "title": "Software Performance Engineering for Foundation Model-Powered Software (FMware)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rise of Foundation Models (FMs) like Large Language Models (LLMs) is revolutionizing software development. Despite the impressive prototypes, transforming FMware into production-ready products demands complex engineering across various domains. A critical but overlooked aspect is performance engineering, which aims at ensuring FMware meets performance goals such as throughput and latency to avoid user dissatisfaction and financial loss. Often, performance considerations are an afterthought, leading to costly optimization efforts post-deployment. FMware's high computational resource demands highlight the need for efficient hardware use. Continuous performance engineering is essential to prevent degradation. This paper highlights the significance of Software Performance Engineering (SPE) in FMware, identifying four key challenges: cognitive architecture design, communication protocols, tuning and optimization, and deployment. These challenges are based on literature surveys and experiences from developing an in-house FMware system. We discuss problems, current practices, and innovative paths for the software engineering community.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09635",
        "abstract url": "https://arxiv.org/abs/2411.09635",
        "title": "Counterfactual Uncertainty Quantification of Factual Estimand of Efficacy from Before-and-After Treatment Repeated Measures Randomized Controlled Trials",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The ideal estimand for comparing a new treatment $Rx$ with a control $C$ is the $\\textit{counterfactual}$ efficacy $Rx:C$, the expected differential outcome between $Rx$ and $C$ if each patient were given $\\textit{both}$. While counterfactual $\\textit{point estimation}$ from $\\textit{factual}$ Randomized Controlled Trials (RCTs) has been available, this article shows $\\textit{counterfactual}$ uncertainty quantification (CUQ), quantifying uncertainty for factual point estimates but in a counterfactual setting, is surprisingly achievable. We achieve CUQ whose variability is typically smaller than factual UQ, by creating a new statistical modeling principle called ETZ which is applicable to RCTs with $\\textit{Before-and-After}$ treatment Repeated Measures, common in many therapeutic areas. We urge caution when estimate of the unobservable true condition of a patient before treatment has measurement error, because that violation of standard regression assumption can cause attenuation in estimating treatment effects. Fortunately, we prove that, for traditional medicine in general, and for targeted therapy with efficacy defined as averaged over the population, counterfactual point estimation is unbiased. However, for targeted therapy, both Real Human and Digital Twins approaches should respect this limitation, lest predicted treatment effect in $\\textit{subgroups}$ will have bias.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "39 pages, 7 figures"
    },
    {
        "paper id": "2411.09639",
        "abstract url": "https://arxiv.org/abs/2411.09639",
        "title": "MCCE: Missingness-aware Causal Concept Explainer",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Causal concept effect estimation is gaining increasing interest in the field of interpretable machine learning. This general approach explains the behaviors of machine learning models by estimating the causal effect of human-understandable concepts, which represent high-level knowledge more comprehensibly than raw inputs like tokens. However, existing causal concept effect explanation methods assume complete observation of all concepts involved within the dataset, which can fail in practice due to incomplete annotations or missing concept data. We theoretically demonstrate that unobserved concepts can bias the estimation of the causal effects of observed concepts. To address this limitation, we introduce the Missingness-aware Causal Concept Explainer (MCCE), a novel framework specifically designed to estimate causal concept effects when not all concepts are observable. Our framework learns to account for residual bias resulting from missing concepts and utilizes a linear predictor to model the relationships between these concepts and the outputs of black-box machine learning models. It can offer explanations on both local and global levels. We conduct validations using a real-world dataset, demonstrating that MCCE achieves promising performance compared to state-of-the-art explanation methods in causal concept effect estimation.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09644",
        "abstract url": "https://arxiv.org/abs/2411.09644",
        "title": "Neural Operators Can Play Dynamic Stackelberg Games",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Dynamic Stackelberg games are a broad class of two-player games in which the leader acts first, and the follower chooses a response strategy to the leader's strategy. Unfortunately, only stylized Stackelberg games are explicitly solvable since the follower's best-response operator (as a function of the control of the leader) is typically analytically intractable. This paper addresses this issue by showing that the \\textit{follower's best-response operator} can be approximately implemented by an \\textit{attention-based neural operator}, uniformly on compact subsets of adapted open-loop controls for the leader. We further show that the value of the Stackelberg game where the follower uses the approximate best-response operator approximates the value of the original Stackelberg game. Our main result is obtained using our universal approximation theorem for attention-based neural operators between spaces of square-integrable adapted stochastic processes, as well as stability results for a general class of Stackelberg games.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "math.NA",
            "math.PR",
            "q-fin.CP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09645",
        "abstract url": "https://arxiv.org/abs/2411.09645",
        "title": "How do Machine Learning Models Change?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The proliferation of Machine Learning (ML) models and their open-source implementations has transformed Artificial Intelligence research and applications. Platforms like Hugging Face (HF) enable the development, sharing, and deployment of these models, fostering an evolving ecosystem. While previous studies have examined aspects of models hosted on platforms like HF, a comprehensive longitudinal study of how these models change remains underexplored. This study addresses this gap by utilizing both repository mining and longitudinal analysis methods to examine over 200,000 commits and 1,200 releases from over 50,000 models on HF. We replicate and extend an ML change taxonomy for classifying commits and utilize Bayesian networks to uncover patterns in commit and release activities over time. Our findings indicate that commit activities align with established data science methodologies, such as CRISP-DM, emphasizing iterative refinement and continuous improvement. Additionally, release patterns tend to consolidate significant updates, particularly in documentation, distinguishing between granular changes and milestone-based releases. Furthermore, projects with higher popularity prioritize infrastructure enhancements early in their lifecycle, and those with intensive collaboration practices exhibit improved documentation standards. These and other insights enhance the understanding of model changes on community platforms and provide valuable guidance for best practices in model maintenance.",
        "subjects": [
            "cs.SE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09675",
        "abstract url": "https://arxiv.org/abs/2411.09675",
        "title": "Citation Sentiment Reflects Multiscale Sociocultural Norms",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Modern science is formally structured around scholarly publication, where scientific knowledge is canonized through citation. Precisely how citations are given and accrued can provide information about the value of discovery, the history of scientific ideas, the structure of fields, and the space or scope of inquiry. Yet parsing this information has been challenging because citations are not simply present or absent; rather, they differ in purpose, function, and sentiment. In this paper, we investigate how critical and favorable sentiments are distributed across citations, and demonstrate that citation sentiment tracks sociocultural norms across scales of collaboration, discipline, and country. At the smallest scale of individuals, we find that researchers cite scholars they have collaborated with more favorably (and less critically) than scholars they have not collaborated with. Outside collaborative relationships, higher h-index scholars cite lower h-index scholars more critically. At the mesoscale of disciplines, we find that wetlab disciplines tend to be less critical than drylab disciplines, and disciplines that engage in more synthesis through publishing more review articles tend to be less critical. At the largest scale of countries, we find that greater individualism (and lesser acceptance of the unequal distribution of power) is associated with more critical sentiment. Collectively, our results demonstrate how sociocultural factors can explain variations in sentiment in scientific communication. As such, our study contributes to the broader understanding of how human factors influence the practice of science, and underscore the importance of considering the larger sociocultural contexts in which science progresses.",
        "subjects": [
            "cs.SI"
        ],
        "comment": "16 pages, 8 figures in main; 13 pages, 3 figures in supplement"
    },
    {
        "paper id": "2411.09683",
        "abstract url": "https://arxiv.org/abs/2411.09683",
        "title": "Towards a Classification of Open-Source ML Models and Datasets for Software Engineering",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Background: Open-Source Pre-Trained Models (PTMs) and datasets provide extensive resources for various Machine Learning (ML) tasks, yet these resources lack a classification tailored to Software Engineering (SE) needs. Aims: We apply an SE-oriented classification to PTMs and datasets on a popular open-source ML repository, Hugging Face (HF), and analyze the evolution of PTMs over time. Method: We conducted a repository mining study. We started with a systematically gathered database of PTMs and datasets from the HF API. Our selection was refined by analyzing model and dataset cards and metadata, such as tags, and confirming SE relevance using Gemini 1.5 Pro. All analyses are replicable, with a publicly accessible replication package. Results: The most common SE task among PTMs and datasets is code generation, with a primary focus on software development and limited attention to software management. Popular PTMs and datasets mainly target software development. Among ML tasks, text generation is the most common in SE PTMs and datasets. There has been a marked increase in PTMs for SE since 2023 Q2. Conclusions: This study underscores the need for broader task coverage to enhance the integration of ML within SE practices.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "5 pages, 8 figures"
    },
    {
        "paper id": "2411.09686",
        "abstract url": "https://arxiv.org/abs/2411.09686",
        "title": "Conditional regression for the Nonlinear Single-Variable Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Several statistical models for regression of a function $F$ on $\\mathbb{R}^d$ without the statistical and computational curse of dimensionality exist, for example by imposing and exploiting geometric assumptions on the distribution of the data (e.g. that its support is low-dimensional), or strong smoothness assumptions on $F$, or a special structure $F$. Among the latter, compositional models assume $F=f\\circ g$ with $g$ mapping to $\\mathbb{R}^r$ with $r\\ll d$, have been studied, and include classical single- and multi-index models and recent works on neural networks. While the case where $g$ is linear is rather well-understood, much less is known when $g$ is nonlinear, and in particular for which $g$'s the curse of dimensionality in estimating $F$, or both $f$ and $g$, may be circumvented. In this paper, we consider a model $F(X):=f(\u03a0_\u03b3X) $ where $\u03a0_\u03b3:\\mathbb{R}^d\\to[0,\\rm{len}_\u03b3]$ is the closest-point projection onto the parameter of a regular curve $\u03b3: [0,\\rm{len}_\u03b3]\\to\\mathbb{R}^d$ and $f:[0,\\rm{len}_\u03b3]\\to\\mathbb{R}^1$. The input data $X$ is not low-dimensional, far from $\u03b3$, conditioned on $\u03a0_\u03b3(X)$ being well-defined. The distribution of the data, $\u03b3$ and $f$ are unknown. This model is a natural nonlinear generalization of the single-index model, which corresponds to $\u03b3$ being a line. We propose a nonparametric estimator, based on conditional regression, and show that under suitable assumptions, the strongest of which being that $f$ is coarsely monotone, it can achieve the $one$-$dimensional$ optimal min-max rate for non-parametric regression, up to the level of noise in the observations, and be constructed in time $\\mathcal{O}(d^2n\\log n)$. All the constants in the learning bounds, in the minimal number of samples required for our bounds to hold, and in the computational complexity are at most low-order polynomials in $d$.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "comment": "55 pages, 10 figures"
    },
    {
        "paper id": "2411.09731",
        "abstract url": "https://arxiv.org/abs/2411.09731",
        "title": "To bootstrap or to rollout? An optimal and adaptive interpolation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Bootstrapping and rollout are two fundamental principles for value function estimation in reinforcement learning (RL). We introduce a novel class of Bellman operators, called subgraph Bellman operators, that interpolate between bootstrapping and rollout methods. Our estimator, derived by solving the fixed point of the empirical subgraph Bellman operator, combines the strengths of the bootstrapping-based temporal difference (TD) estimator and the rollout-based Monte Carlo (MC) methods. Specifically, the error upper bound of our estimator approaches the optimal variance achieved by TD, with an additional term depending on the exit probability of a selected subset of the state space. At the same time, the estimator exhibits the finite-sample adaptivity of MC, with sample complexity depending only on the occupancy measure of this subset. We complement the upper bound with an information-theoretic lower bound, showing that the additional term is unavoidable given a reasonable sample size. Together, these results establish subgraph Bellman estimators as an optimal and adaptive framework for reconciling TD and MC methods in policy evaluation.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09734",
        "abstract url": "https://arxiv.org/abs/2411.09734",
        "title": "Modeling AdaGrad, RMSProp, and Adam with Integro-Differential Equations",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a continuous-time formulation for the AdaGrad, RMSProp, and Adam optimization algorithms by modeling them as first-order integro-differential equations. We perform numerical simulations of these equations to demonstrate their validity as accurate approximations of the original algorithms. Our results indicate a strong agreement between the behavior of the continuous-time models and the discrete implementations, thus providing a new perspective on the theoretical understanding of adaptive optimization methods.",
        "subjects": [
            "cs.LG",
            "math.NA",
            "math.OC"
        ],
        "comment": "22 pages"
    },
    {
        "paper id": "2411.09772",
        "abstract url": "https://arxiv.org/abs/2411.09772",
        "title": "Beyond Static Tools: Evaluating Large Language Models for Cryptographic Misuse Detection",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The use of Large Language Models (LLMs) in software development is rapidly growing, with developers increasingly relying on these models for coding assistance, including security-critical tasks. Our work presents a comprehensive comparison between traditional static analysis tools for cryptographic API misuse detection-CryptoGuard, CogniCrypt, and Snyk Code-and the LLMs-GPT and Gemini. Using benchmark datasets (OWASP, CryptoAPI, and MASC), we evaluate the effectiveness of each tool in identifying cryptographic misuses. Our findings show that GPT 4-o-mini surpasses current state-of-the-art static analysis tools on the CryptoAPI and MASC datasets, though it lags on the OWASP dataset. Additionally, we assess the quality of LLM responses to determine which models provide actionable and accurate advice, giving developers insights into their practical utility for secure coding. This study highlights the comparative strengths and limitations of static analysis versus LLM-driven approaches, offering valuable insights into the evolving role of AI in advancing software security practices.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09776",
        "abstract url": "https://arxiv.org/abs/2411.09776",
        "title": "Combining Machine Learning Defenses without Conflicts",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning (ML) defenses protect against various risks to security, privacy, and fairness. Real-life models need simultaneous protection against multiple different risks which necessitates combining multiple defenses. But combining defenses with conflicting interactions in an ML model can be ineffective, incurring a significant drop in the effectiveness of one or more defenses being combined. Practitioners need a way to determine if a given combination can be effective. Experimentally identifying effective combinations can be time-consuming and expensive, particularly when multiple defenses need to be combined. We need an inexpensive, easy-to-use combination technique to identify effective combinations. Ideally, a combination technique should be (a) accurate (correctly identifies whether a combination is effective or not), (b) scalable (allows combining multiple defenses), (c) non-invasive (requires no change to the defenses being combined), and (d) general (is applicable to different types of defenses). Prior works have identified several ad-hoc techniques but none satisfy all the requirements above. We propose a principled combination technique, Def\\Con, to identify effective defense combinations. Def\\Con meets all requirements, achieving 90% accuracy on eight combinations explored in prior work and 81% in 30 previously unexplored combinations that we empirically evaluate in this paper.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09786",
        "abstract url": "https://arxiv.org/abs/2411.09786",
        "title": "Environmental Burden of United States Data Centers in the Artificial Intelligence Era",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The rapid proliferation of data centers in the US - driven partly by the adoption of artificial intelligence - has set off alarm bells about the industry's environmental impact. We compiled detailed information on 2,132 US data centers operating between September 2023 and August 2024 and determined their electricity consumption, electricity sources, and attributable CO$_{2}$e emissions. Our findings reveal that data centers accounted for more than 4% of total US electricity consumption - with 56% derived from fossil fuels - generating more than 105 million tons of CO$_{2}$e (2.18% of US emissions in 2023). Data centers' carbon intensity - the amount of CO$_{2}$e emitted per unit of electricity consumed - exceeded the US average by 48%. Our data pipeline and visualization tools can be used to assess current and future environmental impacts of data centers.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09802",
        "abstract url": "https://arxiv.org/abs/2411.09802",
        "title": "Modeling human decomposition: a Bayesian approach",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Environmental and individualistic variables affect the rate of human decomposition in complex ways. These effects complicate the estimation of the postmortem interval (PMI) based on observed decomposition characteristics. In this work, we develop a generative probabilistic model for decomposing human remains based on PMI and a wide range of environmental and individualistic variables. This model explicitly represents the effect of each variable, including PMI, on the appearance of each decomposition characteristic, allowing for direct interpretation of model effects and enabling the use of the model for PMI inference and optimal experimental design. In addition, the probabilistic nature of the model allows for the integration of expert knowledge in the form of prior distributions. We fit this model to a diverse set of 2,529 cases from the GeoFOR dataset. We demonstrate that the model accurately predicts 24 decomposition characteristics with an ROC AUC score of 0.85. Using Bayesian inference techniques, we invert the decomposition model to predict PMI as a function of the observed decomposition characteristics and environmental and individualistic variables, producing an R-squared measure of 71%. Finally, we demonstrate how to use the fitted model to design future experiments that maximize the expected amount of new information about the mechanisms of decomposition using the Expected Information Gain formalism.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09804",
        "abstract url": "https://arxiv.org/abs/2411.09804",
        "title": "Fair Resource Allocation in Weakly Coupled Markov Decision Processes",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider fair resource allocation in sequential decision-making environments modeled as weakly coupled Markov decision processes, where resource constraints couple the action spaces of $N$ sub-Markov decision processes (sub-MDPs) that would otherwise operate independently. We adopt a fairness definition using the generalized Gini function instead of the traditional utilitarian (total-sum) objective. After introducing a general but computationally prohibitive solution scheme based on linear programming, we focus on the homogeneous case where all sub-MDPs are identical. For this case, we show for the first time that the problem reduces to optimizing the utilitarian objective over the class of \"permutation invariant\" policies. This result is particularly useful as we can exploit Whittle index policies in the restless bandits setting while, for the more general setting, we introduce a count-proportion-based deep reinforcement learning approach. Finally, we validate our theoretical findings with comprehensive experiments, confirming the effectiveness of our proposed method in achieving fairness.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09812",
        "abstract url": "https://arxiv.org/abs/2411.09812",
        "title": "Edge Caching Optimization with PPO and Transfer Learning for Dynamic Environments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper addresses the challenge of edge caching in dynamic environments, where rising traffic loads strain backhaul links and core networks. We propose a Proximal Policy Optimization (PPO)-based caching strategy that fully incorporates key file attributes such as size, lifetime, importance, and popularity, while also considering random file request arrivals, reflecting more realistic edge caching scenarios. In dynamic environments, changes such as shifts in content popularity and variations in request rates frequently occur, making previously learned policies less effective as they were optimized for earlier conditions. Without adaptation, caching efficiency and response times can degrade. While learning a new policy from scratch in a new environment is an option, it is highly inefficient and computationally expensive. Thus, adapting an existing policy to these changes is critical. To address this, we develop a mechanism that detects changes in content popularity and request rates, ensuring timely adjustments to the caching strategy. We also propose a transfer learning-based PPO algorithm that accelerates convergence in new environments by leveraging prior knowledge. Simulation results demonstrate the significant effectiveness of our approach, outperforming a recent Deep Reinforcement Learning (DRL)-based method.",
        "subjects": [
            "cs.NI",
            "cs.LG",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09813",
        "abstract url": "https://arxiv.org/abs/2411.09813",
        "title": "Can Features for Phishing URL Detection Be Trusted Across Diverse Datasets? A Case Study with Explainable AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Phishing has been a prevalent cyber threat that manipulates users into revealing sensitive private information through deceptive tactics, designed to masquerade as trustworthy entities. Over the years, proactively detection of phishing URLs (or websites) has been established as an widely-accepted defense approach. In literature, we often find supervised Machine Learning (ML) models with highly competitive performance for detecting phishing websites based on the extracted features from both phishing and benign (i.e., legitimate) websites. However, it is still unclear if these features or indicators are dependent on a particular dataset or they are generalized for overall phishing detection. In this paper, we delve deeper into this issue by analyzing two publicly available phishing URL datasets, where each dataset has its own set of unique and overlapping features related to URL string and website contents. We want to investigate if overlapping features are similar in nature across datasets and how does the model perform when trained on one dataset and tested on the other. We conduct practical experiments and leverage explainable AI (XAI) methods such as SHAP plots to provide insights into different features' contributions in case of phishing detection to answer our primary question, \"Can features for phishing URL detection be trusted across diverse dataset?\". Our case study experiment results show that features for phishing URL detection can often be dataset-dependent and thus may not be trusted across different datasets even though they share same set of feature behaviors.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": "9 pages, 9 figures, 11th International Conference on Networking, Systems, and Security (NSysS 2024), 2024, Khulna, Bangladesh"
    },
    {
        "paper id": "2411.09816",
        "abstract url": "https://arxiv.org/abs/2411.09816",
        "title": "Learning Parameter Sharing with Tensor Decompositions and Sparsity",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Large neural networks achieve remarkable performance, but their size hinders deployment on resource-constrained devices. While various compression techniques exist, parameter sharing remains relatively unexplored. This paper introduces Fine-grained Parameter Sharing (FiPS), a novel algorithm that leverages the relationship between parameter sharing, tensor decomposition, and sparsity to efficiently compress large vision transformer models. FiPS employs a shared base and sparse factors to represent shared neurons across multi-layer perception (MLP) modules. Shared parameterization is initialized via Singular Value Decomposition (SVD) and optimized by minimizing block-wise reconstruction error. Experiments demonstrate that FiPS compresses DeiT-B and Swin-L MLPs to 25-40% of their original parameter count while maintaining accuracy within 1 percentage point of the original models.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09837",
        "abstract url": "https://arxiv.org/abs/2411.09837",
        "title": "Real-time Adapting Routing (RAR): Improving Efficiency Through Continuous Learning in Software Powered by Layered Foundation Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "To balance the quality and inference cost of a Foundation Model (FM, such as large language models (LLMs)) powered software, people often opt to train a routing model that routes requests to FMs with different sizes and capabilities. Existing routing models rely on learning the optimal routing decision from carefully curated data, require complex computations to be updated, and do not consider the potential evolution of weaker FMs. In this paper, we propose Real-time Adaptive Routing (RAR), an approach to continuously adapt FM routing decisions while using guided in-context learning to enhance the capabilities of weaker FM. The goal is to reduce reliance on stronger, more expensive FMs. We evaluate our approach on different subsets of the popular MMLU benchmark. Over time, our approach routes 50.2% fewer requests to computationally expensive models while maintaining around 90.5% of the general response quality. In addition, the guides generated from stronger models have shown intra-domain generalization and led to a better quality of responses compared to an equivalent approach with a standalone weaker FM.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09847",
        "abstract url": "https://arxiv.org/abs/2411.09847",
        "title": "Towards a Fairer Non-negative Matrix Factorization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Topic modeling, or more broadly, dimensionality reduction, techniques provide powerful tools for uncovering patterns in large datasets and are widely applied across various domains. We investigate how Non-negative Matrix Factorization (NMF) can introduce bias in the representation of data groups, such as those defined by demographics or protected attributes. We present an approach, called Fairer-NMF, that seeks to minimize the maximum reconstruction loss for different groups relative to their size and intrinsic complexity. Further, we present two algorithms for solving this problem. The first is an alternating minimization (AM) scheme and the second is a multiplicative updates (MU) scheme which demonstrates a reduced computational time compared to AM while still achieving similar performance. Lastly, we present numerical experiments on synthetic and real datasets to evaluate the overall performance and trade-offs of Fairer-NMF",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09856",
        "abstract url": "https://arxiv.org/abs/2411.09856",
        "title": "InvestESG: A multi-agent reinforcement learning benchmark for studying climate investment as a social dilemma",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "InvestESG is a novel multi-agent reinforcement learning (MARL) benchmark designed to study the impact of Environmental, Social, and Governance (ESG) disclosure mandates on corporate climate investments. Supported by both PyTorch and GPU-accelerated JAX framework, the benchmark models an intertemporal social dilemma where companies balance short-term profit losses from climate mitigation efforts and long-term benefits from reducing climate risk, while ESG-conscious investors attempt to influence corporate behavior through their investment decisions. Companies allocate capital across mitigation, greenwashing, and resilience, with varying strategies influencing climate outcomes and investor preferences. Our experiments show that without ESG-conscious investors with sufficient capital, corporate mitigation efforts remain limited under the disclosure mandate. However, when a critical mass of investors prioritizes ESG, corporate cooperation increases, which in turn reduces climate risks and enhances long-term financial stability. Additionally, providing more information about global climate risks encourages companies to invest more in mitigation, even without investor involvement. Our findings align with empirical research using real-world data, highlighting MARL's potential to inform policy by providing insights into large-scale socio-economic challenges through efficient testing of alternative policy and market designs.",
        "subjects": [
            "cs.LG",
            "cs.CY",
            "cs.MA",
            "econ.GN"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09891",
        "abstract url": "https://arxiv.org/abs/2411.09891",
        "title": "Off-Dynamics Reinforcement Learning via Domain Adaptation and Reward Augmented Imitation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Training a policy in a source domain for deployment in the target domain under a dynamics shift can be challenging, often resulting in performance degradation. Previous work tackles this challenge by training on the source domain with modified rewards derived by matching distributions between the source and the target optimal trajectories. However, pure modified rewards only ensure the behavior of the learned policy in the source domain resembles trajectories produced by the target optimal policies, which does not guarantee optimal performance when the learned policy is actually deployed to the target domain. In this work, we propose to utilize imitation learning to transfer the policy learned from the reward modification to the target domain so that the new policy can generate the same trajectories in the target domain. Our approach, Domain Adaptation and Reward Augmented Imitation Learning (DARAIL), utilizes the reward modification for domain adaptation and follows the general framework of generative adversarial imitation learning from observation (GAIfO) by applying a reward augmented estimator for the policy optimization step. Theoretically, we present an error bound for our method under a mild assumption regarding the dynamics shift to justify the motivation of our method. Empirically, our method outperforms the pure modified reward method without imitation learning and also outperforms other baselines in benchmark off-dynamics environments.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "Published at Neurips 2024"
    },
    {
        "paper id": "2411.09896",
        "abstract url": "https://arxiv.org/abs/2411.09896",
        "title": "Revealing the Evolution of Order in Materials Microstructures Using Multi-Modal Computer Vision",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The development of high-performance materials for microelectronics, energy storage, and extreme environments depends on our ability to describe and direct property-defining microstructural order. Our present understanding is typically derived from laborious manual analysis of imaging and spectroscopy data, which is difficult to scale, challenging to reproduce, and lacks the ability to reveal latent associations needed for mechanistic models. Here, we demonstrate a multi-modal machine learning (ML) approach to describe order from electron microscopy analysis of the complex oxide La$_{1-x}$Sr$_x$FeO$_3$. We construct a hybrid pipeline based on fully and semi-supervised classification, allowing us to evaluate both the characteristics of each data modality and the value each modality adds to the ensemble. We observe distinct differences in the performance of uni- and multi-modal models, from which we draw general lessons in describing crystal order using computer vision.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": "30 pages, 5 figures, 2 tables"
    },
    {
        "paper id": "2411.09900",
        "abstract url": "https://arxiv.org/abs/2411.09900",
        "title": "Statistical Analysis of Policy Space Compression Problem",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Policy search methods are crucial in reinforcement learning, offering a framework to address continuous state-action and partially observable problems. However, the complexity of exploring vast policy spaces can lead to significant inefficiencies. Reducing the policy space through policy compression emerges as a powerful, reward-free approach to accelerate the learning process. This technique condenses the policy space into a smaller, representative set while maintaining most of the original effectiveness. Our research focuses on determining the necessary sample size to learn this compressed set accurately. We employ R\u00e9nyi divergence to measure the similarity between true and estimated policy distributions, establishing error bounds for good approximations. To simplify the analysis, we employ the $l_1$ norm, determining sample size requirements for both model-based and model-free settings. Finally, we correlate the error bounds from the $l_1$ norm with those from R\u00e9nyi divergence, distinguishing between policies near the vertices and those in the middle of the policy space, to determine the lower and upper bounds for the required sample sizes.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09909",
        "abstract url": "https://arxiv.org/abs/2411.09909",
        "title": "AMXFP4: Taming Activation Outliers with Asymmetric Microscaling Floating-Point for 4-bit LLM Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Scaling Large Language Models (LLMs) with extended context lengths has increased the need for efficient low-bit quantization to manage their substantial computational demands. However, reducing precision to 4 bits frequently degrades performance due to activation outliers. To address this, we propose Asymmetric Microscaling 4-bit Floating-Point (AMXFP4) for efficient LLM inference. This novel data format leverages asymmetric shared scales to mitigate outliers while naturally capturing the asymmetry introduced by group-wise quantization. Unlike conventional 4-bit quantization methods that rely on data rotation and costly calibration, AMXFP4 uses asymmetric shared scales for direct 4-bit casting, achieving near-ideal quantization accuracy across various LLM tasks, including multi-turn conversations, long-context reasoning, and visual question answering. Our AMXFP4 format significantly outperforms MXFP4 and other leading quantization techniques, enabling robust, calibration-free 4-bit inference.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09933",
        "abstract url": "https://arxiv.org/abs/2411.09933",
        "title": "JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging",
        "rating": "0.5",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "medical",
                "Healthcare",
                "X-ray",
                "Radiology"
            ],
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "With the rapid advancement of large language models (LLMs), foundational models (FMs) have seen significant advancements. Healthcare is one of the most crucial application areas for these FMs, given the significant time and effort required for physicians to analyze large volumes of patient data. Recent efforts have focused on adapting multimodal FMs to the medical domain through techniques like instruction-tuning, leading to the development of medical foundation models (MFMs). However, these approaches typically require large amounts of training data to effectively adapt models to the medical field. Moreover, most existing models are trained on English datasets, limiting their practicality in non-English-speaking regions where healthcare professionals and patients are not always fluent in English. The need for translation introduces additional costs and inefficiencies. To address these challenges, we propose a \\textbf{J}apanese \\textbf{Radi}ology report generation model enhanced by \\textbf{Evo}lutionary optimization of model merging (JRadiEvo). This is the first attempt to extend a non-medical vision-language foundation model to the medical domain through evolutionary optimization of model merging. We successfully created a model that generates accurate Japanese reports from X-ray images using only 50 translated samples from publicly available data. This model, developed with highly efficient use of limited data, outperformed leading models from recent research trained on much larger datasets. Additionally, with only 8 billion parameters, this relatively compact foundation model can be deployed locally within hospitals, making it a practical solution for environments where APIs and other external services cannot be used due to strict privacy and security requirements.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.NE"
        ],
        "comment": "Accepted by NeurIPS'24 Workshop on AIM-FM: Advancements In Medical Foundation Models: Explainability, Robustness, Security, and Beyond"
    },
    {
        "paper id": "2411.09945",
        "abstract url": "https://arxiv.org/abs/2411.09945",
        "title": "TEESlice: Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers have Pre-Trained Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Trusted Execution Environments (TEE) are used to safeguard on-device models. However, directly employing TEEs to secure the entire DNN model is challenging due to the limited computational speed. Utilizing GPU can accelerate DNN's computation speed but commercial widely-available GPUs usually lack security protection. To this end, scholars introduce TSDP, a method that protects privacy-sensitive weights within TEEs and offloads insensitive weights to GPUs. Nevertheless, current methods do not consider the presence of a knowledgeable adversary who can access abundant publicly available pre-trained models and datasets. This paper investigates the security of existing methods against such a knowledgeable adversary and reveals their inability to fulfill their security promises. Consequently, we introduce a novel partition before training strategy, which effectively separates privacy-sensitive weights from other components of the model. Our evaluation demonstrates that our approach can offer full model protection with a computational cost reduced by a factor of 10. In addition to traditional CNN models, we also demonstrate the scalability to large language models. Our approach can compress the private functionalities of the large language model to lightweight slices and achieve the same level of protection as the shielding-whole-model baseline.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted by TOSEM. Extended version of the S&P24 paper (arXiv:2310.07152)"
    },
    {
        "paper id": "2411.09946",
        "abstract url": "https://arxiv.org/abs/2411.09946",
        "title": "Assessing Response Disparities in California Wildland-Urban-Interface (WUI) Cities Using the Compartmental Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "The increasing frequency and severity of wildfires pose significant risks to communities, infrastructure, and the environment, especially in Wildland-Urban Interface (WUI) areas. Effective disaster management requires understanding how the public perceives and responds to wildfire threats in real-time. This study uses social media data to assess public responses and explores how these responses are linked to city-level community characteristics. Specifically, we leveraged a transformer-based topic modeling technique called BERTopic to identify wildfire response-related topics and then utilized the Susceptible-Infectious-Recovered (SIR) model to compute two key metrics associated with wildfire responses - awareness and resilience indicators. Additionally, we used GIS-based spatial analysis to map wildfire locations along with four groups of city-level factors (racial/ethnic, socioeconomic, demographic, and wildfire-specific). Our findings reveal significant geographic and socio-spatial differences in public responses. Southern California cities with larger Hispanic populations demonstrate higher wildfire awareness and resilience. In contrast, urbanized regions in Central and Northern California exhibit lower awareness levels. Furthermore, resilience is negatively correlated with unemployment rates, particularly in southern regions where higher unemployment aligns with reduced resilience. These findings highlight the need for targeted and equitable wildfire management strategies to improve the adaptive capacity of WUI communities.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10488",
        "abstract url": "https://arxiv.org/abs/2411.10488",
        "title": "The Future of Skill: What Is It to Be Skilled at Work?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "In this short paper, we introduce work that is aiming to purposefully venture into this mesh of questions from a different starting point. Interjecting into the conversation, we want to ask: 'What is it to be skilled at work?' Building on work from scholars like Tim Ingold, and strands of longstanding research in workplace studies and CSCW, our interest is in turning the attention to the active work of 'being good', or 'being skilled', at what we as workers do. As we see it, skill provides a counterpoint to the version of intelligence that appears to be easily blackboxed in systems like Slack, and that ultimately reduces much of what people do to work well together. To put it slightly differently, skill - as we will argue below - gives us a way into thinking about work as a much more entangled endeavour, unfolding through multiple and interweaving sets of practices, places, tools and collaborations. In this vein, designing for the future of work seems to be about much more than where work is done or how we might bolt on discrete containers of intelligence. More fruitful would be attending to how we succeed in threading so many entities together to do our jobs well - in 'coming to be skilled'.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10490",
        "abstract url": "https://arxiv.org/abs/2411.10490",
        "title": "AI-Spectra: A Visual Dashboard for Model Multiplicity to Enhance Informed and Transparent Decision-Making",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We present an approach, AI-Spectra, to leverage model multiplicity for interactive systems. Model multiplicity means using slightly different AI models yielding equally valid outcomes or predictions for the same task, thus relying on many simultaneous \"expert advisors\" that can have different opinions. Dealing with multiple AI models that generate potentially divergent results for the same task is challenging for users to deal with. It helps users understand and identify AI models are not always correct and might differ, but it can also result in an information overload when being confronted with multiple results instead of one. AI-Spectra leverages model multiplicity by using a visual dashboard designed for conveying what AI models generate which results while minimizing the cognitive effort to detect consensus among models and what type of models might have different opinions. We use a custom adaptation of Chernoff faces for AI-Spectra; Chernoff Bots. This visualization technique lets users quickly interpret complex, multivariate model configurations and compare predictions across multiple models. Our design is informed by building on established Human-AI Interaction guidelines and well know practices in information visualization. We validated our approach through a series of experiments training a wide variation of models with the MNIST dataset to perform number recognition. Our work contributes to the growing discourse on making AI systems more transparent, trustworthy, and effective through the strategic use of multiple models.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "Accepted for publication in an LNCS Volume \"Engineering Interactive Computer Systems - EICS 2024 - International Workshops and Doctoral Consortium, Selected Papers\""
    },
    {
        "paper id": "2411.11900",
        "abstract url": "https://arxiv.org/abs/2411.11900",
        "title": "Identifying Core-Periphery Structures in Networks via Artificial Ants",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Core periphery structure represents a meso-scale structure in networks, characterized by a dense interconnection of core nodes and sparse connections among peripheral nodes. In this paper, we introduce an innovative approach for detecting core periphery structure, leveraging Artificial Ants. Core-periphery structures play a crucial role in elucidating network organization across various domains. The proposed approach, inspired by the foraging behavior of ants, employs artificial pheromone trails to iteratively construct and refine solutions, thereby eliminating the need for arbitrary partitions that often constrain traditional methods. Our method is applied to a diverse selection of real world networks including historical, literary, linguistic, sports, and animal social networks highlighting its adaptability and robustness. We systematically compare the performance of our approach against established core-periphery detection techniques, emphasizing differences in node classification between the core and periphery. Experimental results show that our method achieves superior flexibility and precision, offering marked improvements in the accuracy of core periphery structure detection.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09220",
        "abstract url": "https://arxiv.org/abs/2411.09220",
        "title": "Transferable Adversarial Attacks against ASR",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "eess.AS"
            ]
        ],
        "abstract": "Given the extensive research and real-world applications of automatic speech recognition (ASR), ensuring the robustness of ASR models against minor input perturbations becomes a crucial consideration for maintaining their effectiveness in real-time scenarios. Previous explorations into ASR model robustness have predominantly revolved around evaluating accuracy on white-box settings with full access to ASR models. Nevertheless, full ASR model details are often not available in real-world applications. Therefore, evaluating the robustness of black-box ASR models is essential for a comprehensive understanding of ASR model resilience. In this regard, we thoroughly study the vulnerability of practical black-box attacks in cutting-edge ASR models and propose to employ two advanced time-domain-based transferable attacks alongside our differentiable feature extractor. We also propose a speech-aware gradient optimization approach (SAGO) for ASR, which forces mistranscription with minimal impact on human imperceptibility through voice activity detection rule and a speech-aware gradient-oriented optimizer. Our comprehensive experimental results reveal performance enhancements compared to baseline approaches across five models on two databases.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "eess.SP"
        ],
        "comment": "IEEE SPL"
    },
    {
        "paper id": "2411.09259",
        "abstract url": "https://arxiv.org/abs/2411.09259",
        "title": "Jailbreak Attacks and Defenses against Multimodal Generative Models: A Survey",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "The rapid evolution of multimodal foundation models has led to significant advancements in cross-modal understanding and generation across diverse modalities, including text, images, audio, and video. However, these models remain susceptible to jailbreak attacks, which can bypass built-in safety mechanisms and induce the production of potentially harmful content. Consequently, understanding the methods of jailbreak attacks and existing defense mechanisms is essential to ensure the safe deployment of multimodal generative models in real-world scenarios, particularly in security-sensitive applications. To provide comprehensive insight into this topic, this survey reviews jailbreak and defense in multimodal generative models. First, given the generalized lifecycle of multimodal jailbreak, we systematically explore attacks and corresponding defense strategies across four levels: input, encoder, generator, and output. Based on this analysis, we present a detailed taxonomy of attack methods, defense mechanisms, and evaluation frameworks specific to multimodal generative models. Additionally, we cover a wide range of input-output configurations, including modalities such as Any-to-Text, Any-to-Vision, and Any-to-Any within generative systems. Finally, we highlight current research challenges and propose potential directions for future research.The open-source repository corresponding to this work can be found at https://github.com/liuxuannan/Awesome-Multimodal-Jailbreak.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": "ongoing work"
    },
    {
        "paper id": "2411.09265",
        "abstract url": "https://arxiv.org/abs/2411.09265",
        "title": "BEARD: Benchmarking the Adversarial Robustness for Dataset Distillation",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Dataset Distillation (DD) is an emerging technique that compresses large-scale datasets into significantly smaller synthesized datasets while preserving high test performance and enabling the efficient training of large models. However, current research primarily focuses on enhancing evaluation accuracy under limited compression ratios, often overlooking critical security concerns such as adversarial robustness. A key challenge in evaluating this robustness lies in the complex interactions between distillation methods, model architectures, and adversarial attack strategies, which complicate standardized assessments. To address this, we introduce BEARD, an open and unified benchmark designed to systematically assess the adversarial robustness of DD methods, including DM, IDM, and BACON. BEARD encompasses a variety of adversarial attacks (e.g., FGSM, PGD, C&W) on distilled datasets like CIFAR-10/100 and TinyImageNet. Utilizing an adversarial game framework, it introduces three key metrics: Robustness Ratio (RR), Attack Efficiency Ratio (AE), and Comprehensive Robustness-Efficiency Index (CREI). Our analysis includes unified benchmarks, various Images Per Class (IPC) settings, and the effects of adversarial training. Results are available on the BEARD Leaderboard, along with a library providing model and dataset pools to support reproducible research. Access the code at BEARD.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "15 pages, 6 figures"
    },
    {
        "paper id": "2411.09266",
        "abstract url": "https://arxiv.org/abs/2411.09266",
        "title": "How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative Study of ChatGPT, AI Models and Human Perception",
        "rating": "0",
        "keywords": [
            [
                "Deepfake"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal deepfakes involving audiovisual manipulations are a growing threat because they are difficult to detect with the naked eye or using unimodal deep learningbased forgery detection methods. Audiovisual forensic models, while more capable than unimodal models, require large training datasets and are computationally expensive for training and inference. Furthermore, these models lack interpretability and often do not generalize well to unseen manipulations. In this study, we examine the detection capabilities of a large language model (LLM) (i.e., ChatGPT) to identify and account for any possible visual and auditory artifacts and manipulations in audiovisual deepfake content. Extensive experiments are conducted on videos from a benchmark multimodal deepfake dataset to evaluate the detection performance of ChatGPT and compare it with the detection capabilities of state-of-the-art multimodal forensic models and humans. Experimental results demonstrate the importance of domain knowledge and prompt engineering for video forgery detection tasks using LLMs. Unlike approaches based on end-to-end learning, ChatGPT can account for spatial and spatiotemporal artifacts and inconsistencies that may exist within or across modalities. Additionally, we discuss the limitations of ChatGPT for multimedia forensic tasks.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.HC",
            "cs.LG",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09293",
        "abstract url": "https://arxiv.org/abs/2411.09293",
        "title": "LLV-FSR: Exploiting Large Language-Vision Prior for Face Super-resolution",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "depth"
            ],
            [
                "Super-resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing face super-resolution (FSR) methods have made significant advancements, but they primarily super-resolve face with limited visual information, original pixel-wise space in particular, commonly overlooking the pluralistic clues, like the higher-order depth and semantics, as well as non-visual inputs (text caption and description). Consequently, these methods struggle to produce a unified and meaningful representation from the input face. We suppose that introducing the language-vision pluralistic representation into unexplored potential embedding space could enhance FSR by encoding and exploiting the complementarity across language-vision prior. This motivates us to propose a new framework called LLV-FSR, which marries the power of large vision-language model and higher-order visual prior with the challenging task of FSR. Specifically, besides directly absorbing knowledge from original input, we introduce the pre-trained vision-language model to generate pluralistic priors, involving the image caption, descriptions, face semantic mask and depths. These priors are then employed to guide the more critical feature representation, facilitating realistic and high-quality face super-resolution. Experimental results demonstrate that our proposed framework significantly improves both the reconstruction quality and perceptual quality, surpassing the SOTA by 0.43dB in terms of PSNR on the MMCelebA-HQ dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09301",
        "abstract url": "https://arxiv.org/abs/2411.09301",
        "title": "LHRS-Bot-Nova: Improved Multimodal Large Language Model for Remote Sensing Vision-Language Interpretation",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Automatically and rapidly understanding Earth's surface is fundamental to our grasp of the living environment and informed decision-making. This underscores the need for a unified system with comprehensive capabilities in analyzing Earth's surface to address a wide range of human needs. The emergence of multimodal large language models (MLLMs) has great potential in boosting the efficiency and convenience of intelligent Earth observation. These models can engage in human-like conversations, serve as unified platforms for understanding images, follow diverse instructions, and provide insightful feedbacks. In this study, we introduce LHRS-Bot-Nova, an MLLM specialized in understanding remote sensing (RS) images, designed to expertly perform a wide range of RS understanding tasks aligned with human instructions. LHRS-Bot-Nova features an enhanced vision encoder and a novel bridge layer, enabling efficient visual compression and better language-vision alignment. To further enhance RS-oriented vision-language alignment, we propose a large-scale RS image-caption dataset, generated through feature-guided image recaptioning. Additionally, we introduce an instruction dataset specifically designed to improve spatial recognition abilities. Extensive experiments demonstrate superior performance of LHRS-Bot-Nova across various RS image understanding tasks. We also evaluate different MLLM performances in complex RS perception and instruction following using a complicated multi-choice question evaluation benchmark, providing a reliable guide for future model selection and improvement. Data, code, and models will be available at https://github.com/NJU-LHRS/LHRS-Bot.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09387",
        "abstract url": "https://arxiv.org/abs/2411.09387",
        "title": "Instruction-Driven Fusion of Infrared-Visible Images: Tailoring for Diverse Downstream Tasks",
        "rating": "0",
        "keywords": [
            [
                "Infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The primary value of infrared and visible image fusion technology lies in applying the fusion results to downstream tasks. However, existing methods face challenges such as increased training complexity and significantly compromised performance of individual tasks when addressing multiple downstream tasks simultaneously. To tackle this, we propose Task-Oriented Adaptive Regulation (T-OAR), an adaptive mechanism specifically designed for multi-task environments. Additionally, we introduce the Task-related Dynamic Prompt Injection (T-DPI) module, which generates task-specific dynamic prompts from user-input text instructions and integrates them into target representations. This guides the feature extraction module to produce representations that are more closely aligned with the specific requirements of downstream tasks. By incorporating the T-DPI module into the T-OAR framework, our approach generates fusion images tailored to task-specific requirements without the need for separate training or task-specific weights. This not only reduces computational costs but also enhances adaptability and performance across multiple tasks. Experimental results show that our method excels in object detection, semantic segmentation, and salient object detection, demonstrating its strong adaptability, flexibility, and task specificity. This provides an efficient solution for image fusion in multi-task environments, highlighting the technology's potential across diverse applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "10 pages, 7 figures"
    },
    {
        "paper id": "2411.09389",
        "abstract url": "https://arxiv.org/abs/2411.09389",
        "title": "Less is More: Unseen Domain Fake News Detection via Causal Propagation Substructures",
        "rating": "0",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.SI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "The spread of fake news on social media poses significant threats to individuals and society. Text-based and graph-based models have been employed for fake news detection by analysing news content and propagation networks, showing promising results in specific scenarios. However, these data-driven models heavily rely on pre-existing in-distribution data for training, limiting their performance when confronted with fake news from emerging or previously unseen domains, known as out-of-distribution (OOD) data. Tackling OOD fake news is a challenging yet critical task. In this paper, we introduce the Causal Subgraph-oriented Domain Adaptive Fake News Detection (CSDA) model, designed to enhance zero-shot fake news detection by extracting causal substructures from propagation graphs using in-distribution data and generalising this approach to OOD data. The model employs a graph neural network based mask generation process to identify dominant nodes and edges within the propagation graph, using these substructures for fake news detection. Additionally, the performance of CSDA is further improved through contrastive learning in few-shot scenarios, where a limited amount of OOD data is available for training. Extensive experiments on public social media datasets demonstrate that CSDA effectively handles OOD fake news detection, achieving a 7 to 16 percents accuracy improvement over other state-of-the-art models.",
        "subjects": [
            "cs.SI",
            "cs.AI",
            "cs.CL",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "9 pages, 2 figures, 5 tables"
    },
    {
        "paper id": "2411.09420",
        "abstract url": "https://arxiv.org/abs/2411.09420",
        "title": "SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph Attention for Vision Transformers",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Image classification is a computer vision task where a model analyzes an image to categorize it into a specific label. Vision Transformers (ViT) improve this task by leveraging self-attention to capture complex patterns and long range relationships between image patches. However, a key challenge for ViTs is efficiently incorporating multiscale feature representations, which is inherent in CNNs through their hierarchical structure. In this paper, we introduce the Scale-Aware Graph Attention Vision Transformer (SAG-ViT), a novel framework that addresses this challenge by integrating multi-scale features. Using EfficientNet as a backbone, the model extracts multi-scale feature maps, which are divided into patches to preserve semantic information. These patches are organized into a graph based on spatial and feature similarities, with a Graph Attention Network (GAT) refining the node embeddings. Finally, a Transformer encoder captures long-range dependencies and complex interactions. The SAG-ViT is evaluated on benchmark datasets, demonstrating its effectiveness in enhancing image classification performance.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "10 pages, 4 figures, 3 tables"
    },
    {
        "paper id": "2411.09436",
        "abstract url": "https://arxiv.org/abs/2411.09436",
        "title": "Robot Tasks with Fuzzy Time Requirements from Natural Language Instructions",
        "rating": "0",
        "keywords": [
            [
                "robotics",
                "Robot"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Natural language allows robot programming to be accessible to everyone. However, the inherent fuzziness in natural language poses challenges for inflexible, traditional robot systems. We focus on instructions with fuzzy time requirements (e.g., \"start in a few minutes\"). Building on previous robotics research, we introduce fuzzy skills. These define an execution by the robot with so-called satisfaction functions representing vague execution time requirements. Such functions express a user's satisfaction over potential starting times for skill execution. When the robot handles multiple fuzzy skills, the satisfaction function provides a temporal tolerance window for execution, thus, enabling optimal scheduling based on satisfaction. We generalized such functions based on individual user expectations with a user study. The participants rated their satisfaction with an instruction's execution at various times. Our investigations reveal that trapezoidal functions best approximate the users' satisfaction. Additionally, the results suggest that users are more lenient if the execution is specified further into the future.",
        "subjects": [
            "cs.RO",
            "cs.CL",
            "cs.HC"
        ],
        "comment": "9 pages, 8 figures, to be published in 2024 IEEE International Conference on Robotic Computing (IRC)"
    },
    {
        "paper id": "2411.09449",
        "abstract url": "https://arxiv.org/abs/2411.09449",
        "title": "Image Regeneration: Evaluating Text-to-Image Model via Generating Identical Image with Multimodal Large Language Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have revitalized the image generation domain, playing crucial roles in both academic research and artistic expression. With the emergence of new diffusion models, assessing the performance of text-to-image models has become increasingly important. Current metrics focus on directly matching the input text with the generated image, but due to cross-modal information asymmetry, this leads to unreliable or incomplete assessment results. Motivated by this, we introduce the Image Regeneration task in this study to assess text-to-image models by tasking the T2I model with generating an image according to the reference image. We use GPT4V to bridge the gap between the reference image and the text input for the T2I model, allowing T2I models to understand image content. This evaluation process is simplified as comparisons between the generated image and the reference image are straightforward. Two regeneration datasets spanning content-diverse and style-diverse evaluation dataset are introduced to evaluate the leading diffusion models currently available. Additionally, we present ImageRepainter framework to enhance the quality of generated images by improving content comprehension via MLLM guided iterative generation and revision. Our comprehensive experiments have showcased the effectiveness of this framework in assessing the generative capabilities of models. By leveraging MLLM, we have demonstrated that a robust T2M can produce images more closely resembling the reference image.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09502",
        "abstract url": "https://arxiv.org/abs/2411.09502",
        "title": "Golden Noise for Diffusion Models: A Learning Framework",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image diffusion model is a popular paradigm that synthesizes personalized images by providing a text prompt and a random Gaussian noise. While people observe that some noises are ``golden noises'' that can achieve better text-image alignment and higher human preference than others, we still lack a machine learning framework to obtain those golden noises. To learn golden noises for diffusion sampling, we mainly make three contributions in this paper. First, we identify a new concept termed the \\textit{noise prompt}, which aims at turning a random Gaussian noise into a golden noise by adding a small desirable perturbation derived from the text prompt. Following the concept, we first formulate the \\textit{noise prompt learning} framework that systematically learns ``prompted'' golden noise associated with a text prompt for diffusion models. Second, we design a noise prompt data collection pipeline and collect a large-scale \\textit{noise prompt dataset}~(NPD) that contains 100k pairs of random noises and golden noises with the associated text prompts. With the prepared NPD as the training dataset, we trained a small \\textit{noise prompt network}~(NPNet) that can directly learn to transform a random noise into a golden noise. The learned golden noise perturbation can be considered as a kind of prompt for noise, as it is rich in semantic information and tailored to the given text prompt. Third, our extensive experiments demonstrate the impressive effectiveness and generalization of NPNet on improving the quality of synthesized images across various diffusion models, including SDXL, DreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and efficient controller that acts as a plug-and-play module with very limited additional inference and computational costs, as it just provides a golden noise instead of a random noise without accessing the original pipeline.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09567",
        "abstract url": "https://arxiv.org/abs/2411.09567",
        "title": "VPBSD:Vessel-Pattern-Based Semi-Supervised Distillation for Efficient 3D Microscopic Cerebrovascular Segmentation",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D microscopic cerebrovascular images are characterized by their high resolution, presenting significant annotation challenges, large data volumes, and intricate variations in detail. Together, these factors make achieving high-quality, efficient whole-brain segmentation particularly demanding. In this paper, we propose a novel Vessel-Pattern-Based Semi-Supervised Distillation pipeline (VpbSD) to address the challenges of 3D microscopic cerebrovascular segmentation. This pipeline initially constructs a vessel-pattern codebook that captures diverse vascular structures from unlabeled data during the teacher model's pretraining phase. In the knowledge distillation stage, the codebook facilitates the transfer of rich knowledge from a heterogeneous teacher model to a student model, while the semi-supervised approach further enhances the student model's exposure to diverse learning samples. Experimental results on real-world data, including comparisons with state-of-the-art methods and ablation studies, demonstrate that our pipeline and its individual components effectively address the challenges inherent in microscopic cerebrovascular segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09595",
        "abstract url": "https://arxiv.org/abs/2411.09595",
        "title": "LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived from textual sources like 3D tutorials, and (2) enabling conversational 3D generation and mesh understanding. A primary challenge is effectively tokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly. To address this, we introduce LLaMA-Mesh, a novel approach that represents the vertex coordinates and face definitions of 3D meshes as plain text, allowing direct integration with LLMs without expanding the vocabulary. We construct a supervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate 3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs as required, and (3) understand and interpret 3D meshes. Our work is the first to demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge for 3D mesh generation in a text-based format, effectively unifying the 3D and text modalities. LLaMA-Mesh achieves mesh generation quality on par with models trained from scratch while maintaining strong text generation performance.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": "See the project website at https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/"
    },
    {
        "paper id": "2411.09627",
        "abstract url": "https://arxiv.org/abs/2411.09627",
        "title": "One-Shot Manipulation Strategy Learning by Making Contact Analogies",
        "rating": "0",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "We present a novel approach, MAGIC (manipulation analogies for generalizable intelligent contacts), for one-shot learning of manipulation strategies with fast and extensive generalization to novel objects. By leveraging a reference action trajectory, MAGIC effectively identifies similar contact points and sequences of actions on novel objects to replicate a demonstrated strategy, such as using different hooks to retrieve distant objects of different shapes and sizes. Our method is based on a two-stage contact-point matching process that combines global shape matching using pretrained neural features with local curvature analysis to ensure precise and physically plausible contact points. We experiment with three tasks including scooping, hanging, and hooking objects. MAGIC demonstrates superior performance over existing methods, achieving significant improvements in runtime speed and generalization to different object categories. Website: https://magic-2024.github.io/ .",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "CoRL LEAP Workshop, 2024"
    },
    {
        "paper id": "2411.09703",
        "abstract url": "https://arxiv.org/abs/2411.09703",
        "title": "MagicQuill: An Intelligent Interactive Image Editing System",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "Image Editing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image editing involves a variety of complex tasks and requires efficient and precise manipulation techniques. In this paper, we present MagicQuill, an integrated image editing system that enables swift actualization of creative ideas. Our system features a streamlined yet functionally robust interface, allowing for the articulation of editing operations (e.g., inserting elements, erasing objects, altering color) with minimal input. These interactions are monitored by a multimodal large language model (MLLM) to anticipate editing intentions in real time, bypassing the need for explicit prompt entry. Finally, we apply a powerful diffusion prior, enhanced by a carefully learned two-branch plug-in module, to process editing requests with precise control. Experimental results demonstrate the effectiveness of MagicQuill in achieving high-quality image edits. Please visit https://magic-quill.github.io to try out our system.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Code and demo available at https://magic-quill.github.io"
    },
    {
        "paper id": "2411.09838",
        "abstract url": "https://arxiv.org/abs/2411.09838",
        "title": "OneNet: A Channel-Wise 1D Convolutional U-Net",
        "rating": "0",
        "keywords": [
            [
                "super-resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Many state-of-the-art computer vision architectures leverage U-Net for its adaptability and efficient feature extraction. However, the multi-resolution convolutional design often leads to significant computational demands, limiting deployment on edge devices. We present a streamlined alternative: a 1D convolutional encoder that retains accuracy while enhancing its suitability for edge applications. Our novel encoder architecture achieves semantic segmentation through channel-wise 1D convolutions combined with pixel-unshuffle operations. By incorporating PixelShuffle, known for improving accuracy in super-resolution tasks while reducing computational load, OneNet captures spatial relationships without requiring 2D convolutions, reducing parameters by up to 47%. Additionally, we explore a fully 1D encoder-decoder that achieves a 71% reduction in size, albeit with some accuracy loss. We benchmark our approach against U-Net variants across diverse mask-generation tasks, demonstrating that it preserves accuracy effectively. Although focused on image segmentation, this architecture is adaptable to other convolutional applications. Code for the project is available at https://github.com/shbyun080/OneNet .",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09850",
        "abstract url": "https://arxiv.org/abs/2411.09850",
        "title": "Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "inpainting",
                "super-resolution"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Diffusion models have emerged as a powerful foundation model for visual generation. With an appropriate sampling process, it can effectively serve as a generative prior to solve general inverse problems. Current posterior sampling based methods take the measurement (i.e., degraded image sample) into the posterior sampling to infer the distribution of the target data (i.e., clean image sample). However, in this manner, we show that high-frequency information can be prematurely introduced during the early stages, which could induce larger posterior estimate errors during the restoration sampling. To address this issue, we first reveal that forming the log posterior gradient with the noisy measurement ( i.e., samples from a diffusion forward process) instead of the clean one can benefit the reverse process. Consequently, we propose a novel diffusion posterior sampling method DPS-CM, which incorporates a Crafted Measurement (i.e., samples generated by a reverse denoising process, compared to random sampling with noise in standard methods) to form the posterior estimate. This integration aims to mitigate the misalignment with the diffusion prior caused by cumulative posterior estimate errors. Experimental results demonstrate that our approach significantly improves the overall capacity to solve general and noisy inverse problems, such as Gaussian deblurring, super-resolution, inpainting, nonlinear deblurring, and tasks with Poisson noise, relative to existing approaches.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09894",
        "abstract url": "https://arxiv.org/abs/2411.09894",
        "title": "Free Lunch in Pathology Foundation Model: Task-specific Model Adaptation with Concept-Guided Feature Enhancement",
        "rating": "0",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "medical",
                "Whole slide",
                "cancer"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Whole slide image (WSI) analysis is gaining prominence within the medical imaging field. Recent advances in pathology foundation models have shown the potential to extract powerful feature representations from WSIs for downstream tasks. However, these foundation models are usually designed for general-purpose pathology image analysis and may not be optimal for specific downstream tasks or cancer types. In this work, we present Concept Anchor-guided Task-specific Feature Enhancement (CATE), an adaptable paradigm that can boost the expressivity and discriminativeness of pathology foundation models for specific downstream tasks. Based on a set of task-specific concepts derived from the pathology vision-language model with expert-designed prompts, we introduce two interconnected modules to dynamically calibrate the generic image features extracted by foundation models for certain tasks or cancer types. Specifically, we design a Concept-guided Information Bottleneck module to enhance task-relevant characteristics by maximizing the mutual information between image features and concept anchors while suppressing superfluous information. Moreover, a Concept-Feature Interference module is proposed to utilize the similarity between calibrated features and concept anchors to further generate discriminative task-specific features. The extensive experiments on public WSI datasets demonstrate that CATE significantly enhances the performance and generalizability of MIL models. Additionally, heatmap and umap visualization results also reveal the effectiveness and interpretability of CATE. The source code is available at https://github.com/HKU-MedAI/CATE.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09911",
        "abstract url": "https://arxiv.org/abs/2411.09911",
        "title": "DiffFNO: Diffusion Fourier Neural Operator",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "super-resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce DiffFNO, a novel diffusion framework for arbitrary-scale super-resolution strengthened by a Weighted Fourier Neural Operator (WFNO). Mode Re-balancing in WFNO effectively captures critical frequency components, significantly improving the reconstruction of high-frequency image details that are crucial for super-resolution tasks. Gated Fusion Mechanism (GFM) adaptively complements WFNO's spectral features with spatial features from an Attention-based Neural Operator (AttnNO). This enhances the network's capability to capture both global structures and local details. Adaptive Time-Step (ATS) ODE solver, a deterministic sampling strategy, accelerates inference without sacrificing output quality by dynamically adjusting integration step sizes ATS. Extensive experiments demonstrate that DiffFNO achieves state-of-the-art (SOTA) results, outperforming existing methods across various scaling factors by a margin of 2 to 4 dB in PSNR, including those beyond the training distribution. It also achieves this at lower inference time. Our approach sets a new standard in super-resolution, delivering both superior accuracy and computational efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09199",
        "abstract url": "https://arxiv.org/abs/2411.09199",
        "title": "Ghost-Connect Net: A Generalization-Enhanced Guidance For Sparse Deep Networks Under Distribution Shifts",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Sparse deep neural networks (DNNs) excel in real-world applications like robotics and computer vision, by reducing computational demands that hinder usability. However, recent studies aim to boost DNN efficiency by trimming redundant neurons or filters based on task relevance, but neglect their adaptability to distribution shifts. We aim to enhance these existing techniques by introducing a companion network, Ghost Connect-Net (GC-Net), to monitor the connections in the original network with distribution generalization advantage. GC-Net's weights represent connectivity measurements between consecutive layers of the original network. After pruning GC-Net, the pruned locations are mapped back to the original network as pruned connections, allowing for the combination of magnitude and connectivity-based pruning methods. Experimental results using common DNN benchmarks, such as CIFAR-10, Fashion MNIST, and Tiny ImageNet show promising results for hybridizing the method, and using GC-Net guidance for later layers of a network and direct pruning on earlier layers. We provide theoretical foundations for GC-Net's approach to improving generalization under distribution shifts.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "21 pages, 4 figures, 3 subfigures, 42 tables"
    },
    {
        "paper id": "2411.09255",
        "abstract url": "https://arxiv.org/abs/2411.09255",
        "title": "DAHL: Domain-specific Automated Hallucination Evaluation of Long-Form Text through a Benchmark Dataset in Biomedicine",
        "rating": "-0.5",
        "keywords": [
            [
                "Biomedicine"
            ],
            [
                "cs.CL"
            ],
            [
                "EMNLP"
            ]
        ],
        "abstract": "We introduce DAHL, a benchmark dataset and automated evaluation system designed to assess hallucination in long-form text generation, specifically within the biomedical domain. Our benchmark dataset, meticulously curated from biomedical research papers, consists of 8,573 questions across 29 categories. DAHL evaluates fact-conflicting hallucinations in Large Language Models (LLMs) by deconstructing responses into atomic units, each representing a single piece of information. The accuracy of these responses is averaged to produce the DAHL Score, offering a more in-depth evaluation of hallucinations compared to previous methods that rely on multiple-choice tasks. We conduct experiments with 8 different models, finding that larger models tend to hallucinate less; however, beyond a model size of 7 to 8 billion parameters, further scaling does not significantly improve factual accuracy. The DAHL Score holds potential as an efficient alternative to human-annotated preference labels, being able to be expanded to other specialized domains. We release the dataset and code in public.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "EMNLP2024/FEVER"
    },
    {
        "paper id": "2411.09356",
        "abstract url": "https://arxiv.org/abs/2411.09356",
        "title": "Multi-scale Generative Modeling for Fast Sampling",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "While working within the spatial domain can pose problems associated with ill-conditioned scores caused by power-law decay, recent advances in diffusion-based generative models have shown that transitioning to the wavelet domain offers a promising alternative. However, within the wavelet domain, we encounter unique challenges, especially the sparse representation of high-frequency coefficients, which deviates significantly from the Gaussian assumptions in the diffusion process. To this end, we propose a multi-scale generative modeling in the wavelet domain that employs distinct strategies for handling low and high-frequency bands. In the wavelet domain, we apply score-based generative modeling with well-conditioned scores for low-frequency bands, while utilizing a multi-scale generative adversarial learning for high-frequency bands. As supported by the theoretical analysis and experimental results, our model significantly improve performance and reduce the number of trainable parameters, sampling steps, and time.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09388",
        "abstract url": "https://arxiv.org/abs/2411.09388",
        "title": "A survey of probabilistic generative frameworks for molecular simulations",
        "rating": "-0.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generative artificial intelligence is now a widely used tool in molecular science. Despite the popularity of probabilistic generative models, numerical experiments benchmarking their performance on molecular data are lacking. In this work, we introduce and explain several classes of generative models, broadly sorted into two categories: flow-based models and diffusion models. We select three representative models: Neural Spline Flows, Conditional Flow Matching, and Denoising Diffusion Probabilistic Models, and examine their accuracy, computational cost, and generation speed across datasets with tunable dimensionality, complexity, and modal asymmetry. Our findings are varied, with no one framework being the best for all purposes. In a nutshell, (i) Neural Spline Flows do best at capturing mode asymmetry present in low-dimensional data, (ii) Conditional Flow Matching outperforms other models for high-dimensional data with low complexity, and (iii) Denoising Diffusion Probabilistic Models appears the best for low-dimensional data with high complexity. Our datasets include a Gaussian mixture model and the dihedral torsion angle distribution of the Aib\\textsubscript{9} peptide, generated via a molecular dynamics simulation. We hope our taxonomy of probabilistic generative frameworks and numerical results may guide model selection for a wide range of molecular tasks.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "cond-mat.soft",
            "cond-mat.stat-mech"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09413",
        "abstract url": "https://arxiv.org/abs/2411.09413",
        "title": "Script-centric behavior understanding for assisted autism spectrum disorder diagnosis",
        "rating": "-0.5",
        "keywords": [
            [
                "diagnosis",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Observing and analyzing children's social behaviors is crucial for the early diagnosis of Autism Spectrum Disorders (ASD). This work focuses on automatically detecting ASD using computer vision techniques and large language models (LLMs). Existing methods typically rely on supervised learning. However, the scarcity of ASD diagnostic datasets and the lack of interpretability in diagnostic results significantly limits its clinical application. To address these challenges, we introduce a novel unsupervised approach based on script-centric behavior understanding. Our pipeline converts video content into scripts that describe the behavior of characters, leveraging the generalizability of large language models to detect ASD in a zero-shot or few-shot manner. Specifically, we propose a scripts transcription module for multimodal behavior data textualization and a domain prompts module to bridge LLMs. Our method achieves an accuracy of 92.00\\% in diagnosing ASD in children with an average age of 24 months, surpassing the performance of supervised learning methods by 3.58\\% absolutely. Extensive experiments confirm the effectiveness of our approach and suggest its potential for advancing ASD research through LLMs.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "5 pages, 4 figures, submitted to ICASSP 2025"
    },
    {
        "paper id": "2411.09499",
        "abstract url": "https://arxiv.org/abs/2411.09499",
        "title": "Developement of Reinforcement Learning based Optimisation Method for Side-Sill Design",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Optimisation for crashworthiness is a critical part of the vehicle development process. Due to stringent regulations and increasing market demands, multiple factors must be considered within a limited timeframe. However, for optimal crashworthiness design, multiobjective optimisation is necessary, and for complex parts, multiple design parameters must be evaluated. This crashworthiness analysis requires computationally intensive finite element simulations. This challenge leads to the need for inverse multi-parameter multi-objective optimisation. This challenge leads to the need for multi-parameter, multi-objective inverse optimisation. This article investigates a machine learning-based method for this type of optimisation, focusing on the design optimisation of a multi-cell side sill to improve crashworthiness results. Furthermore, the optimiser is coupled with an FE solver to achieve improved results.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09545",
        "abstract url": "https://arxiv.org/abs/2411.09545",
        "title": "Equation-informed data-driven identification of flow budgets and dynamics",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Computational Fluid Dynamics (CFD) is an indispensable method of fluid modelling in engineering applications, reducing the need for physical prototypes and testing for tasks such as design optimisation and performance analysis. Depending on the complexity of the system under consideration, models ranging from low to high fidelity can be used for prediction, allowing significant speed-up. However, the choice of model requires information about the actual dynamics of the flow regime. Correctly identifying the regions/clusters of flow that share the same dynamics has been a challenging research topic to date. In this study, we propose a novel hybrid approach to flow clustering. It consists of characterising each sample point of the system with equation-based features, i.e. features are budgets that represent the contribution of each term from the original governing equation to the local dynamics at each sample point. This was achieved by applying the Sparse Identification of Nonlinear Dynamical systems (SINDy) method pointwise to time evolution data. The method proceeds with equation-based clustering using the Girvan-Newman algorithm. This allows the detection of communities that share the same physical dynamics. The algorithm is implemented in both Eulerian and Lagrangian frameworks. In the Lagrangian, i.e. dynamic approach, the clustering is performed on the trajectory of each point, allowing the change of clusters to be represented also in time. The performance of the algorithm is first tested on a flow around a cylinder. The construction of the dynamic clusters in this test case clearly shows the evolution of the wake from the steady state solution through the transient to the oscillatory solution. Dynamic clustering was then successfully tested on turbulent flow data. Two distinct and well-defined clusters were identified and their temporal evolution was reconstructed.",
        "subjects": [
            "physics.flu-dyn",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09576",
        "abstract url": "https://arxiv.org/abs/2411.09576",
        "title": "Automating Reformulation of Essence Specifications via Graph Rewriting",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Formulating an effective constraint model of a parameterised problem class is crucial to the efficiency with which instances of the class can subsequently be solved. It is difficult to know beforehand which of a set of candidate models will perform best in practice. This paper presents a system that employs graph rewriting to reformulate an input model for improved performance automatically. By situating our work in the Essence abstract constraint specification language, we can use the structure in its high level variable types to trigger rewrites directly. We implement our system via rewrite rules expressed in the Graph Programs 2 language, applied to the abstract syntax tree of an input specification. We show how to automatically translate the solution of the reformulated problem into a solution of the original problem for verification and presentation. We demonstrate the efficacy of our system with a detailed case study.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Presented at the PTHG 2024 workshop"
    },
    {
        "paper id": "2411.09590",
        "abstract url": "https://arxiv.org/abs/2411.09590",
        "title": "Adopting RAG for LLM-Aided Future Vehicle Design",
        "rating": "-0.5",
        "keywords": [
            [
                "Vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this paper, we explore the integration of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) to enhance automated design and software development in the automotive industry. We present two case studies: a standardization compliance chatbot and a design copilot, both utilizing RAG to provide accurate, context-aware responses. We evaluate four LLMs-GPT-4o, LLAMA3, Mistral, and Mixtral -- comparing their answering accuracy and execution time. Our results demonstrate that while GPT-4 offers superior performance, LLAMA3 and Mistral also show promising capabilities for local deployment, addressing data privacy concerns in automotive applications. This study highlights the potential of RAG-augmented LLMs in improving design workflows and compliance in automotive engineering.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "Conference paper accepted in IEEE FLLM 2024"
    },
    {
        "paper id": "2411.09601",
        "abstract url": "https://arxiv.org/abs/2411.09601",
        "title": "Accelerating Knowledge Graph and Ontology Engineering with Large Language Models",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models bear the promise of significant acceleration of key Knowledge Graph and Ontology Engineering tasks, including ontology modeling, extension, modification, population, alignment, as well as entity disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering as a new and coming area of research, and argue that modular approaches to ontologies will be of central importance.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09820",
        "abstract url": "https://arxiv.org/abs/2411.09820",
        "title": "WelQrate: Defining the Gold Standard in Small Molecule Drug Discovery Benchmarking",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "While deep learning has revolutionized computer-aided drug discovery, the AI community has predominantly focused on model innovation and placed less emphasis on establishing best benchmarking practices. We posit that without a sound model evaluation framework, the AI community's efforts cannot reach their full potential, thereby slowing the progress and transfer of innovation into real-world drug discovery. Thus, in this paper, we seek to establish a new gold standard for small molecule drug discovery benchmarking, WelQrate. Specifically, our contributions are threefold: WelQrate Dataset Collection - we introduce a meticulously curated collection of 9 datasets spanning 5 therapeutic target classes. Our hierarchical curation pipelines, designed by drug discovery experts, go beyond the primary high-throughput screen by leveraging additional confirmatory and counter screens along with rigorous domain-driven preprocessing, such as Pan-Assay Interference Compounds (PAINS) filtering, to ensure the high-quality data in the datasets; WelQrate Evaluation Framework - we propose a standardized model evaluation framework considering high-quality datasets, featurization, 3D conformation generation, evaluation metrics, and data splits, which provides a reliable benchmarking for drug discovery experts conducting real-world virtual screening; Benchmarking - we evaluate model performance through various research questions using the WelQrate dataset collection, exploring the effects of different models, dataset quality, featurization methods, and data splitting strategies on the results. In summary, we recommend adopting our proposed WelQrate as the gold standard in small molecule drug discovery benchmarking. The WelQrate dataset collection, along with the curation codes, and experimental scripts are all publicly available at WelQrate.org.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.BM"
        ],
        "comment": "* denotes equal contribution"
    },
    {
        "paper id": "2411.09834",
        "abstract url": "https://arxiv.org/abs/2411.09834",
        "title": "A Benchmark for Long-Form Medical Question Answering",
        "rating": "-0.5",
        "keywords": [
            [
                "Medical",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "There is a lack of benchmarks for evaluating large language models (LLMs) in long-form medical question answering (QA). Most existing medical QA evaluation benchmarks focus on automatic metrics and multiple-choice questions. While valuable, these benchmarks fail to fully capture or assess the complexities of real-world clinical applications where LLMs are being deployed. Furthermore, existing studies on evaluating long-form answer generation in medical QA are primarily closed-source, lacking access to human medical expert annotations, which makes it difficult to reproduce results and enhance existing baselines. In this work, we introduce a new publicly available benchmark featuring real-world consumer medical questions with long-form answer evaluations annotated by medical doctors. We performed pairwise comparisons of responses from various open and closed-source medical and general-purpose LLMs based on criteria such as correctness, helpfulness, harmfulness, and bias. Additionally, we performed a comprehensive LLM-as-a-judge analysis to study the alignment between human judgments and LLMs. Our preliminary results highlight the strong potential of open LLMs in medical QA compared to leading closed models. Code & Data: https://github.com/lavita-ai/medical-eval-sphere",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "AIM-FM: Advancements in Medical Foundation Models Workshop, 38th Conference on Neural Information Processing Systems (NeurIPS 2024)"
    },
    {
        "paper id": "2411.09842",
        "abstract url": "https://arxiv.org/abs/2411.09842",
        "title": "FedRewind: Rewinding Continual Model Exchange for Decentralized Federated Learning",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we present FedRewind, a novel approach to decentralized federated learning that leverages model exchange among nodes to address the issue of data distribution shift. Drawing inspiration from continual learning (CL) principles and cognitive neuroscience theories for memory retention, FedRewind implements a decentralized routing mechanism where nodes send/receive models to/from other nodes in the federation to address spatial distribution challenges inherent in distributed learning (FL). During local training, federation nodes periodically send their models back (i.e., rewind) to the nodes they received them from for a limited number of iterations. This strategy reduces the distribution shift between nodes' data, leading to enhanced learning and generalization performance. We evaluate our method on multiple benchmarks, demonstrating its superiority over standard decentralized federated learning methods and those enforcing specific routing schemes within the federation. Furthermore, the combination of federated and continual learning concepts enables our method to tackle the more challenging federated continual learning task, with data shifts over both space and time, surpassing existing baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09892",
        "abstract url": "https://arxiv.org/abs/2411.09892",
        "title": "Deep learning robotics using self-supervised spatial differentiation drive autonomous contact-based semiconductor characterization",
        "rating": "-0.5",
        "keywords": [
            [
                "robotics",
                "robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Integrating autonomous contact-based robotic characterization into self-driving laboratories can enhance measurement quality, reliability, and throughput. While deep learning models support robust autonomy, current methods lack pixel-precision positioning and require extensive labeled data. To overcome these challenges, we propose a self-supervised convolutional neural network with a spatially differentiable loss function, incorporating shape priors to refine predictions of optimal robot contact poses for semiconductor characterization. This network improves valid pose generation by 20.0%, relative to existing models. We demonstrate our network's performance by driving a 4-degree-of-freedom robot to characterize photoconductivity at 3,025 predicted poses across a gradient of perovskite compositions, achieving throughputs over 125 measurements per hour. Spatially mapping photoconductivity onto each drop-casted film reveals regions of inhomogeneity. With this self-supervised deep learning-driven robotic system, we enable high-precision and reliable automation of contact-based characterization techniques at high throughputs, thereby allowing the measurement of previously inaccessible yet important semiconductor properties for self-driving laboratories.",
        "subjects": [
            "cs.RO",
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09904",
        "abstract url": "https://arxiv.org/abs/2411.09904",
        "title": "Self-Supervised Learning of Grasping Arbitrary Objects On-the-Move",
        "rating": "-0.5",
        "keywords": [
            [
                "robot"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mobile grasping enhances manipulation efficiency by utilizing robots' mobility. This study aims to enable a commercial off-the-shelf robot for mobile grasping, requiring precise timing and pose adjustments. Self-supervised learning can develop a generalizable policy to adjust the robot's velocity and determine grasp position and orientation based on the target object's shape and pose. Due to mobile grasping's complexity, action primitivization and step-by-step learning are crucial to avoid data sparsity in learning from trial and error. This study simplifies mobile grasping into two grasp action primitives and a moving action primitive, which can be operated with limited degrees of freedom for the manipulator. This study introduces three fully convolutional neural network (FCN) models to predict static grasp primitive, dynamic grasp primitive, and residual moving velocity error from visual inputs. A two-stage grasp learning approach facilitates seamless FCN model learning. The ablation study demonstrated that the proposed method achieved the highest grasping accuracy and pick-and-place efficiency. Furthermore, randomizing object shapes and environments in the simulation effectively achieved generalizable mobile grasping.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "comment": "8 pages, 9 figures"
    },
    {
        "paper id": "2411.09197",
        "abstract url": "https://arxiv.org/abs/2411.09197",
        "title": "Orthogonal Linear Array based Product Beamforming for Real Time Underwater 3D Acoustical Imaging",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "Ocean exploration using acoustical 3D imaging is gaining popularity as it provides information about the 3D geometry of the targets even under mild turbid conditions. A major challenge in underwater 3D imaging is the high cost of the planar arrays and the computational complexity of the image reconstruction algorithms. In this work, we introduce two novel aspects, an L shaped array and a quadrant based time domain receive beamforming with a focus on achieving relatively low computational complexity for real-time 3D imaging in underwater environments. An orthogonal combination of two linear arrays to form an L shape is used to perform two independent and parallel 2D delay and sum beamforming and the 3D image of the target is reconstructed using the product of the resulting beams. In the proposed quadrant-based beamforming, each quadrant in the imaging slice is reconstructed in parallel using the orthogonal L-shaped linear arrays which reside at the edges of the planar array for the quadrant to be reconstructed. The proposed L-array solves the multiple-target ambiguity issue of the cross-array and an L-array placed at the center of the uniform planar array. The proposed method has reduced the main lobe width by 1 degree with 11.8 dB increase in the peak side lobe level when compared to the conventional delay and sum beamforming using a uniform planar array. Although there is an increase in the side lobe level, the asymmetric beam pattern of the proposed L array and the quadrant-based beamforming restrict the side lobes within a quadrant. The proposed method achieves a reduction in computation time by a factor of 97 for 3D imaging compared to the conventional method, while maintaining acceptable image quality. For qualitative analysis, the 3D images of different underwater targets have been reconstructed and compared in simulation and experiment.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09198",
        "abstract url": "https://arxiv.org/abs/2411.09198",
        "title": "Risk-aware MPPI for Stochastic Hybrid Systems",
        "rating": "-1",
        "keywords": [
            [
                "robot",
                "navigation"
            ]
        ],
        "abstract": "Path Planning for stochastic hybrid systems presents a unique challenge of predicting distributions of future states subject to a state-dependent dynamics switching function. In this work, we propose a variant of Model Predictive Path Integral Control (MPPI) to plan kinodynamic paths for such systems. Monte Carlo may be inaccurate when few samples are chosen to predict future states under state-dependent disturbances. We employ recently proposed Unscented Transform-based methods to capture stochasticity in the states as well as the state-dependent switching surfaces. This is in contrast to previous works that perform switching based only on the mean of predicted states. We focus our motion planning application on the navigation of a mobile robot in the presence of dynamically moving agents whose responses are based on sensor-constrained attention zones. We evaluate our framework on a simulated mobile robot and show faster convergence to a goal without collisions when the robot exploits the hybrid human dynamics versus when it does not.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09200",
        "abstract url": "https://arxiv.org/abs/2411.09200",
        "title": "Advancing Software Security and Reliability in Cloud Platforms through AI-based Anomaly Detection",
        "rating": "-1",
        "keywords": [
            [
                "Anomaly Detection"
            ]
        ],
        "abstract": "Continuous Integration/Continuous Deployment (CI/CD) is fundamental for advanced software development, supporting faster and more efficient delivery of code changes into cloud environments. However, security issues in the CI/CD pipeline remain challenging, and incidents (e.g., DDoS, Bot, Log4j, etc.) are happening over the cloud environments. While plenty of literature discusses static security testing and CI/CD practices, only a few deal with network traffic pattern analysis to detect different cyberattacks. This research aims to enhance CI/CD pipeline security by implementing anomaly detection through AI (Artificial Intelligence) support. The goal is to identify unusual behaviour or variations from network traffic patterns in pipeline and cloud platforms. The system shall integrate into the workflow to continuously monitor pipeline activities and cloud infrastructure. Additionally, it aims to explore adaptive response mechanisms to mitigate the detected anomalies or security threats. This research employed two popular network traffic datasets, CSE-CIC-IDS2018 and CSE-CIC-IDS2017. We implemented a combination of Convolution Neural Network(CNN) and Long Short-Term Memory (LSTM) to detect unusual traffic patterns. We achieved an accuracy of 98.69% and 98.30% and generated log files in different CI/CD pipeline stages that resemble the network anomalies affected to address security challenges in modern DevOps practices, contributing to advancing software security and reliability.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2411.09213",
        "abstract url": "https://arxiv.org/abs/2411.09213",
        "title": "Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering",
        "rating": "-1",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising approach to enhance the performance of large language models (LLMs) in knowledge-intensive tasks such as those from medical domain. However, the sensitive nature of the medical domain necessitates a completely accurate and trustworthy system. While existing RAG benchmarks primarily focus on the standard retrieve-answer setting, they overlook many practical scenarios that measure crucial aspects of a reliable medical system. This paper addresses this gap by providing a comprehensive evaluation framework for medical question-answering (QA) systems in a RAG setting for these situations, including sufficiency, integration, and robustness. We introduce Medical Retrieval-Augmented Generation Benchmark (MedRGB) that provides various supplementary elements to four medical QA datasets for testing LLMs' ability to handle these specific scenarios. Utilizing MedRGB, we conduct extensive evaluations of both state-of-the-art commercial LLMs and open-source models across multiple retrieval conditions. Our experimental results reveals current models' limited ability to handle noise and misinformation in the retrieved documents. We further analyze the LLMs' reasoning processes to provides valuable insights and future directions for developing RAG systems in this critical medical domain.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09228",
        "abstract url": "https://arxiv.org/abs/2411.09228",
        "title": "Injection Attacks Against End-to-End Encrypted Applications",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "We explore an emerging threat model for end-to-end (E2E) encrypted applications: an adversary sends chosen messages to a target client, thereby \"injecting\" adversarial content into the application state. Such state is subsequently encrypted and synchronized to an adversarially-visible storage. By observing the lengths of the resulting cloud-stored ciphertexts, the attacker backs out confidential information. We investigate this injection threat model in the context of state-of-the-art encrypted messaging applications that support E2E encrypted backups. We show proof-of-concept attacks that can recover information about E2E encrypted messages or attachments sent via WhatsApp, assuming the ability to compromise the target user's Google or Apple account (which gives access to encrypted backups). We also show weaknesses in Signal's encrypted backup design that would allow injection attacks to infer metadata including a target user's number of contacts and conversations, should the adversary somehow obtain access to the user's encrypted Signal backup. While we do not believe our results should be of immediate concern for users of these messaging applications, our results do suggest that more work is needed to build tools that enjoy strong E2E security guarantees.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Published in IEEE Security and Privacy 2024"
    },
    {
        "paper id": "2411.09243",
        "abstract url": "https://arxiv.org/abs/2411.09243",
        "title": "Towards Unified Neural Decoding of Perceived, Spoken and Imagined Speech from EEG Signals",
        "rating": "-1",
        "keywords": [
            [
                "EEG"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Brain signals accompany various information relevant to human actions and mental imagery, making them crucial to interpreting and understanding human intentions. Brain-computer interface technology leverages this brain activity to generate external commands for controlling the environment, offering critical advantages to individuals with paralysis or locked-in syndrome. Within the brain-computer interface domain, brain-to-speech research has gained attention, focusing on the direct synthesis of audible speech from brain signals. Most current studies decode speech from brain activity using invasive techniques and emphasize spoken speech data. However, humans express various speech states, and distinguishing these states through non-invasive approaches remains a significant yet challenging task. This research investigated the effectiveness of deep learning models for non-invasive-based neural signal decoding, with an emphasis on distinguishing between different speech paradigms, including perceived, overt, whispered, and imagined speech, across multiple frequency bands. The model utilizing the spatial conventional neural network module demonstrated superior performance compared to other models, especially in the gamma band. Additionally, imagined speech in the theta frequency band, where deep learning also showed strong effects, exhibited statistically significant differences compared to the other speech paradigms.",
        "subjects": [
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09283",
        "abstract url": "https://arxiv.org/abs/2411.09283",
        "title": "Leveraging Auxiliary Classification for Rib Fracture Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "CT"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Thoracic trauma often results in rib fractures, which demand swift and accurate diagnosis for effective treatment. However, detecting these fractures on rib CT scans poses considerable challenges, involving the analysis of many image slices in sequence. Despite notable advancements in algorithms for automated fracture segmentation, the persisting challenges stem from the diverse shapes and sizes of these fractures. To address these issues, this study introduces a sophisticated deep-learning model with an auxiliary classification task designed to enhance the accuracy of rib fracture segmentation. The auxiliary classification task is crucial in distinguishing between fractured ribs and negative regions, encompassing non-fractured ribs and surrounding tissues, from the patches obtained from CT scans. By leveraging this auxiliary task, the model aims to improve feature representation at the bottleneck layer by highlighting the regions of interest. Experimental results on the RibFrac dataset demonstrate significant improvement in segmentation performance.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "Accepted at ICVGIP'24"
    },
    {
        "paper id": "2411.09299",
        "abstract url": "https://arxiv.org/abs/2411.09299",
        "title": "Hearing the Robot's Mind: Sonification for Explicit Feedback in Human-Robot Interaction",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Social robots are required not only to understand human intentions but also to effectively communicate their intentions or own internal states to users. This study explores the use of sonification to provide explicit auditory feedback, enhancing mutual understanding in HRI. We introduce a novel sonification approach that conveys the robot's internal state, linked to its perception of nearby individuals and their interaction intentions. The approach is evaluated through a two-fold user study: an online video-based survey with $26$ participants and live experiments with $10$ participants. Results indicate that while sonification improves the robot's expressivity and communication effectiveness, the design of the auditory feedback needs refinement to enhance user experience. Participants found the auditory cues useful but described the sounds as uninteresting and unpleasant. These findings underscore the importance of carefully designed auditory feedback in developing more effective and engaging HRI systems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09339",
        "abstract url": "https://arxiv.org/abs/2411.09339",
        "title": "Re-Parameterization of Lightweight Transformer for On-Device Speech Emotion Recognition",
        "rating": "-1",
        "keywords": [
            [
                "IoT"
            ],
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "With the increasing implementation of machine learning models on edge or Internet-of-Things (IoT) devices, deploying advanced models on resource-constrained IoT devices remains challenging. Transformer models, a currently dominant neural architecture, have achieved great success in broad domains but their complexity hinders its deployment on IoT devices with limited computation capability and storage size. Although many model compression approaches have been explored, they often suffer from notorious performance degradation. To address this issue, we introduce a new method, namely Transformer Re-parameterization, to boost the performance of lightweight Transformer models. It consists of two processes: the High-Rank Factorization (HRF) process in the training stage and the deHigh-Rank Factorization (deHRF) process in the inference stage. In the former process, we insert an additional linear layer before the Feed-Forward Network (FFN) of the lightweight Transformer. It is supposed that the inserted HRF layers can enhance the model learning capability. In the later process, the auxiliary HRF layer will be merged together with the following FFN layer into one linear layer and thus recover the original structure of the lightweight model. To examine the effectiveness of the proposed method, we evaluate it on three widely used Transformer variants, i.e., ConvTransformer, Conformer, and SpeechFormer networks, in the application of speech emotion recognition on the IEMOCAP, M3ED and DAIC-WOZ datasets. Experimental results show that our proposed method consistently improves the performance of lightweight Transformers, even making them comparable to large models. The proposed re-parameterization approach enables advanced Transformer models to be deployed on resource-constrained IoT devices.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09344",
        "abstract url": "https://arxiv.org/abs/2411.09344",
        "title": "Adaptively Augmented Consistency Learning: A Semi-supervised Segmentation Framework for Remote Sensing",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Remote sensing (RS) involves the acquisition of data about objects or areas from a distance, primarily to monitor environmental changes, manage resources, and support planning and disaster response. A significant challenge in RS segmentation is the scarcity of high-quality labeled images due to the diversity and complexity of RS image, which makes pixel-level annotation difficult and hinders the development of effective supervised segmentation algorithms. To solve this problem, we propose Adaptively Augmented Consistency Learning (AACL), a semi-supervised segmentation framework designed to enhances RS segmentation accuracy under condictions of limited labeled data. AACL extracts additional information embedded in unlabeled images through the use of Uniform Strength Augmentation (USAug) and Adaptive Cut-Mix (AdaCM). Evaluations across various RS datasets demonstrate that AACL achieves competitive performance in semi-supervised segmentation, showing up to a 20% improvement in specific categories and 2% increase in overall performance compared to state-of-the-art frameworks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09349",
        "abstract url": "https://arxiv.org/abs/2411.09349",
        "title": "ParaLBench: A Large-Scale Benchmark for Computational Paralinguistics over Acoustic Foundation Models",
        "rating": "-1",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Computational paralinguistics (ComParal) aims to develop algorithms and models to automatically detect, analyze, and interpret non-verbal information from speech communication, e. g., emotion, health state, age, and gender. Despite its rapid progress, it heavily depends on sophisticatedly designed models given specific paralinguistic tasks. Thus, the heterogeneity and diversity of ComParal models largely prevent the realistic implementation of ComParal models. Recently, with the advent of acoustic foundation models because of self-supervised learning, developing more generic models that can efficiently perceive a plethora of paralinguistic information has become an active topic in speech processing. However, it lacks a unified evaluation framework for a fair and consistent performance comparison. To bridge this gap, we conduct a large-scale benchmark, namely ParaLBench, which concentrates on standardizing the evaluation process of diverse paralinguistic tasks, including critical aspects of affective computing such as emotion recognition and emotion dimensions prediction, over different acoustic foundation models. This benchmark contains ten datasets with thirteen distinct paralinguistic tasks, covering short-, medium- and long-term characteristics. Each task is carried out on 14 acoustic foundation models under a unified evaluation framework, which allows for an unbiased methodological comparison and offers a grounded reference for the ComParal community. Based on the insights gained from ParaLBench, we also point out potential research directions, i.e., the cross-corpus generalizability, to propel ComParal research in the future. The code associated with this study will be available to foster the transparency and replicability of this work for succeeding researchers.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09360",
        "abstract url": "https://arxiv.org/abs/2411.09360",
        "title": "D4W: Dependable Data-Driven Dynamics for Wheeled Robots",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "Wheeled robots have gained significant attention due to their wide range of applications in manufacturing, logistics, and service industries. However, due to the difficulty of building a highly accurate dynamics model for wheeled robots, developing and testing control algorithms for them remains challenging and time-consuming, requiring extensive physical experimentation. To address this problem, we propose D4W, i.e., Dependable Data-Driven Dynamics for Wheeled Robots, a simulation framework incorporating data-driven methods to accelerate the development and evaluation of algorithms for wheeled robots. The key contribution of D4W is a solution that utilizes real-world sensor data to learn accurate models of robot dynamics. The learned dynamics can capture complex robot behaviors and interactions with the environment throughout simulations, surpassing the limitations of analytical methods, which only work in simplified scenarios. Experimental results show that D4W achieves the best simulation accuracy compared to traditional approaches, allowing for rapid iteration of wheel robot algorithms with less or no need for fine-tuning in reality. We further verify the usability and practicality of the proposed framework through integration with existing simulators and controllers.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "The Fifth International Conference on Distributed Artificial Intelligence"
    },
    {
        "paper id": "2411.09363",
        "abstract url": "https://arxiv.org/abs/2411.09363",
        "title": "When Mamba Meets xLSTM: An Efficient and Precise Method with the XLSTM-VMUNet Model for Skin lesion Segmentation",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "cancer",
                "skin lesions",
                "lesion"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Automatic melanoma segmentation is essential for early skin cancer detection, yet challenges arise from the heterogeneity of melanoma, as well as interfering factors like blurred boundaries, low contrast, and imaging artifacts. While numerous algorithms have been developed to address these issues, previous approaches have often overlooked the need to jointly capture spatial and sequential features within dermatological images. This limitation hampers segmentation accuracy, especially in cases with indistinct borders or structurally similar lesions. Additionally, previous models lacked both a global receptive field and high computational efficiency. In this work, we present the XLSTM-VMUNet Model, which jointly capture spatial and sequential features within derma-tological images successfully. XLSTM-VMUNet can not only specialize in extracting spatial features from images, focusing on the structural characteristics of skin lesions, but also enhance contextual understanding, allowing more effective handling of complex medical image structures. Experiment results on the ISIC2018 dataset demonstrate that XLSTM-VMUNet outperforms VMUNet by 1.25% on DSC and 2.07% on IoU, with faster convergence and consistently high segmentation perfor-mance. Our code of XLSTM-VMUNet is available at https://github.com/FangZhuoyi/XLSTM-VMUNet.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09391",
        "abstract url": "https://arxiv.org/abs/2411.09391",
        "title": "An Optimizing Just-In-Time Compiler for Rotor",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "The Shared Source CLI (SSCLI), also known as Rotor, is an implementation of the CLI released by Microsoft in source code. Rotor includes a single pass just-in-time compiler that generates non-optimized code for Intel IA-32 and IBM PowerPC processors. We extend Rotor with an optimizing just-in-time compiler for IA-32. This compiler has three passes: control flow graph generation, data dependence graph generation and final code generation. Dominance relations in the control flow graph are used to detect natural loops. A number of optimizations are performed during the generation of the data dependence graph. During native code generation, the rich address modes of IA-32 are used for instruction folding, reducing code size and usage of register names. Despite the overhead of three passes and optimizations, this compiler is only 1.4 to 1.9 times slower than the original SSCLI compiler and generates code that runs 6.4 to 10 times faster.",
        "subjects": [
            "cs.PL"
        ],
        "comment": "First International Conference of Innovative Views of .NET Technologies, June 2005"
    },
    {
        "paper id": "2411.09402",
        "abstract url": "https://arxiv.org/abs/2411.09402",
        "title": "Automated Segmentation of Ischemic Stroke Lesions in Non-Contrast Computed Tomography Images for Enhanced Treatment and Prognosis",
        "rating": "-1",
        "keywords": [
            [
                "lesion"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Stroke is the second leading cause of death worldwide, and is increasingly prevalent in low- and middle-income countries (LMICs). Timely interventions can significantly influence stroke survivability and the quality of life after treatment. However, the standard and most widely available imaging method for confirming strokes and their sub-types, the NCCT, is more challenging and time-consuming to employ in cases of ischemic stroke. For this reason, we developed an automated method for ischemic stroke lesion segmentation in NCCTs using the nnU-Net frame work, aimed at enhancing early treatment and improving the prognosis of ischemic stroke patients. We achieved Dice scores of 0.596 and Intersection over Union (IoU) scores of 0.501 on the sampled dataset. After adjusting for outliers, these scores improved to 0.752 for the Dice score and 0.643 for the IoU. Proper delineation of the region of infarction can help clinicians better assess the potential impact of the infarction, and guide treatment procedures.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "7 pages, 3 figures, MICCAI Meets Africa Workshop"
    },
    {
        "paper id": "2411.09469",
        "abstract url": "https://arxiv.org/abs/2411.09469",
        "title": "An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images",
        "rating": "-1",
        "keywords": [
            [
                "health",
                "cancer",
                "disease"
            ],
            [
                "cs.AI",
                "eess.IV"
            ]
        ],
        "abstract": "Cervical cancer remains a major worldwide health issue, with early identification and risk assessment playing critical roles in effective preventive interventions. This paper presents the Cervix-AID-Net model for cervical precancer risk classification. The study designs and evaluates the proposed Cervix-AID-Net model based on patients colposcopy images. The model comprises a Convolutional Block Attention Module (CBAM) and convolutional layers that extract interpretable and representative features of colposcopic images to distinguish high-risk and low-risk cervical precancer. In addition, the proposed Cervix-AID-Net model integrates four explainable techniques, namely gradient class activation maps, Local Interpretable Model-agnostic Explanations, CartoonX, and pixel rate distortion explanation based on output feature maps and input features. The evaluation using holdout and ten-fold cross-validation techniques yielded a classification accuracy of 99.33\\% and 99.81\\%. The analysis revealed that CartoonX provides meticulous explanations for the decision of the Cervix-AID-Net model due to its ability to provide the relevant piece-wise smooth part of the image. The effect of Gaussian noise and blur on the input shows that the performance remains unchanged up to Gaussian noise of 3\\% and blur of 10\\%, while the performance reduces thereafter. A comparison study of the proposed model's performance compared to other deep learning approaches highlights the Cervix-AID-Net model's potential as a supplemental tool for increasing the effectiveness of cervical precancer risk assessment. The proposed method, which incorporates the CBAM and explainable artificial integration, has the potential to influence cervical cancer prevention and early detection, improving patient outcomes and lowering the worldwide burden of this preventable disease.",
        "subjects": [
            "eess.IV",
            "cs.AI"
        ],
        "comment": "19 pages, 9 figure, and 7 tables"
    },
    {
        "paper id": "2411.09471",
        "abstract url": "https://arxiv.org/abs/2411.09471",
        "title": "Renal Cell Carcinoma subtyping: learning from multi-resolution localization",
        "rating": "-1",
        "keywords": [
            [
                "survival",
                "diagnosis",
                "whole slide",
                "Cancer",
                "tumor"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Renal Cell Carcinoma is typically asymptomatic at the early stages for many patients. This leads to a late diagnosis of the tumor, where the curability likelihood is lower, and makes the mortality rate of Renal Cell Carcinoma high, with respect to its incidence rate. To increase the survival chance, a fast and correct categorization of the tumor subtype is paramount. Nowadays, computerized methods, based on artificial intelligence, represent an interesting opportunity to improve the productivity and the objectivity of the microscopy-based Renal Cell Carcinoma diagnosis. Nonetheless, much of their exploitation is hampered by the paucity of annotated dataset, essential for a proficient training of supervised machine learning technologies. This study sets out to investigate a novel self supervised training strategy for machine learning diagnostic tools, based on the multi-resolution nature of the histological samples. We aim at reducing the need of annotated dataset, without significantly reducing the accuracy of the tool. We demonstrate the classification capability of our tool on a whole slide imaging dataset for Renal Cancer subtyping, and we compare our solution with several state-of-the-art classification counterparts.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09553",
        "abstract url": "https://arxiv.org/abs/2411.09553",
        "title": "OOD-SEG: Out-Of-Distribution detection for image SEGmentation with sparse multi-class positive-only annotations",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "surgical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Despite significant advancements, segmentation based on deep neural networks in medical and surgical imaging faces several challenges, two of which we aim to address in this work. First, acquiring complete pixel-level segmentation labels for medical images is time-consuming and requires domain expertise. Second, typical segmentation pipelines cannot detect out-of-distribution (OOD) pixels, leaving them prone to spurious outputs during deployment. In this work, we propose a novel segmentation approach exploiting OOD detection that learns only from sparsely annotated pixels from multiple positive-only classes. These multi-class positive annotations naturally fall within the in-distribution (ID) set. Unlabelled pixels may contain positive classes but also negative ones, including what is typically referred to as \\emph{background} in standard segmentation formulations. Here, we forgo the need for background annotation and consider these together with any other unseen classes as part of the OOD set. Our framework can integrate, at a pixel-level, any OOD detection approaches designed for classification tasks. To address the lack of existing OOD datasets and established evaluation metric for medical image segmentation, we propose a cross-validation strategy that treats held-out labelled classes as OOD. Extensive experiments on both multi-class hyperspectral and RGB surgical imaging datasets demonstrate the robustness and generalisation capability of our proposed framework.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09565",
        "abstract url": "https://arxiv.org/abs/2411.09565",
        "title": "Vlimb: A Wire-Driven Wearable Robot for Bodily Extension, Balancing Powerfulness and Reachability",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Numerous wearable robots have been developed to meet the demands of physical assistance and entertainment. These wearable robots range from body-enhancing types that assist human arms and legs to body-extending types that have extra arms. This study focuses specifically on wearable robots of the latter category, aimed at bodily extension. However, they have not yet achieved the level of powerfulness and reachability equivalent to that of human limbs, limiting their application to entertainment and manipulation tasks involving lightweight objects. Therefore, in this study, we develop an body-extending wearable robot, Vlimb, which has enough powerfulness to lift a human and can perform manipulation. Leveraging the advantages of tendon-driven mechanisms, Vlimb incorporates a wire routing mechanism capable of accommodating both delicate manipulations and robust lifting tasks. Moreover, by introducing a passive ring structure to overcome the limited reachability inherent in tendon-driven mechanisms, Vlimb achieves both the powerfulness and reachability comparable to that of humans. This paper outlines the design methodology of Vlimb, conducts preliminary manipulation and lifting tasks, and verifies its effectiveness.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09585",
        "abstract url": "https://arxiv.org/abs/2411.09585",
        "title": "Backdoor Mitigation by Distance-Driven Detoxification",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Backdoor attacks undermine the integrity of machine learning models by allowing attackers to manipulate predictions using poisoned training data. Such attacks lead to targeted misclassification when specific triggers are present, while the model behaves normally under other conditions. This paper considers a post-training backdoor defense task, aiming to detoxify the backdoors in pre-trained models. We begin by analyzing the underlying issues of vanilla fine-tuning and observe that it is often trapped in regions with low loss for both clean and poisoned samples. Motivated by such observations, we propose Distance-Driven Detoxification (D3), an innovative approach that reformulates backdoor defense as a constrained optimization problem. Specifically, D3 promotes the model's departure from the vicinity of its initial weights, effectively reducing the influence of backdoors. Extensive experiments on state-of-the-art (SOTA) backdoor attacks across various model architectures and datasets demonstrate that D3 not only matches but often surpasses the performance of existing SOTA post-training defense techniques.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Preprint version"
    },
    {
        "paper id": "2411.09598",
        "abstract url": "https://arxiv.org/abs/2411.09598",
        "title": "Assessing the Performance of the DINOv2 Self-supervised Learning Vision Transformer Model for the Segmentation of the Left Atrium from MRI Images",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "surgical",
                "diagnosing",
                "MRI"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Accurate left atrium (LA) segmentation from pre-operative scans is crucial for diagnosing atrial fibrillation, treatment planning, and supporting surgical interventions. While deep learning models are key in medical image segmentation, they often require extensive manually annotated data. Foundation models trained on larger datasets have reduced this dependency, enhancing generalizability and robustness through transfer learning. We explore DINOv2, a self-supervised learning vision transformer trained on natural images, for LA segmentation using MRI. The challenges for LA's complex anatomy, thin boundaries, and limited annotated data make accurate segmentation difficult before & during the image-guided intervention. We demonstrate DINOv2's ability to provide accurate & consistent segmentation, achieving a mean Dice score of .871 & a Jaccard Index of .792 for end-to-end fine-tuning. Through few-shot learning across various data sizes & patient counts, DINOv2 consistently outperforms baseline models. These results suggest that DINOv2 effectively adapts to MRI with limited data, highlighting its potential as a competitive tool for segmentation & encouraging broader use in medical imaging.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "6 pages, 3 figures, SPIE Medical Imaging, 2025"
    },
    {
        "paper id": "2411.09613",
        "abstract url": "https://arxiv.org/abs/2411.09613",
        "title": "PTR: Precision-Driven Tool Recommendation for Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "By augmenting Large Language Models (LLMs) with external tools, their capacity to solve complex problems has been significantly enhanced. However, despite ongoing advancements in the parsing capabilities of LLMs, incorporating all available tools simultaneously in the prompt remains impractical due to the vast number of external tools. Consequently, it is essential to provide LLMs with a precise set of tools tailored to the specific task, considering both quantity and quality. Current tool retrieval methods primarily focus on refining the ranking list of tools and directly packaging a fixed number of top-ranked tools as the tool set. However, these approaches often fail to equip LLMs with the optimal set of tools prior to execution, since the optimal number of tools for different tasks could be different, resulting in inefficiencies such as redundant or unsuitable tools, which impede immediate access to the most relevant tools. This paper addresses the challenge of recommending precise toolsets for LLMs. We introduce the problem of tool recommendation, define its scope, and propose a novel Precision-driven Tool Recommendation (PTR) approach. PTR captures an initial, concise set of tools by leveraging historical tool bundle usage and dynamically adjusts the tool set by performing tool matching, culminating in a multi-view-based tool addition. Additionally, we present a new dataset, RecTools, and a metric, TRACC, designed to evaluate the effectiveness of tool recommendation for LLMs. We further validate our design choices through comprehensive experiments, demonstrating promising accuracy across two open benchmarks and our RecTools dataset.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09619",
        "abstract url": "https://arxiv.org/abs/2411.09619",
        "title": "Hardness Amplification via Group Theory",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "We employ techniques from group theory to show that, in many cases, counting problems on graphs are almost as hard to solve in a small number of instances as they are in all instances. Specifically, we show the following results. 1. Goldreich (2020) asks if, for every constant $\u03b4< 1 / 2$, there is an $\\tilde{O} \\left( n^2 \\right)$-time randomized reduction from computing the number of $k$-cliques modulo $2$ with a success probability of greater than $2 / 3$ to computing the number of $k$-cliques modulo $2$ with an error probability of at most $\u03b4$. In this work, we show that for almost all choices of the $\u03b42^{n \\choose 2}$ corrupt answers within the average-case solver, we have a reduction taking $\\tilde{O} \\left( n^2 \\right)$-time and tolerating an error probability of $\u03b4$ in the average-case solver for any constant $\u03b4< 1 / 2$. By \"almost all\", we mean that if we choose, with equal probability, any subset $S \\subset \\{0,1\\}^{n \\choose 2}$ with $|S| = \\delta2^{n \\choose 2}$, then with a probability of $1-2^{-\u03a9\\left( n^2 \\right)}$, we can use an average-case solver corrupt on $S$ to obtain a probabilistic algorithm. 2. Inspired by the work of Goldreich and Rothblum in FOCS 2018 to take the weighted versions of the graph counting problems, we prove that if the RETH is true, then for a prime $p = \u0398\\left( 2^n \\right)$, the problem of counting the number of unique Hamiltonian cycles modulo $p$ on $n$-vertex directed multigraphs and the problem of counting the number of unique half-cliques modulo $p$ on $n$-vertex undirected multigraphs, both require exponential time to compute correctly on even a $1 / 2^{n/\\log n}$-fraction of instances. Meanwhile, simply printing $0$ on all inputs is correct on at least a $\u03a9\\left( 1 / 2^n \\right)$-fraction of instances.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "72 pages"
    },
    {
        "paper id": "2411.09625",
        "abstract url": "https://arxiv.org/abs/2411.09625",
        "title": "Local deployment of large-scale music AI models on commodity hardware",
        "rating": "-1",
        "keywords": [
            [
                "music"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "We present the MIDInfinite, a web application capable of generating symbolic music using a large-scale generative AI model locally on commodity hardware. Creating this demo involved porting the Anticipatory Music Transformer, a large language model (LLM) pre-trained on the Lakh MIDI dataset, to the Machine Learning Compilation (MLC) framework. Once the model is ported, MLC facilitates inference on a variety of runtimes including C++, mobile, and the browser. We envision that MLC has the potential to bridge the gap between the landscape of increasingly capable music AI models and technology more familiar to music software developers. As a proof of concept, we build a web application that allows users to generate endless streams of multi-instrumental MIDI in the browser, either from scratch or conditioned on a prompt. On commodity hardware (an M3 Macbook Pro), our demo can generate 51 notes per second, which is faster than real-time playback for 72.9% of generations, and increases to 86.3% with 2 seconds of upfront buffering.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": "2 pages"
    },
    {
        "paper id": "2411.09723",
        "abstract url": "https://arxiv.org/abs/2411.09723",
        "title": "Towards Neural Foundation Models for Vision: Aligning EEG, MEG, and fMRI Representations for Decoding, Encoding, and Modality Conversion",
        "rating": "-1",
        "keywords": [
            [
                "fMRI",
                "EEG"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a novel approach towards creating a foundational model for aligning neural data and visual stimuli across multimodal representationsof brain activity by leveraging contrastive learning. We used electroencephalography (EEG), magnetoencephalography (MEG), and functional magnetic resonance imaging (fMRI) data. Our framework's capabilities are demonstrated through three key experiments: decoding visual information from neural data, encoding images into neural representations, and converting between neural modalities. The results highlight the model's ability to accurately capture semantic information across different brain imaging techniques, illustrating its potential in decoding, encoding, and modality conversion tasks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09763",
        "abstract url": "https://arxiv.org/abs/2411.09763",
        "title": "Evaluating the Predictive Capacity of ChatGPT for Academic Peer Review Outcomes Across Multiple Platforms",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "While previous studies have demonstrated that Large Language Models (LLMs) can predict peer review outcomes to some extent, this paper builds on that by introducing two new contexts and employing a more robust method - averaging multiple ChatGPT scores. The findings that averaging 30 ChatGPT predictions, based on reviewer guidelines and using only the submitted titles and abstracts, failed to predict peer review outcomes for F1000Research (Spearman's rho=0.00). However, it produced mostly weak positive correlations with the quality dimensions of SciPost Physics (rho=0.25 for validity, rho=0.25 for originality, rho=0.20 for significance, and rho = 0.08 for clarity) and a moderate positive correlation for papers from the International Conference on Learning Representations (ICLR) (rho=0.38). Including the full text of articles significantly increased the correlation for ICLR (rho=0.46) and slightly improved it for F1000Research (rho=0.09), while it had variable effects on the four quality dimension correlations for SciPost LaTeX files. The use of chain-of-thought system prompts slightly increased the correlation for F1000Research (rho=0.10), marginally reduced it for ICLR (rho=0.37), and further decreased it for SciPost Physics (rho=0.16 for validity, rho=0.18 for originality, rho=0.18 for significance, and rho=0.05 for clarity). Overall, the results suggest that in some contexts, ChatGPT can produce weak pre-publication quality assessments. However, the effectiveness of these assessments and the optimal strategies for employing them vary considerably across different platforms, journals, and conferences. Additionally, the most suitable inputs for ChatGPT appear to differ depending on the platform.",
        "subjects": [
            "cs.DL",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09767",
        "abstract url": "https://arxiv.org/abs/2411.09767",
        "title": "Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "Diagnosis",
                "whole slide",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Inflammation of the umbilical cord can be seen as a result of ascending intrauterine infection or other inflammatory stimuli. Acute fetal inflammatory response (FIR) is characterized by infiltration of the umbilical cord by fetal neutrophils, and can be associated with neonatal sepsis or fetal inflammatory response syndrome. Recent advances in deep learning in digital pathology have demonstrated favorable performance across a wide range of clinical tasks, such as diagnosis and prognosis. In this study we classified FIR from whole slide images (WSI). We digitized 4100 histological slides of umbilical cord stained with hematoxylin and eosin(H&E) and extracted placental diagnoses from the electronic health record. We build models using attention-based whole slide learning models. We compared strategies between features extracted by a model (ConvNeXtXLarge) pretrained on non-medical images (ImageNet), and one pretrained using histopathology images (UNI). We trained multiple iterations of each model and combined them into an ensemble. The predictions from the ensemble of models trained using UNI achieved an overall balanced accuracy of 0.836 on the test dataset. In comparison, the ensembled predictions using ConvNeXtXLarge had a lower balanced accuracy of 0.7209. Heatmaps generated from top accuracy model appropriately highlighted arteritis in cases of FIR 2. In FIR 1, the highest performing model assigned high attention to areas of activated-appearing stroma in Wharton's Jelly. However, other high-performing models assigned attention to umbilical vessels. We developed models for diagnosis of FIR from placental histology images, helping reduce interobserver variability among pathologists. Future work may examine the utility of these models for identifying infants at risk of systemic inflammatory response or early onset neonatal sepsis.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09770",
        "abstract url": "https://arxiv.org/abs/2411.09770",
        "title": "Misbinding Raw Public Keys to Identities in TLS",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The adoption of security protocols such as Transport Layer Security (TLS) has significantly improved the state of traffic encryption and integrity protection on the Internet. Despite rigorous analysis, vulnerabilities continue to emerge, sometimes due to fundamental flaws in the protocol specification. This paper examines the security of TLS when using Raw Public Key (RPK) authentication. This mode has not been as extensively studied as X.509 certificates and Pre-Shared Keys (PSK). We develop a formal model of TLS RPK using applied pi calculus and the ProVerif verification tool, revealing that the RPK mode is susceptible to identity misbinding attacks. Our contributions include formal models of TLS RPK with several mechanisms for binding the endpoint identity to its public key, verification results, practical scenarios demonstrating the misbinding attack, and recommendations for mitigating such vulnerabilities. These findings highlight the need for improved security measures in TLS RPK.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09777",
        "abstract url": "https://arxiv.org/abs/2411.09777",
        "title": "Virtual Array for Dual Function MIMO Radar Communication Systems using OTFS Waveforms",
        "rating": "-1",
        "keywords": [
            [
                "Radar"
            ]
        ],
        "abstract": "A MIMO dual-function radar communication (DFRC) system transmitting orthogonal time frequency space (OTFS) waveforms is considered. A key advantage of MIMO radar is its ability to create a virtual array, achieving higher sensing resolution than the physical receive array. In this paper, we propose a novel approach to construct a virtual array for the system under consideration. The transmit antennas can use the Doppler-delay (DD) domain bins in a shared fashion. A number of Time-Frequency (TF) bins, referred to as private bins, are exclusively assigned to specific transmit antennas. The TF signals received on the private bins are orthogonal and thus can be used to synthesize a virtual array, which, combined with coarse knowledge of radar parameters (i.e., angle, range, and velocity), enables high-resolution estimation of those parameters. The introduction of $N_p$ private bins necessitates a reduction in DD domain symbols, thereby reducing the data rate of each transmit antenna by $N_p-1$. However, even a small number of private bins is sufficient to achieve significant sensing gains with minimal communication rate loss.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09798",
        "abstract url": "https://arxiv.org/abs/2411.09798",
        "title": "Video Denoising in Fluorescence Guided Surgery",
        "rating": "-1",
        "keywords": [
            [
                "surgical",
                "Surgery"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Fluorescence guided surgery (FGS) is a promising surgical technique that gives surgeons a unique view of tissue that is used to guide their practice by delineating tissue types and diseased areas. As new fluorescent contrast agents are developed that have low fluorescent photon yields, it becomes increasingly important to develop computational models to allow FGS systems to maintain good video quality in real time environments. To further complicate this task, FGS has a difficult bias noise term from laser leakage light (LLL) that represents unfiltered excitation light that can be on the order of the fluorescent signal. Most conventional video denoising methods focus on zero mean noise, and non-causal processing, both of which are violated in FGS. Luckily in FGS, often a co-located reference video is also captured which we use to simulate the LLL and assist in the denoising processes. In this work, we propose an accurate noise simulation pipeline that includes LLL and propose three baseline deep learning based algorithms for FGS video denoising.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09806",
        "abstract url": "https://arxiv.org/abs/2411.09806",
        "title": "On the existence of factors intersecting sets of cycles in regular graphs",
        "rating": "-1",
        "keywords": [
            [
                "graphs"
            ]
        ],
        "abstract": "A recent result by Kardo\u0161, M\u00e1\u010dajov\u00e1 and Zerafa [J. Comb. Theory, Ser. B. 160 (2023) 1--14] related to the famous Berge-Fulkerson conjecture implies that given an arbitrary set of odd pairwise edge-disjoint cycles, say $\\mathcal O$, in a bridgeless cubic graph, there exists a $1$-factor intersecting all cycles in $\\mathcal O$ in at least one edge. This remarkable result opens up natural generalizations in the case of an $r$-regular graph $G$ and a $t$-factor $F$, with $r$ and $t$ being positive integers. In this paper, we start the study of this problem by proving necessary and sufficient conditions on $G$, $t$ and $r$ to assure the existence of a suitable $F$ for any possible choice of the set $\\mathcal O$. First of all, we show that $G$ needs to be $2$-connected. Under this additional assumption, we highlight how the ratio $\\frac{t}{r}$ seems to play a crucial role in assuring the existence of a $t$-factor $F$ with the required properties by proving that $\\frac{t}{r} \\geq \\frac{1}{3}$ is a further necessary condition. We suspect that this condition is also sufficient, and we confirm it in the case $\\frac{t}{r}=\\frac{1}{3}$, generalizing the case $t=1$ and $r=3$ proved by Kardo\u0161, M\u00e1\u010dajov\u00e1, Zerafa, and in the case $\\frac{t}{r}=\\frac{1}{2}$ with $t$ even. Finally, we provide further results in the case of cycles of arbitrary length.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "comment": "17 pages"
    },
    {
        "paper id": "2411.09809",
        "abstract url": "https://arxiv.org/abs/2411.09809",
        "title": "Scalable Readability Evaluation for Graph Layouts: 2D Geometric Distributed Algorithms",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "Graphs, consisting of vertices and edges, are vital for representing complex relationships in fields like social networks, finance, and blockchain. Visualizing these graphs helps analysts identify structural patterns, with readability metrics-such as node occlusion and edge crossing-assessing layout clarity. However, calculating these metrics is computationally intensive, making scalability a challenge for large graphs. Without efficient readability metrics, layout generation processes-despite numerous studies focused on accelerating them-face bottleneck, making it challenging to select or produce optimized layouts swiftly. Previous approaches attempted to accelerate this process through machine learning models. Machine learning approaches aimed to predict readability scores from rendered images of graphs. While these models offered some improvement, they struggled with scalability and accuracy, especially for graphs with thousands of nodes. For instance, this approach requires substantial memory to process large images, as it relies on rendered images of the graph; graphs with more than 600 nodes cannot be inputted into the model, and errors can exceed 55% in some readability metrics due to difficulties in generalizing across diverse graph layouts. This study addresses these limitations by introducing scalable algorithms for readability evaluation in distributed environments, utilizing Spark's DataFrame and GraphFrame frameworks to efficiently manage large data volumes across multiple machines. Experimental results show that these distributed algorithms significantly reduce computation time, achieving up to a 17x speedup for node occlusion and a 146x improvement for edge crossing on large datasets. These enhancements make scalable graph readability evaluation practical and efficient, overcoming the limitations of previous machine-learning approaches.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09810",
        "abstract url": "https://arxiv.org/abs/2411.09810",
        "title": "Robustness Assessment of Static Structures for Efficient Object Handling",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "This work establishes a solution to the problem of assessing the robustness of multi-object assemblies to external forces. Our physically-grounded approach handles arbitrary static structures made from rigid objects of any shape and mass distribution without relying on heuristics or approximations. The result is a method that provides a foundation for autonomous robot decision-making when interacting with objects in frictional contact. Our strategy decouples slipping from toppling, enabling independent assessments of these two phenomena, with a shared robustness representation being key to combining the results into an accurate robustness assessment. Our algorithms can be used by motion planners to produce efficient assembly transportation plans, and by object placement planners to select poses that improve the strength of an assembly. Compared to prior work, our approach is more generally applicable than commonly used heuristics and more efficient than dynamics simulations.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Submitted to IEEE Transactions on Robotics. Contains 16 pages, 13 figures, and 3 tables"
    },
    {
        "paper id": "2411.09884",
        "abstract url": "https://arxiv.org/abs/2411.09884",
        "title": "Research on Domain-Specific Chinese Spelling Correction Method Based on Plugin Extension Modules",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This paper proposes a Chinese spelling correction method based on plugin extension modules, aimed at addressing the limitations of existing models in handling domain-specific texts. Traditional Chinese spelling correction models are typically trained on general-domain datasets, resulting in poor performance when encountering specialized terminology in domain-specific texts. To address this issue, we design an extension module that learns the features of domain-specific terminology, thereby enhancing the model's correction capabilities within specific domains. This extension module can provide domain knowledge to the model without compromising its general spelling correction performance, thus improving its accuracy in specialized fields. Experimental results demonstrate that after integrating extension modules for medical, legal, and official document domains, the model's correction performance is significantly improved compared to the baseline model without any extension modules.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09887",
        "abstract url": "https://arxiv.org/abs/2411.09887",
        "title": "Planning by Simulation: Motion Planning with Learning-based Parallel Scenario Prediction for Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving",
                "trajectory",
                "vehicle"
            ]
        ],
        "abstract": "Planning safe trajectories for autonomous vehicles is essential for operational safety but remains extremely challenging due to the complex interactions among traffic participants. Recent autonomous driving frameworks have focused on improving prediction accuracy to explicitly model these interactions. However, some methods overlook the significant influence of the ego vehicle's planning on the possible trajectories of other agents, which can alter prediction accuracy and lead to unsafe planning decisions. In this paper, we propose a novel motion Planning approach by Simulation with learning-based parallel scenario prediction (PS). PS deduces predictions iteratively based on Monte Carlo Tree Search (MCTS), jointly inferring scenarios that cooperate with the ego vehicle's planning set. Our method simulates possible scenes and calculates their costs after the ego vehicle executes potential actions. To balance and prune unreasonable actions and scenarios, we adopt MCTS as the foundation to explore possible future interactions encoded within the prediction network. Moreover, the query-centric trajectory prediction streamlines our scene generation, enabling a sophisticated framework that captures the mutual influence between other agents' predictions and the ego vehicle's planning. We evaluate our framework on the Argoverse 2 dataset, and the results demonstrate that our approach effectively achieves parallel ego vehicle planning.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09893",
        "abstract url": "https://arxiv.org/abs/2411.09893",
        "title": "Memory Proxy Maps for Visual Navigation",
        "rating": "-1",
        "keywords": [
            [
                "Navigation"
            ],
            [
                "graph"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Visual navigation takes inspiration from humans, who navigate in previously unseen environments using vision without detailed environment maps. Inspired by this, we introduce a novel no-RL, no-graph, no-odometry approach to visual navigation using feudal learning to build a three tiered agent. Key to our approach is a memory proxy map (MPM), an intermediate representation of the environment learned in a self-supervised manner by the high-level manager agent that serves as a simplified memory, approximating what the agent has seen. We demonstrate that recording observations in this learned latent space is an effective and efficient memory proxy that can remove the need for graphs and odometry in visual navigation tasks. For the mid-level manager agent, we develop a waypoint network (WayNet) that outputs intermediate subgoals, or waypoints, imitating human waypoint selection during local navigation. For the low-level worker agent, we learn a classifier over a discrete action space that avoids local obstacles and moves the agent towards the WayNet waypoint. The resulting feudal navigation network offers a novel approach with no RL, no graph, no odometry, and no metric map; all while achieving SOTA results on the image goal navigation task.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2402.12498"
    },
    {
        "paper id": "2411.09895",
        "abstract url": "https://arxiv.org/abs/2411.09895",
        "title": "Exploiting Cross-Layer Vulnerabilities: Off-Path Attacks on the TCP/IP Protocol Suite",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "After more than 40 years of development, the fundamental TCP/IP protocol suite, serving as the backbone of the Internet, is widely recognized for having achieved an elevated level of robustness and security. Distinctively, we take a new perspective to investigate the security implications of cross-layer interactions within the TCP/IP protocol suite caused by ICMP error messages. Through a comprehensive analysis of interactions among Wi-Fi, IP, ICMP, UDP, and TCP due to ICMP errors, we uncover several significant vulnerabilities, including information leakage, desynchronization, semantic gaps, and identity spoofing. These vulnerabilities can be exploited by off-path attackers to manipulate network traffic stealthily, affecting over 20% of popular websites and more than 89% of public Wi-Fi networks, thus posing risks to the Internet. By responsibly disclosing these vulnerabilities to affected vendors and proposing effective countermeasures, we enhance the robustness of the TCP/IP protocol suite, receiving acknowledgments from well-known organizations such as the Linux community, the OpenWrt community, the FreeBSD community, Wi-Fi Alliance, Qualcomm, HUAWEI, China Telecom, Alibaba, and H3C.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "9 pages, 11 figures"
    },
    {
        "paper id": "2411.09906",
        "abstract url": "https://arxiv.org/abs/2411.09906",
        "title": "A Survey of Machine Learning-based Physical-Layer Authentication in Wireless Communications",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "To ensure secure and reliable communication in wireless systems, authenticating the identities of numerous nodes is imperative. Traditional cryptography-based authentication methods suffer from issues such as low compatibility, reliability, and high complexity. Physical-Layer Authentication (PLA) is emerging as a promising complement due to its exploitation of unique properties in wireless environments. Recently, Machine Learning (ML)-based PLA has gained attention for its intelligence, adaptability, universality, and scalability compared to non-ML approaches. However, a comprehensive overview of state-of-the-art ML-based PLA and its foundational aspects is lacking. This paper presents a comprehensive survey of characteristics and technologies that can be used in the ML-based PLA. We categorize existing ML-based PLA schemes into two main types: multi-device identification and attack detection schemes. In deep learning-based multi-device identification schemes, Deep Neural Networks are employed to train models, avoiding complex processing and expert feature transformation. Deep learning-based multi-device identification schemes are further subdivided, with schemes based on Convolutional Neural Networks being extensively researched. In ML-based attack detection schemes, receivers utilize intelligent ML techniques to set detection thresholds automatically, eliminating the need for manual calculation or knowledge of channel models. ML-based attack detection schemes are categorized into three sub-types: Supervised Learning, Unsupervised Learning, and Reinforcement Learning. Additionally, we summarize open-source datasets used for PLA, encompassing Radio Frequency fingerprints and channel fingerprints. Finally, this paper outlines future research directions to guide researchers in related fields.",
        "subjects": [
            "cs.CR",
            "eess.SY"
        ],
        "comment": "111 pages, 9 figures"
    },
    {
        "paper id": "2411.09913",
        "abstract url": "https://arxiv.org/abs/2411.09913",
        "title": "A Graph-based Strategic Sensor Deployment Approach for k-coverage in WSN",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "This paper studies a graph-based sensor deployment approach in wireless sensor networks (WSNs). Specifically, in today's world, where sensors are everywhere, detecting various attributes like temperature and movement, their deteriorating lifetime is indeed a very concerning issue. In many scenarios, these sensors are placed in extremely remote areas, where maintenance becomes challenging. As a result, it is not very wise to depend on a single sensor to obtain data from a particular terrain or place. Hence, multiple sensors are deployed in these places, such that no problem arises if one or few of them fail. In this work, this problem of intelligent placement of sensors is modelled from the graph theoretic point of view. We propose a new sensor deployment approach here, which results in lesser sensor density per unit area and less number of sensors as compared to the existing benchmark schemes. Finally, the numerical results also support our claims and provide insights regarding the selection of parameters that enhance the system performance.",
        "subjects": [
            "eess.SY",
            "cs.NI"
        ],
        "comment": "Submitted for a possible publication"
    },
    {
        "paper id": "2411.09914",
        "abstract url": "https://arxiv.org/abs/2411.09914",
        "title": "mmSpyVR: Exploiting mmWave Radar for Penetrating Obstacles to Uncover Privacy Vulnerability of Virtual Reality",
        "rating": "-1",
        "keywords": [
            [
                "Radar"
            ],
            [
                "attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Virtual reality (VR), while enhancing user experiences, introduces significant privacy risks. This paper reveals a novel vulnerability in VR systems that allows attackers to capture VR privacy through obstacles utilizing millimeter-wave (mmWave) signals without physical intrusion and virtual connection with the VR devices. We propose mmSpyVR, a novel attack on VR user's privacy via mmWave radar. The mmSpyVR framework encompasses two main parts: (i) A transfer learning-based feature extraction model to achieve VR feature extraction from mmWave signal. (ii) An attention-based VR privacy spying module to spy VR privacy information from the extracted feature. The mmSpyVR demonstrates the capability to extract critical VR privacy from the mmWave signals that have penetrated through obstacles. We evaluate mmSpyVR through IRB-approved user studies. Across 22 participants engaged in four experimental scenes utilizing VR devices from three different manufacturers, our system achieves an application recognition accuracy of 98.5\\% and keystroke recognition accuracy of 92.6\\%. This newly discovered vulnerability has implications across various domains, such as cybersecurity, privacy protection, and VR technology development. We also engage with VR manufacturer Meta to discuss and explore potential mitigation strategies. Data and code are publicly available for scrutiny and research at https://github.com/luoyumei1-a/mmSpyVR/",
        "subjects": [
            "cs.CR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09935",
        "abstract url": "https://arxiv.org/abs/2411.09935",
        "title": "Whole-Body Impedance Coordinative Control of Wheel-Legged Robot on Uncertain Terrain",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "This article propose a whole-body impedance coordinative control framework for a wheel-legged humanoid robot to achieve adaptability on complex terrains while maintaining robot upper body stability. The framework contains a bi-level control strategy. The outer level is a variable damping impedance controller, which optimizes the damping parameters to ensure the stability of the upper body while holding an object. The inner level employs Whole-Body Control (WBC) optimization that integrates real-time terrain estimation based on wheel-foot position and force data. It generates motor torques while accounting for dynamic constraints, joint limits,friction cones, real-time terrain updates, and a model-free friction compensation strategy. The proposed whole-body coordinative control method has been tested on a recently developed quadruped humanoid robot. The results demonstrate that the proposed algorithm effectively controls the robot, maintaining upper body stability to successfully complete a water-carrying task while adapting to varying terrains.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09942",
        "abstract url": "https://arxiv.org/abs/2411.09942",
        "title": "ALPHA-$\u03b1$ and Bi-ACT Are All You Need: Importance of Position and Force Information/Control for Imitation Learning of Unimanual and Bimanual Robotic Manipulation with Low-Cost System",
        "rating": "-1",
        "keywords": [
            [
                "robot",
                "Robotic Manipulation"
            ]
        ],
        "abstract": "Autonomous manipulation in everyday tasks requires flexible action generation to handle complex, diverse real-world environments, such as objects with varying hardness and softness. Imitation Learning (IL) enables robots to learn complex tasks from expert demonstrations. However, a lot of existing methods rely on position/unilateral control, leaving challenges in tasks that require force information/control, like carefully grasping fragile or varying-hardness objects. As the need for diverse controls increases, there are demand for low-cost bimanual robots that consider various motor inputs. To address these challenges, we introduce Bilateral Control-Based Imitation Learning via Action Chunking with Transformers(Bi-ACT) and\"A\" \"L\"ow-cost \"P\"hysical \"Ha\"rdware Considering Diverse Motor Control Modes for Research in Everyday Bimanual Robotic Manipulation (ALPHA-$\u03b1$). Bi-ACT leverages bilateral control to utilize both position and force information, enhancing the robot's adaptability to object characteristics such as hardness, shape, and weight. The concept of ALPHA-$\u03b1$ is affordability, ease of use, repairability, ease of assembly, and diverse control modes (position, velocity, torque), allowing researchers/developers to freely build control systems using ALPHA-$\u03b1$. In our experiments, we conducted a detailed analysis of Bi-ACT in unimanual manipulation tasks, confirming its superior performance and adaptability compared to Bi-ACT without force control. Based on these results, we applied Bi-ACT to bimanual manipulation tasks. Experimental results demonstrated high success rates in coordinated bimanual operations across multiple tasks. The effectiveness of the Bi-ACT and ALPHA-$\u03b1$ can be seen through comprehensive real-world experiments. Video available at: https://mertcookimg.github.io/alpha-biact/",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10489",
        "abstract url": "https://arxiv.org/abs/2411.10489",
        "title": "Biometrics in Extended Reality: A Review",
        "rating": "-1",
        "keywords": [
            [
                "Biometrics"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In the domain of Extended Reality (XR), particularly Virtual Reality (VR), extensive research has been devoted to harnessing this transformative technology in various real-world applications. However, a critical challenge that must be addressed before unleashing the full potential of XR in practical scenarios is to ensure robust security and safeguard user privacy. This paper presents a systematic survey of the utility of biometric characteristics applied in the XR environment. To this end, we present a comprehensive overview of the different types of biometric modalities used for authentication and representation of users in a virtual environment. We discuss different biometric vulnerability gateways in general XR systems for the first time in the literature along with taxonomy. A comprehensive discussion on generating and authenticating biometric-based photorealistic avatars in XR environments is presented with a stringent taxonomy. We also discuss the availability of different datasets that are widely employed in evaluating biometric authentication in XR environments together with performance evaluation metrics. Finally, we discuss the open challenges and potential future work that need to be addressed in the field of biometrics in XR.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.15170",
        "abstract url": "https://arxiv.org/abs/2411.15170",
        "title": "Improving the Test-retest Reliability of Quantitative Susceptibility Mapping",
        "rating": "-1",
        "keywords": [
            [
                "disease"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Motivation - The test-retest reliability of quantitative susceptibility mapping (QSM) is affected by parameters of the acquisition protocol such as the angulation of acquisition plane with respect to the B0 field direction and spatial resolution. Goal - We aim to reduce the protocol-dependent biases/errors that might overshadow subtle changes of the susceptibility values due to pathology in the brain. Approach - The magnitude and phase images used for QSM are registered according to a standard reference protocol in the k-space through nonuniform fast Fourier transform (NUFFT). Results - With the help of our proposed approach, the test-retest reliability of scans acquired from different protocols is notably improved. Impact - The improved test-retest reliability of QSM makes it easier to detect subtle susceptibility changes in the early stages of neurodegeneration such as Alzheimer's disease and Parkinson's disease.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09210",
        "abstract url": "https://arxiv.org/abs/2411.09210",
        "title": "Classical Verification of Quantum Learning Advantages with Noises",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Classical verification of quantum learning allows classical clients to reliably leverage quantum computing advantages by interacting with untrusted quantum servers. Yet, current quantum devices available in practice suffers from a variety of noises and whether existed classical verification protocols carry over to noisy scenarios remains unclear. Here, we propose an efficient classical error rectification algorithm to reconstruct the noise-free results given by the quantum Fourier sampling circuit with practical constant-level noises. In particular, we prove that the error rectification algorithm can restore the heavy Fourier coefficients by using a small number of noisy samples that scales logarithmically with the problem size. We apply this algorithm to the agnostic parity learning task with uniform input marginal and prove that this task can be accomplished in an efficient way on noisy quantum devices with our algorithm. In addition, we prove that a classical client with access to the random example oracle can verify the agnostic parity learning results from the noisy quantum prover in an efficient way, under the condition that the Fourier coefficients are sparse. Our results demonstrate the feasibility of classical verification of quantum learning advantages with noises, which provide a valuable guide for both theoretical studies and practical applications with current noisy intermediate scale quantum devices.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "comment": "13 pages 1 figure"
    },
    {
        "paper id": "2411.09211",
        "abstract url": "https://arxiv.org/abs/2411.09211",
        "title": "Dynamic Neural Communication: Convergence of Computer Vision and Brain-Computer Interface",
        "rating": "-1.5",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Interpreting human neural signals to decode static speech intentions such as text or images and dynamic speech intentions such as audio or video is showing great potential as an innovative communication tool. Human communication accompanies various features, such as articulatory movements, facial expressions, and internal speech, all of which are reflected in neural signals. However, most studies only generate short or fragmented outputs, while providing informative communication by leveraging various features from neural signals remains challenging. In this study, we introduce a dynamic neural communication method that leverages current computer vision and brain-computer interface technologies. Our approach captures the user's intentions from neural signals and decodes visemes in short time steps to produce dynamic visual outputs. The results demonstrate the potential to rapidly capture and reconstruct lip movements during natural speech attempts from human neural signals, enabling dynamic neural communication through the convergence of computer vision and brain--computer interface.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "4 pages, 2 figures, 1 table, Name of Conference: International Conference on Brain-Computer Interface"
    },
    {
        "paper id": "2411.09269",
        "abstract url": "https://arxiv.org/abs/2411.09269",
        "title": "Harnessing multiple LLMs for Information Retrieval: A case study on Deep Learning methodologies in Biodiversity publications",
        "rating": "-1.5",
        "keywords": [
            [
                "Biodiversity"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Deep Learning (DL) techniques are increasingly applied in scientific studies across various domains to address complex research questions. However, the methodological details of these DL models are often hidden in the unstructured text. As a result, critical information about how these models are designed, trained, and evaluated is challenging to access and comprehend. To address this issue, in this work, we use five different open-source Large Language Models (LLMs): Llama-3 70B, Llama-3.1 70B, Mixtral-8x22B-Instruct-v0.1, Mixtral 8x7B, and Gemma 2 9B in combination with Retrieval-Augmented Generation (RAG) approach to extract and process DL methodological details from scientific publications automatically. We built a voting classifier from the outputs of five LLMs to accurately report DL methodological information. We tested our approach using biodiversity publications, building upon our previous research. To validate our pipeline, we employed two datasets of DL-related biodiversity publications: a curated set of 100 publications from our prior work and a set of 364 publications from the Ecological Informatics journal. Our results demonstrate that the multi-LLM, RAG-assisted pipeline enhances the retrieval of DL methodological information, achieving an accuracy of 69.5% (417 out of 600 comparisons) based solely on textual content from publications. This performance was assessed against human annotators who had access to code, figures, tables, and other supplementary information. Although demonstrated in biodiversity, our methodology is not limited to this field; it can be applied across other scientific domains where detailed methodological reporting is essential for advancing knowledge and ensuring reproducibility. This study presents a scalable and reliable approach for automating information extraction, facilitating better reproducibility and knowledge transfer across studies.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09286",
        "abstract url": "https://arxiv.org/abs/2411.09286",
        "title": "A Centralized-Distributed Transfer Model for Cross-Domain Recommendation Based on Multi-Source Heterogeneous Transfer Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Recommendation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Cross-domain recommendation (CDR) methods are proposed to tackle the sparsity problem in click through rate (CTR) estimation. Existing CDR methods directly transfer knowledge from the source domains to the target domain and ignore the heterogeneities among domains, including feature dimensional heterogeneity and latent space heterogeneity, which may lead to negative transfer. Besides, most of the existing methods are based on single-source transfer, which cannot simultaneously utilize knowledge from multiple source domains to further improve the model performance in the target domain. In this paper, we propose a centralized-distributed transfer model (CDTM) for CDR based on multi-source heterogeneous transfer learning. To address the issue of feature dimension heterogeneity, we build a dual embedding structure: domain specific embedding (DSE) and global shared embedding (GSE) to model the feature representation in the single domain and the commonalities in the global space,separately. To solve the latent space heterogeneity, the transfer matrix and attention mechanism are used to map and combine DSE and GSE adaptively. Extensive offline and online experiments demonstrate the effectiveness of our model.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Published in: 2022 IEEE International Conference on Data Mining (ICDM) (The authors were affiliated Hangzhou NetEase Cloud Music Technology Co., Ltd.)"
    },
    {
        "paper id": "2411.09373",
        "abstract url": "https://arxiv.org/abs/2411.09373",
        "title": "Are nuclear masks all you need for improved out-of-domain generalisation? A closer look at cancer classification in histopathology",
        "rating": "-1.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cancer"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Domain generalisation in computational histopathology is challenging because the images are substantially affected by differences among hospitals due to factors like fixation and staining of tissue and imaging equipment. We hypothesise that focusing on nuclei can improve the out-of-domain (OOD) generalisation in cancer detection. We propose a simple approach to improve OOD generalisation for cancer detection by focusing on nuclear morphology and organisation, as these are domain-invariant features critical in cancer detection. Our approach integrates original images with nuclear segmentation masks during training, encouraging the model to prioritise nuclei and their spatial arrangement. Going beyond mere data augmentation, we introduce a regularisation technique that aligns the representations of masks and original images. We show, using multiple datasets, that our method improves OOD generalisation and also leads to increased robustness to image corruptions and adversarial attacks. The source code is available at https://github.com/undercutspiky/SFL/",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Poster at NeurIPS 2024"
    },
    {
        "paper id": "2411.09459",
        "abstract url": "https://arxiv.org/abs/2411.09459",
        "title": "Caravan MultiMet: Extending Caravan with Multiple Weather Nowcasts and Forecasts",
        "rating": "-1.5",
        "keywords": [
            [
                "forecast"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The Caravan large-sample hydrology dataset (Kratzert et al., 2023) was created to standardize and harmonize streamflow data from various regional datasets, combined with globally available meteorological forcing and catchment attributes. This community-driven project also allows researchers to conveniently extend the dataset for additional basins, as done 6 times to date (see https://github.com/kratzert/Caravan/discussions/10). We present a novel extension to Caravan, focusing on enriching the meteorological forcing data. Our extension adds three precipitation nowcast products (CPC, IMERG v07 Early, and CHIRPS) and three weather forecast products (ECMWF IFS HRES, GraphCast, and CHIRPS-GEFS) to the existing ERA5-Land reanalysis data. The inclusion of diverse data sources, particularly weather forecasts, enables more robust evaluation and benchmarking of hydrological models, especially for real-time forecasting scenarios. To the best of our knowledge, this extension makes Caravan the first large-sample hydrology dataset to incorporate weather forecast data, significantly enhancing its capabilities and fostering advancements in hydrological research, benchmarking, and real-time hydrologic forecasting. The data is publicly available under a CC-BY-4.0 license on Zenodo in two parts (https://zenodo.org/records/14161235, https://zenodo.org/records/14161281) and on Google Cloud Platform (GCP) - see more under the Data Availability chapter.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09486",
        "abstract url": "https://arxiv.org/abs/2411.09486",
        "title": "An Approach to Twinning and Mining Collaborative Network of Construction Projects",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Understanding complex collaboration processes is essential for the success of construction projects. However, there is still a lack of efficient methods for timely collection and analysis of collaborative networks. Therefore, an integrated framework consisting three parts, namely, system updating for data collection, data preprocessing, and social network analysis, is proposed for the twinning and mining collaborative network of a construction project. First, a system updating strategy for automatic data collection is introduced. Centrality measures are then utilized to identify key players, including hubs and brokers. Meanwhile, information sharing frequency (ISF) and association rule mining are introduced to discover collaborative patterns, that is, frequently collaborating users (FCUs) and associations between information flows and task levels. Finally, the proposed framework is validated and demonstrated in a large-scale project. The results show that key players, FCUs, and associations between information flows and task levels were successfully discovered, providing a deep understanding of collaboration and communication for decision-making processes. This research contributes to the body of knowledge by: 1) introducing ISF and Apriori-based association mining algorithm to identify FCUs and information flow patterns in collaboration; 2) establishing a new data-driven framework to map and analyze fine-grained collaborative networks automatically. It is also shown that people tend to form small groups to handle certain levels or types of tasks more efficiently. Other researchers and industrial practitioners may use this work as a foundation to further improve the efficiency of collaboration and communication.",
        "subjects": [
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09549",
        "abstract url": "https://arxiv.org/abs/2411.09549",
        "title": "Quantum computing inspired paintings: reinterpreting classical masterpieces",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "We aim to apply a quantum computing technique to compose artworks. The main idea is to revisit three paintings of different styles and historical periods: ''Narciso'', painted circa 1597-1599 by Michelangelo Merisi (Caravaggio), ''Les fils de l'homme'', painted in 1964 by Rene Magritte and ''192 Farben'', painted in 1966 by Gerard Richter. We utilize the output of a quantum computation to change the composition in the paintings, leading to a paintings series titled ''Quantum Transformation I, II, III''. In particular, the figures are discretized into square lattices and the order of the pieces is changed according to the result of the quantum simulation. We consider an Ising Hamiltonian as the observable in the quantum computation and its time evolution as the final outcome. From a classical subject to abstract forms, we seek to combine classical and quantum aesthetics through these three art pieces. Besides experimenting with hardware runs and circuit noise, our goal is to reproduce these works as physical oil paintings on wooden panels. With this process, we complete a full circle between classical and quantum techniques and contribute to rethinking Art practice in the era of quantum computing technologies.",
        "subjects": [
            "quant-ph",
            "cs.CY"
        ],
        "comment": "10 pages, 8 figures"
    },
    {
        "paper id": "2411.09591",
        "abstract url": "https://arxiv.org/abs/2411.09591",
        "title": "Expert Study on Interpretable Machine Learning Models with Missing Data",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Inherently interpretable machine learning (IML) models provide valuable insights for clinical decision-making but face challenges when features have missing values. Classical solutions like imputation or excluding incomplete records are often unsuitable in applications where values are missing at test time. In this work, we conducted a survey with 71 clinicians from 29 trauma centers across France, including 20 complete responses to study the interaction between medical professionals and IML applied to data with missing values. This provided valuable insights into how missing data is interpreted in clinical machine learning. We used the prediction of hemorrhagic shock as a concrete example to gauge the willingness and readiness of the participants to adopt IML models from three classes of methods. Our findings show that, while clinicians value interpretability and are familiar with common IML methods, classical imputation techniques often misalign with their intuition, and that models that natively handle missing values are preferred. These results emphasize the need to integrate clinical intuition into future IML models for better human-computer interaction.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Findings paper presented at Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024, Vancouver, Canada, 13 pages"
    },
    {
        "paper id": "2411.09648",
        "abstract url": "https://arxiv.org/abs/2411.09648",
        "title": "Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces Med-Bot, an AI-powered chatbot designed to provide users with accurate and reliable medical information. Utilizing advanced libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq, Med-Bot is built to handle the complexities of natural language understanding in a healthcare context. The integration of llamaassisted data processing and AutoGPT-Q provides enhanced performance in processing and responding to queries based on PDFs of medical literature, ensuring that users receive precise and trustworthy information. This research details the methodologies employed in developing Med-Bot and evaluates its effectiveness in disseminating healthcare information.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "comment": "3 figures, 5 pages Keywords-LLM, AI-powered healthcare, Medical chatbot, Context-based interaction, Llama-assisted data processing, AutoGPT-Q, PyTorch, TensorFlow, Reliable medical information, Machine learning in healthcare, Conversational AI"
    },
    {
        "paper id": "2411.09678",
        "abstract url": "https://arxiv.org/abs/2411.09678",
        "title": "NeuralDEM -- Real-time Simulation of Industrial Particulate Flows",
        "rating": "-1.5",
        "keywords": [
            [
                "Industrial",
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Advancements in computing power have made it possible to numerically simulate large-scale fluid-mechanical and/or particulate systems, many of which are integral to core industrial processes. Among the different numerical methods available, the discrete element method (DEM) provides one of the most accurate representations of a wide range of physical systems involving granular and discontinuous materials. Consequently, DEM has become a widely accepted approach for tackling engineering problems connected to granular flows and powder mechanics. Additionally, DEM can be integrated with grid-based computational fluid dynamics (CFD) methods, enabling the simulation of chemical processes taking place, e.g., in fluidized beds. However, DEM is computationally intensive because of the intrinsic multiscale nature of particulate systems, restricting simulation duration or number of particles. Towards this end, NeuralDEM presents an end-to-end approach to replace slow numerical DEM routines with fast, adaptable deep learning surrogates. NeuralDEM is capable of picturing long-term transport processes across different regimes using macroscopic observables without any reference to microscopic model parameters. First, NeuralDEM treats the Lagrangian discretization of DEM as an underlying continuous field, while simultaneously modeling macroscopic behavior directly as additional auxiliary fields. Second, NeuralDEM introduces multi-branch neural operators scalable to real-time modeling of industrially-sized scenarios - from slow and pseudo-steady to fast and transient. Such scenarios have previously posed insurmountable challenges for deep learning models. Notably, NeuralDEM faithfully models coupled CFD-DEM fluidized bed reactors of 160k CFD cells and 500k DEM particles for trajectories of 28s. NeuralDEM will open many new doors to advanced engineering and much faster process cycles.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Project page: https://nx-ai.github.io/NeuralDEM/"
    },
    {
        "paper id": "2411.09718",
        "abstract url": "https://arxiv.org/abs/2411.09718",
        "title": "NFRs in Medical Imaging",
        "rating": "-1.5",
        "keywords": [
            [
                "Medical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The diagnostic imaging departments are under great pressure due to a growing workload. The number of required scans is growing and there is a shortage of qualified labor. AI solutions for medical imaging applications have shown great potential. However, very few diagnostic imaging models have been approved for hospital use and even fewer are being implemented at the hospitals. The most common reason why software projects fail is poor requirement engineering, especially non-functional requirements (NFRs) can be detrimental to a project. Research shows that machine learning professionals struggle to work with NFRs and that there is a need to adapt NFR frameworks to machine learning, AI-based, software. This study uses qualitative methods to interact with key stakeholders to identify which types of NFRs are important for medical imaging applications. The study was done on a single Danish hospital and found that NFRs of type Efficiency, Accuracy, Interoperability, Reliability, Usability, Adaptability, and Fairness were important to the stakeholders. Especially Efficiency since the diagnostic imaging department is trying to spend as little time as possible on each scan.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09720",
        "abstract url": "https://arxiv.org/abs/2411.09720",
        "title": "Early-Scheduled Handover Preparation in 5G NR Millimeter-Wave Systems",
        "rating": "-1.5",
        "keywords": [
            [
                "5G"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The handover (HO) procedure is one of the most critical functions in a cellular network driven by measurements of the user channel of the serving and neighboring cells. The success rate of the entire HO procedure is significantly affected by the preparation stage. As massive Multiple-Input Multiple-Output (MIMO) systems with large antenna arrays allow resolving finer details of channel behavior, we investigate how machine learning can be applied to time series data of beam measurements in the Fifth Generation (5G) New Radio (NR) system to improve the HO procedure. This paper introduces the Early-Scheduled Handover Preparation scheme designed to enhance the robustness and efficiency of the HO procedure, particularly in scenarios involving high mobility and dense small cell deployments. Early-Scheduled Handover Preparation focuses on optimizing the timing of the HO preparation phase by leveraging machine learning techniques to predict the earliest possible trigger points for HO events. We identify a new early trigger for HO preparation and demonstrate how it can beneficially reduce the required time for HO execution reducing channel quality degradation. These insights enable a new HO preparation scheme that offers a novel, user-aware, and proactive HO decision making in MIMO scenarios incorporating mobility.",
        "subjects": [
            "cs.LG",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09722",
        "abstract url": "https://arxiv.org/abs/2411.09722",
        "title": "Iterative Batch Reinforcement Learning via Safe Diversified Model-based Policy Search",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Batch reinforcement learning enables policy learning without direct interaction with the environment during training, relying exclusively on previously collected sets of interactions. This approach is, therefore, well-suited for high-risk and cost-intensive applications, such as industrial control. Learned policies are commonly restricted to act in a similar fashion as observed in the batch. In a real-world scenario, learned policies are deployed in the industrial system, inevitably leading to the collection of new data that can subsequently be added to the existing recording. The process of learning and deployment can thus take place multiple times throughout the lifespan of a system. In this work, we propose to exploit this iterative nature of applying offline reinforcement learning to guide learned policies towards efficient and informative data collection during deployment, leading to continuous improvement of learned policies while remaining within the support of collected data. We present an algorithmic methodology for iterative batch reinforcement learning based on ensemble-based model-based policy search, augmented with safety and, importantly, a diversity criterion.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "Workshop on Safe and Robust Robot Learning for Operation in the Real World (SAFE-ROL) at CoRL 2024"
    },
    {
        "paper id": "2411.09726",
        "abstract url": "https://arxiv.org/abs/2411.09726",
        "title": "Spatio-Temporal Jump Model for Urban Thermal Comfort Monitoring",
        "rating": "-1.5",
        "keywords": [
            [
                "Thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Thermal comfort is essential for well-being in urban spaces, especially as cities face increasing heat from urbanization and climate change. Existing thermal comfort models usually overlook temporal dynamics alongside spatial dependencies. We address this problem by introducing a spatio-temporal jump model that clusters data with persistence across both spatial and temporal dimensions. This framework enhances interpretability, minimizes abrupt state changes, and easily handles missing data. We validate our approach through extensive simulations, demonstrating its accuracy in recovering the true underlying partition. When applied to hourly environmental data gathered from a set of weather stations located across the city of Singapore, our proposal identifies meaningful thermal comfort regimes, demonstrating its effectiveness in dynamic urban settings and suitability for real-world monitoring. The comparison of these regimes with feedback on thermal preference indicates the potential of an unsupervised approach to avoid extensive surveys.",
        "subjects": [
            "stat.AP",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09784",
        "abstract url": "https://arxiv.org/abs/2411.09784",
        "title": "Reinforced Disentanglers on Random Unitary Circuits",
        "rating": "-1.5",
        "keywords": [
            [
                "quantum"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We search for efficient disentanglers on random Clifford circuits of two-qubit gates arranged in a brick-wall pattern, using the proximal policy optimization (PPO) algorithm \\cite{schulman2017proximalpolicyoptimizationalgorithms}. Disentanglers are defined as a set of projective measurements inserted between consecutive entangling layers. An efficient disentangler is a set of projective measurements that minimize the averaged von Neumann entropy of the final state with the least number of total projections possible. The problem is naturally amenable to reinforcement learning techniques by taking the binary matrix representing the projective measurements along the circuit as our state, and actions as bit flipping operations on this binary matrix that add or delete measurements at specified locations. We give rewards to our agent dependent on the averaged von Neumann entropy of the final state and the configuration of measurements, such that the agent learns the optimal policy that will take him from the initial state of no measurements to the optimal measurement state that minimizes the entanglement entropy. Our results indicate that the number of measurements required to disentangle a random quantum circuit is drastically less than the numerical results of measurement-induced phase transition papers. Additionally, the reinforcement learning procedure enables us to characterize the pattern of optimal disentanglers, which is not possible in the works of measurement-induced phase transitions.",
        "subjects": [
            "quant-ph",
            "cond-mat.dis-nn",
            "cond-mat.stat-mech",
            "cs.LG"
        ],
        "comment": "9 pages, 7 figures, 1 table. Submitted to QIP 2025"
    },
    {
        "paper id": "2411.09807",
        "abstract url": "https://arxiv.org/abs/2411.09807",
        "title": "Evaluating Loss Landscapes from a Topology Perspective",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Characterizing the loss of a neural network with respect to model parameters, i.e., the loss landscape, can provide valuable insights into properties of that model. Various methods for visualizing loss landscapes have been proposed, but less emphasis has been placed on quantifying and extracting actionable and reproducible insights from these complex representations. Inspired by powerful tools from topological data analysis (TDA) for summarizing the structure of high-dimensional data, here we characterize the underlying shape (or topology) of loss landscapes, quantifying the topology to reveal new insights about neural networks. To relate our findings to the machine learning (ML) literature, we compute simple performance metrics (e.g., accuracy, error), and we characterize the local structure of loss landscapes using Hessian-based metrics (e.g., largest eigenvalue, trace, eigenvalue spectral density). Following this approach, we study established models from image pattern recognition (e.g., ResNets) and scientific ML (e.g., physics-informed neural networks), and we show how quantifying the shape of loss landscapes can provide new insights into model performance and learning dynamics.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09844",
        "abstract url": "https://arxiv.org/abs/2411.09844",
        "title": "Deep Autoencoders for Unsupervised Anomaly Detection in Wildfire Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "SVM"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Wildfires pose a significantly increasing hazard to global ecosystems due to the climate crisis. Due to its complex nature, there is an urgent need for innovative approaches to wildfire prediction, such as machine learning. This research took a unique approach, differentiating from classical supervised learning, and addressed the gap in unsupervised wildfire prediction using autoencoders and clustering techniques for anomaly detection. Historical weather and normalised difference vegetation index datasets of Australia for 2005 - 2021 were utilised. Two main unsupervised approaches were analysed. The first used a deep autoencoder to obtain latent features, which were then fed into clustering models, isolation forest, local outlier factor and one-class SVM for anomaly detection. The second approach used a deep autoencoder to reconstruct the input data and use reconstruction errors to identify anomalies. Long Short-Term Memory (LSTM) autoencoders and fully connected (FC) autoencoders were employed in this part, both in an unsupervised way learning only from nominal data. The FC autoencoder outperformed its counterparts, achieving an accuracy of 0.71, an F1-score of 0.74, and an MCC of 0.42. These findings highlight the practicality of this method, as it effectively predicts wildfires in the absence of ground truth, utilising an unsupervised learning technique.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "33 pages, 18 figure, 16 tables. To appear in Earth and Space Science"
    },
    {
        "paper id": "2411.09849",
        "abstract url": "https://arxiv.org/abs/2411.09849",
        "title": "Self-Supervised Radio Pre-training: Toward Foundational Models for Spectrogram Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Foundational deep learning (DL) models are general models, trained on large, diverse, and unlabelled datasets, typically using self-supervised learning techniques have led to significant advancements especially in natural language processing. These pretrained models can be fine-tuned for related downstream tasks, offering faster development and reduced training costs, while often achieving improved performance. In this work, we introduce Masked Spectrogram Modeling, a novel self-supervised learning approach for pretraining foundational DL models on radio signals. Adopting a Convolutional LSTM architecture for efficient spatio-temporal processing, we pretrain the model with an unlabelled radio dataset collected from over-the-air measurements. Subsequently, the pretrained model is fine-tuned for two downstream tasks: spectrum forecasting and segmentation. Experimental results demonstrate that our methodology achieves competitive performance in both forecasting accuracy and segmentation, validating its effectiveness for developing foundational radio models.",
        "subjects": [
            "eess.SP",
            "cs.AI",
            "cs.LG",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09851",
        "abstract url": "https://arxiv.org/abs/2411.09851",
        "title": "SymbolFit: Automatic Parametric Modeling with Symbolic Regression",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We introduce SymbolFit, a framework that automates parametric modeling by using symbolic regression to perform a machine-search for functions that fit the data, while simultaneously providing uncertainty estimates in a single run. Traditionally, constructing a parametric model to accurately describe binned data has been a manual and iterative process, requiring an adequate functional form to be determined before the fit can be performed. The main challenge arises when the appropriate functional forms cannot be derived from first principles, especially when there is no underlying true closed-form function for the distribution. In this work, we address this problem by utilizing symbolic regression, a machine learning technique that explores a vast space of candidate functions without needing a predefined functional form, treating the functional form itself as a trainable parameter. Our approach is demonstrated in data analysis applications in high-energy physics experiments at the CERN Large Hadron Collider (LHC). We demonstrate its effectiveness and efficiency using five real proton-proton collision datasets from new physics searches at the LHC, namely the background modeling in resonance searches for high-mass dijet, trijet, paired-dijet, diphoton, and dimuon events. We also validate the framework using several toy datasets with one and more variables.",
        "subjects": [
            "hep-ex",
            "cs.LG",
            "physics.data-an"
        ],
        "comment": "53 pages, 35 figures. Under review"
    },
    {
        "paper id": "2411.09852",
        "abstract url": "https://arxiv.org/abs/2411.09852",
        "title": "InterFormer: Towards Effective Heterogeneous Interaction Learning for Click-Through Rate Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Click-through rate (CTR) prediction, which predicts the probability of a user clicking an ad, is a fundamental task in recommender systems. The emergence of heterogeneous information, such as user profile and behavior sequences, depicts user interests from different aspects. A mutually beneficial integration of heterogeneous information is the cornerstone towards the success of CTR prediction. However, most of the existing methods suffer from two fundamental limitations, including (1) insufficient inter-mode interaction due to the unidirectional information flow between modes, and (2) aggressive information aggregation caused by early summarization, resulting in excessive information loss. To address the above limitations, we propose a novel module named InterFormer to learn heterogeneous information interaction in an interleaving style. To achieve better interaction learning, InterFormer enables bidirectional information flow for mutually beneficial learning across different modes. To avoid aggressive information aggregation, we retain complete information in each data mode and use a separate bridging arch for effective information selection and summarization. Our proposed InterFormer achieves state-of-the-art performance on three public datasets and a large-scale industrial dataset.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "10 pages, 6 figures"
    },
    {
        "paper id": "2411.09874",
        "abstract url": "https://arxiv.org/abs/2411.09874",
        "title": "A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation",
        "rating": "-1.5",
        "keywords": [
            [
                "diagnosis",
                "EEG"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Electroencephalography (EEG) plays a crucial role in the diagnosis of various neurological disorders. However, small hospitals and clinics often lack advanced EEG signal analysis systems and are prone to misinterpretation in manual EEG reading. This study proposes an innovative hybrid artificial intelligence (AI) system for automatic interpretation of EEG background activity and report generation. The system combines deep learning models for posterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and expert-designed algorithms for abnormality detection. For PDR prediction, 1530 labeled EEGs were used, and the best ensemble model achieved a mean absolute error (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of 91.8% within a 0.6Hz error, and an accuracy of 99% within a 1.2Hz error. The AI system significantly outperformed neurologists in detecting generalized background slowing (p = 0.02; F1: AI 0.93, neurologists 0.82) and demonstrated improved focal abnormality detection, although not statistically significant (p = 0.79; F1: AI 0.71, neurologists 0.55). Validation on both an internal dataset and the Temple University Abnormal EEG Corpus showed consistent performance (F1: 0.884 and 0.835, respectively; p = 0.66), demonstrating generalizability. The use of large language models (LLMs) for report generation demonstrated 100% accuracy, verified by three other independent LLMs. This hybrid AI system provides an easily scalable and accurate solution for EEG interpretation in resource-limited settings, assisting neurologists in improving diagnostic accuracy and reducing misdiagnosis rates.",
        "subjects": [
            "cs.AI",
            "eess.SP"
        ],
        "comment": "Example code available at https://github.com/tcs211/AI_EEEG_REPORT"
    },
    {
        "paper id": "2411.09928",
        "abstract url": "https://arxiv.org/abs/2411.09928",
        "title": "Is Precise Recovery Necessary? A Task-Oriented Imputation Approach for Time Series Forecasting on Variable Subset",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Variable Subset Forecasting (VSF) refers to a unique scenario in multivariate time series forecasting, where available variables in the inference phase are only a subset of the variables in the training phase. VSF presents significant challenges as the entire time series may be missing, and neither inter- nor intra-variable correlations persist. Such conditions impede the effectiveness of traditional imputation methods, primarily focusing on filling in individual missing data points. Inspired by the principle of feature engineering that not all variables contribute positively to forecasting, we propose Task-Oriented Imputation for VSF (TOI-VSF), a novel framework shifts the focus from accurate data recovery to directly support the downstream forecasting task. TOI-VSF incorporates a self-supervised imputation module, agnostic to the forecasting model, designed to fill in missing variables while preserving the vital characteristics and temporal patterns of time series data. Additionally, we implement a joint learning strategy for imputation and forecasting, ensuring that the imputation process is directly aligned with and beneficial to the forecasting objective. Extensive experiments across four datasets demonstrate the superiority of TOI-VSF, outperforming baseline methods by $15\\%$ on average.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09204",
        "abstract url": "https://arxiv.org/abs/2411.09204",
        "title": "RibCageImp: A Deep Learning Framework for 3D Ribcage Implant Generation",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "CT"
            ],
            [
                "cs.AI",
                "eess.IV"
            ]
        ],
        "abstract": "The recovery of damaged or resected ribcage structures requires precise, custom-designed implants to restore the integrity and functionality of the thoracic cavity. Traditional implant design methods rely mainly on manual processes, making them time-consuming and susceptible to variability. In this work, we explore the feasibility of automated ribcage implant generation using deep learning. We present a framework based on 3D U-Net architecture that processes CT scans to generate patient-specific implant designs. To the best of our knowledge, this is the first investigation into automated thoracic implant generation using deep learning approaches. Our preliminary results, while moderate, highlight both the potential and the significant challenges in this complex domain. These findings establish a foundation for future research in automated ribcage reconstruction and identify key technical challenges that need to be addressed for practical implementation.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "physics.med-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09231",
        "abstract url": "https://arxiv.org/abs/2411.09231",
        "title": "AEAKA: An Adaptive and Efficient Authentication and Key Agreement Scheme for IoT in Cloud-Edge-Device Collaborative Environments",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "To meet the diverse needs of users, the rapid advancement of cloud-edge-device collaboration has become a standard practice. However, this complex environment, particularly in untrusted (non-collaborative) scenarios, presents numerous security challenges. Authentication acts as the first line of defense and is fundamental to addressing these issues. Although many authentication and key agreement schemes exist, they often face limitations, such as being tailored to overly specific scenarios where devices authenticate solely with either the edge or the cloud, or being unsuitable for resource-constrained devices. To address these challenges, we propose an adaptive and efficient authentication and key agreement scheme (AEAKA) for Cloud-Edge-Device IoT environments. This scheme is highly adaptive and scalable, capable of automatically and dynamically initiating different authentication methods based on device requirements. Additionally, it employs an edge-assisted authentication approach to reduce the load on third-party trust authorities. Furthermore, we introduce a hash-based algorithm for the authentication protocol, ensuring a lightweight method suitable for a wide range of resource-constrained devices while maintaining security. AEAKA ensures that entities use associated authentication credentials, enhancing the privacy of the authentication process. Security proofs and performance analyses demonstrate that AEAKA outperforms other methods in terms of security and authentication efficiency.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "17 pages,14 figures,submitted to Transactions on Dependable and Secure Computing in 30-May-2024"
    },
    {
        "paper id": "2411.09237",
        "abstract url": "https://arxiv.org/abs/2411.09237",
        "title": "Unsupervised Physics-Informed Neural Network-based Nonlinear Observer design for autonomous systems using contraction analysis",
        "rating": "-2",
        "keywords": [
            [
                "Physics"
            ]
        ],
        "abstract": "Contraction analysis offers, through elegant mathematical developments, a unified way of designing observers for a general class of nonlinear systems, where the observer correction term is obtained by solving an infinite dimensional inequality that guarantees global exponential convergence. However, solving the matrix partial differential inequality involved in contraction analysis design is both analytically and numerically challenging and represents a long-lasting challenge that prevented its wide use. Therefore, the present paper proposes a novel approach that relies on an unsupervised Physics Informed Neural Network (PINN) to design the observer's correction term by enforcing the partial differential inequality in the loss function. The performance of the proposed PINN-based nonlinear observer is assessed in numerical simulation as well as its robustness to measurement noise and neural network approximation error.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09241",
        "abstract url": "https://arxiv.org/abs/2411.09241",
        "title": "BlueME: Robust Underwater Robot-to-Robot Communication Using Compact Magnetoelectric Antennas",
        "rating": "-2",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "robotics",
                "Robot"
            ]
        ],
        "abstract": "We present the design, development, and experimental validation of BlueME, a compact magnetoelectric (ME) antenna array system for underwater robot-to-robot communication. BlueME employs ME antennas operating at their natural mechanical resonance frequency to efficiently transmit and receive very-low-frequency (VLF) electromagnetic signals underwater. To evaluate its performance, we deployed BlueME on an autonomous surface vehicle (ASV) and a remotely operated vehicle (ROV) in open-water field trials. Our tests demonstrate that BlueME maintains reliable signal transmission at distances beyond 200 meters while consuming only 1 watt of power. Field trials show that the system operates effectively in challenging underwater conditions such as turbidity, obstacles, and multipath interference -- that generally affect acoustics and optics. Our analysis also examines the impact of complete submersion on system performance and identifies key deployment considerations. This work represents the first practical underwater deployment of ME antennas outside the laboratory and implements the largest VLF ME array system to date. BlueME demonstrates significant potential for marine robotics and automation in multi-robot cooperative systems and remote sensor networks.",
        "subjects": [
            "cs.RO",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09251",
        "abstract url": "https://arxiv.org/abs/2411.09251",
        "title": "Cross Space and Time: A Spatio-Temporal Unitized Model for Traffic Flow Forecasting",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Predicting spatio-temporal traffic flow presents significant challenges due to complex interactions between spatial and temporal factors. Existing approaches often address these dimensions in isolation, neglecting their critical interdependencies. In this paper, we introduce the Spatio-Temporal Unitized Model (STUM), a unified framework designed to capture both spatial and temporal dependencies while addressing spatio-temporal heterogeneity through techniques such as distribution alignment and feature fusion. It also ensures both predictive accuracy and computational efficiency. Central to STUM is the Adaptive Spatio-temporal Unitized Cell (ASTUC), which utilizes low-rank matrices to seamlessly store, update, and interact with space, time, as well as their correlations. Our framework is also modular, allowing it to integrate with various spatio-temporal graph neural networks through components such as backbone models, feature extractors, residual fusion blocks, and predictive modules to collectively enhance forecasting outcomes. Experimental results across multiple real-world datasets demonstrate that STUM consistently improves prediction performance with minimal computational cost. These findings are further supported by hyperparameter optimization, pre-training analysis, and result visualization. We provide our source code for reproducibility at https://anonymous.4open.science/r/STUM-E4F0.",
        "subjects": [
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09254",
        "abstract url": "https://arxiv.org/abs/2411.09254",
        "title": "Are the flows of complex-valued Laplacians and their pseudoinverses related?",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "graphs"
            ]
        ],
        "abstract": "Laplacian flows model the rate of change of each node's state as being proportional to the difference between its value and that of its neighbors. Typically, these flows capture diffusion or synchronization dynamics and are well-studied. Expanding on these classical flows, we introduce a pseudoinverse Laplacian flow system, substituting the Laplacian with its pseudoinverse within complex-valued networks. Interestingly, for undirected graphs and unsigned weight-balanced digraphs, Laplacian and the pseudoinverse Laplacian flows exhibit an interdependence in terms of consensus. To show this relation, we first present the conditions for achieving consensus in the pseudoinverse Laplacian flow system using the property of real eventually exponentially positivity. Thereafter, we show that the pseudoinverse Laplacian flow system converges to consensus if and only if the Laplacian flow system achieves consensus in the above-mentioned networks. However, these are only the sufficient conditions for digraphs. Further, we illustrate the efficacy of the proposed approach through examples, focusing primarily on power networks.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09268",
        "abstract url": "https://arxiv.org/abs/2411.09268",
        "title": "LES-Talker: Fine-Grained Emotion Editing for Talking Head Generation in Linear Emotion Space",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While existing one-shot talking head generation models have achieved progress in coarse-grained emotion editing, there is still a lack of fine-grained emotion editing models with high interpretability. We argue that for an approach to be considered fine-grained, it needs to provide clear definitions and sufficiently detailed differentiation. We present LES-Talker, a novel one-shot talking head generation model with high interpretability, to achieve fine-grained emotion editing across emotion types, emotion levels, and facial units. We propose a Linear Emotion Space (LES) definition based on Facial Action Units to characterize emotion transformations as vector transformations. We design the Cross-Dimension Attention Net (CDAN) to deeply mine the correlation between LES representation and 3D model representation. Through mining multiple relationships across different feature and structure dimensions, we enable LES representation to guide the controllable deformation of 3D model. In order to adapt the multimodal data with deviations to the LES and enhance visual quality, we utilize specialized network design and training strategies. Experiments show that our method provides high visual quality along with multilevel and interpretable fine-grained emotion editing, outperforming mainstream methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09279",
        "abstract url": "https://arxiv.org/abs/2411.09279",
        "title": "A Comparative Analysis of Electricity Consumption Flexibility in Different Industrial Plant Configurations",
        "rating": "-2",
        "keywords": [
            [
                "Industrial"
            ]
        ],
        "abstract": "The flexibility of industrial power consumption plays a key role in the transition to renewable energy systems, contributing to grid stability, cost reduction and decarbonization efforts. This paper presents a novel methodology to quantify and optimize the flexibility of electricity consumption in manufacturing plants. The proposed model is applied to actual cement and steel plant configurations. Comparative simulations performed with the model reveal significant differences in flexibility and cost-effectiveness, driven by factors such as production capacity, downstream process demand, storage capacity, and operational constraints. A comprehensive sensitivity analysis further clarifies the impact of various parameters on production optimization and flexibility savings. Specifically, as demand approaches production levels, flexibility decreases. Although increasing storage capacity typically reduces production costs, the benefits diminish above a certain threshold. The results provide valuable information for industrial operators wishing to improve operational efficiency, reduce costs and increase the flexibility of their operations.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09302",
        "abstract url": "https://arxiv.org/abs/2411.09302",
        "title": "EEG-Based Speech Decoding: A Novel Approach Using Multi-Kernel Ensemble Diffusion Models",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "EEG"
            ],
            [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "In this study, we propose an ensemble learning framework for electroencephalogram-based overt speech classification, leveraging denoising diffusion probabilistic models with varying convolutional kernel sizes. The ensemble comprises three models with kernel sizes of 51, 101, and 201, effectively capturing multi-scale temporal features inherent in signals. This approach improves the robustness and accuracy of speech decoding by accommodating the rich temporal complexity of neural signals. The ensemble models work in conjunction with conditional autoencoders that refine the reconstructed signals and maximize the useful information for downstream classification tasks. The results indicate that the proposed ensemble-based approach significantly outperforms individual models and existing state-of-the-art techniques. These findings demonstrate the potential of ensemble methods in advancing brain signal decoding, offering new possibilities for non-verbal communication applications, particularly in brain-computer interface systems aimed at aiding individuals with speech impairments.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09361",
        "abstract url": "https://arxiv.org/abs/2411.09361",
        "title": "Time-to-Event Pretraining for 3D Medical Imaging",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "biomarkers",
                "Medical",
                "health",
                "CT",
                "disease",
                "clinical",
                "organ"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "With the rise of medical foundation models and the growing availability of imaging data, scalable pretraining techniques offer a promising way to identify imaging biomarkers predictive of future disease risk. While current self-supervised methods for 3D medical imaging models capture local structural features like organ morphology, they fail to link pixel biomarkers with long-term health outcomes due to a missing context problem. Current approaches lack the temporal context necessary to identify biomarkers correlated with disease progression, as they rely on supervision derived only from images and concurrent text descriptions. To address this, we introduce time-to-event pretraining, a pretraining framework for 3D medical imaging models that leverages large-scale temporal supervision from paired, longitudinal electronic health records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D images) and time-to-event distributions across thousands of EHR-derived tasks, our method improves outcome prediction, achieving an average AUROC increase of 23.7% and a 29.4% gain in Harrell's C-index across 8 benchmark tasks. Importantly, these gains are achieved without sacrificing diagnostic classification performance. This study lays the foundation for integrating longitudinal EHR and 3D imaging data to advance clinical risk prediction.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "34 pages, 19 figures"
    },
    {
        "paper id": "2411.09410",
        "abstract url": "https://arxiv.org/abs/2411.09410",
        "title": "LLM-assisted Explicit and Implicit Multi-interest Learning Framework for Sequential Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Multi-interest modeling in current recommender systems (RS) is mainly based on user behavioral data, capturing user interest preferences from multiple dimensions. However, since behavioral data is implicit and often highly sparse, it is challenging to understand users' complex and diverse interests. Recent studies have shown that the rich semantic information in the text can effectively supplement the deficiencies of behavioral data. Despite this, it is still difficult for small models to directly extract semantic features associated with users' deep interests. That is, how to effectively align semantics with behavioral information to form a more comprehensive and accurate understanding of user interests has become a critical research problem. To address this, we propose an LLM-assisted explicit and implicit multi-interest learning framework (named EIMF) to model user interests on two levels: behavior and semantics. The framework consists of two parts: Implicit Behavioral Interest Module (IBIM) and Explicit Semantic Interest Module (ESIM). The traditional multi-interest RS model in IBIM can learn users' implicit behavioral interests from interactions with items. In ESIM, we first adopt a clustering algorithm to select typical samples and design a prompting strategy on LLM to obtain explicit semantic interests. Furthermore, in the training phase, the semantic interests of typical samples can enhance the representation learning of behavioral interests based on the multi-task learning on semantic prediction and modality alignment. Therefore, in the inference stage, accurate recommendations can be achieved with only the user's behavioral data. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed EIMF framework, which effectively and efficiently combines small models with LLM to improve the accuracy of multi-interest modeling.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2411.09411",
        "abstract url": "https://arxiv.org/abs/2411.09411",
        "title": "Building Height Estimation Using Shadow Length in Satellite Imagery",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "Satellite"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Estimating building height from satellite imagery poses significant challenges, especially when monocular images are employed, resulting in a loss of essential 3D information during imaging. This loss of spatial depth further complicates the height estimation process. We addressed this issue by using shadow length as an additional cue to compensate for the loss of building height estimation using single-view imagery. We proposed a novel method that first localized a building and its shadow in the given satellite image. After localization, the shadow length is estimated using a regression model. To estimate the final height of each building, we utilize the principles of photogrammetry, specifically considering the relationship between the solar elevation angle, the vertical edge length of the building, and the length of the building's shadow. For the localization of buildings in our model, we utilized a modified YOLOv7 detector, and to regress the shadow length for each building we utilized the ResNet18 as backbone architecture. Finally, we estimated the associated building height using solar elevation with shadow length through analytical formulation. We evaluated our method on 42 different cities and the results showed that the proposed framework surpasses the state-of-the-art methods with a suitable margin.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "6 pages, 5 figures, 2 tables"
    },
    {
        "paper id": "2411.09425",
        "abstract url": "https://arxiv.org/abs/2411.09425",
        "title": "MARM: Unlocking the Future of Recommendation Systems through Memory Augmentation and Scalable Complexity",
        "rating": "-2",
        "keywords": [
            [
                "Recommendation"
            ]
        ],
        "abstract": "Scaling-law has guided the language model designing for past years, however, it is worth noting that the scaling laws of NLP cannot be directly applied to RecSys due to the following reasons: (1) The amount of training samples and model parameters is typically not the bottleneck for the model. Our recommendation system can generate over 50 billion user samples daily, and such a massive amount of training data can easily allow our model parameters to exceed 200 billion, surpassing many LLMs (about 100B). (2) To ensure the stability and robustness of the recommendation system, it is essential to control computational complexity FLOPs carefully. Considering the above differences with LLM, we can draw a conclusion that: for a RecSys model, compared to model parameters, the computational complexity FLOPs is a more expensive factor that requires careful control. In this paper, we propose our milestone work, MARM (Memory Augmented Recommendation Model), which explores a new cache scaling-laws successfully.",
        "subjects": [
            "cs.IR"
        ],
        "comment": "Work in progress"
    },
    {
        "paper id": "2411.09426",
        "abstract url": "https://arxiv.org/abs/2411.09426",
        "title": "Movable Antenna Enhanced Networked Full-Duplex Integrated Sensing and Communication System",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "Integrated sensing and communication (ISAC) is envisioned as a key technology for future sixth-generation (6G) networks. Classical ISAC system considering monostatic and/or bistatic settings will inevitably degrade both communication and sensing performance due to the limited service coverage and easily blocked transmission paths. Besides, existing ISAC studies usually focus on downlink (DL) or uplink (UL) communication demands and unable to achieve the systematic DL and UL communication tasks. These challenges can be overcome by networked FD ISAC framework. Moreover, ISAC generally considers the trade-off between communication and sensing, unavoidably leading to a loss in communication performance. This shortcoming can be solved by the emerging movable antenna (MA) technology. In this paper, we utilize the MA to promote communication capability with guaranteed sensing performance via jointly designing beamforming, power allocation, receiving filters and MA configuration towards maximizing sum rate. The optimization problem is highly difficult due to the unique channel model deriving from the MA. To resolve this challenge, via leveraging the cutting-the-edge majorization-minimization (MM) method, we develop an efficient solution that optimizes all variables via convex optimization techniques. Extensive simulation results verify the effectiveness of our proposed algorithms and demonstrate the substantial performance promotion by deploying MA in the networked FD ISAC system.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09441",
        "abstract url": "https://arxiv.org/abs/2411.09441",
        "title": "A ROS~2-based Navigation and Simulation Stack for the Robotino",
        "rating": "-2",
        "keywords": [
            [
                "LIDAR"
            ],
            [
                "robotics",
                "Navigation"
            ]
        ],
        "abstract": "The Robotino, developed by Festo Didactic, serves as a versatile platform in education and research for mobile robotics tasks. However, there currently is no ROS2 integration for the Robotino available. In this paper, we describe our work on a Webots simulation environment for a Robotino platform extended by LIDAR sensors. A ROS2 integration and a pre-configured setup for localization and navigation using existing ROS packages from the Nav2 suite are provided. We validate our setup by comparing simulations with real-world experiments conducted by three Robotinos in a logistics environment in our lab. Additionally, we tested the setup using a ROS 2 hardware driver for the Robotino developed by team GRIPS of the RoboCup Logistics League. The results demonstrate the feasibility of using ROS2 and Nav2 for navigation tasks on the Robotino platform showing great consistency between simulation and real-world performance.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Published at RoboCup 2024: Robot World Cup XXVII, Springer-Verlag, 2024"
    },
    {
        "paper id": "2411.09462",
        "abstract url": "https://arxiv.org/abs/2411.09462",
        "title": "SINETRA: a Versatile Framework for Evaluating Single Neuron Tracking in Behaving Animals",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "biological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Accurately tracking neuronal activity in behaving animals presents significant challenges due to complex motions and background noise. The lack of annotated datasets limits the evaluation and improvement of such tracking algorithms. To address this, we developed SINETRA, a versatile simulator that generates synthetic tracking data for particles on a deformable background, closely mimicking live animal recordings. This simulator produces annotated 2D and 3D videos that reflect the intricate movements seen in behaving animals like Hydra Vulgaris. We evaluated four state-of-the-art tracking algorithms highlighting the current limitations of these methods in challenging scenarios and paving the way for improved cell tracking techniques in dynamic biological systems.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 3 figures, submitted at 2025 IEEE International Symposium on Biomedical Imaging (ISBI)"
    },
    {
        "paper id": "2411.09495",
        "abstract url": "https://arxiv.org/abs/2411.09495",
        "title": "ISAC Super-Resolution Receiver via Lifted Atomic Norm Minimization",
        "rating": "-2",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "radar"
            ]
        ],
        "abstract": "This paper introduces an off-the-grid estimator for integrated sensing and communication (ISAC) systems, utilizing lifted atomic norm minimization (LANM). The key challenge in this scenario is that neither the transmit signals nor the radar-and-communication channels are known. We prove that LANM can simultaneously achieve localization of radar targets and decoding of communication symbols, when the number of observations is proportional to the degrees of freedom in the ISAC systems. Despite the inherent ill-posed nature of the problem, we employ the lifting technique to initially encode the transmit signals. Then, we leverage the atomic norm to promote the structured low-rankness for the ISAC channel. We utilize a dual technique to transform the LANM into an infinite-dimensional search over the signal domain. Subsequently, we use semidefinite relaxation (SDR) to implement the dual problem. We extend our approach to practical scenarios where received signals are contaminated by additive white Gaussian noise (AWGN) and jamming signals. Furthermore, we derive the computational complexity of the proposed estimator and demonstrate that it is equivalent to the conventional pilot-aided ANM for estimating the channel parameters. Our simulation experiments demonstrate the ability of the proposed LANM approach to estimate both communication data and target parameters with a performance comparable to traditional radar-only super-resolution techniques.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09512",
        "abstract url": "https://arxiv.org/abs/2411.09512",
        "title": "GAN-Based Architecture for Low-dose Computed Tomography Imaging Denoising",
        "rating": "-2",
        "keywords": [
            [
                "GAN",
                "Super-Resolution"
            ],
            [
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Generative Adversarial Networks (GANs) have surfaced as a revolutionary element within the domain of low-dose computed tomography (LDCT) imaging, providing an advanced resolution to the enduring issue of reconciling radiation exposure with image quality. This comprehensive review synthesizes the rapid advancements in GAN-based LDCT denoising techniques, examining the evolution from foundational architectures to state-of-the-art models incorporating advanced features such as anatomical priors, perceptual loss functions, and innovative regularization strategies. We critically analyze various GAN architectures, including conditional GANs (cGANs), CycleGANs, and Super-Resolution GANs (SRGANs), elucidating their unique strengths and limitations in the context of LDCT denoising. The evaluation provides both qualitative and quantitative results related to the improvements in performance in benchmark and clinical datasets with metrics such as PSNR, SSIM, and LPIPS. After highlighting the positive results, we discuss some of the challenges preventing a wider clinical use, including the interpretability of the images generated by GANs, synthetic artifacts, and the need for clinically relevant metrics. The review concludes by highlighting the essential significance of GAN-based methodologies in the progression of precision medicine via tailored LDCT denoising models, underlining the transformative possibilities presented by artificial intelligence within contemporary radiological practice.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09524",
        "abstract url": "https://arxiv.org/abs/2411.09524",
        "title": "FlowNav: Learning Efficient Navigation Policies via Conditional Flow Matching",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "robot",
                "Navigation"
            ]
        ],
        "abstract": "Effective robot navigation in dynamic environments is a challenging task that depends on generating precise control actions at high frequencies. Recent advancements have framed navigation as a goal-conditioned control problem. Current state-of-the-art methods for goal-based navigation, such as diffusion policies, either generate sub-goal images or robot control actions to guide robots. However, despite their high accuracy, these methods incur substantial computational costs, which limits their practicality for real-time applications. Recently, Conditional Flow Matching(CFM) has emerged as a more efficient and robust generalization of diffusion. In this work we explore the use of CFM to learn action policies that help the robot navigate its environment. Our results demonstrate that CFM is able to generate highly accurate robot actions. CFM not only matches the accuracy of diffusion policies but also significantly improves runtime performance. This makes it particularly advantageous for real-time robot navigation, where swift, reliable action generation is vital for collision avoidance and smooth operation. By leveraging CFM, we provide a pathway to more scalable, responsive robot navigation systems capable of handling the demands of dynamic and unpredictable environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at CoRL 2024 workshop on Learning Effective Abstractions for Planning (LEAP) and workshop on Differentiable Optimization Everywhere: Simulation, Estimation, Learning, and Control. 7 pages + 2 pages of references, 7 figures"
    },
    {
        "paper id": "2411.09534",
        "abstract url": "https://arxiv.org/abs/2411.09534",
        "title": "Enabling Efficient Wearables: An Analysis of Low-Power Microcontrollers for Biomedical Applications",
        "rating": "-2",
        "keywords": [
            [
                "Biomedical"
            ]
        ],
        "abstract": "Breakthroughs in ultra-low-power chip technology are transforming biomedical wearables, making it possible to monitor patients in real time with devices operating on mere \u03bcW. Although many studies have examined the power performance of commercial microcontrollers, it remains unclear which ones perform best across diverse application profiles and which hardware features are most crucial for minimizing energy consumption under varying computational loads. Identifying these features for typical wearable applications and understanding their effects on performance and energy efficiency are essential for optimizing deployment strategies and informing future hardware designs. In this work, we conduct an in-depth study of state-of-the-art (SoA) micro-controller units(MCUs) in terms of processing capability and energy efficiency using representative end-to-end SoA wearable applications. We systematically benchmark each platform across three primary application phases: idle, data acquisition, and processing, allowing a holistic assessment of the platform processing capability and overall energy efficiency across varying patient-monitoring application profiles. Our detailed analysis of performance and energy discrepancies across different platforms reveals key strengths and limitations of the current low-power hardware design and pinpoints the strengths and weaknesses of SoA MCUs. We conclude with actionable insights for wearable application designers and hardware engineers, aiming to inform future hardware design improvements and support optimal platform selection for energy-constrained biomedical applications.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "21 pages, 6 Figures, 6 Tables, Submitted to ACM TECS journal"
    },
    {
        "paper id": "2411.09538",
        "abstract url": "https://arxiv.org/abs/2411.09538",
        "title": "Marker-free Human Gait Analysis using a Smart Edge Sensor System",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "biomechanics",
                "medical",
                "physiological"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The human gait is a complex interplay between the neuronal and the muscular systems, reflecting an individual's neurological and physiological condition. This makes gait analysis a valuable tool for biomechanics and medical experts. Traditional observational gait analysis is cost-effective but lacks reliability and accuracy, while instrumented gait analysis, particularly using marker-based optical systems, provides accurate data but is expensive and time-consuming. In this paper, we introduce a novel markerless approach for gait analysis using a multi-camera setup with smart edge sensors to estimate 3D body poses without fiducial markers. We propose a Siamese embedding network with triplet loss calculation to identify individuals by their gait pattern. This network effectively maps gait sequences to an embedding space that enables clustering sequences from the same individual or activity closely together while separating those of different ones. Our results demonstrate the potential of the proposed system for efficient automated gait analysis in diverse real-world environments, facilitating a wide range of applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted for SII 2025"
    },
    {
        "paper id": "2411.09593",
        "abstract url": "https://arxiv.org/abs/2411.09593",
        "title": "SMILE-UHURA Challenge -- Small Vessel Segmentation at Mesoscopic Scale from Ultra-High Resolution 7T Magnetic Resonance Angiograms",
        "rating": "-2",
        "keywords": [
            [
                "Flight"
            ],
            [
                "MRI"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The human brain receives nutrients and oxygen through an intricate network of blood vessels. Pathology affecting small vessels, at the mesoscopic scale, represents a critical vulnerability within the cerebral blood supply and can lead to severe conditions, such as Cerebral Small Vessel Diseases. The advent of 7 Tesla MRI systems has enabled the acquisition of higher spatial resolution images, making it possible to visualise such vessels in the brain. However, the lack of publicly available annotated datasets has impeded the development of robust, machine learning-driven segmentation algorithms. To address this, the SMILE-UHURA challenge was organised. This challenge, held in conjunction with the ISBI 2023, in Cartagena de Indias, Colombia, aimed to provide a platform for researchers working on related topics. The SMILE-UHURA challenge addresses the gap in publicly available annotated datasets by providing an annotated dataset of Time-of-Flight angiography acquired with 7T MRI. This dataset was created through a combination of automated pre-segmentation and extensive manual refinement. In this manuscript, sixteen submitted methods and two baseline methods are compared both quantitatively and qualitatively on two different datasets: held-out test MRAs from the same dataset as the training data (with labels kept secret) and a separate 7T ToF MRA dataset where both input volumes and labels are kept secret. The results demonstrate that most of the submitted deep learning methods, trained on the provided training dataset, achieved reliable segmentation performance. Dice scores reached up to 0.838 $\\pm$ 0.066 and 0.716 $\\pm$ 0.125 on the respective datasets, with an average performance of up to 0.804 $\\pm$ 0.15.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09658",
        "abstract url": "https://arxiv.org/abs/2411.09658",
        "title": "Motion Before Action: Diffusing Object Motion as Manipulation Condition",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "robot",
                "robotic manipulation"
            ]
        ],
        "abstract": "Inferring object motion representations from observations enhances the performance of robotic manipulation tasks. This paper introduces a new paradigm for robot imitation learning that generates action sequences by reasoning about object motion from visual observations. We propose MBA (Motion Before Action), a novel module that employs two cascaded diffusion processes for object motion generation and robot action generation under object motion guidance. MBA first predicts the future pose sequence of the object based on observations, then uses this sequence as a condition to guide robot action generation. Designed as a plug-and-play component, MBA can be flexibly integrated into existing robotic manipulation policies with diffusion action heads. Extensive experiments in both simulated and real-world environments demonstrate that our approach substantially improves the performance of existing policies across a wide range of manipulation tasks. Project page: https://selen-suyue.github.io/MBApage/",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09660",
        "abstract url": "https://arxiv.org/abs/2411.09660",
        "title": "Capacity and Power Consumption of Multi-Layer 6G Networks Using the Upper Mid-Band",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "This paper presents a new system model to evaluate the capacity and power consumption of multi-layer 6G networks utilising the upper mid-band (FR3). The model captures heterogeneous 4G, 5G, and 6G deployments, analyzing their performance under different deployment strategies. Our results show that strategic 6G deployments, non-co-located with existing 5G sites, significantly enhance throughput, with median and peak user rates of 300 Mbps and exceeding 1 Gbps, respectively. We also emphasize the importance of priority-based cell reselection and beam configuration to fully leverage 6G capabilities. While 6G implementation increases power consumption by 33%, non-colocated deployments strike a balance between performance and power consumption.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09738",
        "abstract url": "https://arxiv.org/abs/2411.09738",
        "title": "Optimal State Preparation for Logical Arrays on Zoned Neutral Atom Quantum Computers",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Quantum computing promises to solve problems previously deemed infeasible. However, high error rates necessitate quantum error correction for practical applications. Seminal experiments with zoned neutral atom architectures have shown remarkable potential for fault-tolerant quantum computing. To fully harness their potential, efficient software solutions are vital. A key aspect of quantum error correction is the initialization of physical qubits representing a logical qubit in a highly entangled state. This process, known as state preparation, is the foundation of most quantum error correction codes and, hence, a crucial step towards fault-tolerant quantum computing. Generating a schedule of target-specific instructions to perform the state preparation is highly complex. First software tools exist but are not suitable for the zoned neutral atom architectures. This work addresses this gap by leveraging the computational power of SMT solvers and generating minimal schedules for the state preparation of logical arrays. Experimental evaluations demonstrate that actively utilizing zones to shield idling qubits consistently results in higher fidelities than solutions disregarding these zones. The complete code is publicly available in open-source as part of the Munich Quantum Toolkit (MQT) at https://github.com/cda-tum/mqt-qmap/tree/main/src/na/nasp.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": "7 pages, 4 figures"
    },
    {
        "paper id": "2411.09764",
        "abstract url": "https://arxiv.org/abs/2411.09764",
        "title": "ModelPredictiveControl.jl: advanced process control made easy in Julia",
        "rating": "-2",
        "keywords": [
            [
                "industrial"
            ]
        ],
        "abstract": "Proprietary closed-source software is still the norm in advanced process control. Transparency and reproducibility are key aspects of scientific research. Free and open-source toolkit can contribute to the development, sharing and advancement of new and efficient control approaches, and the industrial sector will certainly benefit from them. This paper presents ModelPredictiveControl.jl, an open-source software package for designing model predictive controllers in the Julia programming language. It is designed to be easy to use and modular, while providing advanced features like nonlinear control and moving horizon estimation. It relies on powerful control system and mathematical optimization frameworks to simplify the construction and testing of state estimators and predictive controllers. It also integrates with the standard plotting library to quickly visualize closed-loop data. The paper presents the main functionalities and illustrates them with two case studies in simulation. The first example is a continuously stirred tank reactor described by linear dynamics. The second one implements a nonlinear, an economic, and a successive linearization model predictive controllers for an inverted pendulum. The solving times are benchmarked against equivalent implementations in MATLAB to show the efficiency of the package.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "11 pages, 11 figures, 1 table"
    },
    {
        "paper id": "2411.09766",
        "abstract url": "https://arxiv.org/abs/2411.09766",
        "title": "NACNet: A Histology Context-aware Transformer Graph Convolution Network for Predicting Treatment Response to Neoadjuvant Chemotherapy in Triple Negative Breast Cancer",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "whole slide",
                "Cancer",
                "clinical",
                "tumor"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Neoadjuvant chemotherapy (NAC) response prediction for triple negative breast cancer (TNBC) patients is a challenging task clinically as it requires understanding complex histology interactions within the tumor microenvironment (TME). Digital whole slide images (WSIs) capture detailed tissue information, but their giga-pixel size necessitates computational methods based on multiple instance learning, which typically analyze small, isolated image tiles without the spatial context of the TME. To address this limitation and incorporate TME spatial histology interactions in predicting NAC response for TNBC patients, we developed a histology context-aware transformer graph convolution network (NACNet). Our deep learning method identifies the histopathological labels on individual image tiles from WSIs, constructs a spatial TME graph, and represents each node with features derived from tissue texture and social network analysis. It predicts NAC response using a transformer graph convolution network model enhanced with graph isomorphism network layers. We evaluate our method with WSIs of a cohort of TNBC patient (N=105) and compared its performance with multiple state-of-the-art machine learning and deep learning models, including both graph and non-graph approaches. Our NACNet achieves 90.0% accuracy, 96.0% sensitivity, 88.0% specificity, and an AUC of 0.82, through eight-fold cross-validation, outperforming baseline models. These comprehensive experimental results suggest that NACNet holds strong potential for stratifying TNBC patients by NAC response, thereby helping to prevent overtreatment, improve patient quality of life, reduce treatment cost, and enhance clinical outcomes, marking an important advancement toward personalized breast cancer treatment.",
        "subjects": [
            "cs.CV",
            "q-bio.QM"
        ],
        "comment": "This paper is accepted by Computerized Medical Imaging and Graphics (Nov 07 2024)"
    },
    {
        "paper id": "2411.09823",
        "abstract url": "https://arxiv.org/abs/2411.09823",
        "title": "Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical 2D Inpainting",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "diffusion",
                "Inpainting"
            ],
            [
                "Robotics"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Creating large-scale interactive 3D environments is essential for the development of Robotics and Embodied AI research. Current methods, including manual design, procedural generation, diffusion-based scene generation, and large language model (LLM) guided scene design, are hindered by limitations such as excessive human effort, reliance on predefined rules or training datasets, and limited 3D spatial reasoning ability. Since pre-trained 2D image generative models better capture scene and object configuration than LLMs, we address these challenges by introducing Architect, a generative framework that creates complex and realistic 3D embodied environments leveraging diffusion-based 2D image inpainting. In detail, we utilize foundation visual perception models to obtain each generated object from the image and leverage pre-trained depth estimation models to lift the generated 2D image to 3D space. Our pipeline is further extended to a hierarchical and iterative inpainting process to continuously generate placement of large furniture and small objects to enrich the scene. This iterative structure brings the flexibility for our method to generate or refine scenes from various starting points, such as text, floor plans, or pre-arranged environments.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09859",
        "abstract url": "https://arxiv.org/abs/2411.09859",
        "title": "Skew-Symmetric Matrix Decompositions on Shared-Memory Architectures",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "The factorization of skew-symmetric matrices is a critically understudied area of dense linear algebra (DLA), particularly in comparison to that of symmetric matrices. While some algorithms can be adapted from the symmetric case, the cost of algorithms can be reduced by exploiting skew-symmetry. A motivating example is the factorization $X=LTL^T$ of a skew-symmetric matrix $X$, which is used in practical applications as a means of determining the determinant of $X$ as the square of the (cheaply-computed) Pfaffian of the skew-symmetric tridiagonal matrix $T$, for example in fields such as quantum electronic structure and machine learning. Such applications also often require pivoting in order to improve numerical stability. In this work we explore a combination of known literature algorithms and new algorithms recently derived using formal methods. High-performance parallel CPU implementations are created, leveraging the concept of fusion at multiple levels in order to reduce memory traffic overhead, as well as the BLIS framework which provides high-performance GEMM kernels, hierarchical parallelism, and cache blocking. We find that operation fusion and improved use of available bandwidth via parallelization of bandwidth-bound (level-2 BLAS) operations are essential for obtaining high performance, while a concise C++ implementation provides a clear and close connection to the formal derivation process without sacrificing performance.",
        "subjects": [
            "cs.MS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09863",
        "abstract url": "https://arxiv.org/abs/2411.09863",
        "title": "Face De-identification: State-of-the-art Methods and Comparative Studies",
        "rating": "-2",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The widespread use of image acquisition technologies, along with advances in facial recognition, has raised serious privacy concerns. Face de-identification usually refers to the process of concealing or replacing personal identifiers, which is regarded as an effective means to protect the privacy of facial images. A significant number of methods for face de-identification have been proposed in recent years. In this survey, we provide a comprehensive review of state-of-the-art face de-identification methods, categorized into three levels: pixel-level, representation-level, and semantic-level techniques. We systematically evaluate these methods based on two key criteria, the effectiveness of privacy protection and preservation of image utility, highlighting their advantages and limitations. Our analysis includes qualitative and quantitative comparisons of the main algorithms, demonstrating that deep learning-based approaches, particularly those using Generative Adversarial Networks (GANs) and diffusion models, have achieved significant advancements in balancing privacy and utility. Experimental results reveal that while recent methods demonstrate strong privacy protection, trade-offs remain in visual fidelity and computational complexity. This survey not only summarizes the current landscape but also identifies key challenges and future research directions in face de-identification.",
        "subjects": [
            "cs.CV",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09873",
        "abstract url": "https://arxiv.org/abs/2411.09873",
        "title": "LLM-Powered AI Tutors with Personas for d/Deaf and Hard-of-Hearing Online Learners",
        "rating": "-2",
        "keywords": [
            [
                "sign language"
            ]
        ],
        "abstract": "Intelligent tutoring systems (ITS) using artificial intelligence (AI) technology have shown promise in supporting learners with diverse abilities; however, they often fail to meet the specific communication needs and cultural nuances needed by d/Deaf and Hard-of-Hearing (DHH) learners. As large language models (LLMs) provide new opportunities to incorporate personas to AI-based tutors and support dynamic interactive dialogue, this paper explores how DHH learners perceive LLM-powered ITS with different personas and identified design suggestions for improving the interaction. We developed an interface that allows DHH learners to interact with ChatGPT and three LLM-powered AI tutors with different experiences in DHH education while the learners watch an educational video. A user study with 16 DHH participants showed that they perceived conversations with the AI tutors who had DHH education experiences to be more human-like and trustworthy due to the tutors' cultural knowledge of DHH communities. Participants also suggested providing more transparency regarding the tutors' background information to clarify each AI tutor's position within the DHH community. We discuss design implications for more inclusive LLM-based systems, such as supports for the multimodality of sign language.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09875",
        "abstract url": "https://arxiv.org/abs/2411.09875",
        "title": "EEG Spectral Analysis in Gray Zone Between Healthy and Insomnia",
        "rating": "-2",
        "keywords": [
            [
                "EEG",
                "clinical"
            ]
        ],
        "abstract": "This study investigates the sleep characteristics and brain activity of individuals in the gray zone of insomnia, a population that experiences sleep disturbances yet does not fully meet the clinical criteria for chronic insomnia. Thirteen healthy participants and thirteen individuals from the gray zone were assessed using polysomnography and electroencephalogram to analyze both sleep architecture and neural activity. Although no significant differences in objective sleep quality or structure were found between the groups, gray zone individuals reported higher insomnia severity index scores, indicating subjective sleep difficulties. Electroencephalogram analysis revealed increased delta and alpha activity during the wake stage, suggesting lingering sleep inertia, while non-rapid eye movement stages 1 and 2 exhibited elevated beta and gamma activity, often associated with chronic insomnia. However, these high-frequency patterns were not observed in non-rapid eye movement stage 3 or rapid eye movement sleep, suggesting less severe disruptions compared to chronic insomnia. This study emphasizes that despite normal polysomnography findings, EEG patterns in gray zone individuals suggest a potential risk for chronic insomnia, highlighting the need for early identification and tailored intervention strategies to prevent progression.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "4 pages, 2 figures"
    },
    {
        "paper id": "2411.09879",
        "abstract url": "https://arxiv.org/abs/2411.09879",
        "title": "A Multi-Label EEG Dataset for Mental Attention State Classification in Online Learning",
        "rating": "-2",
        "keywords": [
            [
                "EEG",
                "psychological",
                "physiological"
            ]
        ],
        "abstract": "Attention is a vital cognitive process in the learning and memory environment, particularly in the context of online learning. Traditional methods for classifying attention states of online learners based on behavioral signals are prone to distortion, leading to increased interest in using electroencephalography (EEG) signals for authentic and accurate assessment. However, the field of attention state classification based on EEG signals in online learning faces challenges, including the scarcity of publicly available datasets, the lack of standardized data collection paradigms, and the requirement to consider the interplay between attention and other psychological states. In light of this, we present the Multi-label EEG dataset for classifying Mental Attention states (MEMA) in online learning. We meticulously designed a reliable and standard experimental paradigm with three attention states: neutral, relaxing, and concentrating, considering human physiological and psychological characteristics. This paradigm collected EEG signals from 20 subjects, each participating in 12 trials, resulting in 1,060 minutes of data. Emotional state labels, basic personal information, and personality traits were also collected to investigate the relationship between attention and other psychological states. Extensive quantitative and qualitative analysis, including a multi-label correlation study, validated the quality of the EEG attention data. The MEMA dataset and analysis provide valuable insights for advancing research on attention in online learning. The dataset is publicly available at \\url{https://github.com/GuanjianLiu/MEMA}.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09929",
        "abstract url": "https://arxiv.org/abs/2411.09929",
        "title": "Autonomous Robotic Pepper Harvesting: Imitation Learning in Unstructured Agricultural Environments",
        "rating": "-2",
        "keywords": [
            [
                "Agricultural"
            ]
        ],
        "abstract": "Automating tasks in outdoor agricultural fields poses significant challenges due to environmental variability, unstructured terrain, and diverse crop characteristics. We present a robotic system for autonomous pepper harvesting designed to operate in these unprotected, complex settings. Utilizing a custom handheld shear-gripper, we collected 300 demonstrations to train a visuomotor policy, enabling the system to adapt to varying field conditions and crop diversity. We achieved a success rate of 28.95% with a cycle time of 31.71 seconds, comparable to existing systems tested under more controlled conditions like greenhouses. Our system demonstrates the feasibility and effectiveness of leveraging imitation learning for automated harvesting in unstructured agricultural environments. This work aims to advance scalable, automated robotic solutions for agriculture in natural settings.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "8 pages, 11 figures"
    },
    {
        "paper id": "2411.09943",
        "abstract url": "https://arxiv.org/abs/2411.09943",
        "title": "Zero-shot Voice Conversion with Diffusion Transformers",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Voice Conversion"
            ],
            [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Zero-shot voice conversion aims to transform a source speech utterance to match the timbre of a reference speech from an unseen speaker. Traditional approaches struggle with timbre leakage, insufficient timbre representation, and mismatches between training and inference tasks. We propose Seed-VC, a novel framework that addresses these issues by introducing an external timbre shifter during training to perturb the source speech timbre, mitigating leakage and aligning training with inference. Additionally, we employ a diffusion transformer that leverages the entire reference speech context, capturing fine-grained timbre features through in-context learning. Experiments demonstrate that Seed-VC outperforms strong baselines like OpenVoice and CosyVoice, achieving higher speaker similarity and lower word error rates in zero-shot voice conversion tasks. We further extend our approach to zero-shot singing voice conversion by incorporating fundamental frequency (F0) conditioning, resulting in comparative performance to current state-of-the-art methods. Our findings highlight the effectiveness of Seed-VC in overcoming core challenges, paving the way for more accurate and versatile voice conversion systems.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10492",
        "abstract url": "https://arxiv.org/abs/2411.10492",
        "title": "MFP3D: Monocular Food Portion Estimation Leveraging 3D Point Clouds",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "point cloud",
                "depth"
            ],
            [
                "health"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Food portion estimation is crucial for monitoring health and tracking dietary intake. Image-based dietary assessment, which involves analyzing eating occasion images using computer vision techniques, is increasingly replacing traditional methods such as 24-hour recalls. However, accurately estimating the nutritional content from images remains challenging due to the loss of 3D information when projecting to the 2D image plane. Existing portion estimation methods are challenging to deploy in real-world scenarios due to their reliance on specific requirements, such as physical reference objects, high-quality depth information, or multi-view images and videos. In this paper, we introduce MFP3D, a new framework for accurate food portion estimation using only a single monocular image. Specifically, MFP3D consists of three key modules: (1) a 3D Reconstruction Module that generates a 3D point cloud representation of the food from the 2D image, (2) a Feature Extraction Module that extracts and concatenates features from both the 3D point cloud and the 2D RGB image, and (3) a Portion Regression Module that employs a deep regression model to estimate the food's volume and energy content based on the extracted features. Our MFP3D is evaluated on MetaFood3D dataset, demonstrating its significant improvement in accurate portion estimation over existing methods.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "9th International Workshop on Multimedia Assisted Dietary Management, in conjunction with the 27th International Conference on Pattern Recognition (ICPR2024)"
    },
    {
        "paper id": "2411.09267",
        "abstract url": "https://arxiv.org/abs/2411.09267",
        "title": "Towards efficient compression and communication for prototype-based decentralized learning",
        "rating": "-2.5",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "IoT"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In prototype-based federated learning, the exchange of model parameters between clients and the master server is replaced by transmission of prototypes or quantized versions of the data samples to the aggregation server. A fully decentralized deployment of prototype-based learning, without a central agregartor of prototypes, is more robust upon network failures and reacts faster to changes in the statistical distribution of the data, suggesting potential advantages and quick adaptation in dynamic learning tasks, e.g., when the data sources are IoT devices or when data is non-iid. In this paper, we consider the problem of designing a communication-efficient decentralized learning system based on prototypes. We address the challenge of prototype redundancy by leveraging on a twofold data compression technique, i.e., sending only update messages if the prototypes are informationtheoretically useful (via the Jensen-Shannon distance), and using clustering on the prototypes to compress the update messages used in the gossip protocol. We also use parallel instead of sequential gossiping, and present an analysis of its age-of-information (AoI). Our experimental results show that, with these improvements, the communications load can be substantially reduced without decreasing the convergence rate of the learning algorithm.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "15 pages, 2 tables, 7 figures, 6 algorithms"
    },
    {
        "paper id": "2411.09296",
        "abstract url": "https://arxiv.org/abs/2411.09296",
        "title": "Enhancing generalization in high energy physics using white-box adversarial attacks",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Machine learning is becoming increasingly popular in the context of particle physics. Supervised learning, which uses labeled Monte Carlo (MC) simulations, remains one of the most widely used methods for discriminating signals beyond the Standard Model. However, this paper suggests that supervised models may depend excessively on artifacts and approximations from Monte Carlo simulations, potentially limiting their ability to generalize well to real data. This study aims to enhance the generalization properties of supervised models by reducing the sharpness of local minima. It reviews the application of four distinct white-box adversarial attacks in the context of classifying Higgs boson decay signals. The attacks are divided into weight space attacks, and feature space attacks. To study and quantify the sharpness of different local minima this paper presents two analysis methods: gradient ascent and reduced Hessian eigenvalue analysis. The results show that white-box adversarial attacks significantly improve generalization performance, albeit with increased computational complexity.",
        "subjects": [
            "hep-ph",
            "cs.LG"
        ],
        "comment": "10 pages, 4 figures, 8 tables, 3 algorithms, to be published in Physical Review D (PRD), presented at the ML4Jets 2024 conference"
    },
    {
        "paper id": "2411.09329",
        "abstract url": "https://arxiv.org/abs/2411.09329",
        "title": "Improving hp-Variational Physics-Informed Neural Networks for Steady-State Convection-Dominated Problems",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper proposes and studies two extensions of applying hp-variational physics-informed neural networks, more precisely the FastVPINNs framework, to convection-dominated convection-diffusion-reaction problems. First, a term in the spirit of a SUPG stabilization is included in the loss functional and a network architecture is proposed that predicts spatially varying stabilization parameters. Having observed that the selection of the indicator function in hard-constrained Dirichlet boundary conditions has a big impact on the accuracy of the computed solutions, the second novelty is the proposal of a network architecture that learns good parameters for a class of indicator functions. Numerical studies show that both proposals lead to noticeably more accurate results than approaches that can be found in the literature.",
        "subjects": [
            "math.NA",
            "cs.CE",
            "cs.LG"
        ],
        "comment": "25 pages, 11 figures, 8 tables"
    },
    {
        "paper id": "2411.09359",
        "abstract url": "https://arxiv.org/abs/2411.09359",
        "title": "Your Fixed Watermark is Fragile: Towards Semantic-Aware Watermark for EaaS Copyright Protection",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Watermark"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Embedding-as-a-Service (EaaS) has emerged as a successful business pattern but faces significant challenges related to various forms of copyright infringement, including API misuse and different attacks. Various studies have proposed backdoor-based watermarking schemes to protect the copyright of EaaS services. In this paper, we reveal that previous watermarking schemes possess semantic-independent characteristics and propose the Semantic Perturbation Attack (SPA). Our theoretical and experimental analyses demonstrate that this semantic-independent nature makes current watermarking schemes vulnerable to adaptive attacks that exploit semantic perturbations test to bypass watermark verification. To address this vulnerability, we propose the Semantic Aware Watermarking (SAW) scheme, a robust defense mechanism designed to resist SPA, by injecting a watermark that adapts to the text semantics. Extensive experimental results across multiple datasets demonstrate that the True Positive Rate (TPR) for detecting watermarked samples under SPA can reach up to more than 95%, rendering previous watermarks ineffective. Meanwhile, our watermarking scheme can resist such attack while ensuring the watermark verification capability. Our code is available at https://github.com/Zk4-ps/EaaS-Embedding-Watermark.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09451",
        "abstract url": "https://arxiv.org/abs/2411.09451",
        "title": "DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous Vehicle Testing",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "Vehicle"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Generating realistic and diverse road scenarios is essential for autonomous vehicle testing and validation. Nevertheless, owing to the complexity and variability of real-world road environments, creating authentic and varied scenarios for intelligent driving testing is challenging. In this paper, we propose DiffRoad, a novel diffusion model designed to produce controllable and high-fidelity 3D road scenarios. DiffRoad leverages the generative capabilities of diffusion models to synthesize road layouts from white noise through an inverse denoising process, preserving real-world spatial features. To enhance the quality of generated scenarios, we design the Road-UNet architecture, optimizing the balance between backbone and skip connections for high-realism scenario generation. Furthermore, we introduce a road scenario evaluation module that screens adequate and reasonable scenarios for intelligent driving testing using two critical metrics: road continuity and road reasonableness. Experimental results on multiple real-world datasets demonstrate DiffRoad's ability to generate realistic and smooth road structures while maintaining the original distribution. Additionally, the generated scenarios can be fully automated into the OpenDRIVE format, facilitating generalized autonomous vehicle simulation testing. DiffRoad provides a rich and diverse scenario library for large-scale autonomous vehicle testing and offers valuable insights for future infrastructure designs that are better suited for autonomous vehicles.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "14 pages, 9 figures"
    },
    {
        "paper id": "2411.09600",
        "abstract url": "https://arxiv.org/abs/2411.09600",
        "title": "Latency Optimization in LEO Satellite Communications with Hybrid Beam Pattern and Interference Control",
        "rating": "-2.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "Satellite"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The rapid advancement of low Earth orbit (LEO) satellite communication systems has significantly enhanced global connectivity, offering high-capacity, low-latency services crucial for next-generation applications. However, the dense configuration of LEO constellations poses challenges in resource allocation optimization and interference management, complicating coexistence with other communication systems. To address these limitations, this paper proposes a novel framework for optimizing the beam scheduling and resource allocation in multi-beam LEO systems. To satisfy the uneven terrestrial traffic demand, a hybrid beam pattern is employed to enhance the downlink quality of service and minimize the transmission latency from LEO satellites to ground user terminals. Additionally, a dynamic co-channel interference (CCI) control mechanism is developed to mitigate inter-beam interference within the LEO constellation and limit cross-system interference affecting protected users from other networks. The problem of user-beam-frequency allocation with power optimization is formulated as a mixed-integer dynamic programming model and solved using a low-complexity neural network-based graph generation algorithm. Simulation results show that the proposed approach outperforms the baseline methods of full frequency reuse and single-channel transmission, and highlights the potential for further performance improvement with multi-user transmissions.",
        "subjects": [
            "cs.IT",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09728",
        "abstract url": "https://arxiv.org/abs/2411.09728",
        "title": "Physics-informed neural networks (PINNs) for numerical model error approximation and superresolution",
        "rating": "-2.5",
        "keywords": [
            [
                "superresolution"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Numerical modeling errors are unavoidable in finite element analysis. The presence of model errors inherently reflects both model accuracy and uncertainty. To date there have been few methods for explicitly quantifying errors at points of interest (e.g. at finite element nodes). The lack of explicit model error approximators has been addressed recently with the emergence of machine learning (ML), which closes the loop between numerical model features/solutions and explicit model error approximations. In this paper, we propose physics-informed neural networks (PINNs) for simultaneous numerical model error approximation and superresolution. To test our approach, numerical data was generated using finite element simulations on a two-dimensional elastic plate with a central opening. Four- and eight-node quadrilateral elements were used in the discretization to represent the reduced-order and higher-order models, respectively. It was found that the developed PINNs effectively predict model errors in both x and y displacement fields with small differences between predictions and ground truth. Our findings demonstrate that the integration of physics-informed loss functions enables neural networks (NNs) to surpass a purely data-driven approach for approximating model errors.",
        "subjects": [
            "cs.LG",
            "math.NA",
            "stat.CO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09201",
        "abstract url": "https://arxiv.org/abs/2411.09201",
        "title": "Noncontact Multi-Point Vital Sign Monitoring with mmWave MIMO Radar",
        "rating": "-3",
        "keywords": [
            [
                "Radar"
            ],
            [
                "physiological"
            ]
        ],
        "abstract": "Multi-point vital sign monitoring is essential for providing detailed insights into physiological changes. Traditional single-sensor approaches are inadequate for capturing multi-point vibrations. Existing contact-based solutions, while addressing this need, can cause discomfort and skin allergies, whereas noncontact optical and acoustic methods are highly susceptible to light interference and environmental noise. In this paper, we aim to develop a non-contact, multi-point vital sign monitoring technique using MIMO radar, focused on physically differentiating and precisely measuring chest-wall surface vibrations at multiple points induced by cardiopulmonary mechanical activity. The primary challenges in developing such a technique involve developing algorithms to extract and separate entangled signals, as well as establishing a reliable method for validating detection accuracy. To address these limitations, we introduce MultiVital, a wireless system that leverages mmWave Multiple-input Multiple-output (MIMO) radar for synchronous multi-point vital sign monitoring. It integrates two reference modalities: five-channel seismocardiography (SCG) sensors and a one-channel electrocardiogram (ECG) electrode, enabling comprehensive radar-based research and performance validation across multiple physiological metrics. Additionally, we have developed a multi-modal signal processing framework, consisting of a radar signal processing module, an SCG calibration module, and a spatial alignment scheme. To evaluate the radar signal processing module, we conducted mathematical derivation and simulation. The experimental results indicate that the noncontact MultiVital system achieves multi-point synchronous monitoring with high precision, highly consistent with the results from reference modalities.",
        "subjects": [
            "cs.AR",
            "eess.SP"
        ],
        "comment": "15 pages"
    },
    {
        "paper id": "2411.09209",
        "abstract url": "https://arxiv.org/abs/2411.09209",
        "title": "JoyVASA: Portrait and Animal Image Animation with Diffusion-Based Audio-Driven Facial Dynamics and Head Motion Generation",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "Facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Audio-driven portrait animation has made significant advances with diffusion-based models, improving video quality and lipsync accuracy. However, the increasing complexity of these models has led to inefficiencies in training and inference, as well as constraints on video length and inter-frame continuity. In this paper, we propose JoyVASA, a diffusion-based method for generating facial dynamics and head motion in audio-driven facial animation. Specifically, in the first stage, we introduce a decoupled facial representation framework that separates dynamic facial expressions from static 3D facial representations. This decoupling allows the system to generate longer videos by combining any static 3D facial representation with dynamic motion sequences. Then, in the second stage, a diffusion transformer is trained to generate motion sequences directly from audio cues, independent of character identity. Finally, a generator trained in the first stage uses the 3D facial representation and the generated motion sequences as inputs to render high-quality animations. With the decoupled facial representation and the identity-independent motion generation process, JoyVASA extends beyond human portraits to animate animal faces seamlessly. The model is trained on a hybrid dataset of private Chinese and public English data, enabling multilingual support. Experimental results validate the effectiveness of our approach. Future work will focus on improving real-time performance and refining expression control, further expanding the applications in portrait animation. The code is available at: https://github.com/jdh-algo/JoyVASA.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09229",
        "abstract url": "https://arxiv.org/abs/2411.09229",
        "title": "Efficient and Secure Cross-Domain Data-Sharing for Resource-Constrained Internet of Things",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "The growing complexity of Internet of Things (IoT) environments, particularly in cross-domain data sharing, presents significant security challenges. Existing data-sharing schemes often rely on computationally expensive cryptographic operations and centralized key management, limiting their effectiveness for resource-constrained devices. To address these issues, we propose an efficient, secure blockchain-based data-sharing scheme. First, our scheme adopts a distributed key generation method, which avoids single point of failure. This method also allows independent pseudonym generation and key updates, enhancing authentication flexibility while reducing computational overhead. Additionally, the scheme provides a complete data-sharing process, covering data uploading, storage, and sharing, while ensuring data traceability, integrity, and privacy. Security analysis shows that the proposed scheme is theoretically secure and resistant to various attacks, while performance evaluations demonstrate lower computational and communication overhead compared to existing solutions, making it both secure and efficient for IoT applications.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "15 pages,10 figures, submitted to Transactions on Information Forensics & Security in 19-Sep-2024"
    },
    {
        "paper id": "2411.09306",
        "abstract url": "https://arxiv.org/abs/2411.09306",
        "title": "Iterative tomographic reconstruction with TV prior for low-dose CBCT dental imaging",
        "rating": "-3",
        "keywords": [
            [
                "3D"
            ],
            [
                "clinical"
            ]
        ],
        "abstract": "Abstract Objective. Cone-beam computed tomography is becoming more and more popular in applications such as 3D dental imaging. Iterative methods compared to the standard Feldkamp algorithm have shown improvements in image quality of reconstruction of low-dose acquired data despite their long computing time. An interesting aspect of iterative methods is their ability to include prior information such as sparsity-constraint. While a large panel of optimization algorithms along with their adaptation to tomographic problems are available, they are mainly studied on 2D parallel or fan-beam data. The issues raised by 3D CBCT and moreover by truncated projections are still poorly understood. Approach. We compare different carefully designed optimization schemes in the context of realistic 3D dental imaging. Besides some known algorithms, SIRT-TV and MLEM, we investigate the primal-dual hybrid gradient (PDHG) approach and a newly proposed MLEM-TV optimizer. The last one is alternating EM steps and TV-denoising, combination not yet investigated for CBCT. Experiments are performed on both simulated data from a 3D jaw phantom and data acquired with a dental clinical scanner. Main results. With some adaptations to the specificities of CBCT operators, PDHG and MLEM-TV algorithms provide the best reconstruction quality. These results were obtained by comparing the full-dose image with a low-dose image and an ultra low-dose image. Significance. The convergence speed of the original iterative methods is hampered by the conical geometry and significantly reduced compared to parallel geometries. We promote the pre-conditioned version of PDHG and we propose a pre-conditioned version of the MLEM-TV algorithm. To the best of our knowledge, this is the first time PDHG and convergent MLEM-TV algorithms are evaluated on experimental dental CBCT data, where constraints such as projection truncation and presence of metal have to be jointly overcome.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09473",
        "abstract url": "https://arxiv.org/abs/2411.09473",
        "title": "Enhancing Scalability and Performance in Influence Maximization with Optimized Parallel Processing",
        "rating": "-3",
        "keywords": [
            [
                "graph"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "Influence Maximization (IM) is vital in viral marketing and biological network analysis for identifying key influencers. Given its NP-hard nature, approximate solutions are employed. This paper addresses scalability challenges in scale-out shared memory system by focusing on the state-of-the-art Influence Maximization via Martingales (IMM) benchmark. To enhance the work efficiency of the current IMM implementation, we propose EFFICIENTIMM with key strategies, including new parallelization scheme, NUMA-aware memory usage, dynamic load balancing and fine-grained adaptive data structures. Benchmarking on a 128-core CPU system with 8 NUMA nodes, EFFICIENTIMM demonstrated significant performance improvements, achieving an average 5.9x speedup over Ripples across 8 diverse SNAP datasets, when compared to the best execution times of the original Ripples framework. Additionally, on the Youtube graph, EFFICIENTIMM demonstrates a better memory access pattern with 357.4x reduction in L1+L2 cache misses as compared to Ripples.",
        "subjects": [
            "cs.DC",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09623",
        "abstract url": "https://arxiv.org/abs/2411.09623",
        "title": "Vision-based Manipulation of Transparent Plastic Bags in Industrial Setups",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "robotics",
                "robot"
            ],
            [
                "Industrial"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "This paper addresses the challenges of vision-based manipulation for autonomous cutting and unpacking of transparent plastic bags in industrial setups, aligning with the Industry 4.0 paradigm. Industry 4.0, driven by data, connectivity, analytics, and robotics, promises enhanced accessibility and sustainability throughout the value chain. The integration of autonomous systems, including collaborative robots (cobots), into industrial processes is pivotal for efficiency and safety. The proposed solution employs advanced Machine Learning algorithms, particularly Convolutional Neural Networks (CNNs), to identify transparent plastic bags under varying lighting and background conditions. Tracking algorithms and depth sensing technologies are utilized for 3D spatial awareness during pick and placement. The system addresses challenges in grasping and manipulation, considering optimal points, compliance control with vacuum gripping technology, and real-time automation for safe interaction in dynamic environments. The system's successful testing and validation in the lab with the FRANKA robot arm, showcases its potential for widespread industrial applications, while demonstrating effectiveness in automating the unpacking and cutting of transparent plastic bags for an 8-stack bulk-loader based on specific requirements and rigorous testing.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09643",
        "abstract url": "https://arxiv.org/abs/2411.09643",
        "title": "Modular Fault Diagnosis Framework for Complex Autonomous Driving Systems",
        "rating": "-3",
        "keywords": [
            [
                "Autonomous Driving",
                "vehicle"
            ],
            [
                "Diagnosis"
            ]
        ],
        "abstract": "Fault diagnosis is crucial for complex autonomous mobile systems, especially for modern-day autonomous driving (AD). Different actors, numerous use cases, and complex heterogeneous components motivate a fault diagnosis of the system and overall system integrity. AD systems are composed of many heterogeneous components, each with different functionality and possibly using a different algorithm (e.g., rule-based vs. AI components). In addition, these components are subject to the vehicle's driving state and are highly dependent. This paper, therefore, faces this problem by presenting the concept of a modular fault diagnosis framework for AD systems. The concept suggests modular state monitoring and diagnosis elements, together with a state- and dependency-aware aggregation method. Our proposed classification scheme allows for the categorization of the fault diagnosis modules. The concept is implemented on AD shuttle buses and evaluated to demonstrate its capabilities.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Accepted at 2024 IEEE 20th International Conference on Intelligent Computer Communication and Processing (ICCP 2024)"
    },
    {
        "paper id": "2411.09749",
        "abstract url": "https://arxiv.org/abs/2411.09749",
        "title": "Adversarial Attacks Using Differentiable Rendering: A Survey",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "depth",
                "Radiance Fields"
            ],
            [
                "Attacks"
            ],
            [
                "facial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Differentiable rendering methods have emerged as a promising means for generating photo-realistic and physically plausible adversarial attacks by manipulating 3D objects and scenes that can deceive deep neural networks (DNNs). Recently, differentiable rendering capabilities have evolved significantly into a diverse landscape of libraries, such as Mitsuba, PyTorch3D, and methods like Neural Radiance Fields and 3D Gaussian Splatting for solving inverse rendering problems that share conceptually similar properties commonly used to attack DNNs, such as back-propagation and optimization. However, the adversarial machine learning research community has not yet fully explored or understood such capabilities for generating attacks. Some key reasons are that researchers often have different attack goals, such as misclassification or misdetection, and use different tasks to accomplish these goals by manipulating different representation in a scene, such as the mesh or texture of an object. This survey adopts a task-oriented unifying framework that systematically summarizes common tasks, such as manipulating textures, altering illumination, and modifying 3D meshes to exploit vulnerabilities in DNNs. Our framework enables easy comparison of existing works, reveals research gaps and spotlights exciting future research directions in this rapidly evolving field. Through focusing on how these tasks enable attacks on various DNNs such as image classification, facial recognition, object detection, optical flow and depth estimation, our survey helps researchers and practitioners better understand the vulnerabilities of computer vision systems against photorealistic adversarial attacks that could threaten real-world applications.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09787",
        "abstract url": "https://arxiv.org/abs/2411.09787",
        "title": "ART-Rx: A Proportional-Integral-Derivative (PID) Controlled Adaptive Real-Time Threshold Receiver for Molecular Communication",
        "rating": "-3",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Bio-Nano",
                "healthcare"
            ]
        ],
        "abstract": "Molecular communication (MC) in microfluidic channels faces significant challenges in signal detection due to the stochastic nature of molecule propagation and dynamic, noisy environments. Conventional detection methods often struggle under varying channel conditions, leading to high bit error rates (BER) and reduced communication efficiency. This paper introduces ART-Rx, a novel Adaptive Real-Time Threshold Receiver for MC that addresses these challenges. Implemented within a conceptual system-on-chip (SoC), ART-Rx employs a Proportional-Integral-Derivative (PID) controller to dynamically adjust the detection threshold based on observed errors in real time. Comprehensive simulations using MATLAB and Smoldyn compare ART-Rx's performance against a statistically optimal detection threshold across various scenarios, including different levels of interference, concentration shift keying (CSK) levels, flow velocities, transmitter-receiver distances, diffusion coefficients, and binding rates. The results demonstrate that ART-Rx significantly outperforms conventional methods, maintaining consistently low BER and bit error probabilities (BEP) even in high-noise conditions and extreme channel environments. The system exhibits exceptional robustness to interference and shows the potential to enable higher data rates in CSK modulation. Furthermore, because ART-Rx is effectively adaptable to varying environmental conditions in microfluidic channels, it offers a computationally efficient and straightforward approach to enhance signal detection in nanoscale communication systems. This approach presents a promising control theory-based solution to improve the reliability of data transmission in practical MC systems, with potential applications in healthcare, brain-machine interfaces (BMI), and the Internet of Bio-Nano Things (IoBNT).",
        "subjects": [
            "cs.ET",
            "eess.SY"
        ],
        "comment": "14 pages, 7 figures, submitted to IEEE Transactions on Molecular, Biological, and Multi-Scale Communications (TMBMC)"
    },
    {
        "paper id": "2411.09870",
        "abstract url": "https://arxiv.org/abs/2411.09870",
        "title": "Impact-Aware Control using Time-Invariant Reference Spreading",
        "rating": "-3",
        "keywords": [
            [
                "robotic manipulation"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "With the goal of increasing the speed and efficiency in robotic manipulation, a control approach is presented that aims to utilize intentional simultaneous impacts to its advantage. This approach exploits the concept of the time-invariant reference spreading framework, in which partly-overlapping ante- and post-impact reference vector fields are used. These vector fields are coupled via an impact model in proximity of the expected impact area, minimizing the otherwise large impact-induced velocity errors and control efforts. We show how a nonsmooth physics engine can be used to construct this impact model for complex scenarios, which warrants applicability to a large range of possible impact states without requiring contact stiffness and damping parameters. In addition, a novel interim-impact control mode provides robustness in the execution against the inevitable lack of exact impact simultaneity and the corresponding unreliable velocity error during the time when contact is only partially established. This interim mode uses a position feedback signal that is derived from the ante-impact velocity reference to promote contact completion, and smoothly transitions into the post-impact mode. An experimental validation of time-invariant reference spreading control is presented for the first time through a set of 600 robotic hit-and-push and dual-arm grabbing experiments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "15 pages, 10 figures. Submitted to IEEE Transactions on Robotics (T-RO)"
    },
    {
        "paper id": "2411.10487",
        "abstract url": "https://arxiv.org/abs/2411.10487",
        "title": "Architectural Patterns for Designing Quantum Artificial Intelligence Systems",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Utilising quantum computing technology to enhance artificial intelligence systems is expected to improve training and inference times, increase robustness against noise and adversarial attacks, and reduce the number of parameters without compromising accuracy. However, moving beyond proof-of-concept or simulations to develop practical applications of these systems while ensuring high software quality faces significant challenges due to the limitations of quantum hardware and the underdeveloped knowledge base in software engineering for such systems. In this work, we have conducted a systematic mapping study to identify the challenges and solutions associated with the software architecture of quantum-enhanced artificial intelligence systems. Our review uncovered several architectural patterns that describe how quantum components can be integrated into inference engines, as well as middleware patterns that facilitate communication between classical and quantum components. These insights have been compiled into a catalog of architectural patterns. Each pattern realises a trade-off between efficiency, scalability, trainability, simplicity, portability and deployability, and other software quality attributes.",
        "subjects": [
            "cs.SE",
            "quant-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.13577",
        "abstract url": "https://arxiv.org/abs/2411.13577",
        "title": "WavChat: A Survey of Spoken Dialogue Models",
        "rating": "-3",
        "keywords": [
            [
                "industrial"
            ],
            [
                "music",
                "text-to-speech"
            ],
            [
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recent advancements in spoken dialogue models, exemplified by systems like GPT-4o, have captured significant attention in the speech domain. Compared to traditional three-tier cascaded spoken dialogue models that comprise speech recognition (ASR), large language models (LLMs), and text-to-speech (TTS), modern spoken dialogue models exhibit greater intelligence. These advanced spoken dialogue models not only comprehend audio, music, and other speech-related features, but also capture stylistic and timbral characteristics in speech. Moreover, they generate high-quality, multi-turn speech responses with low latency, enabling real-time interaction through simultaneous listening and speaking capability. Despite the progress in spoken dialogue systems, there is a lack of comprehensive surveys that systematically organize and analyze these systems and the underlying technologies. To address this, we have first compiled existing spoken dialogue systems in the chronological order and categorized them into the cascaded and end-to-end paradigms. We then provide an in-depth overview of the core technologies in spoken dialogue models, covering aspects such as speech representation, training paradigm, streaming, duplex, and interaction capabilities. Each section discusses the limitations of these technologies and outlines considerations for future research. Additionally, we present a thorough review of relevant datasets, evaluation metrics, and benchmarks from the perspectives of training and evaluating spoken dialogue systems. We hope this survey will contribute to advancing both academic research and industrial applications in the field of spoken dialogue systems. The related material is available at https://github.com/jishengpeng/WavChat.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.LG",
            "cs.MM",
            "cs.SD"
        ],
        "comment": "60 papes, working in progress"
    },
    {
        "paper id": "2411.09403",
        "abstract url": "https://arxiv.org/abs/2411.09403",
        "title": "Quantum Machine Learning: An Interplay Between Quantum Computing and Machine Learning",
        "rating": "-3.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "Quantum"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Quantum machine learning (QML) is a rapidly growing field that combines quantum computing principles with traditional machine learning. It seeks to revolutionize machine learning by harnessing the unique capabilities of quantum mechanics and employs machine learning techniques to advance quantum computing research. This paper introduces quantum computing for the machine learning paradigm, where variational quantum circuits (VQC) are used to develop QML architectures on noisy intermediate-scale quantum (NISQ) devices. We discuss machine learning for the quantum computing paradigm, showcasing our recent theoretical and empirical findings. In particular, we delve into future directions for studying QML, exploring the potential industrial impacts of QML research.",
        "subjects": [
            "quant-ph",
            "cs.AI"
        ],
        "comment": "In submission"
    },
    {
        "paper id": "2411.09476",
        "abstract url": "https://arxiv.org/abs/2411.09476",
        "title": "Graph Neural Networks and Differential Equations: A hybrid approach for data assimilation of fluid flows",
        "rating": "-3.5",
        "keywords": [
            [
                "inpainting"
            ],
            [
                "GNNs",
                "Graph"
            ],
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This study presents a novel hybrid approach that combines Graph Neural Networks (GNNs) with Reynolds-Averaged Navier Stokes (RANS) equations to enhance the accuracy of mean flow reconstruction across a range of fluid dynamics applications. Traditional purely data-driven Neural Networks (NNs) models, often struggle maintaining physical consistency. Moreover, they typically require large datasets to achieve reliable performances. The GNN framework, which naturally handles unstructured data such as complex geometries in Computational Fluid Dynamics (CFD), is here integrated with RANS equations as a physical baseline model. The methodology leverages the adjoint method, enabling the use of RANS-derived gradients as optimization terms in the GNN training process. This ensures that the learned model adheres to the governing physics, maintaining physical consistency while improving the prediction accuracy. We test our approach on multiple CFD scenarios, including cases involving generalization with respect to the Reynolds number, sparse measurements, denoising and inpainting of missing portions of the mean flow. The results demonstrate significant improvements in the accuracy of the reconstructed mean flow compared to purely data-driven models, using limited amounts of data in the training dataset. The key strengths of this study are the integration of physical laws into the training process of the GNN, and the ability to achieve high-accuracy predictions with a limited amount of data, making this approach particularly valuable for applications in fluid dynamics where data is often scarce.",
        "subjects": [
            "physics.flu-dyn",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09618",
        "abstract url": "https://arxiv.org/abs/2411.09618",
        "title": "MICCAI-CDMRI 2023 QuantConn Challenge Findings on Achieving Robust Quantitative Connectivity through Harmonized Preprocessing of Diffusion MRI",
        "rating": "-3.5",
        "keywords": [
            [
                "voxel"
            ],
            [
                "Diffusion"
            ],
            [
                "biological",
                "MRI"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "White matter alterations are increasingly implicated in neurological diseases and their progression. International-scale studies use diffusion-weighted magnetic resonance imaging (DW-MRI) to qualitatively identify changes in white matter microstructure and connectivity. Yet, quantitative analysis of DW-MRI data is hindered by inconsistencies stemming from varying acquisition protocols. There is a pressing need to harmonize the preprocessing of DW-MRI datasets to ensure the derivation of robust quantitative diffusion metrics across acquisitions. In the MICCAI-CDMRI 2023 QuantConn challenge, participants were provided raw data from the same individuals collected on the same scanner but with two different acquisitions and tasked with preprocessing the DW-MRI to minimize acquisition differences while retaining biological variation. Submissions are evaluated on the reproducibility and comparability of cross-acquisition bundle-wise microstructure measures, bundle shape features, and connectomics. The key innovations of the QuantConn challenge are that (1) we assess bundles and tractography in the context of harmonization for the first time, (2) we assess connectomics in the context of harmonization for the first time, and (3) we have 10x additional subjects over prior harmonization challenge, MUSHAC and 100x over SuperMUDI. We find that bundle surface area, fractional anisotropy, connectome assortativity, betweenness centrality, edge count, modularity, nodal strength, and participation coefficient measures are most biased by acquisition and that machine learning voxel-wise correction, RISH mapping, and NeSH methods effectively reduce these biases. In addition, microstructure measures AD, MD, RD, bundle length, connectome density, efficiency, and path length are least biased by these acquisition differences.",
        "subjects": [
            "physics.med-ph",
            "cs.LG"
        ],
        "comment": "Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2024/019"
    },
    {
        "paper id": "2411.09915",
        "abstract url": "https://arxiv.org/abs/2411.09915",
        "title": "Physics-informed Machine Learning for Battery Pack Thermal Management",
        "rating": "-3.5",
        "keywords": [
            [
                "Thermal"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "With the popularity of electric vehicles, the demand for lithium-ion batteries is increasing. Temperature significantly influences the performance and safety of batteries. Battery thermal management systems can effectively control the temperature of batteries; therefore, the performance and safety can be ensured. However, the development process of battery thermal management systems is time-consuming and costly due to the extensive training dataset needed by data-driven models requiring enormous computational costs for finite element analysis. Therefore, a new approach to constructing surrogate models is needed in the era of AI. Physics-informed machine learning enforces the physical laws in surrogate models, making it the perfect candidate for estimating battery pack temperature distribution. In this study, we first developed a 21700 battery pack indirect liquid cooling system with cold plates on the top and bottom with thermal paste surrounding the battery cells. Then, the simplified finite element model was built based on experiment results. Due to the high coolant flow rate, the cold plates can be considered as constant temperature boundaries, while battery cells are the heat sources. The physics-informed convolutional neural network served as a surrogate model to estimate the temperature distribution of the battery pack. The loss function was constructed considering the heat conduction equation based on the finite difference method. The physics-informed loss function helped the convergence of the training process with less data. As a result, the physics-informed convolutional neural network showed more than 15 percents improvement in accuracy compared to the data-driven method with the same training data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09310",
        "abstract url": "https://arxiv.org/abs/2411.09310",
        "title": "Exploring Zero-Shot Anomaly Detection with CLIP in Medical Imaging: Are We There Yet?",
        "rating": "-4",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "Medical",
                "clinical",
                "tumor"
            ],
            [
                "industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Zero-shot anomaly detection (ZSAD) offers potential for identifying anomalies in medical imaging without task-specific training. In this paper, we evaluate CLIP-based models, originally developed for industrial tasks, on brain tumor detection using the BraTS-MET dataset. Our analysis examines their ability to detect medical-specific anomalies with no or minimal supervision, addressing the challenges posed by limited data annotation. While these models show promise in transferring general knowledge to medical tasks, their performance falls short of the precision required for clinical use. Our findings highlight the need for further adaptation before CLIP-based models can be reliably applied to medical anomaly detection.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted at 3rd AIxIA Workshop on Artificial Intelligence for Healthcare and 5th Data4SmartHealth"
    },
    {
        "paper id": "2411.09320",
        "abstract url": "https://arxiv.org/abs/2411.09320",
        "title": "AMARETTO: Enabling Efficient Quantum Algorithm Emulation on Low-Tier FPGAs",
        "rating": "-4",
        "keywords": [
            [
                "FPGAs"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "Researchers and industries are increasingly drawn to quantum computing for its computational potential. However, validating new quantum algorithms is challenging due to the limitations of current quantum devices. Software simulators are time and memory-consuming, making hardware emulators an attractive alternative. This article introduces AMARETTO (quAntuM ARchitecture EmulaTion TechnOlogy), designed for quantum computing emulation on low-tier Field-Programmable gate arrays (FPGAs), supporting Clifford+T and rotational gate sets. It simplifies and accelerates the verification of quantum algorithms using a Reduced-Instruction-Set-Computer (RISC)-like structure and efficient handling of sparse quantum gates. A dedicated compiler translates OpenQASM 2.0 into RISC-like instructions. AMARETTO is validated against the Qiskit simulators. Our results show successful emulation of sixteen qubits on a AMD Kria KV260 SoM. This approach rivals other works in emulated qubit capacity on a smaller, more affordable FPGA",
        "subjects": [
            "quant-ph",
            "eess.SY"
        ],
        "comment": "paper accepted at the IEEE International Conference on Electronics Circuits and Systems 2024 conference, 4 pages, 6 figures"
    },
    {
        "paper id": "2411.09440",
        "abstract url": "https://arxiv.org/abs/2411.09440",
        "title": "Evaluation of RIS-Enabled B5G/6G Indoor Positioning and Mapping using Ray Tracing Models",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "super-resolution"
            ],
            [
                "6G"
            ]
        ],
        "abstract": "A Reconfigurable Intelligent Surface (RIS) can significantly enhance network positioning and mapping, acting as an additional anchor point in the reference system and improving signal strength and measurement diversity through the generation of favorable scattering conditions and virtual line-of-sight paths. In this paper, we present a comprehensive framework aimed at user localization and scatterer position estimation in an indoor environment with multipath effects. Our approach leverages beam sweeping through codebook-based beamforming at an 1-bit RIS to scan the environment, applies signal component extraction mechanisms, and utilizes a super-resolution algorithm for angle-based positioning of both connected users and scatterers. To validate the system's effectiveness, accurate 3D ray tracing models are employed, ensuring the robustness and effectiveness of the proposed approach in practical scenarios.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "6 pages, 4 figures, to be presented in an ESA workshop"
    },
    {
        "paper id": "2411.09493",
        "abstract url": "https://arxiv.org/abs/2411.09493",
        "title": "Strategic Sacrifice: Self-Organized Robot Swarm Localization for Inspection Productivity",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "Robot"
            ],
            [
                "biological"
            ]
        ],
        "abstract": "Robot swarms offer significant potential for inspecting diverse infrastructure, ranging from bridges to space stations. However, effective inspection requires accurate robot localization, which demands substantial computational resources and limits productivity. Inspired by biological systems, we introduce a novel cooperative localization mechanism that minimizes collective computation expenditure through self-organized sacrifice. Here, a few agents bear the computational burden of localization; through local interactions, they improve the inspection productivity of the swarm. Our approach adaptively maximizes inspection productivity for unconstrained trajectories in dynamic interaction and environmental settings. We demonstrate the optimality and robustness using mean-field analytical models, multi-agent simulations, and hardware experiments with metal climbing robots inspecting a 3D cylinder.",
        "subjects": [
            "cs.RO",
            "cs.MA"
        ],
        "comment": "14 pages, 10 figures, 17th International Symposium on Distributed Autonomous Robotic Systems (DARS'24)"
    },
    {
        "paper id": "2411.09603",
        "abstract url": "https://arxiv.org/abs/2411.09603",
        "title": "Smart Automation in Luxury Leather Shoe Polishing: A Human Centric Robotic Approach",
        "rating": "-4",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "robot"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "The polishing of luxury leather shoes is a delicate, labor intensive process traditionally performed by skilled craftsmen. Footwear companies aim to automate parts of this process to enhance quality, productivity, and operator well-being, but the unique nature of luxury shoe production presents challenges. This paper introduces a solution involving a collaborative robotic cell to assist in shoe polishing. A collaborative robotic manipulator, equipped with a specialized tool and governed by force control, executes the polishing tasks. Key factors such as trajectory design, applied force, polishing speed, and polish amount were analyzed. Polishing trajectories are designed using CAM software and transferred to the robot control system. Human operators design the process, supervise the robot, and perform final finishing, ensuring their expertise is integral to achieving quality. Extensive testing on various shoe models showed significant improvements in quality and reliability, leading to successful implementation on an industrial production line.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09666",
        "abstract url": "https://arxiv.org/abs/2411.09666",
        "title": "Evaluating 5G Networks for U-Space Applications: Insights from Dense Urban Measurement Campaign",
        "rating": "-4",
        "keywords": [
            [
                "5G"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "This paper examines the communication performance of unmanned aerial vehicles (UAVs) in dense urban environments, specifically in Benidorm, Spain. Through a comprehensive measurement campaign, we assessed key performance indicators (KPIs) relating to received signal strength and quality as well as rate across various locations, altitudes, operators, technologies, and frequencies, using different measurement equipment. The results highlight significant challenges, primarily due to the lack of planning for aerial coverage and interference, revealing that current cellular networks may fall short in supporting U-space communication needs. The paper calls for network upgrades to ensure reliable UAV operations in urban airspace, contributing to the integration of UAVS in urban logistics and mobility.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09822",
        "abstract url": "https://arxiv.org/abs/2411.09822",
        "title": "A Self-Supervised Model for Multi-modal Stroke Risk Prediction",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "Biobank",
                "MRI",
                "clinical"
            ],
            [
                "tabular"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Predicting stroke risk is a complex challenge that can be enhanced by integrating diverse clinically available data modalities. This study introduces a self-supervised multimodal framework that combines 3D brain imaging, clinical data, and image-derived features to improve stroke risk prediction prior to onset. By leveraging large unannotated clinical datasets, the framework captures complementary and synergistic information across image and tabular data modalities. Our approach is based on a contrastive learning framework that couples contrastive language-image pretraining with an image-tabular matching module, to better align multimodal data representations in a shared latent space. The model is trained on the UK Biobank, which includes structural brain MRI and clinical data. We benchmark its performance against state-of-the-art unimodal and multimodal methods using tabular, image, and image-tabular combinations under diverse frozen and trainable model settings. The proposed model outperformed self-supervised tabular (image) methods by 2.6% (2.6%) in ROC-AUC and by 3.3% (5.6%) in balanced accuracy. Additionally, it showed a 7.6% increase in balanced accuracy compared to the best multimodal supervised model. Through interpretable tools, our approach demonstrated better integration of tabular and image data, providing richer and more aligned embeddings. Gradient-weighted Class Activation Mapping heatmaps further revealed activated brain regions commonly associated in the literature with brain aging, stroke risk, and clinical outcomes. This robust self-supervised multimodal framework surpasses state-of-the-art methods for stroke risk prediction and offers a strong foundation for future studies integrating diverse data modalities to advance clinical predictive modelling.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted as oral paper at AIM-FM workshop, Neurips 2024"
    },
    {
        "paper id": "2411.09867",
        "abstract url": "https://arxiv.org/abs/2411.09867",
        "title": "To Optimize Human-in-the-loop Learning in Repeated Routing Games",
        "rating": "-4",
        "keywords": [
            [
                "navigation"
            ],
            [
                "graphs"
            ],
            [
                "recommendation"
            ]
        ],
        "abstract": "Today navigation applications (e.g., Waze and Google Maps) enable human users to learn and share the latest traffic observations, yet such information sharing simply aids selfish users to predict and choose the shortest paths to jam each other. Prior routing game studies focus on myopic users in oversimplified one-shot scenarios to regulate selfish routing via information hiding or pricing mechanisms. For practical human-in-the-loop learning (HILL) in repeated routing games, we face non-myopic users of differential past observations and need new mechanisms (preferably non-monetary) to persuade users to adhere to the optimal path recommendations. We model the repeated routing game in a typical parallel transportation network, which generally contains one deterministic path and $N$ stochastic paths. We first prove that no matter under the information sharing mechanism in use or the latest routing literature's hiding mechanism, the resultant price of anarchy (PoA) for measuring the efficiency loss from social optimum can approach infinity, telling arbitrarily poor exploration-exploitation tradeoff over time. Then we propose a novel user-differential probabilistic recommendation (UPR) mechanism to differentiate and randomize path recommendations for users with differential learning histories. We prove that our UPR mechanism ensures interim individual rationality for all users and significantly reduces $\\text{PoA}=\\infty$ to close-to-optimal $\\text{PoA}=1+\\frac{1}{4N+3}$, which cannot be further reduced by any other non-monetary mechanism. In addition to theoretical analysis, we conduct extensive experiments using real-world datasets to generalize our routing graphs and validate the close-to-optimal performance of UPR mechanism.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "This is the technical report of our TMC paper"
    },
    {
        "paper id": "2411.09924",
        "abstract url": "https://arxiv.org/abs/2411.09924",
        "title": "A Polarization Image Dehazing Method Based on the Principle of Physical Diffusion",
        "rating": "-4",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "remote sensing"
            ],
            [
                "Dehazing"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Computer vision is increasingly used in areas such as unmanned vehicles, surveillance systems and remote sensing. However, in foggy scenarios, image degradation leads to loss of target details, which seriously affects the accuracy and effectiveness of these vision tasks. Polarized light, due to the fact that its electromagnetic waves vibrate in a specific direction, is able to resist scattering and refraction effects in complex media more effectively compared to unpolarized light. As a result, polarized light has a greater ability to maintain its polarization characteristics in complex transmission media and under long-distance imaging conditions. This property makes polarized imaging especially suitable for complex scenes such as outdoor and underwater, especially in foggy environments, where higher quality images can be obtained. Based on this advantage, we propose an innovative semi-physical polarization dehazing method that does not rely on an external light source. The method simulates the diffusion process of fog and designs a diffusion kernel that corresponds to the image blurriness caused by this diffusion. By employing spatiotemporal Fourier transforms and deconvolution operations, the method recovers the state of fog droplets prior to diffusion and the light inversion distribution of objects. This approach effectively achieves dehazing and detail enhancement of the scene.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09693",
        "abstract url": "https://arxiv.org/abs/2411.09693",
        "title": "CropCraft: Inverse Procedural Modeling for 3D Reconstruction of Crop Plants",
        "rating": "-5",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "robotics"
            ],
            [
                "biologically"
            ],
            [
                "agricultural"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The ability to automatically build 3D digital twins of plants from images has countless applications in agriculture, environmental science, robotics, and other fields. However, current 3D reconstruction methods fail to recover complete shapes of plants due to heavy occlusion and complex geometries. In this work, we present a novel method for 3D reconstruction of agricultural crops based on optimizing a parametric model of plant morphology via inverse procedural modeling. Our method first estimates depth maps by fitting a neural radiance field and then employs Bayesian optimization to estimate plant morphological parameters that result in consistent depth renderings. The resulting 3D model is complete and biologically plausible. We validate our method on a dataset of real images of agricultural fields, and demonstrate that the reconstructions can be used for a variety of monitoring and simulation applications.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2411.09191",
        "abstract url": "https://arxiv.org/abs/2411.09191",
        "title": "Informational Puts",
        "rating": "-10",
        "keywords": [],
        "abstract": "We fully characterize how dynamic information should be provided to uniquely implement the largest equilibrium in dynamic binary-action supermodular games. The designer offers an informational put: she stays silent in good times, but injects asymmetric and inconclusive public information if players lose faith. There is (i) no multiplicity gap: the largest (partially) implementable equilibrium can be implemented uniquely; and (ii) no intertemporal commitment gap: the policy is sequentially optimal. Our results have sharp implications for the design of policy in coordination environments.",
        "subjects": [
            "econ.TH",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09217",
        "abstract url": "https://arxiv.org/abs/2411.09217",
        "title": "SmartInv: Multimodal Learning for Smart Contract Invariant Inference",
        "rating": "-10",
        "keywords": [],
        "abstract": "Smart contracts are software programs that enable diverse business activities on the blockchain. Recent research has identified new classes of \"machine un-auditable\" bugs that arise from both transactional contexts and source code. Existing detection methods require human understanding of underlying transaction logic and manual reasoning across different sources of context (i.e. modalities), such as code, dynamic transaction executions, and natural language specifying the expected transaction behavior. To automate the detection of ``machine un-auditable'' bugs, we present SmartInv, an accurate and fast smart contract invariant inference framework. Our key insight is that the expected behavior of smart contracts, as specified by invariants, relies on understanding and reasoning across multimodal information, such as source code and natural language. We propose a new prompting strategy to foundation models, Tier of Thought (ToT), to reason across multiple modalities of smart contracts and ultimately to generate invariants. By checking the violation of these generated invariants, SmartInv can identify potential vulnerabilities. We evaluate SmartInv on real-world contracts and re-discover bugs that resulted in multi-million dollar losses over the past 2.5 years (from January 1, 2021 to May 31, 2023). Our extensive evaluation shows that SmartInv generates (3.5X) more bug-critical invariants and detects (4$\\times$) more critical bugs compared to the state-of-the-art tools in significantly (150X) less time. \\sys uncovers 119 zero-day vulnerabilities from the 89,621 real-world contracts. Among them, five are critical zero-day bugs confirmed by developers as ``high severity.''",
        "subjects": [
            "cs.SE",
            "cs.CR",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09235",
        "abstract url": "https://arxiv.org/abs/2411.09235",
        "title": "FAS for Secure and Covert Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "This letter considers a fluid antenna system (FAS)-aided secure and covert communication system, where the transmitter adjusts multiple fluid antennas' positions to achieve secure and covert transmission under the threat of an eavesdropper and the detection of a warden. This letter aims to maximize the secrecy rate while satisfying the covertness constraint. Unfortunately, the optimization problem is non-convex due to the coupled variables. To tackle this, we propose an alternating optimization (AO) algorithm to alternatively optimize the optimization variables in an iterative manner. In particular, we use a penalty-based method and the majorization-minimization (MM) algorithm to optimize the transmit beamforming and fluid antennas' positions, respectively. Simulation results show that FAS can significantly improve the performance of secrecy and covertness compared to the fixed-position antenna (FPA)-based schemes.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09252",
        "abstract url": "https://arxiv.org/abs/2411.09252",
        "title": "Implementing an Optimized and Secured Multimedia Streaming Protocol in a Participatory Sensing Scenario",
        "rating": "-10",
        "keywords": [],
        "abstract": "Multimedia streaming protocols are becoming increasingly popular in Crowdsensing due to their ability to deliver high-quality video content over the internet in real-time. Streaming multimedia content, as in the context of live video streaming, requires high bandwidth and large storage capacity to ensure a sufficient throughput. Crowdsensing can distribute information about shared video contents among multiple users in network, reducing storage capacity and computational and bandwidth requirements. However, Crowdsensing introduces several security constraints that must be taken into account to ensure the confidentiality, integrity, and availability of the data. In the specific case of video streaming, commonly named as visual crowdsensing (VCS) within this context, data is transmitted over wireless networks, making it vulnerable to security breaches and susceptible to eavesdropping and interception by attackers. Multimedias often contains sensitive user data and may be subject to various privacy laws, including data protection laws and laws related to photography and video recording, based on local GDPR (General Data Protection Regulation). For this reason the realization of a secure protocol optimized for a distributed data streaming in real-time becomes increasingly important in crowdsensing and smart-enviroment context. In this article, we will discuss the use of a symmetric AES-CTR encryption based protocol for securing data streaming over a crowd-sensed network.",
        "subjects": [
            "cs.NI",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09275",
        "abstract url": "https://arxiv.org/abs/2411.09275",
        "title": "Pkd-tree: Parallel $k$d-tree with Batch Updates",
        "rating": "-10",
        "keywords": [],
        "abstract": "The $k$d-tree is one of the most widely used data structures to manage multi-dimensional data. Due to the ever-growing data volume, it is imperative to consider parallelism in $k$d-trees. However, we observed challenges in existing parallel kd-tree implementations, for both constructions and updates. The goal of this paper is to develop efficient in-memory $k$d-trees by supporting high parallelism and cache-efficiency. We propose the Pkd-tree (Parallel $k$d-tree), a parallel $k$d-tree that is efficient both in theory and in practice. The Pkd-tree supports parallel tree construction, batch update (insertion and deletion), and various queries including k-nearest neighbor search, range query, and range count. We proved that our algorithms have strong theoretical bounds in work (sequential time complexity), span (parallelism), and cache complexity. Our key techniques include 1) an efficient construction algorithm that optimizes work, span, and cache complexity simultaneously, and 2) reconstruction-based update algorithms that guarantee the tree to be weight-balanced. With the new algorithmic insights and careful engineering effort, we achieved a highly optimized implementation of the Pkd-tree. We tested Pkd-tree with various synthetic and real-world datasets, including both uniform and highly skewed data. We compare the Pkd-tree with state-of-the-art parallel $k$d-tree implementations. In all tests, with better or competitive query performance, Pkd-tree is much faster in construction and updates consistently than all baselines. We released our code.",
        "subjects": [
            "cs.DS",
            "cs.DB",
            "cs.DC",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09287",
        "abstract url": "https://arxiv.org/abs/2411.09287",
        "title": "The Communication-Friendly Privacy-Preserving Machine Learning against Malicious Adversaries",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the increasing emphasis on privacy regulations, such as GDPR, protecting individual privacy and ensuring compliance have become critical concerns for both individuals and organizations. Privacy-preserving machine learning (PPML) is an innovative approach that allows for secure data analysis while safeguarding sensitive information. It enables organizations to extract valuable insights from data without compromising privacy. Secure multi-party computation (MPC) is a key tool in PPML, as it allows multiple parties to jointly compute functions without revealing their private inputs, making it essential in multi-server environments. We address the performance overhead of existing maliciously secure protocols, particularly in finite rings like $\\mathbb{Z}_{2^\\ell}$, by introducing an efficient protocol for secure linear function evaluation. We implement our maliciously secure MPC protocol on GPUs, significantly improving its efficiency and scalability. We extend the protocol to handle linear and non-linear layers, ensuring compatibility with a wide range of machine-learning models. Finally, we comprehensively evaluate machine learning models by integrating our protocol into the workflow, enabling secure and efficient inference across simple and complex models, such as convolutional neural networks (CNNs).",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09303",
        "abstract url": "https://arxiv.org/abs/2411.09303",
        "title": "Model-Guided Fieldwork: A Practical, Methodological and Philosophical Investigation in the use of Ethnomethodology for Engineering Software Requirements",
        "rating": "-10",
        "keywords": [],
        "abstract": "Ethnomethodological fieldwork has long been acknowledged as a potentially valuable way of informing the design of technology. However, there is relatively little methodological support for this activity, particularly in relation to the systematic approaches to development advocated in mainstream software and requirements engineering. This thesis focuses on the use of ethnomethodological fieldwork for the engineering of software requirements. Firstly, it proposes an approach, dubbed \"Model Guided Fieldwork,\" to support a fieldworker in making observations that may contribute to a technological development process. It does this by supplementing the normal debriefing sessions that a fieldworker and a technologist might have, with a lightweight iterative system modelling exercise, in such a way that the fieldwork and modelling can be mutually guiding. Secondly, the thesis presents an application of this approach in a high-profile e-Science project. This case study provides an opportunity to examine the relationship between ethnomethodological ethnography and requirements engineering empirically. Thirdly, the thesis addresses a number of theoretical and philosophical concerns relating to its project. This consists in a number of clarifications and counterarguments which aim to better situate ethnomethodological fieldwork as a method of requirements elicitation. In these three regards the thesis constitutes a practical methodological and philosophical investigation into the topic at hand.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "A thesis submitted for the degree of DPhil"
    },
    {
        "paper id": "2411.09307",
        "abstract url": "https://arxiv.org/abs/2411.09307",
        "title": "Model-Based Event-Triggered Implementation of Hybrid Controllers Using Finite-Time Convergent Observers",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we explore the conditions for asymptotic stability of the hybrid closed-loop system resulting from the interconnection of a nonlinear plant, an intelligent sensor that generates finite-time convergent estimates of the plant state, and a controller node that receives opportunistic samples from the sensor node when certain model-based event-triggering conditions are met. The proposed method is endowed with a degree of separation, in the sense that the controller design is independent of the sensor design. This is achieved under mild regularity conditions imposed on the hybrid closed-loop system and the existence of persistently flowing solutions. We demonstrate the versatility of the method by implementing it on: 1) a sampled-data controller for regulation of linear plants; 2) a synergistic controller for attitude stabilization of rigid bodies. The effectiveness of these novel controllers is demonstrated through numerical simulations.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09315",
        "abstract url": "https://arxiv.org/abs/2411.09315",
        "title": "Sustainable Hardware Specialization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Hardware specialization is commonly viewed as a way to scale performance in the dark silicon era with modern-day SoCs featuring multiple tens of dedicated accelerators. By only powering on hardware circuitry when needed, accelerators fundamentally trade off chip area for power efficiency. Dark silicon however comes with a severe downside, namely its environmental footprint. While hardware specialization typically reduces the operational footprint through high energy efficiency, the embodied footprint incurred by integrating additional accelerators on chip leads to a net overall increase in environmental footprint, which has led prior work to conclude that dark silicon is not a sustainable design paradigm. We explore sustainable hardware specialization through reconfigurable logic that has the potential to drastically reduce the environmental footprint compared to a sea of accelerators by amortizing its embodied footprint across multiple applications. We present an abstract analytical model that evaluates the sustainability implications of replacing dedicated accelerators with a reconfigurable accelerator. We derive hardware synthesis results on ASIC and CGRA (a representative reconfigurable fabric) for chip area and energy numbers for a wide variety of kernels. We input these results to the analytical model and conclude that reconfigurable fabric is more sustainable. We find that as few as a handful to a dozen accelerators can be replaced by a CGRA. Moreover, replacing a sea of accelerators with a CGRA leads to a drastically reduced environmental footprint (by a factor of $2.5 \\times$ to $7.6 \\times$).",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09328",
        "abstract url": "https://arxiv.org/abs/2411.09328",
        "title": "A Flexible Framework for Grant-Free Random Access in Cell-Free Massive MIMO Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "We propose a novel generalized framework for grant-free random-access (GFRA) in cell-free massive multiple input multiple-output systems where multiple geographically separated access points (APs) or base stations (BSs) aim to detect sporadically active user-equipment (UEs). Unlike a conventional architecture in which all the active UEs transmit their signature or pilot sequences of equal length, we admit a flexible pilot length for each UE, which also enables a seamless integration into conventional grant-based wireless systems. We formulate the joint UE activity detection and the distributed channel estimation as a sparse support and signal recovery problem, and describe a Bayesian learning procedure to solve it. We develop a scheme to fuse the posterior statistics of the latent variables inferred by each AP to jointly detect the UEs' activities, and utilize them to further refine the channel estimates. In addition, we allude to an interesting point which enables this flexible GFRA framework to encode the information bits from the active UEs. We numerically evaluate the normalized mean square error and the probability of miss-detection performances obtained by the Bayesian algorithm and show that the latent-variable fusion enhances the detection and the channel estimation performances by a large margin. We also benchmark against a genie-aided algorithm which has a prior knowledge of the UEs' activities.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "Published in the Proceedings of SPAWC 2024"
    },
    {
        "paper id": "2411.09335",
        "abstract url": "https://arxiv.org/abs/2411.09335",
        "title": "Experimental Demonstration of Remote Synchronization in Coupled Nonlinear Oscillator",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study investigates remote synchronization in scale-free networks of coupled nonlinear oscillators inspired by synchronization observed in the brain's cortical regions and power grid. We employ the Master Stability Function (MSF) approach to analyze network stability across various oscillator models. Synchronization results are obtained for a star network using linearization techniques and extended to arbitrary networks with benchmark oscillators, verifying consistent behavior. Stable synchronous solutions emerge as the Floquet multiplier decreases and the MSF becomes negative. Additionally, we demonstrate remote synchronization in a star network, where peripheral oscillators communicate exclusively through a central hub, drawing parallels to neuronal synchronization in the brain. Experimental validation is achieved through an electronic circuit testbed, supported by nonlinear ODE modeling and LTspice simulation. Future work will extend the investigation to arbitrary network topologies, further elucidating synchronization dynamics in complex systems.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09347",
        "abstract url": "https://arxiv.org/abs/2411.09347",
        "title": "The Denotational Semantics of SSA",
        "rating": "-10",
        "keywords": [],
        "abstract": "Static single assignment form, or SSA, has been the dominant compiler intermediate representation for decades. In this paper, we give a type theory for a variant of SSA, including its equational theory, which are strong enough to validate a variety of control and data flow transformations. We also give a categorical semantics for SSA, and show that the type theory is sound and complete with respect to the categorical axiomatization. We demonstrate the utility of our model by exhibiting a variety of concrete models satisfying our axioms, including in particular a model of TSO weak memory. The correctness of the syntactic metatheory, as well as the completeness proof has been mechanized in the Lean proof assistant.",
        "subjects": [
            "cs.PL",
            "cs.LO"
        ],
        "comment": "94 pages, 38 figures, mechanization available at https://github.com/imbrem/debruijn-ssa/tree/toplas-artifact"
    },
    {
        "paper id": "2411.09362",
        "abstract url": "https://arxiv.org/abs/2411.09362",
        "title": "Circuit-Compliant Optimization of Dynamic Metasurface Antennas for Near-Field Localization",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents an optimization framework for near-field localization with Dynamic Metasurface Antenna (DMA) receivers. This metasurface technology offers enhanced angular and range resolution realizing efficient hybrid Analog and Digital (A/D) BeamForming (BF) with sub-wavelength-spaced metamaterials of tunable responses. However, the vast majority of the state-of-the-art DMA designs is based on an idealized model for their reception operation, which neglects several practical aspects, such as the inevitable mutual coupling among the densely deployed metamaterials within a given aperture. Capitalizing on a recent circuit-compliant active metasurface model, we present a novel mutual-coupling-aware framework for localization-optimized hybrid A/D BF weights at the reception DMA. To deal with the intrinsic complexity of the deployed model, we introduce first- and second-order approximations for the DMA analog BF matrix that enable efficient optimization, while maintaining accuracy. We derive the Cramer-Rao Bound for the user position estimation which serves as our design objective for the hybrid A/D BF matrices. Closed-form solutions for these matrices for both approximations are presented, whose validity is confirmed via numerical investigations. It is also demonstrated that the proposed DMA design outperforms state-of-the-art multi-antenna reception architectures optimized for the same localization objective.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09380",
        "abstract url": "https://arxiv.org/abs/2411.09380",
        "title": "Connecting the Unconnected: A DT Case Study of Nomadic Nodes Deployment in Nepal",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper addresses the challenge of robust cellular connectivity in dense, underdeveloped urban environments, specifically focusing on Kathmandu, Nepal. As cities grow, existing cellular infrastructure struggles to meet the demand for reliable, high-throughput, and low-latency communication services. The lack of investment in new technologies and the intricacies of the cities' landscape pose even more difficulties for robust connectivity. This work addresses the above challenges in a cost-effective and flexible way. We investigate the deployment of LTE Nomadic Nodes (NNs) at scale in order to enhance network capacity and coverage. Utilising a Digital Twin (DT), we simulate and optimise NN placement, considering Kathmandu's physical and environmental characteristics. Our approach leverages the DRIVE DT framework, which enables the systemic evaluation of various network configurations and user mobility scenarios. The results demonstrate that NNs significantly improve signal strength and expected user datarates, presenting a viable solution for enhancing urban cellular connectivity.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Accepted for publication at IEEE CCNC 2025"
    },
    {
        "paper id": "2411.09460",
        "abstract url": "https://arxiv.org/abs/2411.09460",
        "title": "Analysis Methodology for Age of Information under Sequence Based Scheduling",
        "rating": "-10",
        "keywords": [],
        "abstract": "We focus on the Age of Information (AoI) performance in a system where each user generates packets periodically to send to a common access point (AP) for status updating. To avoid heavy overhead, we assume that channel sensing, feedback information from the AP, and time synchronization are not available in the system. We adopt a multi-access scheme called the sequence scheme, where each user is assigned a periodic binary sequence to schedule their transmissions. In our previous work [18], we have thoroughly studied the AoI performance under sequence scheme when the period of schedule sequences, $L$, is equal to the status generating period, $T$. The results can be extended to the case where $T>L$. However, the case of $T<L$ is not covered by [18]. Therefore, in this paper, we concentrate on analyzing the AoI performance in the case of $T<L$, which is more challenging and requires different approaches. We conduct in-depth analysis on this case and develop a mathematical tool based on integer partitions to facilitate the analysis. We derive low-complexity closed-form expressions for two scenarios under $T<L$. Based on the obtained analytical results, we propose an algorithm to optimize the construction parameters of the sequence scheme. Finally, we compare our proposed sequence scheme with two commonly used baselines, and show that our proposed scheme outperforms the baselines in terms of AoI performance while consuming less energy.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09463",
        "abstract url": "https://arxiv.org/abs/2411.09463",
        "title": "Teaching Program Decomposition in CS1: A Conceptual Framework for Improved Code Quality",
        "rating": "-10",
        "keywords": [],
        "abstract": "Program decomposition is essential for developing maintainable and efficient software, yet it remains a challenging skill to teach and learn in introductory programming courses. What does program decomposition for procedural CS1 programs entail? How can CS1 students improve the decomposition of their programs? What scaffolded exercises can instructors use to teach program decomposition skills? We aim to answer all these questions by presenting a conceptual framework that (1) is grounded in the established code style principles, (2) provides a systematic approach that can be taught to students as an actionable strategy to improve the program decomposition of their programs, and (3) includes scaffolded exercises to be used in classroom activities. In addition, this systematic approach is automatable and can further be used to implement visualizers, automated feedback generators and digital tutors.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "SIGCSE 2025"
    },
    {
        "paper id": "2411.09467",
        "abstract url": "https://arxiv.org/abs/2411.09467",
        "title": "The Perceptions of Software Engineers Concerning the Utilization of Bots in the OSS Development Process: An Exploratory Survey",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software bots, extensively adopted by Open Source Software (OSS) projects, support developers across several activities, from automating predefined tasks to generating code that aids software engineers. However, with the growing prominence of bots, questions have emerged regarding the extension to which they truly assist or hinder software engineers in their routine tasks. To address this, an exploratory survey was conducted with 37 software engineers to gather insights into their views on the use of bots within the software development process. The findings suggest that bots are present across multiple phases of the software development lifecycle, providing daily support to professionals by enhancing productivity and facilitating task automation. Respondents stated that current bots are not sufficiently intelligent and raised new challenges and enhancements to aid bot designers in developing additional functionalities and integrations.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "6 pages, 6 figures, 3 tables"
    },
    {
        "paper id": "2411.09472",
        "abstract url": "https://arxiv.org/abs/2411.09472",
        "title": "An Algorithm for the Longest Common Subsequence and Substring Problem for Multiple Strings",
        "rating": "-10",
        "keywords": [],
        "abstract": "Let $X_1, X_2, ..., X_s$ and $Y_1, Y_2, ..., Y_t$ be strings over an alphabet $\u03a3$, where $s$ and $t$ are positive integers. The longest common subsequence and substring problem for multiple strings $X_1, X_2, ..., X_s$ and $Y_1, Y_2, ..., Y_t$ is to find the longest string which is a subsequence of $X_1, X_2, ..., X_s$ and a substring of $Y_1, Y_2, ..., Y_t$. In this paper, we propose an algorithm to solve the problem.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09489",
        "abstract url": "https://arxiv.org/abs/2411.09489",
        "title": "Positive Focusing is Directly Useful",
        "rating": "-10",
        "keywords": [],
        "abstract": "Recently, Miller and Wu introduced the positive $\u03bb$-calculus, a call-by-value $\u03bb$-calculus with sharing obtained by assigning proof terms to the positively polarized focused proofs for minimal intuitionistic logic. The positive $\u03bb$-calculus stands out among $\u03bb$-calculi with sharing for a compactness property related to the sharing of variables. We show that -- thanks to compactness -- the positive calculus neatly captures the core of useful sharing, a technique for the study of reasonable time cost models.",
        "subjects": [
            "cs.LO",
            "cs.PL"
        ],
        "comment": "Paper for the proceedings of MFPS 2024"
    },
    {
        "paper id": "2411.09531",
        "abstract url": "https://arxiv.org/abs/2411.09531",
        "title": "Efficient top-down updates in AVL trees",
        "rating": "-10",
        "keywords": [],
        "abstract": "Since AVL trees were invented in 1962, two major open questions about rebalancing operations, which found positive answers in other balanced binary search trees, were left open: can these operations be performed top-down (with a fixed look-ahead), and can they use an amortised constant number of write operations per update? We propose an algorithm that answers both questions positively.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09550",
        "abstract url": "https://arxiv.org/abs/2411.09550",
        "title": "A small-gain criterion for 2-contraction of large scale interconnected systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Despite modular conditions to guarantee stability for large-scale systems have been widely studied, few methods are available to tackle the case of networks with multiple equilibria. This paper introduces small-gain like sufficient conditions for 2-contraction of large-scale interconnected systems on the basis of a family of upper-bounds to the $L_2$ gains that arise from the gains computed on individual channels of the second additive variational equation. Such a condition guarantee the 2-additive compound of the system's Jacobian to be exponentially contractive, thus implying convergence towards equilibria of the system's solutions. The gains are obtained by solving suitable Linear Matrix Inequalities. Three interconnected Thomas' systems are considered in order to illustrate the application of the theory and the degree of conservatism.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09577",
        "abstract url": "https://arxiv.org/abs/2411.09577",
        "title": "SimTube: Generating Simulated Video Comments through Multimodal AI and User Personas",
        "rating": "-10",
        "keywords": [],
        "abstract": "Audience feedback is crucial for refining video content, yet it typically comes after publication, limiting creators' ability to make timely adjustments. To bridge this gap, we introduce SimTube, a generative AI system designed to simulate audience feedback in the form of video comments before a video's release. SimTube features a computational pipeline that integrates multimodal data from the video-such as visuals, audio, and metadata-with user personas derived from a broad and diverse corpus of audience demographics, generating varied and contextually relevant feedback. Furthermore, the system's UI allows creators to explore and customize the simulated comments. Through a comprehensive evaluation-comprising quantitative analysis, crowd-sourced assessments, and qualitative user studies-we show that SimTube's generated comments are not only relevant, believable, and diverse but often more detailed and informative than actual audience comments, highlighting its potential to help creators refine their content before release.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09582",
        "abstract url": "https://arxiv.org/abs/2411.09582",
        "title": "Safety Filter for Robust Disturbance Rejection via Online Optimization",
        "rating": "-10",
        "keywords": [],
        "abstract": "Disturbance rejection in high-precision control applications can be significantly improved upon via online convex optimization (OCO). This includes classical techniques such as recursive least squares (RLS) and more recent, regret-based formulations. However, these methods can cause instabilities in the presence of model uncertainty. This paper introduces a safety filter for systems with OCO in the form of adaptive finite impulse response (FIR) filtering to ensure robust disturbance rejection. The safety filter enforces a robust stability constraint on the FIR coefficients while minimally altering the OCO command in the $\\infty$-norm cost. Additionally, we show that the induced $\\ell_\\infty$-norm allows for easy online implementation of the safety filter by directly limiting the OCO command. The constraint can be tuned to trade off robustness and performance. We provide a simple example to demonstrate the safety filter.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": "Submitted to the 2025 European Control Conference. This paper builds on the work done in arXiv:2405.07037"
    },
    {
        "paper id": "2411.09597",
        "abstract url": "https://arxiv.org/abs/2411.09597",
        "title": "Rare-Case Hard Functions Against Various Adversaries",
        "rating": "-10",
        "keywords": [],
        "abstract": "We say that a function is rare-case hard against a given class of algorithms (the adversary) if all algorithms in the class can compute the function only on an $o(1)$-fraction of instances of size $n$ for large enough $n$. Starting from any NP-complete language, for each $k > 0$, we construct a function that cannot be computed correctly on even a $1/n^k$-fraction of instances for polynomial-sized circuit families if NP $\\not \\subset$ P/POLY and by polynomial-time algorithms if NP $\\not \\subset$ BPP - functions that are rare-case hard against polynomial-time algorithms and polynomial-sized circuits. The constructed function is a number-theoretic polynomial evaluated over specific finite fields. For NP-complete languages that admit parsimonious reductions from all of NP (for example, SAT), the constructed functions are hard to compute on even a $1/n^k$-fraction of instances by polynomial-time algorithms and polynomial-sized circuit families simply if $P^{\\#P} \\not \\subset$ BPP and $P^{\\#P} \\not \\subset$ P/POLY, respectively. We also show that if the Randomized Exponential Time Hypothesis (RETH) is true, none of these constructed functions can be computed on even a $1/n^k$-fraction of instances in subexponential time. These functions are very hard, almost always. While one may not be able to efficiently compute the values of these constructed functions themselves, in polynomial time, one can verify that the evaluation of a function, $s = f(x)$, is correct simply by asking a prover to compute $f(y)$ on targeted queries.",
        "subjects": [
            "cs.CC"
        ],
        "comment": "25 pages"
    },
    {
        "paper id": "2411.09636",
        "abstract url": "https://arxiv.org/abs/2411.09636",
        "title": "Nash equilibrium seeking for a class of quadratic-bilinear Wasserstein distributionally robust games",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider a class of Wasserstein distributionally robust Nash equilibrium problems, where agents construct heterogeneous data-driven Wasserstein ambiguity sets using private samples and radii, in line with their individual risk-averse behaviour. By leveraging relevant properties of this class of games, we show that equilibria of the original seemingly infinite-dimensional problem can be obtained as a solution to a finite-dimensional Nash equilibrium problem. We then reformulate the problem as a finite-dimensional variational inequality and establish the connection between the corresponding solution sets. Our reformulation has scalable behaviour with respect to the data size and maintains a fixed number of constraints, independently of the number of samples. To compute a solution, we leverage two algorithms, based on the golden ratio algorithm. The efficiency of both algorithmic schemes is corroborated through extensive simulation studies on an illustrative example and a stochastic portfolio allocation game, where behavioural coupling among investors is modeled.",
        "subjects": [
            "math.OC",
            "cs.MA",
            "eess.SY"
        ],
        "comment": "14 pages, 5 figures"
    },
    {
        "paper id": "2411.09646",
        "abstract url": "https://arxiv.org/abs/2411.09646",
        "title": "Reducing Stochastic Games to Semidefinite Programming",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present a polynomial-time reduction from max-average constraints to the feasibility problem for semidefinite programs. This shows that Condon's simple stochastic games, stochastic mean payoff games, and in particular mean payoff games and parity games can all be reduced to semidefinite programming.",
        "subjects": [
            "math.OC",
            "cs.CC",
            "cs.GT"
        ],
        "comment": "15 pages, 1 figure"
    },
    {
        "paper id": "2411.09653",
        "abstract url": "https://arxiv.org/abs/2411.09653",
        "title": "How to implement the Bayes' formula in the age of ML?",
        "rating": "-10",
        "keywords": [],
        "abstract": "This chapter contains a self-contained introduction to the significance of Bayes' formula in the context of nonlinear filtering problems. Both discrete-time and continuous-time settings of the problem are considered in a unified manner. In control theory, the focus on optimization-based solution approaches is stressed together with a discussion of historical developments in this area (from 1960s onwards). The heart of this chapter contains a presentation of a novel optimal transportation formulation for the Bayes formula (developed recently by the first author) and its relationship to some of the prior joint work (feedback particle filter) from the authors. The presentation highlights how optimal transportation theory is leveraged to overcome some of the numerical challenges of implementing Bayes' law by enabling the use of machine learning (ML) tools.",
        "subjects": [
            "eess.SY",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09717",
        "abstract url": "https://arxiv.org/abs/2411.09717",
        "title": "Integrating Fuzzy Set Theory with Pandora Temporal Fault Trees for Dynamic Failure Analysis of Complex Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Pandora temporal fault tree, as one notable extension of the fault tree, introduces temporal gates and temporal laws. Pandora Temporal Fault Tree(TFT) enhances the capability of fault trees and enables the modeling of system failure behavior that depends on sequences. The calculation of system failure probability in Pandora TFT relies on precise probabilistic information on component failures. However, obtaining such precise failure data can often be challenging. The data may be uncertain as historical records are used to derive failure data for system components. To mitigate this uncertainty, in this study, we proposed a method that integrates fuzzy set theory with Pandora TFT. This integration aims to enable dynamic analysis of complex systems, even in cases where quantitative failure data of components is unreliable or imprecise. The proposed work introduces the development of Fuzzy AND, Fuzzy OR, Fuzzy PAND, and Fuzzy POR logic gates for Pandora TFT. We also introduce a fuzzy importance measure for criticality analysis of basic events. All events in our analysis are assumed to have exponentially distributed failures, with their failure rates represented as triangular fuzzy numbers. We illustrate the proposed method through a case study of the Aircraft Fuel Distribution System (AFDS), highlighting its practical application and effectiveness in analyzing complex systems. The results are compared with existing results from Petri net and Bayesian network techniques to validate the findings.",
        "subjects": [
            "eess.SY",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09760",
        "abstract url": "https://arxiv.org/abs/2411.09760",
        "title": "SpecPCM: A Low-power PCM-based In-Memory Computing Accelerator for Full-stack Mass Spectrometry Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mass spectrometry (MS) is essential for proteomics and metabolomics but faces impending challenges in efficiently processing the vast volumes of data. This paper introduces SpecPCM, an in-memory computing (IMC) accelerator designed to achieve substantial improvements in energy and delay efficiency for both MS spectral clustering and database (DB) search. SpecPCM employs analog processing with low-voltage swing and utilizes recently introduced phase change memory (PCM) devices based on superlattice materials, optimized for low-voltage and low-power programming. Our approach integrates contributions across multiple levels: application, algorithm, circuit, device, and instruction sets. We leverage a robust hyperdimensional computing (HD) algorithm with a novel dimension-packing method and develop specialized hardware for the end-to-end MS pipeline to overcome the non-ideal behavior of PCM devices. We further optimize multi-level PCM devices for different tasks by using different materials. We also perform a comprehensive design exploration to improve energy and delay efficiency while maintaining accuracy, exploring various combinations of hardware and software parameters controlled by the instruction set architecture (ISA). SpecPCM, with up to three bits per cell, achieves speedups of up to 82x and 143x for MS clustering and DB search tasks, respectively, along with a four-orders-of-magnitude improvement in energy efficiency compared with state-of-the-art CPU/GPU tools.",
        "subjects": [
            "cs.AR",
            "cs.ET",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09768",
        "abstract url": "https://arxiv.org/abs/2411.09768",
        "title": "Research evaluation with ChatGPT: Is it age, country, length, or field biased?",
        "rating": "-10",
        "keywords": [],
        "abstract": "Some research now suggests that ChatGPT can estimate the quality of journal articles from their titles and abstracts. This has created the possibility to use ChatGPT quality scores, perhaps alongside citation-based formulae, to support peer review for research evaluation. Nevertheless, ChatGPT's internal processes are effectively opaque, despite it writing a report to support its scores, and its biases are unknown. This article investigates whether publication date and field are biasing factors. Based on submitting a monodisciplinary journal-balanced set of 117,650 articles from 26 fields published in the years 2003, 2008, 2013, 2018 and 2023 to ChatGPT 4o-mini, the results show that average scores increased over time, and this was not due to author nationality or title and abstract length changes. The results also varied substantially between fields, and first author countries. In addition, articles with longer abstracts tended to receive higher scores, but plausibly due to such articles tending to be better rather than due to ChatGPT analysing more text. Thus, for the most accurate research quality evaluation results from ChatGPT, it is important to normalise ChatGPT scores for field and year and check for anomalies caused by sets of articles with short abstracts.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09779",
        "abstract url": "https://arxiv.org/abs/2411.09779",
        "title": "Variational methods for Learning Multilevel Genetic Algorithms using the Kantorovich Monad",
        "rating": "-10",
        "keywords": [],
        "abstract": "Levels of selection and multilevel evolutionary processes are essential concepts in evolutionary theory, and yet there is a lack of common mathematical models for these core ideas. Here, we propose a unified mathematical framework for formulating and optimizing multilevel evolutionary processes and genetic algorithms over arbitrarily many levels based on concepts from category theory and population genetics. We formulate a multilevel version of the Wright-Fisher process using this approach, and we show that this model can be analyzed to clarify key features of multilevel selection. Particularly, we derive an extended multilevel probabilistic version of Price's Equation via the Kantorovich Monad, and we use this to characterize regimes of parameter space within which selection acts antagonistically or cooperatively across levels. Finally, we show how our framework can provide a unified setting for learning genetic algorithms (GAs), and we show how we can use a Variational Optimization and a multi-level analogue of coalescent analysis to fit multilevel GAs to simulated data.",
        "subjects": [
            "q-bio.PE",
            "cs.NE",
            "math.CT"
        ],
        "comment": "18 pages, 3 figures"
    },
    {
        "paper id": "2411.09783",
        "abstract url": "https://arxiv.org/abs/2411.09783",
        "title": "Exploring the Use of Autonomous Unmanned Vehicles for Supporting Power Grid Operations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper explores the use of autonomous unmanned vehicles for supporting power grid operations. With built-in batteries and the capability to carry additional battery energy storage, the rising number of autonomous vehicles can represent a substantial amount of capacity that is currently underutilized in the power grid. Unlike traditional electric vehicles which require drivers, the operations of autonomous vehicles can be performed without human intervention. To guide idle vehicles to support power grids autonomously, we propose a tractable optimization-based method for effectively integrating these ``mobile batteries'' into grid operations. During real-time operations, the vehicles are strategically routed to target locations to help maintain system power balance and reduce operating costs. Numerical studies have confirmed both the validity and scalability of the proposed algorithm for efficiently integrating autonomous vehicles into routine power system operations.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09803",
        "abstract url": "https://arxiv.org/abs/2411.09803",
        "title": "Using a Single-Parity-Check to reduce the Guesswork of Guessing Codeword Decoding",
        "rating": "-10",
        "keywords": [],
        "abstract": "Guessing Codeword Decoding (GCD) is a recently proposed soft-input forward error correction decoder for arbitrary linear forward error correction codes. Inspired by recent proposals that leverage binary linear codebook structure to reduce the number of queries made by Guessing Random Additive Noise Decoding (GRAND), for binary linear codes that include one full single parity-check (SPC) bit, we show that it is possible to reduce the number of queries made by GCD by a factor of up to 2 without impacting decoding precision. The greatest guesswork reduction is realized at lower SNRs, where the decoder output is usually correct but guesswork is most burdensome. Codes without a SPC can be modified to include one by swapping a column of the generator matrix for an all-ones column to obtain a decoding complexity advantage, and we demonstrate that this can often be done without losing decoding precision. To practically avail of the complexity advantage, a noise effect pattern generator capable of producing sequences for given Hamming weights, such as the one underlying ORBGRAND, is necessary.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09817",
        "abstract url": "https://arxiv.org/abs/2411.09817",
        "title": "Dynamic Envy-Free Permanency in Child Welfare Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Caseworkers in foster care systems seek to place waiting children in the most suitable homes. Furthermore, social work guidelines prioritize heterogeneous attributes of children and homes when deliberating placements. We use insights from market design and dynamic matching to characterize a class of dynamically envy-free mechanisms that incentivize expedient placements when children and homes arrive to the market over time and homes may accept or decline placements. The mechanisms have robustness against justified envy and costly patience. We analyze strategic incentives and efficiency properties of dynamic envy-freeness. Finally, we conduct empirical simulations that affirm that our mechanisms drastically increase placements and reduce waiting costs while maintaining robustness to prediction error versus a naive mechanism that always sequentially runs Deferred Acceptance. Practitioners can implement our mechanisms through assigning priority to child-home matches.",
        "subjects": [
            "econ.TH",
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09846",
        "abstract url": "https://arxiv.org/abs/2411.09846",
        "title": "Leveraging Propagated Infection to Crossfire Mutants",
        "rating": "-10",
        "keywords": [],
        "abstract": "Mutation testing was proposed to identify weaknesses in test suites by repeatedly generating artificially faulty versions of the software (mutants) and determining if the test suite is sufficient to detect them (kill them). When the tests are insufficient, each surviving mutant provides an opportunity to improve the test suite. We conducted a study and found that many such surviving mutants (up to 84% for the subjects of our study) are detectable by simply augmenting existing tests with additional assertions, or assertion amplification. Moreover, we find that many of these mutants are detectable by multiple existing tests, giving developers options for how to detect them. To help with these challenges, we created a technique that performs memory-state analysis to identify candidate assertions that developers can use to detect the surviving mutants. Additionally, we build upon prior research that identifies ``crossfiring'' opportunities -- tests that coincidentally kill multiple mutants. To this end, we developed a theoretical model that describes the varying granularities that crossfiring can occur in the existing test suite, which provide opportunities and options for how to kill surviving mutants. We operationalize this model to an accompanying technique that optimizes the assertion amplification of the existing tests to crossfire multiple mutants with fewer added assertions, optionally concentrated within fewer tests. Our experiments show that we can kill all surviving mutants that are detectable with existing test data with only 1.1% of the identified assertion candidates, and increasing by a factor of 6x, on average, the number of killed mutants from amplified tests, over tests that do not crossfire.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted at ICSE '25"
    },
    {
        "paper id": "2411.09866",
        "abstract url": "https://arxiv.org/abs/2411.09866",
        "title": "Power Allocation for Compute-and-Forward over Fading Channels",
        "rating": "-10",
        "keywords": [],
        "abstract": "Compute-and-forward (CF) is a relaying strategy which allows the relay to decode a linear combination of the transmitted messages. This work studies the optimal power allocation problem for the CF scheme in fast fading channels for maximizing the symmetric computation rate, which is a non-convex optimization problem with no simple analytical or numerical solutions. In the first part of the paper, we investigate the problem when there are finitely many channel states (discrete case). We establish several important properties of the optimal solutions and show that if all users share the same power allocation policy (symmetric policy), the optimal solution takes the form of a water-filling type when the power constraint exceeds a certain threshold. However, if asymmetric policies are allowed, the optimal solution does not take this form for any power constraint. We propose a low-complexity order-based algorithm for both scenarios and compare its performance with baseline algorithms. In the second part of the paper, we state relevant results when the channel coefficients are modelled as continuous random variables (continuous case) and propose a similar low-complexity iterative algorithm for the symmetric policy scenario. Numerical results are provided for both discrete and continuous cases. It is shown that in general our proposed algorithm finds good suboptimal solutions with low complexity, and for some examples considered, finds an exact optimal solution.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09868",
        "abstract url": "https://arxiv.org/abs/2411.09868",
        "title": "Phase Transitions with Structured Sparsity",
        "rating": "-10",
        "keywords": [],
        "abstract": "In the field of signal processing, phase transition phenomena have recently attracted great attention. Donoho's work established the signal recovery threshold using indicators such as restricted isotropy (RIP) and incoherence and proved that phase transition phenomena occur in compressed sampling. Nevertheless, the phase transition phenomenon of structured sparse signals remains unclear, and these studies mainly focused on simple sparse signals. Signals with a specific structure, such as the block or tree structures common in real-world applications, are called structured sparse signals. The objectives of this article are to study the phase transition phenomenon of structured sparse signals and to investigate how structured sparse signals affect the phase transition threshold. It begins with a summary of the common subspace of structured sparse signals and the theory of high-dimensional convex polytope random projections. Next, the strong threshold expression of block-structured and tree-structured sparse signals is derived after examining the weak and strong thresholds of structured sparse signals.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09881",
        "abstract url": "https://arxiv.org/abs/2411.09881",
        "title": "Regulating Stability Margins in Symbiotic Control: A Low-Pass Filter Approach",
        "rating": "-10",
        "keywords": [],
        "abstract": "Symbiotic control synergistically integrates fixed-gain control and adaptive learning architectures to mitigate system uncertainties more predictably than adaptive learning alone and without requiring prior knowledge of uncertainty bounds as compared to fixed-gain control alone. Specifically, increasing the fixed-gain control parameter achieves a desired level of closed-loop system performance while the adaptive law simultaneously learns and suppresses the system uncertainties. However, stability margins can be reduced when this parameter is large and this paper aims to address this practical challenge. To this end, we propose a new fixed-gain control architecture predicated on a low-pass filter approach to regulate stability margins in the symbiotic control framework. In addition to the presented system-theoretical results focusing on the stability of the closed-loop system, we provide two illustrative numerical examples to demonstrate how the low-pass filter parameters are chosen for the stability margin regulation problem without significantly compromising the closed-loop system performance.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09916",
        "abstract url": "https://arxiv.org/abs/2411.09916",
        "title": "LLMs are Imperfect, Then What? An Empirical Study on LLM Failures in Software Engineering",
        "rating": "-10",
        "keywords": [],
        "abstract": "Software engineers are integrating AI assistants into their workflows to enhance productivity and reduce cognitive strain. However, experiences vary significantly, with some engineers finding large language models (LLMs), like ChatGPT, beneficial, while others consider them counterproductive. Researchers also found that ChatGPT's answers included incorrect information. Given the fact that LLMs are still imperfect, it is important to understand how to best incorporate LLMs into the workflow for software engineering (SE) task completion. Therefore, we conducted an observational study with 22 participants using ChatGPT as a coding assistant in a non-trivial SE task to understand the practices, challenges, and opportunities for using LLMs for SE tasks. We identified the cases where ChatGPT failed, their root causes, and the corresponding mitigation solutions used by users. These findings contribute to the overall understanding and strategies for human-AI interaction on SE tasks. Our study also highlights future research and tooling support directions.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.09938",
        "abstract url": "https://arxiv.org/abs/2411.09938",
        "title": "Affine Frequency Division Multiplexing with Index Modulation: Full Diversity Condition, Performance Analysis, and Low-Complexity Detection",
        "rating": "-10",
        "keywords": [],
        "abstract": "Affine frequency division multiplexing (AFDM) is a novel modulation technique based on chirp signals that has been recently proposed as an effective solution for highly reliable communications in high-mobility scenarios. In this paper, we focus on the design of robust index modulation (IM) schemes under the multiple-antenna AFDM transmission framework. To this end, the cyclic delay diversity (CDD) technique is employed to harvest the transmit diversity gain. As a result, we propose two novel AFDM-IM schemes with transmit diversity, termed as CDD-AFDM-IM-I and CDD-AFDM-IM-II. We analyze the full diversity conditions and parameter settings of the proposed CDD-AFDM-IM schemes for both integer and fractional Doppler cases over linear time-varying (LTV) channels. Moreover, we prove that IM enables AFDM to have stronger diversity protection when the full diversity condition is not satisfied. Asymptotically tight upper bounds on the average bit error rates (BERs) of the proposed schemes with maximum-likelihood (ML) detection are derived in closed-form. Furthermore, we propose a low-complexity double-layer message passing (DLMP) algorithm for practical large-dimensional signal detection in the proposed CDD-AFDM-IM systems. Comparison with existing detections shows that the proposed DLMP algorithm achieves a better tradeoff between the BER performance and the computational complexity. Finally, BER simulation results confirm that our proposed CDD-AFDM-IM schemes with both the ML and DLMP detections outperform the benchmark schemes over the LTV channels.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "accepted by IEEE Journal on Selected Areas in Communications"
    },
    {
        "paper id": "2411.10491",
        "abstract url": "https://arxiv.org/abs/2411.10491",
        "title": "A Bibliometric Analysis of Highly Cited Artificial Intelligence Publications in Science Citation Index Expanded",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study aimed to identify and analyze the characteristics of highly cited publications in the field of artificial intelligence within the Science Citation Index Expanded from 1991 to 2022. The assessment focused on documents that garnered 100 citations or more from the Web of Science Core Collection, spanning from their publication date to the end of 2022. Various aspects of these documents were analyzed, encompassing document types, the distribution of annual production, the average number of citations per publication, Web of Science categories, and journals. Moreover, the publication performance of countries, institutions, and authors underwent evaluation through six publication indicators and associated citation metrics. To facilitate a comprehensive comparison of the authors research performance, the Y-index was employed. The outcomes of the analysis revealed that a majority of the highly cited articles were published within the Web of Science categories of \"artificial intelligence computer science\" and \"electrical and electronic engineering\". Notably, the United States exhibited dominance across all six publication indicators. Within the realm of average citations per publication, the United Kingdom emerged as a leader for independent articles, first-author articles, and corresponding-author articles. Exceptionally, the Chinese Academy of Sciences in China and the Massachusetts Institute of Technology (MIT) in the USA, contributed significantly. The significant impact of highly cited articles extended to the output of Stanford University in the USA. B.L. Bassler published the most highly cited articles. Upon employing the Y-index analysis, J.E.P. Santos was identified as having the highest potential for publication. In addition to the primary analysis, this study also presented nine classic articles that have left an indelible mark on artificial intelligence research.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    }
]