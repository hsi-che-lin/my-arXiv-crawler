[
    {
        "paper id": "2411.10922",
        "abstract url": "https://arxiv.org/abs/2411.10922",
        "title": "Exploiting VLM Localizability and Semantics for Open Vocabulary Action Detection",
        "rating": "2.5",
        "keywords": [
            [
                "vision-language",
                "VLM"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Action detection aims to detect (recognize and localize) human actions spatially and temporally in videos. Existing approaches focus on the closed-set setting where an action detector is trained and tested on videos from a fixed set of action categories. However, this constrained setting is not viable in an open world where test videos inevitably come beyond the trained action categories. In this paper, we address the practical yet challenging Open-Vocabulary Action Detection (OVAD) problem. It aims to detect any action in test videos while training a model on a fixed set of action categories. To achieve such an open-vocabulary capability, we propose a novel method OpenMixer that exploits the inherent semantics and localizability of large vision-language models (VLM) within the family of query-based detection transformers (DETR). Specifically, the OpenMixer is developed by spatial and temporal OpenMixer blocks (S-OMB and T-OMB), and a dynamically fused alignment (DFA) module. The three components collectively enjoy the merits of strong generalization from pre-trained VLMs and end-to-end learning from DETR design. Moreover, we established OVAD benchmarks under various settings, and the experimental results show that the OpenMixer performs the best over baselines for detecting seen and unseen actions. We release the codes, models, and dataset splits at https://github.com/Cogito2012/OpenMixer.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "WACV 2025 Accepted"
    },
    {
        "paper id": "2411.10730",
        "abstract url": "https://arxiv.org/abs/2411.10730",
        "title": "Comparison of Multilingual and Bilingual Models for Satirical News Detection of Arabic and English",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Satirical news is real news combined with a humorous comment or exaggerated content, and it often mimics the format and style of real news. However, satirical news is often misunderstood as misinformation, especially by individuals from different cultural and social backgrounds. This research addresses the challenge of distinguishing satire from truthful news by leveraging multilingual satire detection methods in English and Arabic. We explore both zero-shot and chain-of-thought (CoT) prompting using two language models, Jais-chat(13B) and LLaMA-2-chat(7B). Our results show that CoT prompting offers a significant advantage for the Jais-chat model over the LLaMA-2-chat model. Specifically, Jais-chat achieved the best performance, with an F1-score of 80\\% in English when using CoT prompting. These results highlight the importance of structured reasoning in CoT, which enhances contextual understanding and is vital for complex tasks like satire detection.",
        "subjects": [
            "cs.CL",
            "cs.CR"
        ],
        "comment": "ALTA 2024 (Selected for publication)"
    },
    {
        "paper id": "2411.10739",
        "abstract url": "https://arxiv.org/abs/2411.10739",
        "title": "A Wearable Gait Monitoring System for 17 Gait Parameters Based on Computer Vision",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We developed a shoe-mounted gait monitoring system capable of tracking up to 17 gait parameters, including gait length, step time, stride velocity, and others. The system employs a stereo camera mounted on one shoe to track a marker placed on the opposite shoe, enabling the estimation of spatial gait parameters. Additionally, a Force Sensitive Resistor (FSR) affixed to the heel of the shoe, combined with a custom-designed algorithm, is utilized to measure temporal gait parameters. Through testing on multiple participants and comparison with the gait mat, the proposed gait monitoring system exhibited notable performance, with the accuracy of all measured gait parameters exceeding 93.61%. The system also demonstrated a low drift of 4.89% during long-distance walking. A gait identification task conducted on participants using a trained Transformer model achieved 95.7% accuracy on the dataset collected by the proposed system, demonstrating that our hardware has the potential to collect long-sequence gait data suitable for integration with current Large Language Models (LLMs). The system is cost-effective, user-friendly, and well-suited for real-life measurements.",
        "subjects": [
            "eess.SY",
            "cs.CV",
            "eess.SP"
        ],
        "comment": "13 pages, 14 figures. This paper was submitted for publication to the IEEE Transactions on Instrumentation and Measurement"
    },
    {
        "paper id": "2411.10742",
        "abstract url": "https://arxiv.org/abs/2411.10742",
        "title": "It Takes Two: Accurate Gait Recognition in the Wild via Cross-granularity Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Existing studies for gait recognition primarily utilized sequences of either binary silhouette or human parsing to encode the shapes and dynamics of persons during walking. Silhouettes exhibit accurate segmentation quality and robustness to environmental variations, but their low information entropy may result in sub-optimal performance. In contrast, human parsing provides fine-grained part segmentation with higher information entropy, but the segmentation quality may deteriorate due to the complex environments. To discover the advantages of silhouette and parsing and overcome their limitations, this paper proposes a novel cross-granularity alignment gait recognition method, named XGait, to unleash the power of gait representations of different granularity. To achieve this goal, the XGait first contains two branches of backbone encoders to map the silhouette sequences and the parsing sequences into two latent spaces, respectively. Moreover, to explore the complementary knowledge across the features of two representations, we design the Global Cross-granularity Module (GCM) and the Part Cross-granularity Module (PCM) after the two encoders. In particular, the GCM aims to enhance the quality of parsing features by leveraging global features from silhouettes, while the PCM aligns the dynamics of human parts between silhouette and parsing features using the high information entropy in parsing sequences. In addition, to effectively guide the alignment of two representations with different granularity at the part level, an elaborate-designed learnable division mechanism is proposed for the parsing features. Comprehensive experiments on two large-scale gait datasets not only show the superior performance of XGait with the Rank-1 accuracy of 80.5% on Gait3D and 88.3% CCPG but also reflect the robustness of the learned features even under challenging conditions like occlusions and cloth changes.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 9 figures; Accepted by ACM MM 2024"
    },
    {
        "paper id": "2411.10753",
        "abstract url": "https://arxiv.org/abs/2411.10753",
        "title": "Chain-of-Programming (CoP) : Empowering Large Language Models for Geospatial Code Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "With the rapid growth of interdisciplinary demands for geospatial modeling and the rise of large language models (LLMs), geospatial code generation technology has seen significant advancements. However, existing LLMs often face challenges in the geospatial code generation process due to incomplete or unclear user requirements and insufficient knowledge of specific platform syntax rules, leading to the generation of non-executable code, a phenomenon known as \"code hallucination.\" To address this issue, this paper proposes a Chain of Programming (CoP) framework, which decomposes the code generation process into five steps: requirement analysis, algorithm design, code implementation, code debugging, and code annotation. The framework incorporates a shared information pool, knowledge base retrieval, and user feedback mechanisms, forming an end-to-end code generation flow from requirements to code without the need for model fine-tuning. Based on a geospatial problem classification framework and evaluation benchmarks, the CoP strategy significantly improves the logical clarity, syntactical correctness, and executability of the generated code, with improvements ranging from 3.0% to 48.8%. Comparative and ablation experiments further validate the superiority of the CoP strategy over other optimization approaches and confirm the rationality and necessity of its key components. Through case studies on building data visualization and fire data analysis, this paper demonstrates the application and effectiveness of CoP in various geospatial scenarios. The CoP framework offers a systematic, step-by-step approach to LLM-based geospatial code generation tasks, significantly enhancing code generation performance in geospatial tasks and providing valuable insights for code generation in other vertical domains.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10764",
        "abstract url": "https://arxiv.org/abs/2411.10764",
        "title": "ML$^2$Tuner: Efficient Code Tuning via Multi-Level Machine Learning Models",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "The increasing complexity of deep learning models necessitates specialized hardware and software optimizations, particularly for deep learning accelerators. Existing autotuning methods often suffer from prolonged tuning times due to profiling invalid configurations, which can cause runtime errors. We introduce ML$^2$Tuner, a multi-level machine learning tuning technique that enhances autotuning efficiency by incorporating a validity prediction model to filter out invalid configurations and an advanced performance prediction model utilizing hidden features from the compilation process. Experimental results on an extended VTA accelerator demonstrate that ML$^2$Tuner achieves equivalent performance improvements using only 12.3% of the samples required with a similar approach as TVM and reduces invalid profiling attempts by an average of 60.8%, Highlighting its potential to enhance autotuning performance by filtering out invalid configurations",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted in NeurIPS 2024 workshop on Machine Learning for Systems, 12 pages, 5 figures"
    },
    {
        "paper id": "2411.10773",
        "abstract url": "https://arxiv.org/abs/2411.10773",
        "title": "An End-to-End Real-World Camera Imaging Pipeline",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Recent advances in neural camera imaging pipelines have demonstrated notable progress. Nevertheless, the real-world imaging pipeline still faces challenges including the lack of joint optimization in system components, computational redundancies, and optical distortions such as lens shading.In light of this, we propose an end-to-end camera imaging pipeline (RealCamNet) to enhance real-world camera imaging performance. Our methodology diverges from conventional, fragmented multi-stage image signal processing towards end-to-end architecture. This architecture facilitates joint optimization across the full pipeline and the restoration of coordinate-biased distortions. RealCamNet is designed for high-quality conversion from RAW to RGB and compact image compression. Specifically, we deeply analyze coordinate-dependent optical distortions, e.g., vignetting and dark shading, and design a novel Coordinate-Aware Distortion Restoration (CADR) module to restore coordinate-biased distortions. Furthermore, we propose a Coordinate-Independent Mapping Compression (CIMC) module to implement tone mapping and redundant information compression. Existing datasets suffer from misalignment and overly idealized conditions, making them inadequate for training real-world imaging pipelines. Therefore, we collected a real-world imaging dataset. Experiment results show that RealCamNet achieves the best rate-distortion performance with lower inference latency.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "accept by ACMMM 2024"
    },
    {
        "paper id": "2411.10794",
        "abstract url": "https://arxiv.org/abs/2411.10794",
        "title": "Going Beyond Conventional OOD Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Out-of-distribution (OOD) detection is critical to ensure the safe deployment of deep learning models in critical applications. Deep learning models can often misidentify OOD samples as in-distribution (ID) samples. This vulnerability worsens in the presence of spurious correlation in the training set. Likewise, in fine-grained classification settings, detection of fine-grained OOD samples becomes inherently challenging due to their high similarity to ID samples. However, current research on OOD detection has largely ignored these challenging scenarios, focusing instead on relatively easier (conventional) cases. In this work, we present a unified Approach to Spurious, fine-grained, and Conventional OOD Detection (ASCOOD). First, we propose synthesizing virtual outliers from ID data by approximating the destruction of invariant features. We identify invariant features with the pixel attribution method using the model being learned. This approach eliminates the burden of curating external OOD datasets. Then, we simultaneously incentivize ID classification and predictive uncertainty towards the virtual outliers leveraging standardized feature representation. Our approach effectively mitigates the impact of spurious correlations and encourages capturing fine-grained attributes. Extensive experiments across six datasets demonstrate the merit of ASCOOD in spurious, fine-grained, and conventional settings. The code is available at: https://github.com/sudarshanregmi/ASCOOD/",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10803",
        "abstract url": "https://arxiv.org/abs/2411.10803",
        "title": "Multi-Stage Vision Token Dropping: Towards Efficient Multimodal Large Language Model",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "The vision tokens in multimodal large language models usually exhibit significant spatial and temporal redundancy and take up most of the input tokens, which harms their inference efficiency. To solve this problem, some recent works were introduced to drop the unimportant tokens during inference where the importance of each token is decided only by the information in either the vision encoding stage or the prefilling stage. In this paper, we propose Multi-stage Token Dropping (MustDrop) to measure the importance of each token from the whole lifecycle, including the vision encoding stage, prefilling stage, and decoding stage. Concretely, in the visual encoding stage, MustDrop merges spatially adjacent tokens with high similarity, and establishes a key token set to retain the most vision-critical tokens, preventing them from being discarded in later stages. In the prefilling stage, MustDrop further compresses vision tokens by the guidance of text semantics, with a dual-attention filtering strategy. In the decoding stage, an output-aware cache policy is proposed to further reduce the size of the KV cache. By leveraging tailored strategies in the multi-stage process, MustDrop can more precisely recognize the important and redundant tokens, thus achieving an optimal balance between performance and efficiency. For instance, MustDrop reduces about 88.5\\% FLOPs on LLaVA with a compression ratio of 92.2\\% while maintaining comparable accuracy. Our codes are available at \\url{https://github.com/liuting20/MustDrop}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 4figures"
    },
    {
        "paper id": "2411.10808",
        "abstract url": "https://arxiv.org/abs/2411.10808",
        "title": "FISTA Iterates Converge Linearly for Denoiser-Driven Regularization",
        "rating": "1",
        "keywords": [
            [
                "eess.IV"
            ]
        ],
        "abstract": "The effectiveness of denoising-driven regularization for image reconstruction has been widely recognized. Two prominent algorithms in this area are Plug-and-Play ($\\texttt{PnP}$) and Regularization-by-Denoising ($\\texttt{RED}$). We consider two specific algorithms $\\texttt{PnP-FISTA}$ and $\\texttt{RED-APG}$, where regularization is performed by replacing the proximal operator in the $\\texttt{FISTA}$ algorithm with a powerful denoiser. The iterate convergence of $\\texttt{FISTA}$ is known to be challenging with no universal guarantees. Yet, we show that for linear inverse problems and a class of linear denoisers, global linear convergence of the iterates of $\\texttt{PnP-FISTA}$ and $\\texttt{RED-APG}$ can be established through simple spectral analysis.",
        "subjects": [
            "math.OC",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10813",
        "abstract url": "https://arxiv.org/abs/2411.10813",
        "title": "Information Anxiety in Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated strong performance as knowledge repositories, enabling models to understand user queries and generate accurate and context-aware responses. Extensive evaluation setups have corroborated the positive correlation between the retrieval capability of LLMs and the frequency of entities in their pretraining corpus. We take the investigation further by conducting a comprehensive analysis of the internal reasoning and retrieval mechanisms of LLMs. Our work focuses on three critical dimensions - the impact of entity popularity, the models' sensitivity to lexical variations in query formulation, and the progression of hidden state representations across LLM layers. Our preliminary findings reveal that popular questions facilitate early convergence of internal states toward the correct answer. However, as the popularity of a query increases, retrieved attributes across lexical variations become increasingly dissimilar and less accurate. Interestingly, we find that LLMs struggle to disentangle facts, grounded in distinct relations, from their parametric memory when dealing with highly popular subjects. Through a case study, we explore these latent strains within LLMs when processing highly popular queries, a phenomenon we term information anxiety. The emergence of information anxiety in LLMs underscores the adversarial injection in the form of linguistic variations and calls for a more holistic evaluation of frequently occurring entities.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10828",
        "abstract url": "https://arxiv.org/abs/2411.10828",
        "title": "Bilingual Text-dependent Speaker Verification with Pre-trained Models for TdSV Challenge 2024",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "This paper presents our submissions to the Iranian division of the Text-dependent Speaker Verification Challenge (TdSV) 2024. TdSV aims to determine if a specific phrase was spoken by a target speaker. We developed two independent subsystems based on pre-trained models: For phrase verification, a phrase classifier rejected incorrect phrases, while for speaker verification, a pre-trained ResNet293 with domain adaptation extracted speaker embeddings for computing cosine similarity scores. In addition, we evaluated Whisper-PMFA, a pre-trained ASR model adapted for speaker verification, and found that, although it outperforms randomly initialized ResNets, it falls short of the performance of pre-trained ResNets, highlighting the importance of large-scale pre-training. The results also demonstrate that achieving competitive performance on TdSV without joint modeling of speaker and text is possible. Our best system achieved a MinDCF of 0.0358 on the evaluation subset and won the challenge.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "5 pages, no figures"
    },
    {
        "paper id": "2411.10836",
        "abstract url": "https://arxiv.org/abs/2411.10836",
        "title": "AnimateAnything: Consistent and Controllable Animation for Video Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present a unified controllable video generation approach AnimateAnything that facilitates precise and consistent video manipulation across various conditions, including camera trajectories, text prompts, and user motion annotations. Specifically, we carefully design a multi-scale control feature fusion network to construct a common motion representation for different conditions. It explicitly converts all control information into frame-by-frame optical flows. Then we incorporate the optical flows as motion priors to guide final video generation. In addition, to reduce the flickering issues caused by large-scale motion, we propose a frequency-based stabilization module. It can enhance temporal coherence by ensuring the video's frequency domain consistency. Experiments demonstrate that our method outperforms the state-of-the-art approaches. For more details and videos, please refer to the webpage: https://yu-shaonian.github.io/Animate_Anything/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10878",
        "abstract url": "https://arxiv.org/abs/2411.10878",
        "title": "Empowering Meta-Analysis: Leveraging Large Language Models for Scientific Synthesis",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study investigates the automation of meta-analysis in scientific documents using large language models (LLMs). Meta-analysis is a robust statistical method that synthesizes the findings of multiple studies support articles to provide a comprehensive understanding. We know that a meta-article provides a structured analysis of several articles. However, conducting meta-analysis by hand is labor-intensive, time-consuming, and susceptible to human error, highlighting the need for automated pipelines to streamline the process. Our research introduces a novel approach that fine-tunes the LLM on extensive scientific datasets to address challenges in big data handling and structured data extraction. We automate and optimize the meta-analysis process by integrating Retrieval Augmented Generation (RAG). Tailored through prompt engineering and a new loss metric, Inverse Cosine Distance (ICD), designed for fine-tuning on large contextual datasets, LLMs efficiently generate structured meta-analysis content. Human evaluation then assesses relevance and provides information on model performance in key metrics. This research demonstrates that fine-tuned models outperform non-fine-tuned models, with fine-tuned LLMs generating 87.6% relevant meta-analysis abstracts. The relevance of the context, based on human evaluation, shows a reduction in irrelevancy from 4.56% to 1.9%. These experiments were conducted in a low-resource environment, highlighting the study's contribution to enhancing the efficiency and reliability of meta-analysis automation.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": "Accepted in 2024 IEEE International Conference on Big Data (IEEE BigData)"
    },
    {
        "paper id": "2411.10879",
        "abstract url": "https://arxiv.org/abs/2411.10879",
        "title": "BanglaDialecto: An End-to-End AI-Powered Regional Speech Standardization",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This study focuses on recognizing Bangladeshi dialects and converting diverse Bengali accents into standardized formal Bengali speech. Dialects, often referred to as regional languages, are distinctive variations of a language spoken in a particular location and are identified by their phonetics, pronunciations, and lexicon. Subtle changes in pronunciation and intonation are also influenced by geographic location, educational attainment, and socioeconomic status. Dialect standardization is needed to ensure effective communication, educational consistency, access to technology, economic opportunities, and the preservation of linguistic resources while respecting cultural diversity. Being the fifth most spoken language with around 55 distinct dialects spoken by 160 million people, addressing Bangla dialects is crucial for developing inclusive communication tools. However, limited research exists due to a lack of comprehensive datasets and the challenges of handling diverse dialects. With the advancement in multilingual Large Language Models (mLLMs), emerging possibilities have been created to address the challenges of dialectal Automated Speech Recognition (ASR) and Machine Translation (MT). This study presents an end-to-end pipeline for converting dialectal Noakhali speech to standard Bangla speech. This investigation includes constructing a large-scale diverse dataset with dialectal speech signals that tailored the fine-tuning process in ASR and LLM for transcribing the dialect speech to dialect text and translating the dialect text to standard Bangla text. Our experiments demonstrated that fine-tuning the Whisper ASR model achieved a CER of 0.8% and WER of 1.5%, while the BanglaT5 model attained a BLEU score of 41.6% for dialect-to-standard text translation.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "comment": "Accepted in 2024 IEEE International Conference on Big Data (IEEE BigData)"
    },
    {
        "paper id": "2411.10889",
        "abstract url": "https://arxiv.org/abs/2411.10889",
        "title": "Neuc-MDS: Non-Euclidean Multidimensional Scaling Through Bilinear Forms",
        "rating": "1",
        "keywords": [
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We introduce Non-Euclidean-MDS (Neuc-MDS), an extension of classical Multidimensional Scaling (MDS) that accommodates non-Euclidean and non-metric inputs. The main idea is to generalize the standard inner product to symmetric bilinear forms to utilize the negative eigenvalues of dissimilarity Gram matrices. Neuc-MDS efficiently optimizes the choice of (both positive and negative) eigenvalues of the dissimilarity Gram matrix to reduce STRESS, the sum of squared pairwise error. We provide an in-depth error analysis and proofs of the optimality in minimizing lower bounds of STRESS. We demonstrate Neuc-MDS's ability to address limitations of classical MDS raised by prior research, and test it on various synthetic and real-world datasets in comparison with both linear and non-linear dimension reduction methods.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Accepted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024)"
    },
    {
        "paper id": "2411.10891",
        "abstract url": "https://arxiv.org/abs/2411.10891",
        "title": "ChannelDropBack: Forward-Consistent Stochastic Regularization for Deep Networks",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Incorporating stochasticity into the training process of deep convolutional networks is a widely used technique to reduce overfitting and improve regularization. Existing techniques often require modifying the architecture of the network by adding specialized layers, are effective only to specific network topologies or types of layers - linear or convolutional, and result in a trained model that is different from the deployed one. We present ChannelDropBack, a simple stochastic regularization approach that introduces randomness only into the backward information flow, leaving the forward pass intact. ChannelDropBack randomly selects a subset of channels within the network during the backpropagation step and applies weight updates only to them. As a consequence, it allows for seamless integration into the training process of any model and layers without the need to change its architecture, making it applicable to various network topologies, and the exact same network is deployed during training and inference. Experimental evaluations validate the effectiveness of our approach, demonstrating improved accuracy on popular datasets and models, including ImageNet and ViT. Code is available at \\url{https://github.com/neiterman21/ChannelDropBack.git}.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10896",
        "abstract url": "https://arxiv.org/abs/2411.10896",
        "title": "Targeting Negative Flips in Active Learning using Validation Sets",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "The performance of active learning algorithms can be improved in two ways. The often used and intuitive way is by reducing the overall error rate within the test set. The second way is to ensure that correct predictions are not forgotten when the training set is increased in between rounds. The former is measured by the accuracy of the model and the latter is captured in negative flips between rounds. Negative flips are samples that are correctly predicted when trained with the previous/smaller dataset and incorrectly predicted after additional samples are labeled. In this paper, we discuss improving the performance of active learning algorithms both in terms of prediction accuracy and negative flips. The first observation we make in this paper is that negative flips and overall error rates are decoupled and reducing one does not necessarily imply that the other is reduced. Our observation is important as current active learning algorithms do not consider negative flips directly and implicitly assume the opposite. The second observation is that performing targeted active learning on subsets of the unlabeled pool has a significant impact on the behavior of the active learning algorithm and influences both negative flips and prediction accuracy. We then develop ROSE - a plug-in algorithm that utilizes a small labeled validation set to restrict arbitrary active learning acquisition functions to negative flips within the unlabeled pool. We show that integrating a validation set results in a significant performance boost in terms of accuracy, negative flip rate reduction, or both.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Presented at the IEEE International Conference on Big Data 2024, Washington DC, USA"
    },
    {
        "paper id": "2411.10912",
        "abstract url": "https://arxiv.org/abs/2411.10912",
        "title": "SPICA: Retrieving Scenarios for Pluralistic In-Context Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Alignment of large language models (LLMs) to societal values should account for pluralistic values from diverse groups. One technique uses in-context learning for inference-time alignment, but only considers similarity when drawing few-shot examples, not accounting for cross-group differences in value prioritization. We propose SPICA, a framework for pluralistic alignment that accounts for group-level differences during in-context example retrieval. SPICA introduces three designs to facilitate pluralistic alignment: scenario banks, group-informed metrics, and in-context alignment prompts. From an evaluation of SPICA on an alignment task collecting inputs from four demographic groups ($n = 544$), our metrics retrieve in-context examples that more closely match observed preferences, with the best prompt configuration using multiple contrastive responses to demonstrate examples. In an end-to-end evaluation ($n = 80$), we observe that SPICA-aligned models are higher rated than a baseline similarity-only retrieval approach, with groups seeing up to a +0.16 point improvement on a 5 point scale. Additionally, gains from SPICA were more uniform, with all groups benefiting from alignment rather than only some. Finally, we find that while a group-agnostic approach can effectively align to aggregated values, it is not most suited for aligning to divergent groups.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10914",
        "abstract url": "https://arxiv.org/abs/2411.10914",
        "title": "BPO: Towards Balanced Preference Optimization between Knowledge Breadth and Depth in Alignment",
        "rating": "1",
        "keywords": [
            [
                "training efficiency"
            ],
            [
                "Depth"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Reinforcement Learning with Human Feedback (RLHF) is the key to the success of large language models (LLMs) in recent years. In this work, we first introduce the concepts of knowledge breadth and knowledge depth, which measure the comprehensiveness and depth of an LLM or knowledge source respectively. We reveal that the imbalance in the number of prompts and responses can lead to a potential disparity in breadth and depth learning within alignment tuning datasets by showing that even a simple uniform method for balancing the number of instructions and responses can lead to significant improvements. Building on this, we further propose Balanced Preference Optimization (BPO), designed to dynamically augment the knowledge depth of each sample. BPO is motivated by the observation that the usefulness of knowledge varies across samples, necessitating tailored learning of knowledge depth. To achieve this, we introduce gradient-based clustering, estimating the knowledge informativeness and usefulness of each augmented sample based on the model's optimization direction. Our experimental results across various benchmarks demonstrate that BPO outperforms other baseline methods in alignment tuning while maintaining training efficiency. Furthermore, we conduct a detailed analysis of each component of BPO, providing guidelines for future research in preference data optimization.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10927",
        "abstract url": "https://arxiv.org/abs/2411.10927",
        "title": "Inter-linguistic Phonetic Composition (IPC): A Theoretical and Computational Approach to Enhance Second Language Pronunciation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Learners of a second language (L2) often unconsciously substitute unfamiliar L2 phonemes with similar phonemes from their native language (L1), even though native speakers of the L2 perceive these sounds as distinct and non-interchangeable. This phonemic substitution leads to deviations from the standard phonological patterns of the L2, creating challenges for learners in acquiring accurate L2 pronunciation. To address this, we propose Inter-linguistic Phonetic Composition (IPC), a novel computational method designed to minimize incorrect phonological transfer by reconstructing L2 phonemes as composite sounds derived from multiple L1 phonemes. Tests with two automatic speech recognition models demonstrated that when L2 speakers produced IPC-generated composite sounds, the recognition rate of target L2 phonemes improved by 20% compared to when their pronunciation was influenced by original phonological transfer patterns. The improvement was observed within a relatively shorter time frame, demonstrating rapid acquisition of the composite sound.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10928",
        "abstract url": "https://arxiv.org/abs/2411.10928",
        "title": "Learn from Downstream and Be Yourself in Multimodal Large Language Model Fine-Tuning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal Large Language Model (MLLM) have demonstrated strong generalization capabilities across diverse distributions and tasks, largely due to extensive pre-training datasets. Fine-tuning MLLM has become a common practice to improve performance on specific downstream tasks. However, during fine-tuning, MLLM often faces the risk of forgetting knowledge acquired during pre-training, which can result in a decline in generalization abilities. To balance the trade-off between generalization and specialization, we propose measuring the parameter importance for both pre-trained and fine-tuning distributions, based on frozen pre-trained weight magnitude and accumulated fine-tuning gradient values. We further apply an importance-aware weight allocation strategy, selectively updating relatively important parameters for downstream tasks. We conduct empirical evaluations on both image captioning and visual question-answering tasks using various MLLM architectures. The comprehensive experimental analysis demonstrates the effectiveness of the proposed solution, highlighting the efficiency of the crucial modules in enhancing downstream specialization performance while mitigating generalization degradation in MLLM Fine-Tuning.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10934",
        "abstract url": "https://arxiv.org/abs/2411.10934",
        "title": "Analyzing Pok\u00e9mon and Mario Streamers' Twitch Chat with LLM-based User Embeddings",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "We present a novel digital humanities method for representing our Twitch chatters as user embeddings created by a large language model (LLM). We cluster these embeddings automatically using affinity propagation and further narrow this clustering down through manual analysis. We analyze the chat of one stream by each Twitch streamer: SmallAnt, DougDoug and PointCrow. Our findings suggest that each streamer has their own type of chatters, however two categories emerge for all of the streamers: supportive viewers and emoji and reaction senders. Repetitive message spammers is a shared chatter category for two of the streamers.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "NLP4DH 2024"
    },
    {
        "paper id": "2411.10939",
        "abstract url": "https://arxiv.org/abs/2411.10939",
        "title": "Evaluating Generative AI Systems is a Social Science Measurement Challenge",
        "rating": "1",
        "keywords": [
            [
                "cs.CY"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Across academia, industry, and government, there is an increasing awareness that the measurement tasks involved in evaluating generative AI (GenAI) systems are especially difficult. We argue that these measurement tasks are highly reminiscent of measurement tasks found throughout the social sciences. With this in mind, we present a framework, grounded in measurement theory from the social sciences, for measuring concepts related to the capabilities, impacts, opportunities, and risks of GenAI systems. The framework distinguishes between four levels: the background concept, the systematized concept, the measurement instrument(s), and the instance-level measurements themselves. This four-level approach differs from the way measurement is typically done in ML, where researchers and practitioners appear to jump straight from background concepts to measurement instruments, with little to no explicit systematization in between. As well as surfacing assumptions, thereby making it easier to understand exactly what the resulting measurements do and do not mean, this framework has two important implications for evaluating evaluations: First, it can enable stakeholders from different worlds to participate in conceptual debates, broadening the expertise involved in evaluating GenAI systems. Second, it brings rigor to operational debates by offering a set of lenses for interrogating the validity of measurement instruments and their resulting measurements.",
        "subjects": [
            "cs.CY"
        ],
        "comment": "NeurIPS 2024 Workshop on Evaluating Evaluations (EvalEval)"
    },
    {
        "paper id": "2411.10950",
        "abstract url": "https://arxiv.org/abs/2411.10950",
        "title": "Understanding Multimodal LLMs: the Mechanistic Interpretability of Llava in Visual Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Understanding the mechanisms behind Large Language Models (LLMs) is crucial for designing improved models and strategies. While recent studies have yielded valuable insights into the mechanisms of textual LLMs, the mechanisms of Multi-modal Large Language Models (MLLMs) remain underexplored. In this paper, we apply mechanistic interpretability methods to analyze the visual question answering (VQA) mechanisms in the first MLLM, Llava. We compare the mechanisms between VQA and textual QA (TQA) in color answering tasks and find that: a) VQA exhibits a mechanism similar to the in-context learning mechanism observed in TQA; b) the visual features exhibit significant interpretability when projecting the visual embeddings into the embedding space; and c) Llava enhances the existing capabilities of the corresponding textual LLM Vicuna during visual instruction tuning. Based on these findings, we develop an interpretability tool to help users and researchers identify important visual locations for final predictions, aiding in the understanding of visual hallucination. Our method demonstrates faster and more effective results compared to existing interpretability approaches. Code: \\url{https://github.com/zepingyu0512/llava-mechanism}",
        "subjects": [
            "cs.CL"
        ],
        "comment": "preprint"
    },
    {
        "paper id": "2411.10954",
        "abstract url": "https://arxiv.org/abs/2411.10954",
        "title": "Dialectal Toxicity Detection: Evaluating LLM-as-a-Judge Consistency Across Language Varieties",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "There has been little systematic study on how dialectal differences affect toxicity detection by modern LLMs. Furthermore, although using LLMs as evaluators (\"LLM-as-a-judge\") is a growing research area, their sensitivity to dialectal nuances is still underexplored and requires more focused attention. In this paper, we address these gaps through a comprehensive toxicity evaluation of LLMs across diverse dialects. We create a multi-dialect dataset through synthetic transformations and human-assisted translations, covering 10 language clusters and 60 varieties. We then evaluated three LLMs on their ability to assess toxicity across multilingual, dialectal, and LLM-human consistency. Our findings show that LLMs are sensitive in handling both multilingual and dialectal variations. However, if we have to rank the consistency, the weakest area is LLM-human agreement, followed by dialectal consistency. Code repository: \\url{https://github.com/ffaisal93/dialect_toxicity_llm_judge}",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10955",
        "abstract url": "https://arxiv.org/abs/2411.10955",
        "title": "A Topic-aware Comparable Corpus of Chinese Variations",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study aims to fill the gap by constructing a topic-aware comparable corpus of Mainland Chinese Mandarin and Taiwanese Mandarin from the social media in Mainland China and Taiwan, respectively. Using Dcard for Taiwanese Mandarin and Sina Weibo for Mainland Chinese, we create a comparable corpus that updates regularly and reflects modern language use on social media.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "4 pages, 4 figures, presented at APCLC2018: ASIA-PACIFIC CORPUS LINGUISTICS CONFERENCE 2018"
    },
    {
        "paper id": "2411.10958",
        "abstract url": "https://arxiv.org/abs/2411.10958",
        "title": "SageAttention2 Technical Report: Accurate 4 Bit Attention for Plug-and-play Inference Acceleration",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Although quantization for linear layers has been widely used, its application to accelerate the attention process remains limited. SageAttention utilizes 8-bit matrix multiplication, 16-bit matrix multiplication with 16-bit accumulator, and precision-enhancing methods, implementing an accurate and 2x speedup kernel compared to FlashAttention2. To further enhance the efficiency of attention computation while maintaining precision, we propose SageAttention2, which utilizes significantly faster 4-bit matrix multiplication (Matmul) alongside additional precision-enhancing techniques. First, we propose to quantize matrixes $(Q, K)$ to INT4 in a warp-level granularity and quantize matrixes $(\\widetilde P, V)$ to FP8. Second, we propose a method to smooth $Q$ and $V$, enhancing the accuracy of attention with INT4 $QK$ and FP8 $PV$. Third, we analyze the quantization accuracy across timesteps and layers, then propose an adaptive quantization method to ensure the end-to-end metrics over various models. The operations per second (OPS) of SageAttention2 surpass FlashAttention2 and xformers by about 3x and 5x on RTX4090, respectively. Comprehensive experiments confirm that our approach incurs negligible end-to-end metrics loss across diverse models, including those for large language processing, image generation, and video generation. The codes are available at https://github.com/thu-ml/SageAttention.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.NE",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2411.13582",
        "abstract url": "https://arxiv.org/abs/2411.13582",
        "title": "Deep Feature Response Discriminative Calibration",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Deep neural networks (DNNs) have numerous applications across various domains. Several optimization techniques, such as ResNet and SENet, have been proposed to improve model accuracy. These techniques improve the model performance by adjusting or calibrating feature responses according to a uniform standard. However, they lack the discriminative calibration for different features, thereby introducing limitations in the model output. Therefore, we propose a method that discriminatively calibrates feature responses. The preliminary experimental results indicate that the neural feature response follows a Gaussian distribution. Consequently, we compute confidence values by employing the Gaussian probability density function, and then integrate these values with the original response values. The objective of this integration is to improve the feature discriminability of the neural feature response. Based on the calibration values, we propose a plugin-based calibration module incorporated into a modified ResNet architecture, termed Response Calibration Networks (ResCNet). Extensive experiments on datasets like CIFAR-10, CIFAR-100, SVHN, and ImageNet demonstrate the effectiveness of the proposed approach. The developed code is publicly available at https://github.com/tcmyxc/ResCNet.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.14460",
        "abstract url": "https://arxiv.org/abs/2411.14460",
        "title": "LLaSA: Large Language and Structured Data Assistant",
        "rating": "1",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "GNNs",
                "graphs"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Structured data, such as tables, graphs, and databases, play a critical role in plentiful NLP tasks such as question answering and dialogue system. Recently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs) have been introduced as an additional modality into the input of Large Language Models (LLMs) to improve their performance on Structured Knowledge Grounding (SKG) tasks. However, those GNN-enhanced LLMs have the following limitations: (1) They employ diverse GNNs to model varying types of structured data, rendering them unable to uniformly process various forms of structured data. (2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs from fully aligning with the textual space and limits their adaptability to other LLMs. To address these issues, we propose \\textbf{L}arge \\textbf{L}anguage and \\textbf{S}tructured Data \\textbf{A}ssistant (LLaSA), a general framework for enhancing LLMs' ability to handle structured data. Specifically, we represent various types of structured data in a unified hypergraph format, and use self-supervised learning to pretrain a hypergraph encoder, and a G-Former compressing encoded hypergraph representations with cross-attention. The compressed hypergraph representations are appended to the serialized inputs during training and inference stages of LLMs. Experimental results on multiple SKG tasks show that our pretrained hypergraph encoder can adapt to various LLMs and enhance their ability to process different types of structured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous SOTA method using full parameters tuning.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10718",
        "abstract url": "https://arxiv.org/abs/2411.10718",
        "title": "Transforming Teacher Education in Developing Countries: The Role of Generative AI in Bridging Theory and Practice",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This study examines the transformative potential of Generative AI (GenAI) in teacher education within developing countries, focusing on Ghana, where challenges such as limited pedagogical modeling, performance-based assessments, and practitioner-expertise gaps hinder progress. GenAI has the capacity to address these issues by supporting content knowledge acquisition, a role that currently dominates teacher education programs. By taking on this foundational role, GenAI allows teacher educators to redirect their focus to other critical areas, including pedagogical modeling, authentic assessments, and fostering digital literacy and critical thinking. These roles are interconnected, creating a ripple effect where pre-service teachers (PSTs) are better equipped to enhance K-12 learning outcomes and align education with workforce needs. The study emphasizes that GenAI's roles are multifaceted, directly addressing resistance to change, improving resource accessibility, and supporting teacher professional development. However, it cautions against misuse, which could undermine critical thinking and creativity, essential skills nurtured through traditional teaching methods. To ensure responsible and effective integration, the study advocates a scaffolding approach to GenAI literacy. This includes educating PSTs on its supportive role, training them in ethical use and prompt engineering, and equipping them to critically assess AI-generated content for biases and validity. The study concludes by recommending empirical research to explore these roles further and develop practical steps for integrating GenAI into teacher education systems responsibly and effectively.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10741",
        "abstract url": "https://arxiv.org/abs/2411.10741",
        "title": "MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Various linear complexity models, such as Linear Transformer (LinFormer), State Space Model (SSM), and Linear RNN (LinRNN), have been proposed to replace the conventional softmax attention in Transformer structures. However, the optimal design of these linear models is still an open question. In this work, we attempt to answer this question by finding the best linear approximation to softmax attention from a theoretical perspective. We start by unifying existing linear complexity models as the linear attention form and then identify three conditions for the optimal linear attention design: 1) Dynamic memory ability; 2) Static approximation ability; 3) Least parameter approximation. We find that none of the current linear models meet all three conditions, resulting in suboptimal performance. Instead, we propose Meta Linear Attention (MetaLA) as a solution that satisfies these conditions. Our experiments on Multi-Query Associative Recall (MQAR) task, language modeling, image classification, and Long-Range Arena (LRA) benchmark demonstrate that MetaLA is more effective than the existing linear models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10743",
        "abstract url": "https://arxiv.org/abs/2411.10743",
        "title": "Never eat a Pigeon with a Pumpkin: a model for the emergence and fixation of unsupported beliefs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "A popular poster from Myanmar lists food pairings that should be avoided, sometimes at all costs. Coconut and honey taken together, for example, are believed to cause nausea, while pork and curdled milk will induce diarrhea. Worst of all, according to the poster, many seemingly innocuous combinations that include jelly and coffee, beef and star fruit, or pigeon and pumpkin, are likely to kill the unwary consumer. But why are these innocuous combinations considered dangerous, even fatal? The answer is relevant, not just to food beliefs, but to social beliefs of many kinds. Here we describe the prevalence of food combination superstitions, and an opinion formation model simulating their emergence and fixation. We find that such food norms are influenced, not just by actual risks, but also by strong forces of cultural learning that can drive and lock in arbitrary rules, even in the face of contrary evidence.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": "A shortened version has been published as Chapter 30 in Food Rules and Rituals: Proceedings of the Oxford Symposium on Food and Cookery 2023, ed. Mark McWilliams, Equinox eBooks Publishing, United Kingdom. pp. 294-306"
    },
    {
        "paper id": "2411.10784",
        "abstract url": "https://arxiv.org/abs/2411.10784",
        "title": "On Reductions and Representations of Learning Problems in Euclidean Spaces",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Many practical prediction algorithms represent inputs in Euclidean space and replace the discrete 0/1 classification loss with a real-valued surrogate loss, effectively reducing classification tasks to stochastic optimization. In this paper, we investigate the expressivity of such reductions in terms of key resources, including dimension and the role of randomness. We establish bounds on the minimum Euclidean dimension $D$ needed to reduce a concept class with VC dimension $d$ to a Stochastic Convex Optimization (SCO) problem in $\\mathbb{R}^D$, formally addressing the intuitive interpretation of the VC dimension as the number of parameters needed to learn the class. To achieve this, we develop a generalization of the Borsuk-Ulam Theorem that combines the classical topological approach with convexity considerations. Perhaps surprisingly, we show that, in some cases, the number of parameters $D$ must be exponentially larger than the VC dimension $d$, even if the reduction is only slightly non-trivial. We also present natural classification tasks that can be represented in much smaller dimensions by leveraging randomness, as seen in techniques like random initialization. This result resolves an open question posed by Kamath, Montasser, and Srebro (COLT 2020). Our findings introduce new variants of \\emph{dimension complexity} (also known as \\emph{sign-rank}), a well-studied parameter in learning and complexity theory. Specifically, we define an approximate version of sign-rank and another variant that captures the minimum dimension required for a reduction to SCO. We also propose several open questions and directions for future research.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10822",
        "abstract url": "https://arxiv.org/abs/2411.10822",
        "title": "A Data-Efficient Sequential Learning Framework for Melt Pool Defect Classification in Laser Powder Bed Fusion",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Ensuring the quality and reliability of Metal Additive Manufacturing (MAM) components is crucial, especially in the Laser Powder Bed Fusion (L-PBF) process, where melt pool defects such as keyhole, balling, and lack of fusion can significantly compromise structural integrity. This study presents SL-RF+ (Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential Learning (SL) framework for melt pool defect classification designed to maximize data efficiency and model accuracy in data-scarce environments. SL-RF+ utilizes RF classifier combined with Least Confidence Sampling (LCS) and Sobol sequence-based synthetic sampling to iteratively select the most informative samples to learn from, thereby refining the model's decision boundaries with minimal labeled data. Results show that SL-RF+ outperformed traditional machine learning models across key performance metrics, including accuracy, precision, recall, and F1 score, demonstrating significant robustness in identifying melt pool defects with limited data. This framework efficiently captures complex defect patterns by focusing on high-uncertainty regions in the process parameter space, ultimately achieving superior classification performance without the need for extensive labeled datasets. While this study utilizes pre-existing experimental data, SL-RF+ shows strong potential for real-world applications in pure sequential learning settings, where data is acquired and labeled incrementally, mitigating the high costs and time constraints of sample acquisition.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10830",
        "abstract url": "https://arxiv.org/abs/2411.10830",
        "title": "One-Layer Transformer Provably Learns One-Nearest Neighbor In Context",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Transformers have achieved great success in recent years. Interestingly, transformers have shown particularly strong in-context learning capability -- even without fine-tuning, they are still able to solve unseen tasks well purely based on task-specific prompts. In this paper, we study the capability of one-layer transformers in learning one of the most classical nonparametric estimators, the one-nearest neighbor prediction rule. Under a theoretical framework where the prompt contains a sequence of labeled training data and unlabeled test data, we show that, although the loss function is nonconvex when trained with gradient descent, a single softmax attention layer can successfully learn to behave like a one-nearest neighbor classifier. Our result gives a concrete example of how transformers can be trained to implement nonparametric machine learning algorithms, and sheds light on the role of softmax attention in transformer models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10841",
        "abstract url": "https://arxiv.org/abs/2411.10841",
        "title": "Adaptive Learning of Design Strategies over Non-Hierarchical Multi-Fidelity Models via Policy Alignment",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Multi-fidelity Reinforcement Learning (RL) frameworks significantly enhance the efficiency of engineering design by leveraging analysis models with varying levels of accuracy and computational costs. The prevailing methodologies, characterized by transfer learning, human-inspired strategies, control variate techniques, and adaptive sampling, predominantly depend on a structured hierarchy of models. However, this reliance on a model hierarchy overlooks the heterogeneous error distributions of models across the design space, extending beyond mere fidelity levels. This work proposes ALPHA (Adaptively Learned Policy with Heterogeneous Analyses), a novel multi-fidelity RL framework to efficiently learn a high-fidelity policy by adaptively leveraging an arbitrary set of non-hierarchical, heterogeneous, low-fidelity models alongside a high-fidelity model. Specifically, low-fidelity policies and their experience data are dynamically used for efficient targeted learning, guided by their alignment with the high-fidelity policy. The effectiveness of ALPHA is demonstrated in analytical test optimization and octocopter design problems, utilizing two low-fidelity models alongside a high-fidelity one. The results highlight ALPHA's adaptive capability to dynamically utilize models across time and design space, eliminating the need for scheduling models as required in a hierarchical framework. Furthermore, the adaptive agents find more direct paths to high-performance solutions, showing superior convergence behavior compared to hierarchical agents.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "48 pages, 20 figures"
    },
    {
        "paper id": "2411.10861",
        "abstract url": "https://arxiv.org/abs/2411.10861",
        "title": "See-Saw Generative Mechanism for Scalable Recursive Code Generation with Generative AI",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The generation of complex, large-scale code projects using generative AI models presents challenges due to token limitations, dependency management, and iterative refinement requirements. This paper introduces the See-Saw generative mechanism, a novel methodology for dynamic and recursive code generation. The proposed approach alternates between main code updates and dependency generation to ensure alignment and functionality. By dynamically optimizing token usage and incorporating key elements of the main code into the generation of dependencies, the method enables efficient and scalable code generation for projects requiring hundreds of interdependent files. The mechanism ensures that all code components are synchronized and functional, enabling scalable and efficient project generation. Experimental validation demonstrates the method's capability to manage dependencies effectively while maintaining coherence and minimizing computational overhead.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SE"
        ],
        "comment": "18 pages, 4 figures"
    },
    {
        "paper id": "2411.10868",
        "abstract url": "https://arxiv.org/abs/2411.10868",
        "title": "Destabilizing a Social Network Model via Intrinsic Feedback Vulnerabilities",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI"
            ]
        ],
        "abstract": "Social influence plays an important role in shaping individual opinions and actions, particularly in our digitally connected world. AI-generated, personalized content has led to serious and well-founded concerns, including United States Supreme Court Cases regarding the potential for the radicalization of individuals based on social influence. Motivated by these developments, we present a case study investigating the effects of small but intentional perturbations on the integrity of a simple social network. We employ Taylor's classic model of social influence and use tools from robust control theory (most notably the Dynamic Structure Function (DSF)), to identify precisely the perturbations that are sufficient to qualitatively alter the system's equilibrium and also minimal in norm. In particular, we examine two scenarios: perturbations to an existing link and perturbations taking the form of the addition of a new link to the network. In each case, we identify destabilizing perturbations and simulate their effects. Remarkably, we find that even small alterations to network structure may cause sentiments to grow in magnitude without bound, indicating the potential for large-scale shifts in collective behavior to be triggered by minor adjustments in social influence. Our findings emphasize the imperative need for further investigation into vulnerabilities in real-world social networks, where such dynamics may already exist.",
        "subjects": [
            "cs.SI",
            "math.OC",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10877",
        "abstract url": "https://arxiv.org/abs/2411.10877",
        "title": "Developer Perspectives on Licensing and Copyright Issues Arising from Generative AI for Coding",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Generative AI (GenAI) tools have already started to transform software development practices. Despite their utility in tasks such as writing code, the use of these tools raises important legal questions and potential risks, particularly those associated with copyright law. In the midst of this uncertainty, this paper presents a study jointly conducted by software engineering and legal researchers that surveyed 574 GitHub developers who use GenAI tools for development activities. The survey and follow-up interviews probed the developers' opinions on emerging legal issues as well as their perception of copyrightability, ownership of generated code, and related considerations. We also investigate potential developer misconceptions, the impact of GenAI on developers' work, and developers' awareness of licensing/copyright risks. Qualitative and quantitative analysis showed that developers' opinions on copyright issues vary broadly and that many developers are aware of the nuances these legal questions involve. We provide: (1) a survey of 574 developers on the licensing and copyright aspects of GenAI for coding, (2) a snapshot of practitioners' views at a time when GenAI and perceptions of it are rapidly evolving, and (3) an analysis of developers' views, yielding insights and recommendations that can inform future regulatory decisions in this evolving field.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10895",
        "abstract url": "https://arxiv.org/abs/2411.10895",
        "title": "Evolution of IVR building techniques: from code writing to AI-powered automation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Interactive Voice Response (IVR) systems have undergone significant transformation in recent years, moving from traditional code-based development to more user-friendly approaches leveraging widgets and, most recently, harnessing the power of Artificial Intelligence (AI) for automated IVR flow creation. This paper explores the evolution of IVR building techniques, highlighting the industry's revolution and shaping the future of IVR systems. The authors delve into the historical context, current trends, and future prospects of IVR development, elucidating the impact of AI on simplifying IVR creation processes and enhancing customer experiences.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "6 pages, 3 figures"
    },
    {
        "paper id": "2411.10906",
        "abstract url": "https://arxiv.org/abs/2411.10906",
        "title": "Efficient, Low-Regret, Online Reinforcement Learning for Linear MDPs",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Reinforcement learning algorithms are usually stated without theoretical guarantees regarding their performance. Recently, Jin, Yang, Wang, and Jordan (COLT 2020) showed a polynomial-time reinforcement learning algorithm (namely, LSVI-UCB) for the setting of linear Markov decision processes, and provided theoretical guarantees regarding its running time and regret. In real-world scenarios, however, the space usage of this algorithm can be prohibitive due to a utilized linear regression step. We propose and analyze two modifications of LSVI-UCB, which alternate periods of learning and not-learning, to reduce space and time usage while maintaining sublinear regret. We show experimentally, on synthetic data and real-world benchmarks, that our algorithms achieve low space usage and running time, while not significantly sacrificing regret.",
        "subjects": [
            "cs.LG",
            "cs.DS"
        ],
        "comment": "27 pages, 9 figures"
    },
    {
        "paper id": "2411.11908",
        "abstract url": "https://arxiv.org/abs/2411.11908",
        "title": "LLM4DS: Evaluating Large Language Models for Data Science Code Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The adoption of Large Language Models (LLMs) for code generation in data science offers substantial potential for enhancing tasks such as data manipulation, statistical analysis, and visualization. However, the effectiveness of these models in the data science domain remains underexplored. This paper presents a controlled experiment that empirically assesses the performance of four leading LLM-based AI assistants-Microsoft Copilot (GPT-4 Turbo), ChatGPT (o1-preview), Claude (3.5 Sonnet), and Perplexity Labs (Llama-3.1-70b-instruct)-on a diverse set of data science coding challenges sourced from the Stratacratch platform. Using the Goal-Question-Metric (GQM) approach, we evaluated each model's effectiveness across task types (Analytical, Algorithm, Visualization) and varying difficulty levels. Our findings reveal that all models exceeded a 50% baseline success rate, confirming their capability beyond random chance. Notably, only ChatGPT and Claude achieved success rates significantly above a 60% baseline, though none of the models reached a 70% threshold, indicating limitations in higher standards. ChatGPT demonstrated consistent performance across varying difficulty levels, while Claude's success rate fluctuated with task complexity. Hypothesis testing indicates that task type does not significantly impact success rate overall. For analytical tasks, efficiency analysis shows no significant differences in execution times, though ChatGPT tended to be slower and less predictable despite high success rates. This study provides a structured, empirical evaluation of LLMs in data science, delivering insights that support informed model selection tailored to specific task demands. Our findings establish a framework for future AI assessments, emphasizing the value of rigorous evaluation beyond basic accuracy measures.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.ET"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2411.12760",
        "abstract url": "https://arxiv.org/abs/2411.12760",
        "title": "VayuBuddy: an LLM-Powered Chatbot to Democratize Air Quality Insights",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Nearly 6.7 million lives are lost due to air pollution every year. While policymakers are working on the mitigation strategies, public awareness can help reduce the exposure to air pollution. Air pollution data from government-installed sensors is often publicly available in raw format, but there is a non-trivial barrier for various stakeholders in deriving meaningful insights from that data. In this work, we present VayuBuddy, a Large Language Model (LLM)-powered chatbot system to reduce the barrier between the stakeholders and air quality sensor data. VayuBuddy receives the questions in natural language, analyses the structured sensory data with a LLM-generated Python code and provides answers in natural language. We use the data from Indian government air quality sensors. We benchmark the capabilities of 7 LLMs on 45 diverse question-answer pairs prepared by us. Additionally, VayuBuddy can also generate visual analysis such as line-plots, map plot, bar charts and many others from the sensory data as we demonstrate in this work.",
        "subjects": [
            "cs.HC",
            "cs.CY",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.12761",
        "abstract url": "https://arxiv.org/abs/2411.12761",
        "title": "AI-Empowered Human Research Integrating Brain Science and Social Sciences Insights",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper explores the transformative role of artificial intelligence (AI) in enhancing scientific research, particularly in the fields of brain science and social sciences. We analyze the fundamental aspects of human research and argue that it is high time for researchers to transition to human-AI joint research. Building upon this foundation, we propose two innovative research paradigms of human-AI joint research: \"AI-Brain Science Research Paradigm\" and \"AI-Social Sciences Research Paradigm\". In these paradigms, we introduce three human-AI collaboration models: AI as a research tool (ART), AI as a research assistant (ARA), and AI as a research participant (ARP). Furthermore, we outline the methods for conducting human-AI joint research. This paper seeks to redefine the collaborative interactions between human researchers and AI system, setting the stage for future research directions and sparking innovation in this interdisciplinary field.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": "Accepted to IEIR 2024, 10 pages, 4 figures"
    },
    {
        "paper id": "2411.13583",
        "abstract url": "https://arxiv.org/abs/2411.13583",
        "title": "Enhanced FIWARE-Based Architecture for Cyberphysical Systems With Tiny Machine Learning and Machine Learning Operations: A Case Study on Urban Mobility Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rise of AI and the Internet of Things is accelerating the digital transformation of society. Mobility computing presents specific barriers due to its real-time requirements, decentralization, and connectivity through wireless networks. New research on edge computing and tiny machine learning (tinyML) explores the execution of AI models on low-performance devices to address these issues. However, there are not many studies proposing agnostic architectures that manage the entire lifecycle of intelligent cyberphysical systems. This article extends a previous architecture based on FIWARE software components to implement the machine learning operations flow, enabling the management of the entire tinyML lifecycle in cyberphysical systems. We also provide a use case to showcase how to implement the FIWARE architecture through a complete example of a smart traffic system. We conclude that the FIWARE ecosystem constitutes a real reference option for developing tinyML and edge computing in cyberphysical systems.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.DC",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.14458",
        "abstract url": "https://arxiv.org/abs/2411.14458",
        "title": "Improving training time and GPU utilization in geo-distributed language model training",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The widespread adoption of language models (LMs) across multiple industries has caused huge surge in demand for GPUs. Training LMs requires tens of thousands of GPUs and housing them in the same datacenter (DCs) is becoming challenging. We focus on training such models across multiple DCs connected via Wide-Area-Network (WAN). We build ATLAS that speeds up such training time using novel temporal bandwidth sharing and many other design choices. While ATLAS improves the training time, it does not eliminate the bubbles (idle GPU cycles). We built BUBBLETEA that runs prefill-as-a-service (part of LM inference) during the bubbles that improves the GPU utilization substantially without any impact of training. Together, ATLAS and BUBBLETEA improve training time by up to 17X and achieve GPU utilization of up to 94%.",
        "subjects": [
            "cs.DC",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10705",
        "abstract url": "https://arxiv.org/abs/2411.10705",
        "title": "Poster: Reliable 3D Reconstruction for Ad-hoc Edge Implementations",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Ad-hoc edge deployments to support real-time complex video processing applications such as, multi-view 3D reconstruction often suffer from spatio-temporal system disruptions that greatly impact reconstruction quality. In this poster paper, we present a novel portfolio theory-inspired edge resource management strategy to ensure reliable multi-view 3D reconstruction by accounting for possible system disruptions.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "3 Pages, 2 figures, IEEE SEC 2024"
    },
    {
        "paper id": "2411.10713",
        "abstract url": "https://arxiv.org/abs/2411.10713",
        "title": "A Regularized LSTM Method for Detecting Fake News Articles",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.LG",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Nowadays, the rapid diffusion of fake news poses a significant problem, as it can spread misinformation and confusion. This paper aims to develop an advanced machine learning solution for detecting fake news articles. Leveraging a comprehensive dataset of news articles, including 23,502 fake news articles and 21,417 accurate news articles, we implemented and evaluated three machine-learning models. Our dataset, curated from diverse sources, provides rich textual content categorized into title, text, subject, and Date features. These features are essential for training robust classification models to distinguish between fake and authentic news articles. The initial model employed a Long Short-Term Memory (LSTM) network, achieving an accuracy of 94%. The second model improved upon this by incorporating additional regularization techniques and fine-tuning hyperparameters, resulting in a 97% accuracy. The final model combined the strengths of previous architectures with advanced optimization strategies, achieving a peak accuracy of 98%. These results demonstrate the effectiveness of our approach in identifying fake news with high precision. Implementing these models showcases significant advancements in natural language processing and machine learning techniques, contributing valuable tools for combating misinformation. Our work highlights the potential for deploying such models in real-world applications, providing a reliable method for automated fake news detection and enhancing the credibility of news dissemination.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CY"
        ],
        "comment": "6 pages, 7 figures, 2024 IEEE International Conference on Signal Processing, Information, Communication and Systems (SPICSCON)"
    },
    {
        "paper id": "2411.10781",
        "abstract url": "https://arxiv.org/abs/2411.10781",
        "title": "Bag of Design Choices for Inference of High-Resolution Masked Generative Transformer",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "Text-to-image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image diffusion models (DMs) develop at an unprecedented pace, supported by thorough theoretical exploration and empirical analysis. Unfortunately, the discrepancy between DMs and autoregressive models (ARMs) complicates the path toward achieving the goal of unified vision and language generation. Recently, the masked generative Transformer (MGT) serves as a promising intermediary between DM and ARM by predicting randomly masked image tokens (i.e., masked image modeling), combining the efficiency of DM with the discrete token nature of ARM. However, we find that the comprehensive analyses regarding the inference for MGT are virtually non-existent, and thus we aim to present positive design choices to fill this gap. We modify and re-design a set of DM-based inference techniques for MGT and further elucidate their performance on MGT. We also discuss the approach to correcting token's distribution to enhance inference. Extensive experiments and empirical analyses lead to concrete and effective design choices, and these design choices can be merged to achieve further performance gains. For instance, in terms of enhanced inference, we achieve winning rates of approximately 70% compared to vanilla sampling on HPS v2 with the recent SOTA MGT Meissonic. Our contributions have the potential to further enhance the capabilities and future development of MGTs.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10798",
        "abstract url": "https://arxiv.org/abs/2411.10798",
        "title": "Unveiling Hidden Details: A RAW Data-Enhanced Paradigm for Real-World Super-Resolution",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Super-Resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Real-world image super-resolution (Real SR) aims to generate high-fidelity, detail-rich high-resolution (HR) images from low-resolution (LR) counterparts. Existing Real SR methods primarily focus on generating details from the LR RGB domain, often leading to a lack of richness or fidelity in fine details. In this paper, we pioneer the use of details hidden in RAW data to complement existing RGB-only methods, yielding superior outputs. We argue that key image processing steps in Image Signal Processing, such as denoising and demosaicing, inherently result in the loss of fine details in LR images, making LR RAW a valuable information source. To validate this, we present RealSR-RAW, a comprehensive dataset comprising over 10,000 pairs with LR and HR RGB images, along with corresponding LR RAW, captured across multiple smartphones under varying focal lengths and diverse scenes. Additionally, we propose a novel, general RAW adapter to efficiently integrate LR RAW data into existing CNNs, Transformers, and Diffusion-based Real SR models by suppressing the noise contained in LR RAW and aligning its distribution. Extensive experiments demonstrate that incorporating RAW data significantly enhances detail recovery and improves Real SR performance across ten evaluation metrics, including both fidelity and perception-oriented metrics. Our findings open a new direction for the Real SR task, with the dataset and code will be made available to support future research.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "We sincerely apologize, but due to some commercial confidentiality agreements related to the report, we have decided to withdraw the submission for now and will resubmit after making the necessary revisions"
    },
    {
        "paper id": "2411.10800",
        "abstract url": "https://arxiv.org/abs/2411.10800",
        "title": "Test-time Conditional Text-to-Image Synthesis Using Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-Image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We consider the problem of conditional text-to-image synthesis with diffusion models. Most recent works need to either finetune specific parts of the base diffusion model or introduce new trainable parameters, leading to deployment inflexibility due to the need for training. To address this gap in the current literature, we propose our method called TINTIN: Test-time Conditional Text-to-Image Synthesis using Diffusion Models which is a new training-free test-time only algorithm to condition text-to-image diffusion model outputs on conditioning factors such as color palettes and edge maps. In particular, we propose to interpret noise predictions during denoising as gradients of an energy-based model, leading to a flexible approach to manipulate the noise by matching predictions inferred from them to the ground truth conditioning input. This results in, to the best of our knowledge, the first approach to control model outputs with input color palettes, which we realize using a novel color distribution matching loss. We also show this test-time noise manipulation can be easily extensible to other types of conditioning, e.g., edge maps. We conduct extensive experiments using a variety of text prompts, color palettes, and edge maps and demonstrate significant improvement over the current state-of-the-art, both qualitatively and quantitatively.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10818",
        "abstract url": "https://arxiv.org/abs/2411.10818",
        "title": "FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "text-to-video"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Sketch animations offer a powerful medium for visual storytelling, from simple flip-book doodles to professional studio productions. While traditional animation requires teams of skilled artists to draw key frames and in-between frames, existing automation attempts still demand significant artistic effort through precise motion paths or keyframe specification. We present FlipSketch, a system that brings back the magic of flip-book animation -- just draw your idea and describe how you want it to move! Our approach harnesses motion priors from text-to-video diffusion models, adapting them to generate sketch animations through three key innovations: (i) fine-tuning for sketch-style frame generation, (ii) a reference frame mechanism that preserves visual integrity of input sketch through noise refinement, and (iii) a dual-attention composition that enables fluid motion without losing visual consistency. Unlike constrained vector animations, our raster frames support dynamic sketch transformations, capturing the expressive freedom of traditional animation. The result is an intuitive system that makes sketch animation as simple as doodling and describing, while maintaining the artistic essence of hand-drawn animation.",
        "subjects": [
            "cs.GR",
            "cs.CV"
        ],
        "comment": "Code: https://github.com/hmrishavbandy/FlipSketch"
    },
    {
        "paper id": "2411.10825",
        "abstract url": "https://arxiv.org/abs/2411.10825",
        "title": "ARM: Appearance Reconstruction Model for Relightable 3D Generation",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent image-to-3D reconstruction models have greatly advanced geometry generation, but they still struggle to faithfully generate realistic appearance. To address this, we introduce ARM, a novel method that reconstructs high-quality 3D meshes and realistic appearance from sparse-view images. The core of ARM lies in decoupling geometry from appearance, processing appearance within the UV texture space. Unlike previous methods, ARM improves texture quality by explicitly back-projecting measurements onto the texture map and processing them in a UV space module with a global receptive field. To resolve ambiguities between material and illumination in input images, ARM introduces a material prior that encodes semantic appearance information, enhancing the robustness of appearance decomposition. Trained on just 8 H100 GPUs, ARM outperforms existing methods both quantitatively and qualitatively.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10845",
        "abstract url": "https://arxiv.org/abs/2411.10845",
        "title": "Automatic Discovery and Assessment of Interpretable Systematic Errors in Semantic Segmentation",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a novel method for discovering systematic errors in segmentation models. For instance, a systematic error in the segmentation model can be a sufficiently large number of misclassifications from the model as a parking meter for a target class of pedestrians. With the rapid deployment of these models in critical applications such as autonomous driving, it is vital to detect and interpret these systematic errors. However, the key challenge is automatically discovering such failures on unlabelled data and forming interpretable semantic sub-groups for intervention. For this, we leverage multimodal foundation models to retrieve errors and use conceptual linkage along with erroneous nature to study the systematic nature of these errors. We demonstrate that such errors are present in SOTA segmentation models (UperNet ConvNeXt and UperNet Swin) trained on the Berkeley Deep Drive and benchmark the approach qualitatively and quantitatively, showing its effectiveness by discovering coherent systematic errors for these models. Our work opens up the avenue to model analysis and intervention that have so far been underexplored in semantic segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "7 pages main paper (without references), total 13 pages & 9 figures"
    },
    {
        "paper id": "2411.10848",
        "abstract url": "https://arxiv.org/abs/2411.10848",
        "title": "NeuroNURBS: Learning Efficient Surface Representations for 3D Solids",
        "rating": "0",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Boundary Representation (B-Rep) is the de facto representation of 3D solids in Computer-Aided Design (CAD). B-Rep solids are defined with a set of NURBS (Non-Uniform Rational B-Splines) surfaces forming a closed volume. To represent a surface, current works often employ the UV-grid approximation, i.e., sample points uniformly on the surface. However, the UV-grid method is not efficient in surface representation and sometimes lacks precision and regularity. In this work, we propose NeuroNURBS, a representation learning method to directly encode the parameters of NURBS surfaces. Our evaluation in solid generation and segmentation tasks indicates that the NeuroNURBS performs comparably and, in some cases, superior to UV-grids, but with a significantly improved efficiency: for training the surface autoencoder, GPU consumption is reduced by 86.7%; memory requirement drops by 79.9% for storing 3D solids. Moreover, adapting BrepGen for solid generation with our NeuroNURBS improves the FID from 30.04 to 27.24, and resolves the undulating issue in generated surfaces.",
        "subjects": [
            "cs.CV",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10854",
        "abstract url": "https://arxiv.org/abs/2411.10854",
        "title": "Explainable DNN-based Beamformer with Postfilter",
        "rating": "0",
        "keywords": [
            [
                "speech enhancement"
            ],
            [
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces an explainable DNN-based beamformer with a postfilter (ExNet-BF+PF) for multichannel signal processing. Our approach combines the U-Net network with a beamformer structure to address this problem. The method involves a two-stage processing pipeline. In the first stage, time-invariant weights are applied to construct a multichannel spatial filter, namely a beamformer. In the second stage, a time-varying single-channel post-filter is applied at the beamformer output. Additionally, we incorporate an attention mechanism inspired by its successful application in noisy and reverberant environments to improve speech enhancement further. Furthermore, our study fills a gap in the existing literature by conducting a thorough spatial analysis of the network's performance. Specifically, we examine how the network utilizes spatial information during processing. This analysis yields valuable insights into the network's functionality, thereby enhancing our understanding of its overall performance. Experimental results demonstrate that our approach is not only straightforward to train but also yields superior results, obviating the necessity for prior knowledge of the speaker's activity.",
        "subjects": [
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10857",
        "abstract url": "https://arxiv.org/abs/2411.10857",
        "title": "Large Vision-Language Models for Remote Sensing Visual Question Answering",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "Remote Sensing",
                "satellite"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Remote Sensing Visual Question Answering (RSVQA) is a challenging task that involves interpreting complex satellite imagery to answer natural language questions. Traditional approaches often rely on separate visual feature extractors and language processing models, which can be computationally intensive and limited in their ability to handle open-ended questions. In this paper, we propose a novel method that leverages a generative Large Vision-Language Model (LVLM) to streamline the RSVQA process. Our approach consists of a two-step training strategy: domain-adaptive pretraining and prompt-based finetuning. This method enables the LVLM to generate natural language answers by conditioning on both visual and textual inputs, without the need for predefined answer categories. We evaluate our model on the RSVQAxBEN dataset, demonstrating superior performance compared to state-of-the-art baselines. Additionally, a human evaluation study shows that our method produces answers that are more accurate, relevant, and fluent. The results highlight the potential of generative LVLMs in advancing the field of remote sensing analysis.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10867",
        "abstract url": "https://arxiv.org/abs/2411.10867",
        "title": "ViBe: A Text-to-Video Benchmark for Evaluating Hallucination in Large Multimodal Models",
        "rating": "0",
        "keywords": [
            [
                "Text-to-Video"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Latest developments in Large Multimodal Models (LMMs) have broadened their capabilities to include video understanding. Specifically, Text-to-video (T2V) models have made significant progress in quality, comprehension, and duration, excelling at creating videos from simple textual prompts. Yet, they still frequently produce hallucinated content that clearly signals the video is AI-generated. We introduce ViBe: a large-scale Text-to-Video Benchmark of hallucinated videos from T2V models. We identify five major types of hallucination: Vanishing Subject, Numeric Variability, Temporal Dysmorphia, Omission Error, and Physical Incongruity. Using 10 open-source T2V models, we developed the first large-scale dataset of hallucinated videos, comprising 3,782 videos annotated by humans into these five categories. ViBe offers a unique resource for evaluating the reliability of T2V models and provides a foundation for improving hallucination detection and mitigation in video generation. We establish classification as a baseline and present various ensemble classifier configurations, with the TimeSFormer + CNN combination yielding the best performance, achieving 0.345 accuracy and 0.342 F1 score. This benchmark aims to drive the development of robust T2V models that produce videos more accurately aligned with input prompts.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10869",
        "abstract url": "https://arxiv.org/abs/2411.10869",
        "title": "Large Language Models (LLMs) as Traffic Control Systems at Urban Intersections: A New Paradigm",
        "rating": "0",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "This study introduces a novel approach for traffic control systems by using Large Language Models (LLMs) as traffic controllers. The study utilizes their logical reasoning, scene understanding, and decision-making capabilities to optimize throughput and provide feedback based on traffic conditions in real-time. LLMs centralize traditionally disconnected traffic control processes and can integrate traffic data from diverse sources to provide context-aware decisions. LLMs can also deliver tailored outputs using various means such as wireless signals and visuals to drivers, infrastructures, and autonomous vehicles. To evaluate LLMs ability as traffic controllers, this study proposed a four-stage methodology. The methodology includes data creation and environment initialization, prompt engineering, conflict identification, and fine-tuning. We simulated multi-lane four-leg intersection scenarios and generates detailed datasets to enable conflict detection using LLMs and Python simulation as a ground truth. We used chain-of-thought prompts to lead LLMs in understanding the context, detecting conflicts, resolving them using traffic rules, and delivering context-sensitive traffic management solutions. We evaluated the prformance GPT-mini, Gemini, and Llama as traffic controllers. Results showed that the fine-tuned GPT-mini achieved 83% accuracy and an F1-score of 0.84. GPT-mini model exhibited a promising performance in generating actionable traffic management insights, with high ROUGE-L scores across conflict identification of 0.95, decision-making of 0.91, priority assignment of 0.94, and waiting time optimization of 0.92. We demonstrated that LLMs can offer precise recommendations to drivers in real-time including yielding, slowing, or stopping based on vehicle dynamics.",
        "subjects": [
            "cs.CL",
            "cs.CE",
            "cs.CY",
            "cs.HC"
        ],
        "comment": "The data and code that support the findings of this study are openly available in Zenodo at https://doi.org/10.5281/zenodo.14171745, reference number 14171745"
    },
    {
        "paper id": "2411.10888",
        "abstract url": "https://arxiv.org/abs/2411.10888",
        "title": "MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language",
                "VLM"
            ],
            [
                "health",
                "Diagnosing",
                "Skin Lesions",
                "clinical",
                "lesion"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In the aftermath of the COVID-19 pandemic and amid accelerating climate change, emerging infectious diseases, particularly those arising from zoonotic spillover, remain a global threat. Mpox (caused by the monkeypox virus) is a notable example of a zoonotic infection that often goes undiagnosed, especially as its rash progresses through stages, complicating detection across diverse populations with different presentations. In August 2024, the WHO Director-General declared the mpox outbreak a public health emergency of international concern for a second time. Despite the deployment of deep learning techniques for detecting diseases from skin lesion images, a robust and publicly accessible foundation model for mpox diagnosis is still lacking due to the unavailability of open-source mpox skin lesion images, multimodal clinical data, and specialized training pipelines. To address this gap, we propose MpoxVLM, a vision-language model (VLM) designed to detect mpox by analyzing both skin lesion images and patient clinical information. MpoxVLM integrates the CLIP visual encoder, an enhanced Vision Transformer (ViT) classifier for skin lesions, and LLaMA-2-7B models, pre-trained and fine-tuned on visual instruction-following question-answer pairs from our newly released mpox skin lesion dataset. Our work achieves 90.38% accuracy for mpox detection, offering a promising pathway to improve early diagnostic accuracy in combating mpox.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accepted by ML4H 2024"
    },
    {
        "paper id": "2411.10902",
        "abstract url": "https://arxiv.org/abs/2411.10902",
        "title": "Attention-based U-Net Method for Autonomous Lane Detection",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Lane detection involves identifying lanes on the road and accurately determining their location and shape. This is a crucial technique for modern assisted and autonomous driving systems. However, several unique properties of lanes pose challenges for detection methods. The lack of distinctive features can cause lane detection algorithms to be confused by other objects with similar appearances. Additionally, the varying number of lanes and the diversity in lane line patterns, such as solid, broken, single, double, merging, and splitting lines, further complicate the task. To address these challenges, Deep Learning (DL) approaches can be employed in various ways. Merging DL models with an attention mechanism has recently surfaced as a new approach. In this context, two deep learning-based lane recognition methods are proposed in this study. The first method employs the Feature Pyramid Network (FPN) model, delivering an impressive 87.59% accuracy in detecting road lanes. The second method, which incorporates attention layers into the U-Net model, significantly boosts the performance of semantic segmentation tasks. The advanced model, achieving an extraordinary 98.98% accuracy and far surpassing the basic U-Net model, clearly showcases its superiority over existing methods in a comparative analysis. The groundbreaking findings of this research pave the way for the development of more effective and reliable road lane detection methods, significantly advancing the capabilities of modern assisted and autonomous driving systems.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.11904",
        "abstract url": "https://arxiv.org/abs/2411.11904",
        "title": "GeoGround: A Unified Large Vision-Language Model. for Remote Sensing Visual Grounding",
        "rating": "0",
        "keywords": [
            [
                "Vision-Language",
                "VLMs"
            ],
            [
                "Remote Sensing"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Remote sensing (RS) visual grounding aims to use natural language expression to locate specific objects (in the form of the bounding box or segmentation mask) in RS images, enhancing human interaction with intelligent RS interpretation systems. Early research in this area was primarily based on horizontal bounding boxes (HBBs), but as more diverse RS datasets have become available, tasks involving oriented bounding boxes (OBBs) and segmentation masks have emerged. In practical applications, different targets require different grounding types: HBB can localize an object's position, OBB provides its orientation, and mask depicts its shape. However, existing specialized methods are typically tailored to a single type of RS visual grounding task and are hard to generalize across tasks. In contrast, large vision-language models (VLMs) exhibit powerful multi-task learning capabilities but struggle to handle dense prediction tasks like segmentation. This paper proposes GeoGround, a novel framework that unifies support for HBB, OBB, and mask RS visual grounding tasks, allowing flexible output selection. Rather than customizing the architecture of VLM, our work aims to elegantly support pixel-level visual grounding output through the Text-Mask technique. We define prompt-assisted and geometry-guided learning to enhance consistency across different signals. To support model training, we present refGeo, a large-scale RS visual instruction-following dataset containing 161k image-text pairs. Experimental results show that GeoGround demonstrates strong performance across four RS visual grounding tasks, matching or surpassing the performance of specialized methods on multiple benchmarks. Code available at https://github.com/zytx121/GeoGround",
        "subjects": [
            "cs.CV"
        ],
        "comment": "25 pages, 19 figures"
    },
    {
        "paper id": "2411.11906",
        "abstract url": "https://arxiv.org/abs/2411.11906",
        "title": "$\\text{S}^{3}$Mamba: Arbitrary-Scale Super-Resolution via Scaleable State Space Model",
        "rating": "0",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Arbitrary scale super-resolution (ASSR) aims to super-resolve low-resolution images to high-resolution images at any scale using a single model, addressing the limitations of traditional super-resolution methods that are restricted to fixed-scale factors (e.g., $\\times2$, $\\times4$). The advent of Implicit Neural Representations (INR) has brought forth a plethora of novel methodologies for ASSR, which facilitate the reconstruction of original continuous signals by modeling a continuous representation space for coordinates and pixel values, thereby enabling arbitrary-scale super-resolution. Consequently, the primary objective of ASSR is to construct a continuous representation space derived from low-resolution inputs. However, existing methods, primarily based on CNNs and Transformers, face significant challenges such as high computational complexity and inadequate modeling of long-range dependencies, which hinder their effectiveness in real-world applications. To overcome these limitations, we propose a novel arbitrary-scale super-resolution method, called $\\text{S}^{3}$Mamba, to construct a scalable continuous representation space. Specifically, we propose a Scalable State Space Model (SSSM) to modulate the state transition matrix and the sampling matrix of step size during the discretization process, achieving scalable and continuous representation modeling with linear computational complexity. Additionally, we propose a novel scale-aware self-attention mechanism to further enhance the network's ability to perceive global important features at different scales, thereby building the $\\text{S}^{3}$Mamba to achieve superior arbitrary-scale super-resolution. Extensive experiments on both synthetic and real-world benchmarks demonstrate that our method achieves state-of-the-art performance and superior generalization capabilities at arbitrary super-resolution scales.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.11907",
        "abstract url": "https://arxiv.org/abs/2411.11907",
        "title": "LoRA Unlearns More and Retains More (Student Abstract)",
        "rating": "0",
        "keywords": [
            [
                "Unlearning"
            ],
            [
                "cs.LG"
            ],
            [
                "AAAI"
            ]
        ],
        "abstract": "Due to increasing privacy regulations and regulatory compliance, Machine Unlearning (MU) has become essential. The goal of unlearning is to remove information related to a specific class from a model. Traditional approaches achieve exact unlearning by retraining the model on the remaining dataset, but incur high computational costs. This has driven the development of more efficient unlearning techniques, including model sparsification techniques, which boost computational efficiency, but degrade the model's performance on the remaining classes. To mitigate these issues, we propose a novel method, PruneLoRA which introduces a new MU paradigm, termed prune first, then adapt, then unlearn. LoRA (Hu et al. 2022) reduces the need for large-scale parameter updates by applying low-rank updates to the model. We leverage LoRA to selectively modify a subset of the pruned model's parameters, thereby reducing the computational cost, memory requirements and improving the model's ability to retain performance on the remaining classes. Experimental Results across various metrics showcase that our method outperforms other approximate MU methods and bridges the gap between exact and approximate unlearning. Our code is available at https://github.com/vlgiitr/LoRA-Unlearn.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "AAAI-25 Student Abstract"
    },
    {
        "paper id": "2411.12762",
        "abstract url": "https://arxiv.org/abs/2411.12762",
        "title": "Playing Language Game with LLMs Leads to Jailbreaking",
        "rating": "0",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The advent of large language models (LLMs) has spurred the development of numerous jailbreak techniques aimed at circumventing their security defenses against malicious attacks. An effective jailbreak approach is to identify a domain where safety generalization fails, a phenomenon known as mismatched generalization. In this paper, we introduce two novel jailbreak methods based on mismatched generalization: natural language games and custom language games, both of which effectively bypass the safety mechanisms of LLMs, with various kinds and different variants, making them hard to defend and leading to high attack rates. Natural language games involve the use of synthetic linguistic constructs and the actions intertwined with these constructs, such as the Ubbi Dubbi language. Building on this phenomenon, we propose the custom language games method: by engaging with LLMs using a variety of custom rules, we successfully execute jailbreak attacks across multiple LLM platforms. Extensive experiments demonstrate the effectiveness of our methods, achieving success rates of 93% on GPT-4o, 89% on GPT-4o-mini and 83% on Claude-3.5-Sonnet. Furthermore, to investigate the generalizability of safety alignments, we fine-tuned Llama-3.1-70B with the custom language games to achieve safety alignment within our datasets and found that when interacting through other language games, the fine-tuned models still failed to identify harmful content. This finding indicates that the safety alignment knowledge embedded in LLMs fails to generalize across different linguistic formats, thus opening new avenues for future research in this area.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10702",
        "abstract url": "https://arxiv.org/abs/2411.10702",
        "title": "Wireless Resource Allocation with Collaborative Distributed and Centralized DRL under Control Channel Attacks",
        "rating": "-0.5",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we consider a wireless resource allocation problem in a cyber-physical system (CPS) where the control channel, carrying resource allocation commands, is subjected to denial-of-service (DoS) attacks. We propose a novel concept of collaborative distributed and centralized (CDC) resource allocation to effectively mitigate the impact of these attacks. To optimize the CDC resource allocation policy, we develop a new CDC-deep reinforcement learning (DRL) algorithm, whereas existing DRL frameworks only formulate either centralized or distributed decision-making problems. Simulation results demonstrate that the CDC-DRL algorithm significantly outperforms state-of-the-art DRL benchmarks, showcasing its ability to address resource allocation problems in large-scale CPSs under control channel attacks.",
        "subjects": [
            "cs.IT",
            "cs.LG",
            "eess.SP",
            "eess.SY"
        ],
        "comment": "This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.10729",
        "abstract url": "https://arxiv.org/abs/2411.10729",
        "title": "On-device Anomaly Detection in Conveyor Belt Operations",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Mining 4.0 leverages advancements in automation, digitalization, and interconnected technologies from Industry 4.0 to address the unique challenges of the mining sector, enhancing efficiency, safety, and sustainability. Conveyor belts are crucial in mining operations by enabling the continuous and efficient movement of bulk materials over long distances, which directly impacts productivity. While detecting anomalies in specific conveyor belt components, such as idlers, pulleys, and belt surfaces, has been widely studied, identifying the root causes of these failures remains critical due to factors like changing production conditions and operator errors. Continuous monitoring of mining conveyor belt work cycles for anomaly detection is still at an early stage and requires robust solutions. This study proposes two distinctive pattern recognition approaches for real-time anomaly detection in the operational cycles of mining conveyor belts, combining feature extraction, threshold-based cycle detection, and tiny machine-learning classification. Both approaches outperformed a state-of-the-art technique on two datasets for duty cycle classification in terms of F1-scores. The first approach, with 97.3% and 80.2% for normal and abnormal cycles, respectively, reaches the highest performance in the first dataset while the second approach excels on the second dataset, scoring 91.3% and 67.9%. Implemented on two low-power microcontrollers, the methods demonstrated efficient, real-time operation with energy consumption of 13.3 and 20.6 $\u03bc$J during inference. These results offer valuable insights for detecting mechanical failure sources, supporting targeted preventive maintenance, and optimizing production cycles.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "eess.SP"
        ],
        "comment": "Preprint submitted to IEEE Transactions on Instrumentation and Measurement"
    },
    {
        "paper id": "2411.10761",
        "abstract url": "https://arxiv.org/abs/2411.10761",
        "title": "Can Generic LLMs Help Analyze Child-adult Interactions Involving Children with Autism in Clinical Observation?",
        "rating": "-0.5",
        "keywords": [
            [
                "Clinical"
            ],
            [
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have shown significant potential in understanding human communication and interaction. However, their performance in the domain of child-inclusive interactions, including in clinical settings, remains less explored. In this work, we evaluate generic LLMs' ability to analyze child-adult dyadic interactions in a clinically relevant context involving children with ASD. Specifically, we explore LLMs in performing four tasks: classifying child-adult utterances, predicting engaged activities, recognizing language skills and understanding traits that are clinically relevant. Our evaluation shows that generic LLMs are highly capable of analyzing long and complex conversations in clinical observation sessions, often surpassing the performance of non-expert human evaluators. The results show their potential to segment interactions of interest, assist in language skills evaluation, identify engaged activities, and offer clinical-relevant context for assessments.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "GenAI for Health Workshop, NeurIPS 2024"
    },
    {
        "paper id": "2411.10913",
        "abstract url": "https://arxiv.org/abs/2411.10913",
        "title": "Generating Compositional Scenes via Text-to-image RGBA Instance Generation",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion",
                "Text-to-image"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Text-to-image diffusion generative models can generate high quality images at the cost of tedious prompt engineering. Controllability can be improved by introducing layout conditioning, however existing methods lack layout editing ability and fine-grained control over object attributes. The concept of multi-layer generation holds great potential to address these limitations, however generating image instances concurrently to scene composition limits control over fine-grained object attributes, relative positioning in 3D space and scene manipulation abilities. In this work, we propose a novel multi-stage generation paradigm that is designed for fine-grained control, flexibility and interactivity. To ensure control over instance attributes, we devise a novel training paradigm to adapt a diffusion model to generate isolated scene components as RGBA images with transparency information. To build complex images, we employ these pre-generated instances and introduce a multi-layer composite generation process that smoothly assembles components in realistic scenes. Our experiments show that our RGBA diffusion model is capable of generating diverse and high quality instances with precise control over object attributes. Through multi-layer composition, we demonstrate that our approach allows to build and manipulate images from highly complex prompts with fine-grained control over object appearance and location, granting a higher degree of control than competing methods.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2411.10932",
        "abstract url": "https://arxiv.org/abs/2411.10932",
        "title": "Constrained Diffusion with Trust Sampling",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Diffusion models have demonstrated significant promise in various generative tasks; however, they often struggle to satisfy challenging constraints. Our approach addresses this limitation by rethinking training-free loss-guided diffusion from an optimization perspective. We formulate a series of constrained optimizations throughout the inference process of a diffusion model. In each optimization, we allow the sample to take multiple steps along the gradient of the proxy constraint function until we can no longer trust the proxy, according to the variance at each diffusion level. Additionally, we estimate the state manifold of diffusion model to allow for early termination when the sample starts to wander away from the state manifold at each diffusion step. Trust sampling effectively balances between following the unconditional diffusion model and adhering to the loss guidance, enabling more flexible and accurate constrained generation. We demonstrate the efficacy of our method through extensive experiments on complex tasks, and in drastically different domains of images and 3D motion generation, showing significant improvements over existing methods in terms of generation quality. Our implementation is available at https://github.com/will-s-h/trust-sampling.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "18 pages, 6 figures, NeurIPS"
    },
    {
        "paper id": "2411.10957",
        "abstract url": "https://arxiv.org/abs/2411.10957",
        "title": "IMPaCT GNN: Imposing invariance with Message Passing in Chronological split Temporal Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graphs"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This paper addresses domain adaptation challenges in graph data resulting from chronological splits. In a transductive graph learning setting, where each node is associated with a timestamp, we focus on the task of Semi-Supervised Node Classification (SSNC), aiming to classify recent nodes using labels of past nodes. Temporal dependencies in node connections create domain shifts, causing significant performance degradation when applying models trained on historical data into recent data. Given the practical relevance of this scenario, addressing domain adaptation in chronological split data is crucial, yet underexplored. We propose Imposing invariance with Message Passing in Chronological split Temporal Graphs (IMPaCT), a method that imposes invariant properties based on realistic assumptions derived from temporal graph structures. Unlike traditional domain adaptation approaches which rely on unverifiable assumptions, IMPaCT explicitly accounts for the characteristics of chronological splits. The IMPaCT is further supported by rigorous mathematical analysis, including a derivation of an upper bound of the generalization error. Experimentally, IMPaCT achieves a 3.8% performance improvement over current SOTA method on the ogbn-mag graph dataset. Additionally, we introduce the Temporal Stochastic Block Model (TSBM), which replicates temporal graphs under varying conditions, demonstrating the applicability of our methods to general spatial GNNs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": "11 pages (without appendix), 35 pages (with appendix), 14 figures"
    },
    {
        "paper id": "2411.13581",
        "abstract url": "https://arxiv.org/abs/2411.13581",
        "title": "Browser Extension for Fake URL Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "In recent years, Cyber attacks have increased in number, and with them, the intensity of the attacks and their potential to damage the user have also increased significantly. In an ever-advancing world, users find it difficult to keep up with the latest developments in technology, which can leave them vulnerable to attacks. To avoid such situations we need tools to deter such attacks, for this machine learning models are among the best options. This paper presents a Browser Extension that uses machine learning models to enhance online security by integrating three crucial functionalities: Malicious URL detection, Spam Email detection and Network logs analysis. The proposed solution uses LGBM classifier for classification of Phishing websites, the model has been trained on a dataset with 87 features, this model achieved an accuracy of 96.5% with a precision of 96.8% and F1 score of 96.49%. The Model for Spam email detection uses Multinomial NB algorithm which has been trained on a dataset with over 5500 messages, this model achieved an accuracy of 97.09% with a precision of 100%. The results demonstrate the effectiveness of using machine learning models for cyber security.",
        "subjects": [
            "cs.CR",
            "cs.CE",
            "cs.CY",
            "cs.LG"
        ],
        "comment": "5 Pages, 2 figures"
    },
    {
        "paper id": "2411.10708",
        "abstract url": "https://arxiv.org/abs/2411.10708",
        "title": "AllRestorer: All-in-One Transformer for Image Restoration under Composite Degradations",
        "rating": "-1",
        "keywords": [
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Image restoration models often face the simultaneous interaction of multiple degradations in real-world scenarios. Existing approaches typically handle single or composite degradations based on scene descriptors derived from text or image embeddings. However, due to the varying proportions of different degradations within an image, these scene descriptors may not accurately differentiate between degradations, leading to suboptimal restoration in practical applications. To address this issue, we propose a novel Transformer-based restoration framework, AllRestorer. In AllRestorer, we enable the model to adaptively consider all image impairments, thereby avoiding errors from scene descriptor misdirection. Specifically, we introduce an All-in-One Transformer Block (AiOTB), which adaptively removes all degradations present in a given image by modeling the relationships between all degradations and the image embedding in latent space. To accurately address different variations potentially present within the same type of degradation and minimize ambiguity, AiOTB utilizes a composite scene descriptor consisting of both image and text embeddings to define the degradation. Furthermore, AiOTB includes an adaptive weight for each degradation, allowing for precise control of the restoration intensity. By leveraging AiOTB, AllRestorer avoids misdirection caused by inaccurate scene descriptors, achieving a 5.00 dB increase in PSNR compared to the baseline on the CDD-11 dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "12 pages, 11 figures"
    },
    {
        "paper id": "2411.10709",
        "abstract url": "https://arxiv.org/abs/2411.10709",
        "title": "Diagnostic Text-guided Representation Learning in Hierarchical Classification for Pathological Whole Slide Image",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "diagnosis",
                "Whole Slide",
                "cancer",
                "Pathological",
                "lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the development of digital imaging in medical microscopy, artificial intelligent-based analysis of pathological whole slide images (WSIs) provides a powerful tool for cancer diagnosis. Limited by the expensive cost of pixel-level annotation, current research primarily focuses on representation learning with slide-level labels, showing success in various downstream tasks. However, given the diversity of lesion types and the complex relationships between each other, these techniques still deserve further exploration in addressing advanced pathology tasks. To this end, we introduce the concept of hierarchical pathological image classification and propose a representation learning called PathTree. PathTree considers the multi-classification of diseases as a binary tree structure. Each category is represented as a professional pathological text description, which messages information with a tree-like encoder. The interactive text features are then used to guide the aggregation of hierarchical multiple representations. PathTree uses slide-text similarity to obtain probability scores and introduces two extra tree specific losses to further constrain the association between texts and slides. Through extensive experiments on three challenging hierarchical classification datasets: in-house cryosectioned lung tissue lesion identification, public prostate cancer grade assessment, and public breast cancer subtyping, our proposed PathTree is consistently competitive compared to the state-of-the-art methods and provides a new perspective on the deep learning-assisted solution for more complex WSI classification.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "15 pages, 13 figures. Under Review"
    },
    {
        "paper id": "2411.10719",
        "abstract url": "https://arxiv.org/abs/2411.10719",
        "title": "Computational Complexity of Envy-free and Exchange-stable Seat Arrangement Problems on Grid Graphs",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "The Seat Arrangement Problem is a problem of finding a desirable seat arrangement for given preferences of agents and a seat graph that represents a configuration of seats. In this paper, we consider decision problems of determining if an envy-free arrangement exists and an exchange-stable arrangement exists, when a seat graph is an $\\ell \\times m$ grid graph. When $\\ell=1$, the seat graph is a path of length $m$ and both problems have been known to be NP-complete. In this paper, we extend it and show that both problems are NP-complete for any integer $\\ell \\geq 2$.",
        "subjects": [
            "cs.GT",
            "cs.CC",
            "cs.DS"
        ],
        "comment": "23 pages, 16 figures"
    },
    {
        "paper id": "2411.10723",
        "abstract url": "https://arxiv.org/abs/2411.10723",
        "title": "Performance Analysis and Power Allocation for Massive MIMO ISAC Systems",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "Integrated sensing and communications (ISAC) is envisioned as a key feature in future wireless communications networks. Its integration with massive multiple-input-multiple-output (MIMO) techniques promises to leverage substantial spatial beamforming gains for both functionalities. In this work, we consider a massive MIMO-ISAC system employing a uniform planar array with zero-forcing and maximum-ratio downlink transmission schemes combined with monostatic radar-type sensing. Our focus lies on deriving closed-form expressions for the achievable communications rate and the Cram\u00e9r--Rao lower bound (CRLB), which serve as performance metrics for communications and sensing operations, respectively. The expressions enable us to investigate important operational characteristics of massive MIMO-ISAC, including the mutual effects of communications and sensing as well as the advantages stemming from using a very large antenna array for each functionality. Furthermore, we devise a power allocation strategy based on successive convex approximation to maximize the communications rate while guaranteeing the CRLB constraints and transmit power budget. Extensive numerical results are presented to validate our theoretical analyses and demonstrate the efficiency of the proposed power allocation approach.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "This paper has been submitted to IEEE Transaction on Signal Processing (on 15 April 2024) for possible publication"
    },
    {
        "paper id": "2411.10724",
        "abstract url": "https://arxiv.org/abs/2411.10724",
        "title": "HJ-Ky-0.1: an Evaluation Dataset for Kyrgyz Word Embeddings",
        "rating": "-1",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "One of the key tasks in modern applied computational linguistics is constructing word vector representations (word embeddings), which are widely used to address natural language processing tasks such as sentiment analysis, information extraction, and more. To choose an appropriate method for generating these word embeddings, quality assessment techniques are often necessary. A standard approach involves calculating distances between vectors for words with expert-assessed 'similarity'. This work introduces the first 'silver standard' dataset for such tasks in the Kyrgyz language, alongside training corresponding models and validating the dataset's suitability through quality evaluation metrics.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10745",
        "abstract url": "https://arxiv.org/abs/2411.10745",
        "title": "TDSM: Triplet Diffusion for Skeleton-Text Matching in Zero-Shot Action Recognition",
        "rating": "-1",
        "keywords": [
            [
                "Skeleton"
            ],
            [
                "Diffusion",
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We firstly present a diffusion-based action recognition with zero-shot learning for skeleton inputs. In zero-shot skeleton-based action recognition, aligning skeleton features with the text features of action labels is essential for accurately predicting unseen actions. Previous methods focus on direct alignment between skeleton and text latent spaces, but the modality gaps between these spaces hinder robust generalization learning. Motivated from the remarkable performance of text-to-image diffusion models, we leverage their alignment capabilities between different modalities mostly by focusing on the training process during reverse diffusion rather than using their generative power. Based on this, our framework is designed as a Triplet Diffusion for Skeleton-Text Matching (TDSM) method which aligns skeleton features with text prompts through reverse diffusion, embedding the prompts into the unified skeleton-text latent space to achieve robust matching. To enhance discriminative power, we introduce a novel triplet diffusion (TD) loss that encourages our TDSM to correct skeleton-text matches while pushing apart incorrect ones. Our TDSM significantly outperforms the very recent state-of-the-art methods with large margins of 2.36%-point to 13.05%-point, demonstrating superior accuracy and scalability in zero-shot settings through effective skeleton-text matching.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Please visit our project page at https://kaist-viclab.github.io/TDSM_site/"
    },
    {
        "paper id": "2411.10746",
        "abstract url": "https://arxiv.org/abs/2411.10746",
        "title": "LTCXNet: Advancing Chest X-Ray Analysis with Solutions for Long-Tailed Multi-Label Classification and Fairness Challenges",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "X-Ray"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Chest X-rays (CXRs) often display various diseases with disparate class frequencies, leading to a long-tailed, multi-label data distribution. In response to this challenge, we explore the Pruned MIMIC-CXR-LT dataset, a curated collection derived from the MIMIC-CXR dataset, specifically designed to represent a long-tailed and multi-label data scenario. We introduce LTCXNet, a novel framework that integrates the ConvNeXt model, ML-Decoder, and strategic data augmentation, further enhanced by an ensemble approach. We demonstrate that LTCXNet improves the performance of CXR interpretation across all classes, especially enhancing detection in rarer classes like `Pneumoperitoneum' and `Pneumomediastinum' by 79\\% and 48\\%, respectively. Beyond performance metrics, our research extends into evaluating fairness, highlighting that some methods, while improving model accuracy, could inadvertently affect fairness across different demographic groups negatively. This work contributes to advancing the understanding and management of long-tailed, multi-label data distributions in medical imaging, paving the way for more equitable and effective diagnostic tools.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "8 pages, 5 figures"
    },
    {
        "paper id": "2411.10752",
        "abstract url": "https://arxiv.org/abs/2411.10752",
        "title": "Towards a Comprehensive Benchmark for Pathological Lymph Node Metastasis in Breast Cancer Sections",
        "rating": "-1",
        "keywords": [
            [
                "whole slide",
                "Cancer",
                "clinical",
                "tumor",
                "Pathological"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Advances in optical microscopy scanning have significantly contributed to computational pathology (CPath) by converting traditional histopathological slides into whole slide images (WSIs). This development enables comprehensive digital reviews by pathologists and accelerates AI-driven diagnostic support for WSI analysis. Recent advances in foundational pathology models have increased the need for benchmarking tasks. The Camelyon series is one of the most widely used open-source datasets in computational pathology. However, the quality, accessibility, and clinical relevance of the labels have not been comprehensively evaluated. In this study, we reprocessed 1,399 WSIs and labels from the Camelyon-16 and Camelyon-17 datasets, removing low-quality slides, correcting erroneous labels, and providing expert pixel annotations for tumor regions in the previously unreleased test set. Based on the sizes of re-annotated tumor regions, we upgraded the binary cancer screening task to a four-class task: negative, micro-metastasis, macro-metastasis, and Isolated Tumor Cells (ITC). We reevaluated pre-trained pathology feature extractors and multiple instance learning (MIL) methods using the cleaned dataset, providing a benchmark that advances AI development in histopathology.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10775",
        "abstract url": "https://arxiv.org/abs/2411.10775",
        "title": "Beyond Feature Mapping GAP: Integrating Real HDRTV Priors for Superior SDRTV-to-HDRTV Conversion",
        "rating": "-1",
        "keywords": [
            [
                "HDR"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The rise of HDR-WCG display devices has highlighted the need to convert SDRTV to HDRTV, as most video sources are still in SDR. Existing methods primarily focus on designing neural networks to learn a single-style mapping from SDRTV to HDRTV. However, the limited information in SDRTV and the diversity of styles in real-world conversions render this process an ill-posed problem, thereby constraining the performance and generalization of these methods. Inspired by generative approaches, we propose a novel method for SDRTV to HDRTV conversion guided by real HDRTV priors. Despite the limited information in SDRTV, introducing real HDRTV as reference priors significantly constrains the solution space of the originally high-dimensional ill-posed problem. This shift transforms the task from solving an unreferenced prediction problem to making a referenced selection, thereby markedly enhancing the accuracy and reliability of the conversion process. Specifically, our approach comprises two stages: the first stage employs a Vector Quantized Generative Adversarial Network to capture HDRTV priors, while the second stage matches these priors to the input SDRTV content to recover realistic HDRTV outputs. We evaluate our method on public datasets, demonstrating its effectiveness with significant improvements in both objective and subjective metrics across real and synthetic datasets.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.MM"
        ],
        "comment": "8 pages,4 figures"
    },
    {
        "paper id": "2411.10788",
        "abstract url": "https://arxiv.org/abs/2411.10788",
        "title": "C-DiffSET: Leveraging Latent Diffusion for SAR-to-EO Image Translation with Confidence-Guided Reliable Object Generation",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Radar"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Synthetic Aperture Radar (SAR) imagery provides robust environmental and temporal coverage (e.g., during clouds, seasons, day-night cycles), yet its noise and unique structural patterns pose interpretation challenges, especially for non-experts. SAR-to-EO (Electro-Optical) image translation (SET) has emerged to make SAR images more perceptually interpretable. However, traditional approaches trained from scratch on limited SAR-EO datasets are prone to overfitting. To address these challenges, we introduce Confidence Diffusion for SAR-to-EO Translation, called C-DiffSET, a framework leveraging pretrained Latent Diffusion Model (LDM) extensively trained on natural images, thus enabling effective adaptation to the EO domain. Remarkably, we find that the pretrained VAE encoder aligns SAR and EO images in the same latent space, even with varying noise levels in SAR inputs. To further improve pixel-wise fidelity for SET, we propose a confidence-guided diffusion (C-Diff) loss that mitigates artifacts from temporal discrepancies, such as appearing or disappearing objects, thereby enhancing structural accuracy. C-DiffSET achieves state-of-the-art (SOTA) results on multiple datasets, significantly outperforming the very recent image-to-image translation methods and SET methods with large margins.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": "Please visit our project page https://kaist-viclab.github.io/C-DiffSET_site/"
    },
    {
        "paper id": "2411.10789",
        "abstract url": "https://arxiv.org/abs/2411.10789",
        "title": "Anatomy-Guided Radiology Report Generation with Pathology-Aware Regional Prompts",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "clinical",
                "pathological",
                "Radiology",
                "lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Radiology reporting generative AI holds significant potential to alleviate clinical workloads and streamline medical care. However, achieving high clinical accuracy is challenging, as radiological images often feature subtle lesions and intricate structures. Existing systems often fall short, largely due to their reliance on fixed size, patch-level image features and insufficient incorporation of pathological information. This can result in the neglect of such subtle patterns and inconsistent descriptions of crucial pathologies. To address these challenges, we propose an innovative approach that leverages pathology-aware regional prompts to explicitly integrate anatomical and pathological information of various scales, significantly enhancing the precision and clinical relevance of generated reports. We develop an anatomical region detector that extracts features from distinct anatomical areas, coupled with a novel multi-label lesion detector that identifies global pathologies. Our approach emulates the diagnostic process of radiologists, producing clinically accurate reports with comprehensive diagnostic capabilities. Experimental results show that our model outperforms previous state-of-the-art methods on most natural language generation and clinical efficacy metrics, with formal expert evaluations affirming its potential to enhance radiology practice.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10809",
        "abstract url": "https://arxiv.org/abs/2411.10809",
        "title": "Stable Continual Reinforcement Learning via Diffusion-based Trajectory Replay",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Trajectory"
            ],
            [
                "cs.LG"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "Given the inherent non-stationarity prevalent in real-world applications, continual Reinforcement Learning (RL) aims to equip the agent with the capability to address a series of sequentially presented decision-making tasks. Within this problem setting, a pivotal challenge revolves around \\textit{catastrophic forgetting} issue, wherein the agent is prone to effortlessly erode the decisional knowledge associated with past encountered tasks when learning the new one. In recent progresses, the \\textit{generative replay} methods have showcased substantial potential by employing generative models to replay data distribution of past tasks. Compared to storing the data from past tasks directly, this category of methods circumvents the growing storage overhead and possible data privacy concerns. However, constrained by the expressive capacity of generative models, existing \\textit{generative replay} methods face challenges in faithfully reconstructing the data distribution of past tasks, particularly in scenarios with a myriad of tasks or high-dimensional data. Inspired by the success of diffusion models in various generative tasks, this paper introduces a novel continual RL algorithm DISTR (Diffusion-based Trajectory Replay) that employs a diffusion model to memorize the high-return trajectory distribution of each encountered task and wakeups these distributions during the policy learning on new tasks. Besides, considering the impracticality of replaying all past data each time, a prioritization mechanism is proposed to prioritize the trajectory replay of pivotal tasks in our method. Empirical experiments on the popular continual RL benchmark \\texttt{Continual World} demonstrate that our proposed method obtains a favorable balance between \\textit{stability} and \\textit{plasticity}, surpassing various existing continual RL baselines in average success rate.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 3 figures, 1 table, inclusion at ICLR 2024 Workshop on Generative Models for Decision Making"
    },
    {
        "paper id": "2411.10831",
        "abstract url": "https://arxiv.org/abs/2411.10831",
        "title": "Neighboring Slice Noise2Noise: Self-Supervised Medical Image Denoising from Single Noisy Image Volume",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In the last few years, with the rapid development of deep learning technologies, supervised methods based on convolutional neural networks have greatly enhanced the performance of medical image denoising. However, these methods require large quantities of noisy-clean image pairs for training, which greatly limits their practicality. Although some researchers have attempted to train denoising networks using only single noisy images, existing self-supervised methods, including blind-spot-based and data-splitting-based methods, heavily rely on the assumption that noise is pixel-wise independent. However, this assumption often does not hold in real-world medical images. Therefore, in the field of medical imaging, there remains a lack of simple and practical denoising methods that can achieve high-quality denoising performance using only single noisy images. In this paper, we propose a novel self-supervised medical image denoising method, Neighboring Slice Noise2Noise (NS-N2N). The proposed method utilizes neighboring slices within a single noisy image volume to construct weighted training data, and then trains the denoising network using a self-supervised scheme with regional consistency loss and inter-slice continuity loss. NS-N2N only requires a single noisy image volume obtained from one medical imaging procedure to achieve high-quality denoising of the image volume itself. Extensive experiments demonstrate that the proposed method outperforms state-of-the-art self-supervised denoising methods in both denoising performance and processing efficiency. Furthermore, since NS-N2N operates solely in the image domain, it is free from device-specific issues such as reconstruction geometry, making it easier to apply in various clinical practices.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10843",
        "abstract url": "https://arxiv.org/abs/2411.10843",
        "title": "A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks",
        "rating": "-1",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Diabetic retinopathy is a leading cause of blindness around the world and demands precise AI-based diagnostic tools. Traditional loss functions in multi-class classification, such as Categorical Cross-Entropy (CCE), are very common but break down with class imbalance, especially in cases with inherently challenging or overlapping classes, which leads to biased and less sensitive models. Since a heavy imbalance exists in the number of examples for higher severity stage 4 diabetic retinopathy, etc., classes compared to those very early stages like class 0, achieving class balance is key. For this purpose, we propose the Adaptive Hybrid Focal-Entropy Loss which combines the ideas of focal loss and entropy loss with adaptive weighting in order to focus on minority classes and highlight the challenging samples. The state-of-the art models applied for diabetic retinopathy detection with AHFE revealed good performance improvements, indicating the top performances of ResNet50 at 99.79%, DenseNet121 at 98.86%, Xception at 98.92%, MobileNetV2 at 97.84%, and InceptionV3 at 93.62% accuracy. This sheds light into how AHFE promotes enhancement in AI-driven diagnostics for complex and imbalanced medical datasets.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "9 pages,7 figures"
    },
    {
        "paper id": "2411.10855",
        "abstract url": "https://arxiv.org/abs/2411.10855",
        "title": "On the Verification of Control Flow Attestation Evidence",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Remote run-time attestation methods, including Control Flow Attestation (CFA) and Data Flow Attestation (DFA), have been proposed to generate precise evidence of execution's control flow path (in CFA) and optionally execution data inputs (in DFA) on a remote and potentially compromised embedded device, hereby referred to as a Prover (Prv). Recent advances in run-time attestation architectures are also able to guarantee that a remote Verifier (Vrf) reliably receives this evidence from Prv, even when Prv's software state is fully compromised. This, in theory, enables secure \"run-time auditing\" in addition to best-effort attestation, i.e., it guarantees that Vrf can examine execution evidence to identify previously unknown compromises as soon as they are exploited, pinpoint their root cause(s), and remediate them. However, prior work has for the most part focused on securely implementing Prv's root of trust (responsible for generating authentic run-time evidence), leaving Vrf 's perspective in this security service unexplored. In this work, we argue that run-time attestation and auditing are only truly useful if Vrf can effectively analyze received evidence. From this premise, we characterize different types of evidence produced by existing run-time attestation/auditing architectures in terms of Vrf 's ability to detect and remediate (previously unknown) vulnerabilities. As a case study for practical uses of run-time evidence by Vrf, we propose SABRE: a Security Analysis and Binary Repair Engine. SABRE showcases how Vrf can systematically leverage run-time evidence to detect control flow attacks, pinpoint corrupted control data and specific instructions used to corrupt them, and leverage this evidence to automatically generate binary patches to buffer overflow and use-after-free vulnerabilities without source code knowledge.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10881",
        "abstract url": "https://arxiv.org/abs/2411.10881",
        "title": "FIAS: Feature Imbalance-Aware Medical Image Segmentation with Dynamic Fusion and Mixing Attention",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "organ"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "With the growing application of transformer in computer vision, hybrid architecture that combine convolutional neural networks (CNNs) and transformers demonstrates competitive ability in medical image segmentation. However, direct fusion of features from CNNs and transformers often leads to feature imbalance and redundant information. To address these issues, we propose a Feaure Imbalance-Aware Segmentation (FIAS) network, which incorporates a dual-path encoder and a novel Mixing Attention (MixAtt) decoder. The dual-branches encoder integrates a DilateFormer for long-range global feature extraction and a Depthwise Multi-Kernel (DMK) convolution for capturing fine-grained local details. A Context-Aware Fusion (CAF) block dynamically balances the contribution of these global and local features, preventing feature imbalance. The MixAtt decoder further enhances segmentation accuracy by combining self-attention and Monte Carlo attention, enabling the model to capture both small details and large-scale dependencies. Experimental results on the Synapse multi-organ and ACDC datasets demonstrate the strong competitiveness of our approach in medical image segmentation tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "5 pages, 2 figures, 3 tables"
    },
    {
        "paper id": "2411.10883",
        "abstract url": "https://arxiv.org/abs/2411.10883",
        "title": "I Know What You Sync: Covert and Side Channel Attacks on File Systems via syncfs",
        "rating": "-1",
        "keywords": [
            [
                "Attacks"
            ]
        ],
        "abstract": "Operating Systems enforce logical isolation using abstractions such as processes, containers, and isolation technologies to protect a system from malicious or buggy code. In this paper, we show new types of side channels through the file system that break this logical isolation. The file system plays a critical role in the operating system, managing all I/O activities between the application layer and the physical storage device. We observe that the file system implementation is shared, leading to timing leakage when using common I/O system calls. Specifically, we found that modern operating systems take advantage of any flush operation (which saves cached blocks in memory to the SSD or disk) to flush all of the I/O buffers, even those used by other isolation domains. Thus, by measuring the delay of syncfs, the attacker can infer the I/O behavior of victim programs. We then demonstrate a syncfs covert channel attack on multiple file systems, including both Linux native file systems and the Windows file system, achieving a maximum bandwidth of 5 Kbps with an error rate of 0.15% on Linux and 7.6 Kbps with an error rate of 1.9% on Windows. In addition, we construct three side-channel attacks targeting both Linux and Android devices. On Linux devices, we implement a website fingerprinting attack and a video fingerprinting attack by tracking the write patterns of temporary buffering files. On Android devices, we design an application fingerprinting attack that leaks application write patterns during boot-up. The attacks achieve over 90% F1 score, precision, and recall. Finally, we demonstrate that these attacks can be exploited across containers implementing a container detection technique and a cross-container covert channel attack.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10886",
        "abstract url": "https://arxiv.org/abs/2411.10886",
        "title": "MetricGold: Leveraging Text-To-Image Latent Diffusion Models for Metric Depth Estimation",
        "rating": "-1",
        "keywords": [
            [
                "Depth"
            ],
            [
                "Diffusion",
                "Text-To-Image"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recovering metric depth from a single image remains a fundamental challenge in computer vision, requiring both scene understanding and accurate scaling. While deep learning has advanced monocular depth estimation, current models often struggle with unfamiliar scenes and layouts, particularly in zero-shot scenarios and when predicting scale-ergodic metric depth. We present MetricGold, a novel approach that harnesses generative diffusion model's rich priors to improve metric depth estimation. Building upon recent advances in MariGold, DDVM and Depth Anything V2 respectively, our method combines latent diffusion, log-scaled metric depth representation, and synthetic data training. MetricGold achieves efficient training on a single RTX 3090 within two days using photo-realistic synthetic data from HyperSIM, VirtualKitti, and TartanAir. Our experiments demonstrate robust generalization across diverse datasets, producing sharper and higher quality metric depth estimates compared to existing approaches.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.RO"
        ],
        "comment": "arXiv admin note: substantial text overlap with arXiv:2312.02145 by other authors"
    },
    {
        "paper id": "2411.10894",
        "abstract url": "https://arxiv.org/abs/2411.10894",
        "title": "Deep BI-RADS Network for Improved Cancer Detection from Mammograms",
        "rating": "-1",
        "keywords": [
            [
                "Cancer",
                "lesion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While state-of-the-art models for breast cancer detection leverage multi-view mammograms for enhanced diagnostic accuracy, they often focus solely on visual mammography data. However, radiologists document valuable lesion descriptors that contain additional information that can enhance mammography-based breast cancer screening. A key question is whether deep learning models can benefit from these expert-derived features. To address this question, we introduce a novel multi-modal approach that combines textual BI-RADS lesion descriptors with visual mammogram content. Our method employs iterative attention layers to effectively fuse these different modalities, significantly improving classification performance over image-only models. Experiments on the CBIS-DDSM dataset demonstrate substantial improvements across all metrics, demonstrating the contribution of handcrafted features to end-to-end.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10904",
        "abstract url": "https://arxiv.org/abs/2411.10904",
        "title": "Invariant Polydiagonal Subspaces of Matrices and Constraint Programming",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "In a polydiagonal subspace of the Euclidean space, certain components of the vectors are equal (synchrony) or opposite (anti-synchrony). Polydiagonal subspaces invariant under a matrix have many applications in graph theory and dynamical systems, especially coupled cell networks. We describe invariant polydiagonal subspaces in terms of coloring vectors. This approach gives an easy formulation of a constraint satisfaction problem for finding invariant polydiagonal subspaces. Solving the resulting problem with existing state-of-the-art constraint solvers greatly outperforms the currently known algorithms.",
        "subjects": [
            "math.DS",
            "cs.DM",
            "cs.MS"
        ],
        "comment": "16 pages"
    },
    {
        "paper id": "2411.10908",
        "abstract url": "https://arxiv.org/abs/2411.10908",
        "title": "The Conflict Graph Design: Estimating Causal Effects under Arbitrary Neighborhood Interference",
        "rating": "-1",
        "keywords": [
            [
                "Graph"
            ]
        ],
        "abstract": "A fundamental problem in network experiments is selecting an appropriate experimental design in order to precisely estimate a given causal effect of interest. In fact, optimal rates of estimation remain unknown for essentially all causal effects in network experiments. In this work, we propose a general approach for constructing experiment designs under network interference with the goal of precisely estimating a pre-specified causal effect. A central aspect of our approach is the notion of a conflict graph, which captures the fundamental unobservability associated with the casual effect and the underlying network. We refer to our experimental design as the Conflict Graph Design. In order to estimate effects, we propose a modified Horvitz--Thompson estimator. We show that its variance under the Conflict Graph Design is bounded as $O(\u03bb(H) / n )$, where $\u03bb(H)$ is the largest eigenvalue of the adjacency matrix of the conflict graph. These rates depend on both the underlying network and the particular causal effect under investigation. Not only does this yield the best known rates of estimation for several well-studied causal effects (e.g. the global and direct effects) but it also provides new methods for effects which have received less attention from the perspective of experiment design (e.g. spill-over effects). Our results corroborate two implicitly understood points in the literature: (1) that in order to increase precision, experiment designs should be tailored to specific causal effects of interest and (2) that \"more local\" effects are easier to estimate than \"more global\" effects. In addition to point estimation, we construct conservative variance estimators which facilitate the construction of asymptotically valid confidence intervals for the casual effect of interest.",
        "subjects": [
            "stat.ME",
            "cs.DS",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10915",
        "abstract url": "https://arxiv.org/abs/2411.10915",
        "title": "Bias in Large Language Models: Origin, Evaluation, and Mitigation",
        "rating": "-1",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have revolutionized natural language processing, but their susceptibility to biases poses significant challenges. This comprehensive review examines the landscape of bias in LLMs, from its origins to current mitigation strategies. We categorize biases as intrinsic and extrinsic, analyzing their manifestations in various NLP tasks. The review critically assesses a range of bias evaluation methods, including data-level, model-level, and output-level approaches, providing researchers with a robust toolkit for bias detection. We further explore mitigation strategies, categorizing them into pre-model, intra-model, and post-model techniques, highlighting their effectiveness and limitations. Ethical and legal implications of biased LLMs are discussed, emphasizing potential harms in real-world applications such as healthcare and criminal justice. By synthesizing current knowledge on bias in LLMs, this review contributes to the ongoing effort to develop fair and responsible AI systems. Our work serves as a comprehensive resource for researchers and practitioners working towards understanding, evaluating, and mitigating bias in LLMs, fostering the development of more equitable AI technologies.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10919",
        "abstract url": "https://arxiv.org/abs/2411.10919",
        "title": "Multi-Modal Self-Supervised Learning for Surgical Feedback Effectiveness Assessment",
        "rating": "-1",
        "keywords": [
            [
                "Surgical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "During surgical training, real-time feedback from trainers to trainees is important for preventing errors and enhancing long-term skill acquisition. Accurately predicting the effectiveness of this feedback, specifically whether it leads to a change in trainee behavior, is crucial for developing methods for improving surgical training and education. However, relying on human annotations to assess feedback effectiveness is laborious and prone to biases, underscoring the need for an automated, scalable, and objective method. Creating such an automated system poses challenges, as it requires an understanding of both the verbal feedback delivered by the trainer and the visual context of the real-time surgical scene. To address this, we propose a method that integrates information from transcribed verbal feedback and corresponding surgical video to predict feedback effectiveness. Our findings show that both transcribed feedback and surgical video are individually predictive of trainee behavior changes, and their combination achieves an AUROC of 0.70+/-0.02, improving prediction accuracy by up to 6.6%. Additionally, we introduce self-supervised fine-tuning as a strategy for enhancing surgical video representation learning, which is scalable and further enhances prediction performance. Our results demonstrate the potential of multi-modal learning to advance the automated assessment of surgical feedback.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": "Accepted as a spotlight proceedings paper at Machine Learning for Health 2024"
    },
    {
        "paper id": "2411.10921",
        "abstract url": "https://arxiv.org/abs/2411.10921",
        "title": "Distributed solar generation forecasting using attention-based deep neural networks for cloud movement prediction",
        "rating": "-1",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Accurate forecasts of distributed solar generation are necessary to reduce negative impacts resulting from the increased uptake of distributed solar photovoltaic (PV) systems. However, the high variability of solar generation over short time intervals (seconds to minutes) caused by cloud movement makes this forecasting task difficult. To address this, using cloud images, which capture the second-to-second changes in cloud cover affecting solar generation, has shown promise. Recently, deep neural networks with \"attention\" that focus on important regions of an image have been applied with success in many computer vision applications. However, their use for forecasting cloud movement has not yet been extensively explored. In this work, we propose an attention-based convolutional long short-term memory network to forecast cloud movement and apply an existing self-attention-based method previously proposed for video prediction to forecast cloud movement. We investigate and discuss the impact of cloud forecasts from attention-based methods towards forecasting distributed solar generation, compared to cloud forecasts from non-attention-based methods. We further provide insights into the different solar forecast performances that can be achieved for high and low altitude clouds. We find that for clouds at high altitudes, the cloud predictions obtained using attention-based methods result in solar forecast skill score improvements of 5.86% or more compared to non-attention-based methods.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10925",
        "abstract url": "https://arxiv.org/abs/2411.10925",
        "title": "A Resilience Perspective on C-V2X Communication Networks under Imperfect CSI",
        "rating": "-1",
        "keywords": [
            [
                "vehicle"
            ]
        ],
        "abstract": "Cellular vehicle-to-everything (C-V2X) networks provide a promising solution to improve road safety and traffic efficiency. One key challenge in such systems lies in meeting different quality-of-service (QoS) requirements of coexisting vehicular communication links, particularly under imperfect channel state information (CSI) conditions caused by the highly dynamic environment. In this paper, a novel analytical framework for examining the resilience of C-V2X networks in face of imperfect CSI is proposed. In this framework, the adaptation phase of the C-V2X network is studied, in which an adaptation power scheme is employed and the probability distribution function (PDF) of the imperfect CSI is estimated. Then, the resilience of C-V2X networks is studied through two principal dimensions: remediation capability and adaptation performance, both of which are defined, quantified, and analyzed for the first time. Particularly, an upper bound on the estimation's mean square error (MSE) is explicitly derived to capture the C-V2X's remediation capability, and a novel metric named hazard rate (HR) is exploited to evaluate the C-V2X's adaptation performance. Afterwards, the impact of the adaptation power scheme on the C-V2X's resilience is examined, revealing a tradeoff between the C-V2X's remediation capability and adaptation performance. Simulation results validate the framework's superiority in capturing the interplay between adaptation and remediation, as well as the effectiveness of the two proposed metrics in guiding the design of the adaptation power scheme to enhance the system's resilience.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "Submitted to ICC 2025"
    },
    {
        "paper id": "2411.10935",
        "abstract url": "https://arxiv.org/abs/2411.10935",
        "title": "Exciting Contact Modes in Differentiable Simulations for Robot Learning",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "In this paper, we explore an approach to actively plan and excite contact modes in differentiable simulators as a means to tighten the sim-to-real gap. We propose an optimal experimental design approach derived from information-theoretic methods to identify and search for information-rich contact modes through the use of contact-implicit optimization. We demonstrate our approach on a robot parameter estimation problem with unknown inertial and kinematic parameters which actively seeks contacts with a nearby surface. We show that our approach improves the identification of unknown parameter estimates over experimental runs by an estimate error reduction of at least $\\sim 84\\%$ when compared to a random sampling baseline, with significantly higher information gains.",
        "subjects": [
            "cs.RO",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10936",
        "abstract url": "https://arxiv.org/abs/2411.10936",
        "title": "Iterative Camera-LiDAR Extrinsic Optimization via Surrogate Diffusion",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Cameras and LiDAR are essential sensors for autonomous vehicles. Camera-LiDAR data fusion compensate for deficiencies of stand-alone sensors but relies on precise extrinsic calibration. Many learning-based calibration methods predict extrinsic parameters in a single step. Driven by the growing demand for higher accuracy, a few approaches utilize multi-range models or integrate multiple methods to improve extrinsic parameter predictions, but these strategies incur extended training times and require additional storage for separate models. To address these issues, we propose a single-model iterative approach based on surrogate diffusion to significantly enhance the capacity of individual calibration methods. By applying a buffering technique proposed by us, the inference time of our surrogate diffusion is 43.7% less than that of multi-range models. Additionally, we create a calibration network as our denoiser, featuring both projection-first and encoding-first branches for effective point feature extraction. Extensive experiments demonstrate that our diffusion model outperforms other single-model iterative methods and delivers competitive results compared to multi-range models. Our denoiser exceeds state-of-the-art calibration methods, reducing the rotation error by 24.5% compared to the second-best method. Furthermore, with the proposed diffusion applied, it achieves 20.4% less rotation error and 9.6% less translation error.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "11 pages, 4 figures, 3 tables"
    },
    {
        "paper id": "2411.10937",
        "abstract url": "https://arxiv.org/abs/2411.10937",
        "title": "Memory-Augmented Multimodal LLMs for Surgical VQA via Self-Contained Inquiry",
        "rating": "-1",
        "keywords": [
            [
                "Surgical"
            ],
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Comprehensively understanding surgical scenes in Surgical Visual Question Answering (Surgical VQA) requires reasoning over multiple objects. Previous approaches address this task using cross-modal fusion strategies to enhance reasoning ability. However, these methods often struggle with limited scene understanding and question comprehension, and some rely on external resources (e.g., pre-extracted object features), which can introduce errors and generalize poorly across diverse surgical environments. To address these challenges, we propose SCAN, a simple yet effective memory-augmented framework that leverages Multimodal LLMs to improve surgical context comprehension via Self-Contained Inquiry. SCAN operates autonomously, generating two types of memory for context augmentation: Direct Memory (DM), which provides multiple candidates (or hints) to the final answer, and Indirect Memory (IM), which consists of self-contained question-hint pairs to capture broader scene context. DM directly assists in answering the question, while IM enhances understanding of the surgical scene beyond the immediate query. Reasoning over these object-aware memories enables the model to accurately interpret images and respond to questions. Extensive experiments on three publicly available Surgical VQA datasets demonstrate that SCAN achieves state-of-the-art performance, offering improved accuracy and robustness across various surgical scenarios.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10940",
        "abstract url": "https://arxiv.org/abs/2411.10940",
        "title": "A Monocular SLAM-based Multi-User Positioning System with Image Occlusion in Augmented Reality",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "SLAM"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In recent years, with the rapid development of augmented reality (AR) technology, there is an increasing demand for multi-user collaborative experiences. Unlike for single-user experiences, ensuring the spatial localization of every user and maintaining synchronization and consistency of positioning and orientation across multiple users is a significant challenge. In this paper, we propose a multi-user localization system based on ORB-SLAM2 using monocular RGB images as a development platform based on the Unity 3D game engine. This system not only performs user localization but also places a common virtual object on a planar surface (such as table) in the environment so that every user holds a proper perspective view of the object. These generated virtual objects serve as reference points for multi-user position synchronization. The positioning information is passed among every user's AR devices via a central server, based on which the relative position and movement of other users in the space of a specific user are presented via virtual avatars all with respect to these virtual objects. In addition, we use deep learning techniques to estimate the depth map of an image from a single RGB image to solve occlusion problems in AR applications, making virtual objects appear more natural in AR scenes.",
        "subjects": [
            "cs.HC",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10947",
        "abstract url": "https://arxiv.org/abs/2411.10947",
        "title": "Direct and Explicit 3D Generation from a Single Image",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "Gaussian splatting",
                "depth"
            ],
            [
                "Diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current image-to-3D approaches suffer from high computational costs and lack scalability for high-resolution outputs. In contrast, we introduce a novel framework to directly generate explicit surface geometry and texture using multi-view 2D depth and RGB images along with 3D Gaussian features using a repurposed Stable Diffusion model. We introduce a depth branch into U-Net for efficient and high quality multi-view, cross-domain generation and incorporate epipolar attention into the latent-to-pixel decoder for pixel-level multi-view consistency. By back-projecting the generated depth pixels into 3D space, we create a structured 3D representation that can be either rendered via Gaussian splatting or extracted to high-quality meshes, thereby leveraging additional novel view synthesis loss to further improve our performance. Extensive experiments demonstrate that our method surpasses existing baselines in geometry and texture quality while achieving significantly faster generation time.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "3DV 2025, Project page: https://hao-yu-wu.github.io/gen3d/"
    },
    {
        "paper id": "2411.10948",
        "abstract url": "https://arxiv.org/abs/2411.10948",
        "title": "Towards Accurate and Efficient Sub-8-Bit Integer Training",
        "rating": "-1",
        "keywords": [
            [
                "FPGA"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Neural network training is a memory- and compute-intensive task. Quantization, which enables low-bitwidth formats in training, can significantly mitigate the workload. To reduce quantization error, recent methods have developed new data formats and additional pre-processing operations on quantizers. However, it remains quite challenging to achieve high accuracy and efficiency simultaneously. In this paper, we explore sub-8-bit integer training from its essence of gradient descent optimization. Our integer training framework includes two components: ShiftQuant to realize accurate gradient estimation, and L1 normalization to smoothen the loss landscape. ShiftQuant attains performance that approaches the theoretical upper bound of group quantization. Furthermore, it liberates group quantization from inefficient memory rearrangement. The L1 normalization facilitates the implementation of fully quantized normalization layers with impressive convergence accuracy. Our method frees sub-8-bit integer training from pre-processing and supports general devices. This framework achieves negligible accuracy loss across various neural networks and tasks ($0.92\\%$ on 4-bit ResNets, $0.61\\%$ on 6-bit Transformers). The prototypical implementation of ShiftQuant achieves more than $1.85\\times/15.3\\%$ performance improvement on CPU/GPU compared to its FP16 counterparts, and $33.9\\%$ resource consumption reduction on FPGA than the FP16 counterparts. The proposed fully-quantized L1 normalization layers achieve more than $35.54\\%$ improvement in throughout on CPU compared to traditional L2 normalization layers. Moreover, theoretical analysis verifies the advancement of our method.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10951",
        "abstract url": "https://arxiv.org/abs/2411.10951",
        "title": "TSFormer: A Robust Framework for Efficient UHD Image Restoration",
        "rating": "-1",
        "keywords": [
            [
                "Image Restoration"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Ultra-high-definition (UHD) image restoration is vital for applications demanding exceptional visual fidelity, yet existing methods often face a trade-off between restoration quality and efficiency, limiting their practical deployment. In this paper, we propose TSFormer, an all-in-one framework that integrates \\textbf{T}rusted learning with \\textbf{S}parsification to boost both generalization capability and computational efficiency in UHD image restoration. The key is that only a small amount of token movement is allowed within the model. To efficiently filter tokens, we use Min-$p$ with random matrix theory to quantify the uncertainty of tokens, thereby improving the robustness of the model. Our model can run a 4K image in real time (40fps) with 3.38 M parameters. Extensive experiments demonstrate that TSFormer achieves state-of-the-art restoration quality while enhancing generalization and reducing computational demands. In addition, our token filtering method can be applied to other image restoration models to effectively accelerate inference and maintain performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10960",
        "abstract url": "https://arxiv.org/abs/2411.10960",
        "title": "Beamforming Design and Multi-User Scheduling in Transmissive RIS Enabled Distributed Cooperative ISAC Networks with RSMA",
        "rating": "-1",
        "keywords": [
            [
                "radar"
            ]
        ],
        "abstract": "In this paper, we propose a novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered distributed cooperative integrated sensing and communication (ISAC) network to enhance coverage as well as to enhance wireless environment understanding. Based on the network requirements, the users are categorized into cooperative users (CUEs) and destination users (DUEs), and the CUEs utilize their own resources to serve the DUEs. To realize cooperation, we implement rate-splitting multiple access (RSMA) at the base station (BS), where the common stream is decoded and reencoded at the CUEs and forwarded to the DUEs, while the private stream satisfies the CUEs' own communication requirements. We construct an optimization problem with maximum minimum radar mutual information (RMI) as the objective function to optimize the BS beamforming matrix, the CUE beamforming matrices, the common stream rate vectors, and the user scheduling vectors. Due to the coupling of the optimization variables and non-convex operation, the proposed problem is a non-convex optimization problem that cannot be solved directly. To address the above challenges, we adopt a consensus alternating direction method of multipliers (ADMM) framework to decouple the optimization variables and solve it. Specifically, the problem is decoupled into multiple subproblems and solved by iterative optimization independently until overall convergence is achieved. Finally, numerical results validate the superiority of the proposed scheme in terms of improving communication sum-rate and RMI, and greatly reduce the algorithm complexity.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.14461",
        "abstract url": "https://arxiv.org/abs/2411.14461",
        "title": "Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "healthcare",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CY",
                "cs.CL"
            ]
        ],
        "abstract": "Artificial Intelligence (AI) has become essential in modern healthcare, with large language models (LLMs) offering promising advances in clinical decision-making. Traditional model-based approaches, including those leveraging in-context demonstrations and those with specialized medical fine-tuning, have demonstrated strong performance in medical language processing but struggle with real-time adaptability, multi-step reasoning, and handling complex medical tasks. Agent-based AI systems address these limitations by incorporating reasoning traces, tool selection based on context, knowledge retrieval, and both short- and long-term memory. These additional features enable the medical AI agent to handle complex medical scenarios where decision-making should be built on real-time interaction with the environment. Therefore, unlike conventional model-based approaches that treat medical queries as isolated questions, medical AI agents approach them as complex tasks and behave more like human doctors. In this paper, we study the choice of the backbone LLM for medical AI agents, which is the foundation for the agent's overall reasoning and action generation. In particular, we consider the emergent o1 model and examine its impact on agents' reasoning, tool-use adaptability, and real-time information retrieval across diverse clinical scenarios, including high-stakes settings such as intensive care units (ICUs). Our findings demonstrate o1's ability to enhance diagnostic accuracy and consistency, paving the way for smarter, more responsive AI tools that support better patient outcomes and decision-making efficacy in clinical practice.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10744",
        "abstract url": "https://arxiv.org/abs/2411.10744",
        "title": "Digital-Analog Quantum Machine Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Quantum"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Machine Learning algorithms are extensively used in an increasing number of systems, applications, technologies, and products, both in industry and in society as a whole. They enable computing devices to learn from previous experience and therefore improve their performance in a certain context or environment. In this way, many useful possibilities have been made accessible. However, dealing with an increasing amount of data poses difficulties for classical devices. Quantum systems may offer a way forward, possibly enabling to scale up machine learning calculations in certain contexts. On the other hand, quantum systems themselves are also hard to scale up, due to decoherence and the fragility of quantum superpositions. In the short and mid term, it has been evidenced that a quantum paradigm that combines evolution under large analog blocks with discrete quantum gates, may be fruitful to achieve new knowledge of classical and quantum systems with no need of having a fault-tolerant quantum computer. In this Perspective, we review some recent works that employ this digital-analog quantum paradigm to carry out efficient machine learning calculations with current quantum devices.",
        "subjects": [
            "quant-ph",
            "cs.AI"
        ],
        "comment": "Invited Perspective for Advanced Intelligent Discovery"
    },
    {
        "paper id": "2411.10754",
        "abstract url": "https://arxiv.org/abs/2411.10754",
        "title": "Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "Survival",
                "Disease",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Chronic kidney disease (CKD) is a significant public health challenge, often progressing to end-stage renal disease (ESRD) if not detected and managed early. Early intervention, warranted by silent disease progression, can significantly reduce associated morbidity, mortality, and financial burden. In this study, we propose a novel approach to modeling CKD progression using a combination of machine learning techniques and classical statistical models. Building on the work of Liu et al. (2023), we evaluate linear models, tree-based methods, and deep learning models to extract novel predictors for CKD progression, with feature importance assessed using Shapley values. These newly identified predictors, integrated with established clinical features from the Kidney Failure Risk Equation, are then applied within the framework of Cox proportional hazards models to predict CKD progression.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.CO",
            "stat.ML"
        ],
        "comment": "Findings paper presented at Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024, Vancouver, Canada, 19 pages"
    },
    {
        "paper id": "2411.10768",
        "abstract url": "https://arxiv.org/abs/2411.10768",
        "title": "Building Interpretable Climate Emulators for Economics",
        "rating": "-1.5",
        "keywords": [
            [
                "biosphere"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a framework for developing efficient and interpretable carbon-cycle emulators (CCEs) as part of climate emulators in Integrated Assessment Models, enabling economists to custom-build CCEs accurately calibrated to advanced climate science. We propose a generalized multi-reservoir linear box-model CCE that preserves key physical quantities and can be use-case tailored for specific use cases. Three CCEs are presented for illustration: the 3SR model (replicating DICE-2016), the 4PR model (including the land biosphere), and the 4PR-X model (accounting for dynamic land-use changes like deforestation that impact the reservoir's storage capacity). Evaluation of these models within the DICE framework shows that land-use changes in the 4PR-X model significantly impact atmospheric carbon and temperatures -- emphasizing the importance of using tailored climate emulators. By providing a transparent and flexible tool for policy analysis, our framework allows economists to assess the economic impacts of climate policies more accurately.",
        "subjects": [
            "econ.EM",
            "cs.CE",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10842",
        "abstract url": "https://arxiv.org/abs/2411.10842",
        "title": "CODECLEANER: Elevating Standards with A Robust Data Contamination Mitigation Toolkit",
        "rating": "-1.5",
        "keywords": [
            [
                "industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Data contamination presents a critical barrier preventing widespread industrial adoption of advanced software engineering techniques that leverage code language models (CLMs). This phenomenon occurs when evaluation data inadvertently overlaps with the public code repositories used to train CLMs, severely undermining the credibility of performance evaluations. For software companies considering the integration of CLM-based techniques into their development pipeline, this uncertainty about true performance metrics poses an unacceptable business risk. Code refactoring, which comprises code restructuring and variable renaming, has emerged as a promising measure to mitigate data contamination. It provides a practical alternative to the resource-intensive process of building contamination-free evaluation datasets, which would require companies to collect, clean, and label code created after the CLMs' training cutoff dates. However, the lack of automated code refactoring tools and scientifically validated refactoring techniques has hampered widespread industrial implementation. To bridge the gap, this paper presents the first systematic study to examine the efficacy of code refactoring operators at multiple scales (method-level, class-level, and cross-class level) and in different programming languages. In particular, we develop an open-sourced toolkit, CODECLEANER, which includes 11 operators for Python, with nine method-level, one class-level, and one cross-class-level operator. A drop of 65% overlap ratio is found when applying all operators in CODECLEANER, demonstrating their effectiveness in addressing data contamination. Additionally, we migrate four operators to Java, showing their generalizability to another language. We make CODECLEANER online available to facilitate further studies on mitigating CLM data contamination.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10863",
        "abstract url": "https://arxiv.org/abs/2411.10863",
        "title": "Improvement in Facial Emotion Recognition using Synthetic Data Generated by Diffusion Model",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "health",
                "Facial"
            ],
            [
                "cs.CV",
                "eess.IV"
            ],
            [
                "ICASSP"
            ]
        ],
        "abstract": "Facial Emotion Recognition (FER) plays a crucial role in computer vision, with significant applications in human-computer interaction, affective computing, and areas such as mental health monitoring and personalized learning environments. However, a major challenge in FER task is the class imbalance commonly found in available datasets, which can hinder both model performance and generalization. In this paper, we tackle the issue of data imbalance by incorporating synthetic data augmentation and leveraging the ResEmoteNet model to enhance the overall performance on facial emotion recognition task. We employed Stable Diffusion 2 and Stable Diffusion 3 Medium models to generate synthetic facial emotion data, augmenting the training sets of the FER2013 and RAF-DB benchmark datasets. Training ResEmoteNet with these augmented datasets resulted in substantial performance improvements, achieving accuracies of 96.47% on FER2013 and 99.23% on RAF-DB. These findings shows an absolute improvement of 16.68% in FER2013, 4.47% in RAF-DB and highlight the efficacy of synthetic data augmentation in strengthening FER models and underscore the potential of advanced generative models in FER research and applications. The source code for ResEmoteNet is available at https://github.com/ArnabKumarRoy02/ResEmoteNet",
        "subjects": [
            "cs.CV",
            "cs.HC",
            "eess.IV"
        ],
        "comment": "5 pages, 4 tables, 4 figures, ICASSP 2025"
    },
    {
        "paper id": "2411.10898",
        "abstract url": "https://arxiv.org/abs/2411.10898",
        "title": "Watermarking Generative Categorical Data",
        "rating": "-1.5",
        "keywords": [
            [
                "Watermarking"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In this paper, we propose a novel statistical framework for watermarking generative categorical data. Our method systematically embeds pre-agreed secret signals by splitting the data distribution into two components and modifying one distribution based on a deterministic relationship with the other, ensuring the watermark is embedded at the distribution-level. To verify the watermark, we introduce an insertion inverse algorithm and detect its presence by measuring the total variation distance between the inverse-decoded data and the original distribution. Unlike previous categorical watermarking methods, which primarily focus on embedding watermarks into a given dataset, our approach operates at the distribution-level, allowing for verification from a statistical distributional perspective. This makes it particularly well-suited for the modern paradigm of synthetic data generation, where the underlying data distribution, rather than specific data points, is of primary importance. The effectiveness of our method is demonstrated through both theoretical analysis and empirical validation.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10945",
        "abstract url": "https://arxiv.org/abs/2411.10945",
        "title": "Anomaly Detection for People with Visual Impairments Using an Egocentric 360-Degree Camera",
        "rating": "-1.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "Crime"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Recent advancements in computer vision have led to a renewed interest in developing assistive technologies for individuals with visual impairments. Although extensive research has been conducted in the field of computer vision-based assistive technologies, most of the focus has been on understanding contexts in images, rather than addressing their physical safety and security concerns. To address this challenge, we propose the first step towards detecting anomalous situations for visually impaired people by observing their entire surroundings using an egocentric 360-degree camera. We first introduce a novel egocentric 360-degree video dataset called VIEW360 (Visually Impaired Equipped with Wearable 360-degree camera), which contains abnormal activities that visually impaired individuals may encounter, such as shoulder surfing and pickpocketing. Furthermore, we propose a new architecture called the FDPN (Frame and Direction Prediction Network), which facilitates frame-level prediction of abnormal events and identifying of their directions. Finally, we evaluate our approach on our VIEW360 dataset and the publicly available UCF-Crime and Shanghaitech datasets, demonstrating state-of-the-art performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "WACV2025"
    },
    {
        "paper id": "2411.10959",
        "abstract url": "https://arxiv.org/abs/2411.10959",
        "title": "Program Evaluation with Remotely Sensed Outcomes",
        "rating": "-1.5",
        "keywords": [
            [
                "Remotely Sensed",
                "satellite"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "While traditional program evaluations typically rely on surveys to measure outcomes, certain economic outcomes such as living standards or environmental quality may be infeasible or costly to collect. As a result, recent empirical work estimates treatment effects using remotely sensed variables (RSVs), such mobile phone activity or satellite images, instead of ground-truth outcome measurements. Common practice predicts the economic outcome from the RSV, using an auxiliary sample of labeled RSVs, and then uses such predictions as the outcome in the experiment. We prove that this approach leads to biased estimates of treatment effects when the RSV is a post-outcome variable. We nonparametrically identify the treatment effect, using an assumption that reflects the logic of recent empirical research: the conditional distribution of the RSV remains stable across both samples, given the outcome and treatment. Our results do not require researchers to know or consistently estimate the relationship between the RSV, outcome, and treatment, which is typically mis-specified with unstructured data. We form a representation of the RSV for downstream causal inference by predicting the outcome and predicting the treatment, with better predictions leading to more precise causal estimates. We re-evaluate the efficacy of a large-scale public program in India, showing that the program's measured effects on local consumption and poverty can be replicated using satellite",
        "subjects": [
            "econ.EM",
            "cs.LG",
            "math.ST",
            "stat.AP",
            "stat.ME",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2411.15173",
        "abstract url": "https://arxiv.org/abs/2411.15173",
        "title": "Decentralizing Test-time Adaptation under Heterogeneous Data Streams",
        "rating": "-1.5",
        "keywords": [
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "While Test-Time Adaptation (TTA) has shown promise in addressing distribution shifts between training and testing data, its effectiveness diminishes with heterogeneous data streams due to uniform target estimation. As previous attempts merely stabilize model fine-tuning over time to handle continually changing environments, they fundamentally assume a homogeneous target domain at any moment, leaving the intrinsic real-world data heterogeneity unresolved. This paper delves into TTA under heterogeneous data streams, moving beyond current model-centric limitations. By revisiting TTA from a data-centric perspective, we discover that decomposing samples into Fourier space facilitates an accurate data separation across different frequency levels. Drawing from this insight, we propose a novel Frequency-based Decentralized Adaptation (FreDA) framework, which transitions data from globally heterogeneous to locally homogeneous in Fourier space and employs decentralized adaptation to manage diverse distribution shifts.Interestingly, we devise a novel Fourier-based augmentation strategy to assist in decentralizing adaptation, which individually enhances sample quality for capturing each type of distribution shifts. Extensive experiments across various settings (corrupted, natural, and medical environments) demonstrate the superiority of our proposed framework over the state-of-the-arts.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10722",
        "abstract url": "https://arxiv.org/abs/2411.10722",
        "title": "DGS-SLAM: Gaussian Splatting SLAM in Dynamic Environment",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "SLAM"
            ]
        ],
        "abstract": "We introduce Dynamic Gaussian Splatting SLAM (DGS-SLAM), the first dynamic SLAM framework built on the foundation of Gaussian Splatting. While recent advancements in dense SLAM have leveraged Gaussian Splatting to enhance scene representation, most approaches assume a static environment, making them vulnerable to photometric and geometric inconsistencies caused by dynamic objects. To address these challenges, we integrate Gaussian Splatting SLAM with a robust filtering process to handle dynamic objects throughout the entire pipeline, including Gaussian insertion and keyframe selection. Within this framework, to further improve the accuracy of dynamic object removal, we introduce a robust mask generation method that enforces photometric consistency across keyframes, reducing noise from inaccurate segmentation and artifacts such as shadows. Additionally, we propose the loop-aware window selection mechanism, which utilizes unique keyframe IDs of 3D Gaussians to detect loops between the current and past frames, facilitating joint optimization of the current camera poses and the Gaussian map. DGS-SLAM achieves state-of-the-art performance in both camera tracking and novel view synthesis on various dynamic SLAM benchmarks, proving its effectiveness in handling real-world dynamic scenes.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "Preprint, Under review"
    },
    {
        "paper id": "2411.10737",
        "abstract url": "https://arxiv.org/abs/2411.10737",
        "title": "Classical optimization with imaginary time block encoding on quantum computers: The MaxCut problem",
        "rating": "-2",
        "keywords": [
            [
                "quantum",
                "physics"
            ]
        ],
        "abstract": "Finding ground state solutions of diagonal Hamiltonians is relevant for both theoretical as well as practical problems of interest in many domains such as finance, physics and computer science. These problems are typically very hard to tackle by classical computing and quantum computing could help in speeding up computations and efficiently tackling larger problems. Here we use imaginary time evolution through a new block encoding scheme to obtain the ground state of such problems and apply our method to MaxCut as an illustration. Our method, which for simplicity we call ITE-BE, requires no variational parameter optimization as all the parameters in the procedure are expressed as analytical functions of the couplings of the Hamiltonian. We demonstrate that our method can be successfully combined with other quantum algorithms such as quantum approximate optimization algorithm (QAOA). We find that the QAOA ansatz increases the post-selection success of ITE-BE, and shallow QAOA circuits, when boosted with ITE-BE, achieve better performance than deeper QAOA circuits. For the special case of the transverse initial state, we adapt our block encoding scheme to allow for a deterministic application of the first layer of the circuit.",
        "subjects": [
            "quant-ph",
            "cs.DS",
            "cs.ET",
            "math.OC"
        ],
        "comment": "11 pages, 7 figures"
    },
    {
        "paper id": "2411.10755",
        "abstract url": "https://arxiv.org/abs/2411.10755",
        "title": "Diffusion-Based Semantic Segmentation of Lumbar Spine MRI Scans of Lower Back Pain Patients",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "diagnosis",
                "MRI"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This study introduces a diffusion-based framework for robust and accurate segmenton of vertebrae, intervertebral discs (IVDs), and spinal canal from Magnetic Resonance Imaging~(MRI) scans of patients with low back pain (LBP), regardless of whether the scans are T1w or T2-weighted. The results showed that SpineSegDiff achieved comparable outperformed non-diffusion state-of-the-art models in the identification of degenerated IVDs. Our findings highlight the potential of diffusion models to improve LBP diagnosis and management through precise spine MRI analysis.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Findings paper presented at Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024, Vancouver, Canada, 5 pages"
    },
    {
        "paper id": "2411.10787",
        "abstract url": "https://arxiv.org/abs/2411.10787",
        "title": "An All-in-one Approach for Accelerated Cardiac MRI Reconstruction",
        "rating": "-2",
        "keywords": [
            [
                "GAN"
            ],
            [
                "diagnosing",
                "MRI",
                "clinical",
                "Cardiac"
            ],
            [
                "eess.IV"
            ]
        ],
        "abstract": "Cardiovascular magnetic resonance (CMR) imaging is the gold standard for diagnosing several heart diseases due to its non-invasive nature and proper contrast. MR imaging is time-consuming because of signal acquisition and image formation issues. Prolonging the imaging process can result in the appearance of artefacts in the final image, which can affect the diagnosis. It is possible to speed up CMR imaging using image reconstruction based on deep learning. For this purpose, the high-quality clinical interpretable images can be reconstructed by acquiring highly undersampled k-space data, that is only partially filled, and using a deep learning model. In this study, we proposed a stepwise reconstruction approach based on the Patch-GAN structure for highly undersampled k-space data compatible with the multi-contrast nature, various anatomical views and trajectories of CMR imaging. The proposed approach was validated using the CMRxRecon2024 challenge dataset and outperformed previous studies. The structural similarity index measure (SSIM) values for the first and second tasks of the challenge are 99.07 and 97.99, respectively. This approach can accelerate CMR imaging to obtain high-quality images, more accurate diagnosis and a pleasant patient experience.",
        "subjects": [
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10835",
        "abstract url": "https://arxiv.org/abs/2411.10835",
        "title": "Qurts: Automatic Quantum Uncomputation by Affine Types with Lifetime",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "Uncomputation is a feature in quantum programming that allows the programmer to discard a value without losing quantum information, and that allows the compiler to reuse resources. Whereas quantum information has to be treated linearly by the type system, automatic uncomputation enables the programmer to treat it affinely to some extent. Automatic uncomputation requires a substructural type system between linear and affine, a subtlety that has only been captured by existing languages in an ad hoc way. We extend the Rust type system to the quantum setting to give a uniform framework for automatic uncomputation called Qurts (pronounced quartz). Specifically, we parameterise types by lifetimes, permitting them to be affine during their lifetime, while being restricted to linear use outside their lifetime. We also provide two operational semantics: one based on classical simulation, and one that does not depend on any specific uncomputation strategy.",
        "subjects": [
            "cs.PL",
            "quant-ph"
        ],
        "comment": "59 pages"
    },
    {
        "paper id": "2411.10837",
        "abstract url": "https://arxiv.org/abs/2411.10837",
        "title": "Towards a Generic Software Architecture for IoT Systems",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "The complexity of IoT, owing to the inherent distributed and dynamic nature of such systems, brings more challenges to the software development process. A vast number of devices with different communication protocols and data formats is involved and needs to be connected and exchange data with each other in a seamless manner. Traditional software architectures fall short of addressing the requirements of IoT systems and, therefore, a new approach to software architecture is required. This paper presents an attempt to lay out the foundation for a quality attribute driven software architecture for the development of IoT systems. This architecture accommodates the appropriate architectural styles and design patterns necessary for the development of a robust IoT system. These include edge computing, microservices and event driven architectures. The proposed architecture treats IoT systems as autonomic systems which require a closed control loop to regulate and orchestrate the operational aspect of the IoT system.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "15 pages, 7 figures"
    },
    {
        "paper id": "2411.10873",
        "abstract url": "https://arxiv.org/abs/2411.10873",
        "title": "Developer Challenges on Large Language Models: A Study of Stack Overflow and OpenAI Developer Forum Posts",
        "rating": "-2",
        "keywords": [
            [
                "healthcare"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have gained widespread popularity due to their exceptional capabilities across various domains, including chatbots, healthcare, education, content generation, and automated support systems. However, developers encounter numerous challenges when implementing, fine-tuning, and integrating these models into real-world applications. This study investigates LLM developers' challenges by analyzing community interactions on Stack Overflow and OpenAI Developer Forum, employing BERTopic modeling to identify and categorize developer discussions. Our analysis yields nine challenges on Stack Overflow (e.g., LLM Ecosystem and Challenges, API Usage, LLM Training with Frameworks) and 17 on the OpenAI Developer Forum (e.g., API Usage and Error Handling, Fine-Tuning and Dataset Management). Results indicate that developers frequently turn to Stack Overflow for implementation guidance, while OpenAI's forum focuses on troubleshooting. Notably, API and functionality issues dominate discussions on the OpenAI forum, with many posts requiring multiple responses, reflecting the complexity of LLM-related problems. We find that LLM-related queries often exhibit great difficulty, with a substantial percentage of unresolved posts (e.g., 79.03\\% on Stack Overflow) and prolonged response times, particularly for complex topics like 'Llama Indexing and GPU Utilization' and 'Agents and Tool Interactions'. In contrast, established fields like Mobile Development and Security enjoy quicker resolutions and stronger community engagement. These findings highlight the need for improved community support and targeted resources to assist LLM developers in overcoming the evolving challenges of this rapidly growing field. This study provides insights into areas of difficulty, paving the way for future research and tool development to better support the LLM developer community.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "52 pages, 6 figures"
    },
    {
        "paper id": "2411.10887",
        "abstract url": "https://arxiv.org/abs/2411.10887",
        "title": "Practitioner Paper: Decoding Intellectual Property: Acoustic and Magnetic Side-channel Attack on a 3D Printer",
        "rating": "-2",
        "keywords": [
            [
                "3D"
            ],
            [
                "Attack"
            ]
        ],
        "abstract": "The widespread accessibility and ease of use of additive manufacturing (AM), widely recognized as 3D printing, has put Intellectual Property (IP) at great risk of theft. As 3D printers emit acoustic and magnetic signals while printing, the signals can be captured and analyzed using a smartphone for the purpose of IP attack. This is an instance of physical-to-cyber exploitation, as there is no direct contact with the 3D printer. Although cyber vulnerabilities in 3D printers are becoming more apparent, the methods for protecting IPs are yet to be fully investigated. The threat scenarios in previous works have mainly rested on advanced recording devices for data collection and entailed placing the device very close to the 3D printer. However, our work demonstrates the feasibility of reconstructing G-codes by performing side-channel attacks on a 3D printer using a smartphone from greater distances. By training models using Gradient Boosted Decision Trees, our prediction results for each axial movement, stepper, nozzle, and rotor speed achieve high accuracy, with a mean of 98.80%, without any intrusiveness. We effectively deploy the model in a real-world examination, achieving a Mean Tendency Error (MTE) of 4.47% on a plain G-code design.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "22 pages, 14 figures, EAI SmartSP 2024 - 2nd EAI International Conference on Security and Privacy in Cyber-Physical Systems and Smart Vehicles"
    },
    {
        "paper id": "2411.10905",
        "abstract url": "https://arxiv.org/abs/2411.10905",
        "title": "Body-Resonance Human Body Communication",
        "rating": "-2",
        "keywords": [
            [
                "healthcare"
            ]
        ],
        "abstract": "Seamless interaction between Humans and AI-empowered battery-operated miniaturized electronic devices, exponentially transforming the wearable technology industry while forming an anthropomorphic artificial nervous system for distributed computing around the human body, demands high-speed low-power connectivity. If interconnected via radio frequency (RF) based wireless communication techniques, that being radiative, incur substantial absorption losses from the body during non-line-of-sight scenarios and consume higher power (more than 10s of mW). Although as a promising alternative with its non-radiative nature that resulted in 100X improvement in energy efficiency (sub-10 pJ/bit) and better signal confinement, Electro-Quasistatic Human Body Communication (EQS HBC) incurs moderate path loss (60-70 dB), limited data rate (less than 20 Mbps), making it less suitable for applications demanding fast connectivity like HD audio-video streaming, AR-VR-based products, distributed computing with wearable AI devices. Hence, to meet the requirement of energy-efficient connectivity at 100s of Mbps between wearables, we propose Body-Resonance (BR) HBC, which operates in the near-intermediate field and utilizes the transmission-line-like behavior of the body channel to offer 30X improvement in channel capacity. Our work sheds new light on the wireless communication system for wearables with potential to increase the channel gain by 20 dB with a 10X improvement in bandwidth compared to the EQS HBC for communication over on-body channels (whole-body coverage area). Experimentally demonstrating BR HBC, we presented low-loss (40-50 dB) and wide-band (hundreds of MHz) body channels that are 10X less leaky than radiative wireless communication, hence, can revolutionize the design of wireless communication system for several applications with wearables from healthcare, defense, to consumer electronics.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "39 pages, 16 figures"
    },
    {
        "paper id": "2411.10907",
        "abstract url": "https://arxiv.org/abs/2411.10907",
        "title": "Decentralized Localization of Distributed Antenna Array Elements Using an Evolutionary Algorithm",
        "rating": "-2",
        "keywords": [
            [
                "remote sensing",
                "satellite"
            ]
        ],
        "abstract": "Distributed phased arrays have recently garnered interest in applications such as satellite communications and high-resolution remote sensing. High-performance coherent distributed operations such as distributed beamforming are dependent on the ability to synchronize the spatio-electrical states of the elements in the array to the order of the operational wavelength, so that coherent signal summation can be achieved at any arbitrary target destination. In this paper, we address the fundamental challenge of precise distributed array element localization to enable coherent operation, even in complex environments where the array may not be capable of directly estimating all nodal link distances. We employ a two-way time transfer technique to synchronize the nodes of the array and perform internode ranging. We implement the classical multidimensional scaling algorithm to recover a decentralized array geometry from a set of range estimates. We also establish the incomplete set of range estimates as a multivariable non-convex optimization problem, and define the differential evolution algorithm which searches the solution space to complete the set of ranges. We experimentally demonstrate wireless localization using a spectrally-sparse pulsed two-tone waveform with 40 MHz tone separation in a laboratory environment, achieving a mean localization error vector magnitude of 0.82 mm in an environment with an average link SNR of 34 dB, theoretically supporting distributed beamforming operation up to 24.3 GHz.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "11 pages, 10 figures. This work has been submitted to the IEEE for possible publication"
    },
    {
        "paper id": "2411.10926",
        "abstract url": "https://arxiv.org/abs/2411.10926",
        "title": "Link-identified Routing Architecture in Space",
        "rating": "-2",
        "keywords": [
            [
                "satellite"
            ]
        ],
        "abstract": "Low earth orbit (LEO) satellite networks have the potential to provide low-latency communication with global coverage. To unleash this potential, it is crucial to achieve efficient packet delivery. In this paper, we propose a Link-identified Routing (LiR) architecture for LEO satellite networks. The LiR architecture leverages the deterministic neighbor relation of LEO constellations, and identifies each inter-satellite link (ISL). Moreover, LiR architecture adopts source-route-style forwarding based on in-packet bloom filter (BF). Each satellite could efficiently encode multiple ISL identifiers via an in-packet BF to specify the end-to-end path for the packets. Due to false positives caused by BF, the more ISLs are encoded at a time, the more redundant forwarding cases emerge. Based on the topology characteristics, we derive the expected forwarding overhead in a closed-form and propose the optimal encoding policy. To accommodate link-state changes in LEO satellite networks, we propose the on-demand rerouting scheme and the on-demand detouring scheme to address the intermittent ISLs. We also elaborate how to take advantage of LiR architecture to achieve seamless handover for ground-satellite links (GSLs). Finally, we conduct extensive numerical experiments and packet-level simulations to verify our analytical results and evaluate the performance of the LiR architecture.",
        "subjects": [
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10956",
        "abstract url": "https://arxiv.org/abs/2411.10956",
        "title": "IVE: Enhanced Probabilistic Forecasting of Intraday Volume Ratio with Transformers",
        "rating": "-2",
        "keywords": [
            [
                "Forecasting"
            ]
        ],
        "abstract": "This paper presents a new approach to volume ratio prediction in financial markets, specifically targeting the execution of Volume-Weighted Average Price (VWAP) strategies. Recognizing the importance of accurate volume profile forecasting, our research leverages the Transformer architecture to predict intraday volume ratio at a one-minute scale. We diverge from prior models that use log-transformed volume or turnover rates, instead opting for a prediction model that accounts for the intraday volume ratio's high variability, stabilized via log-normal transformation. Our input data incorporates not only the statistical properties of volume but also external volume-related features, absolute time information, and stock-specific characteristics to enhance prediction accuracy. The model structure includes an encoder-decoder Transformer architecture with a distribution head for greedy sampling, optimizing performance on high-liquidity stocks across both Korean and American markets. We extend the capabilities of our model beyond point prediction by introducing probabilistic forecasting that captures the mean and standard deviation of volume ratios, enabling the anticipation of significant intraday volume spikes. Furthermore, an agent with a simple trading logic demonstrates the practical application of our model through live trading tests in the Korean market, outperforming VWAP benchmarks over a period of two and a half months. Our findings underscore the potential of Transformer-based probabilistic models for volume ratio prediction and pave the way for future research advancements in this domain.",
        "subjects": [
            "q-fin.CP",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10961",
        "abstract url": "https://arxiv.org/abs/2411.10961",
        "title": "Map-Free Trajectory Prediction with Map Distillation and Hierarchical Encoding",
        "rating": "-2",
        "keywords": [
            [
                "Trajectory"
            ],
            [
                "forecasting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reliable motion forecasting of surrounding agents is essential for ensuring the safe operation of autonomous vehicles. Many existing trajectory prediction methods rely heavily on high-definition (HD) maps as strong driving priors. However, the availability and accuracy of these priors are not guaranteed due to substantial costs to build, localization errors of vehicles, or ongoing road constructions. In this paper, we introduce MFTP, a Map-Free Trajectory Prediction method that offers several advantages. First, it eliminates the need for HD maps during inference while still benefiting from map priors during training via knowledge distillation. Second, we present a novel hierarchical encoder that effectively extracts spatial-temporal agent features and aggregates them into multiple trajectory queries. Additionally, we introduce an iterative decoder that sequentially decodes trajectory queries to generate the final predictions. Extensive experiments show that our approach achieves state-of-the-art performance on the Argoverse dataset under the map-free setting.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.14459",
        "abstract url": "https://arxiv.org/abs/2411.14459",
        "title": "Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation",
        "rating": "-2",
        "keywords": [
            [
                "Graph"
            ],
            [
                "Recommendation"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Conversational Recommender Systems (CRSs) aim to provide personalized recommendations through dynamically capturing user preferences in interactive conversations. Conventional CRSs often extract user preferences as hidden representations, which are criticized for their lack of interpretability. This diminishes the transparency and trustworthiness of the recommendation process. Recent works have explored combining the impressive capabilities of Large Language Models (LLMs) with the domain-specific knowledge of Knowledge Graphs (KGs) to generate human-understandable recommendation explanations. Despite these efforts, the integration of LLMs and KGs for CRSs remains challenging due to the modality gap between unstructured dialogues and structured KGs. Moreover, LLMs pre-trained on large-scale corpora may not be well-suited for analyzing user preferences, which require domain-specific knowledge. In this paper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and KGs to unveil user preferences, enhancing the performance and explainability of existing CRSs. To address integration challenges, COMPASS employs a two-stage training approach: first, it bridges the gap between the structured KG and natural language through an innovative graph entity captioning pre-training mechanism. This enables the LLM to transform KG entities into concise natural language descriptions, allowing them to comprehend domain-specific knowledge. Following, COMPASS optimizes user preference modeling via knowledge-aware instruction fine-tuning, where the LLM learns to reason and summarize user preferences from both dialogue histories and KG-augmented context. This enables COMPASS to perform knowledge-aware reasoning and generate comprehensive and interpretable user preferences that can seamlessly integrate with existing CRS models for improving recommendation performance and explainability.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10720",
        "abstract url": "https://arxiv.org/abs/2411.10720",
        "title": "Multi Scale Graph Neural Network for Alzheimer's Disease",
        "rating": "-2.5",
        "keywords": [
            [
                "GNN",
                "Graph"
            ],
            [
                "Disease"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Alzheimer's disease (AD) is a complex, progressive neurodegenerative disorder characterized by extracellular A\\b{eta} plaques, neurofibrillary tau tangles, glial activation, and neuronal degeneration, involving multiple cell types and pathways. Current models often overlook the cellular context of these pathways. To address this, we developed a multiscale graph neural network (GNN) model, ALZ PINNACLE, using brain omics data from donors spanning the entire aging to AD spectrum. ALZ PINNACLE is based on the PINNACLE GNN framework, which learns context-aware protein, cell type, and tissue representations within a unified latent space. ALZ PINNACLE was trained on 14,951 proteins, 206,850 protein interactions, 7 cell types, and 48 cell subtypes or states. After pretraining, we investigated the learned embedding of APOE, the largest genetic risk factor for AD, across different cell types. Notably, APOE embeddings showed high similarity in microglial, neuronal, and CD8 cells, suggesting a similar role of APOE in these cell types. Fine tuning the model on AD risk genes revealed cell type contexts predictive of the role of APOE in AD. Our results suggest that ALZ PINNACLE may provide a valuable framework for uncovering novel insights into AD neurobiology.",
        "subjects": [
            "cs.LG",
            "q-bio.NC",
            "q-bio.QM"
        ],
        "comment": "Findings paper presented at Machine Learning for Health (ML4H) symposium 2024, December 15-16, 2024, Vancouver, Canada, 9 pages"
    },
    {
        "paper id": "2411.10765",
        "abstract url": "https://arxiv.org/abs/2411.10765",
        "title": "Steam Turbine Anomaly Detection: An Unsupervised Learning Approach Using Enhanced Long Short-Term Memory Variational Autoencoder",
        "rating": "-2.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "As core thermal power generation equipment, steam turbines incur significant expenses and adverse effects on operation when facing interruptions like downtime, maintenance, and damage. Accurate anomaly detection is the prerequisite for ensuring the safe and stable operation of steam turbines. However, challenges in steam turbine anomaly detection, including inherent anomalies, lack of temporal information analysis, and high-dimensional data complexity, limit the effectiveness of existing methods. To address these challenges, we proposed an Enhanced Long Short-Term Memory Variational Autoencoder using Deep Advanced Features and Gaussian Mixture Model (ELSTMVAE-DAF-GMM) for precise unsupervised anomaly detection in unlabeled datasets. Specifically, LSTMVAE, integrating LSTM with VAE, was used to project high-dimensional time-series data to a low-dimensional phase space. The Deep Autoencoder-Local Outlier Factor (DAE-LOF) sample selection mechanism was used to eliminate inherent anomalies during training, further improving the model's precision and reliability. The novel deep advanced features (DAF) hybridize latent embeddings and reconstruction discrepancies from the LSTMVAE model and provide a more comprehensive data representation within a continuous and structured phase space, significantly enhancing anomaly detection by synergizing temporal dynamics with data pattern variations. These DAF were incorporated into GMM to ensure robust and effective unsupervised anomaly detection. We utilized real operating data from industry steam turbines and conducted both comparison and ablation experiments, demonstrating superior anomaly detection outcomes characterized by high accuracy and minimal false alarm rates compared with existing methods.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10772",
        "abstract url": "https://arxiv.org/abs/2411.10772",
        "title": "MRI Parameter Mapping via Gaussian Mixture VAE: Breaking the Assumption of Independent Pixels",
        "rating": "-2.5",
        "keywords": [
            [
                "voxel"
            ],
            [
                "diffusion"
            ],
            [
                "biologically-relevant",
                "MRI",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We introduce and demonstrate a new paradigm for quantitative parameter mapping in MRI. Parameter mapping techniques, such as diffusion MRI and quantitative MRI, have the potential to robustly and repeatably measure biologically-relevant tissue maps that strongly relate to underlying microstructure. Quantitative maps are calculated by fitting a model to multiple images, e.g. with least-squares or machine learning. However, the overwhelming majority of model fitting techniques assume that each voxel is independent, ignoring any co-dependencies in the data. This makes model fitting sensitive to voxelwise measurement noise, hampering reliability and repeatability. We propose a self-supervised deep variational approach that breaks the assumption of independent pixels, leveraging redundancies in the data to effectively perform data-driven regularisation of quantitative maps. We demonstrate that our approach outperforms current model fitting techniques in dMRI simulations and real data. Especially with a Gaussian mixture prior, our model enables sharper quantitative maps, revealing finer anatomical details that are not presented in the baselines. Our approach can hence support the clinical adoption of parameter mapping methods such as dMRI and qMRI.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "NeurIPS 2024 Workshop in Machine Learning and the Physical Sciences"
    },
    {
        "paper id": "2411.10819",
        "abstract url": "https://arxiv.org/abs/2411.10819",
        "title": "An Oversampling-enhanced Multi-class Imbalanced Classification Framework for Patient Health Status Prediction Using Patient-reported Outcomes",
        "rating": "-2.5",
        "keywords": [
            [
                "SVM",
                "Support Vector Machine"
            ],
            [
                "Health",
                "cancer",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Patient-reported outcomes (PROs) directly collected from cancer patients being treated with radiation therapy play a vital role in assisting clinicians in counseling patients regarding likely toxicities. Precise prediction and evaluation of symptoms or health status associated with PROs are fundamental to enhancing decision-making and planning for the required services and support as patients transition into survivorship. However, the raw PRO data collected from hospitals exhibits some intrinsic challenges such as incomplete item reports and imbalance patient toxicities. To the end, in this study, we explore various machine learning techniques to predict patient outcomes related to health status such as pain levels and sleep discomfort using PRO datasets from a cancer photon/proton therapy center. Specifically, we deploy six advanced machine learning classifiers -- Random Forest (RF), XGBoost, Gradient Boosting (GB), Support Vector Machine (SVM), Multi-Layer Perceptron with Bagging (MLP-Bagging), and Logistic Regression (LR) -- to tackle a multi-class imbalance classification problem across three prevalent cancer types: head and neck, prostate, and breast cancers. To address the class imbalance issue, we employ an oversampling strategy, adjusting the training set sample sizes through interpolations of in-class neighboring samples, thereby augmenting minority classes without deviating from the original skewed class distribution. Our experimental findings across multiple PRO datasets indicate that the RF and XGB methods achieve robust generalization performance, evidenced by weighted AUC and detailed confusion matrices, in categorizing outcomes as mild, intermediate, and severe post-radiation therapy. These results underscore the models' effectiveness and potential utility in clinical settings.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "10 pages, 12 figures, 4 tables"
    },
    {
        "paper id": "2411.10821",
        "abstract url": "https://arxiv.org/abs/2411.10821",
        "title": "GeomCLIP: Contrastive Geometry-Text Pre-training for Molecules",
        "rating": "-2.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "biomedical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Pretraining molecular representations is crucial for drug and material discovery. Recent methods focus on learning representations from geometric structures, effectively capturing 3D position information. Yet, they overlook the rich information in biomedical texts, which detail molecules' properties and substructures. With this in mind, we set up a data collection effort for 200K pairs of ground-state geometric structures and biomedical texts, resulting in a PubChem3D dataset. Based on this dataset, we propose the GeomCLIP framework to enhance for multi-modal representation learning from molecular structures and biomedical text. During pre-training, we design two types of tasks, i.e., multimodal representation alignment and unimodal denoising pretraining, to align the 3D geometric encoder with textual information and, at the same time, preserve its original representation power. Experimental results show the effectiveness of GeomCLIP in various tasks such as molecular property prediction, zero-shot text-molecule retrieval, and 3D molecule captioning. Our code and collected dataset are available at \\url{https://github.com/xiaocui3737/GeomCLIP}",
        "subjects": [
            "cs.LG",
            "q-bio.BM"
        ],
        "comment": "BIBM 2024"
    },
    {
        "paper id": "2411.10911",
        "abstract url": "https://arxiv.org/abs/2411.10911",
        "title": "Constructing accurate machine-learned potentials and performing highly efficient atomistic simulations to predict structural and thermal properties",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "thermal"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The $\\text{Cu}_7\\text{P}\\text{S}_6$ compound has garnered significant attention due to its potential in thermoelectric applications. In this study, we introduce a neuroevolution potential (NEP), trained on a dataset generated from ab initio molecular dynamics (AIMD) simulations, using the moment tensor potential (MTP) as a reference. The low root mean square errors (RMSEs) for total energy and atomic forces demonstrate the high accuracy and transferability of both the MTP and NEP. We further calculate the phonon density of states (DOS) and radial distribution function (RDF) using both machine learning potentials, comparing the results to density functional theory (DFT) calculations. While the MTP potential offers slightly higher accuracy, the NEP achieves a remarkable 41-fold increase in computational speed. These findings provide detailed microscopic insights into the dynamics and rapid Cu-ion diffusion, paving the way for future studies on Cu-based solid electrolytes and their applications in energy devices.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG",
            "physics.chem-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2411.12763",
        "abstract url": "https://arxiv.org/abs/2411.12763",
        "title": "Education in the Era of Neurosymbolic AI",
        "rating": "-2.5",
        "keywords": [
            [
                "depth"
            ],
            [
                "diagnosis"
            ],
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Education is poised for a transformative shift with the advent of neurosymbolic artificial intelligence (NAI), which will redefine how we support deeply adaptive and personalized learning experiences. NAI-powered education systems will be capable of interpreting complex human concepts and contexts while employing advanced problem-solving strategies, all grounded in established pedagogical frameworks. This will enable a level of personalization in learning systems that to date has been largely unattainable at scale, providing finely tailored curricula that adapt to an individual's learning pace and accessibility needs, including the diagnosis of student understanding of subjects at a fine-grained level, identifying gaps in foundational knowledge, and adjusting instruction accordingly. In this paper, we propose a system that leverages the unique affordances of pedagogical agents -- embodied characters designed to enhance learning -- as critical components of a hybrid NAI architecture. To do so, these agents can thus simulate nuanced discussions, debates, and problem-solving exercises that push learners beyond rote memorization toward deep comprehension. We discuss the rationale for our system design and the preliminary findings of our work. We conclude that education in the era of NAI will make learning more accessible, equitable, and aligned with real-world skills. This is an era that will explore a new depth of understanding in educational tools.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10715",
        "abstract url": "https://arxiv.org/abs/2411.10715",
        "title": "EVT: Efficient View Transformation for Multi-Modal 3D Object Detection",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "LiDAR"
            ],
            [
                "BEV"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multi-modal sensor fusion in bird's-eye-view (BEV) representation has become the leading approach in 3D object detection. However, existing methods often rely on depth estimators or transformer encoders for view transformation, incurring substantial computational overhead. Furthermore, the lack of precise geometric correspondence between 2D and 3D spaces leads to spatial and ray-directional misalignments, restricting the effectiveness of BEV representations. To address these challenges, we propose a novel 3D object detector via efficient view transformation (EVT), which leverages a well-structured BEV representation to enhance accuracy and efficiency. EVT focuses on two main areas. First, it employs Adaptive Sampling and Adaptive Projection (ASAP), using LiDAR guidance to generate 3D sampling points and adaptive kernels. The generated points and kernels are then used to facilitate the transformation of image features into BEV space and refine the BEV features. Second, EVT includes an improved transformer-based detection framework, which contains a group-wise query initialization method and an enhanced query update framework. It is designed to effectively utilize the obtained multi-modal BEV features within the transformer decoder. By leveraging the geometric properties of object queries, this framework significantly enhances detection performance, especially in a multi-layer transformer decoder structure. EVT achieves state-of-the-art performance on the nuScenes test set with real-time inference speed.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10760",
        "abstract url": "https://arxiv.org/abs/2411.10760",
        "title": "Experimental study of fish-like bodies with passive tail and tunable stiffness",
        "rating": "-3",
        "keywords": [
            [
                "robot"
            ],
            [
                "bio-inspired"
            ]
        ],
        "abstract": "Scombrid fishes and tuna are efficient swimmers capable of maximizing performance to escape predators and save energy during long journeys. A key aspect in achieving these goals is the flexibility of the tail, which the fish optimizes during swimming. Though, the robotic counterparts, although highly efficient, have partially investigated the importance of flexibility. We have designed and tested a fish-like robotic platform (of 30 cm in length) to quantify performance with a tail made flexible through a torsional spring placed at the peduncle. Body kinematics, forces, and power have been measured and compared with real fish. The platform can vary its frequency between 1 and 3 Hz, reaching self-propulsion conditions with speed over 1 BL/s and Strouhal number in the optimal range. We show that changing the frequency of the robot can influence the thrust and power achieved by the fish-like robot. Furthermore, by using appropriately tuned stiffness, the robot deforms in accordance with the travelling wave mechanism, which has been revealed to be the actual motion of real fish. These findings demonstrate the potential of tuning the stiffness in fish swimming and offer a basis for investigating fish-like flexibility in bio-inspired underwater vehicles.",
        "subjects": [
            "physics.flu-dyn",
            "cs.RO"
        ],
        "comment": "Conference Paper submitted to the 15th International Conference on Hydrodynamics (ICHD 2024)"
    },
    {
        "paper id": "2411.10814",
        "abstract url": "https://arxiv.org/abs/2411.10814",
        "title": "DEAL: Decoupled Classifier with Adaptive Linear Modulation for Group Robust Early Diagnosis of MCI to AD Conversion",
        "rating": "-3",
        "keywords": [
            [
                "Diagnosis",
                "MRI",
                "disease"
            ],
            [
                "tabular"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While deep learning-based Alzheimer's disease (AD) diagnosis has recently made significant advancements, particularly in predicting the conversion of mild cognitive impairment (MCI) to AD based on MRI images, there remains a critical gap in research regarding the group robustness of the diagnosis. Although numerous studies pointed out that deep learning-based classifiers may exhibit poor performance in certain groups by relying on unimportant attributes, this issue has been largely overlooked in the early diagnosis of MCI to AD conversion. In this paper, we present the first comprehensive investigation of the group robustness in the early diagnosis of MCI to AD conversion using MRI images, focusing on disparities in accuracy between groups, specifically sMCI and pMCI individuals divided by age. Our experiments reveal that standard classifiers consistently underperform for certain groups across different architectures, highlighting the need for more tailored approaches. To address this, we propose a novel method, dubbed DEAL (DEcoupled classifier with Adaptive Linear modulation), comprising two key components: (1) a linear modulation of features from the penultimate layer, incorporating easily obtainable age and cognitive indicative tabular features, and (2) a decoupled classifier that provides more tailored decision boundaries for each group, further improving performance. Through extensive experiments and evaluations across different architectures, we demonstrate the efficacy of DEAL in improving the group robustness of the MCI to AD conversion prediction.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Under Review"
    },
    {
        "paper id": "2411.10882",
        "abstract url": "https://arxiv.org/abs/2411.10882",
        "title": "Adaptive Soft Actor-Critic Framework for RIS-Assisted and UAV-Aided Communication",
        "rating": "-3",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "In this work, we explore UAV-assisted reconfigurable intelligent surface (RIS) technology to enhance downlink communications in wireless networks. By integrating RIS on both UAVs and ground infrastructure, we aim to boost network coverage, fairness, and resilience against challenges such as UAV jitter. To maximize the minimum achievable user rate, we formulate a joint optimization problem involving beamforming, phase shifts, and UAV trajectory. To address this problem, we propose an adaptive soft actor-critic (ASAC) framework. In this approach, agents are built using adaptive sparse transformers with attentive feature refinement (ASTAFER), enabling dynamic feature processing that adapts to real-time network conditions. The ASAC model learns optimal solutions to the coupled subproblems in real time, delivering an end-to-end solution without relying on iterative or relaxation-based methods. Simulation results demonstrate that our ASAC-based approach achieves better performance compared to the conventional SAC. This makes it a robust, adaptable solution for real-time, fair, and efficient downlink communication in UAV-RIS networks.",
        "subjects": [
            "eess.SP",
            "eess.SY"
        ],
        "comment": "9 pages, 6 figures"
    },
    {
        "paper id": "2411.10924",
        "abstract url": "https://arxiv.org/abs/2411.10924",
        "title": "Hyperspectral Imaging-Based Grain Quality Assessment With Limited Labelled Data",
        "rating": "-3",
        "keywords": [
            [
                "Hyperspectral Imaging"
            ],
            [
                "Quality Assessment"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Recently hyperspectral imaging (HSI)-based grain quality assessment has gained research attention. However, unlike other imaging modalities, HSI data lacks sufficient labelled samples required to effectively train deep convolutional neural network (DCNN)-based classifiers. In this paper, we present a novel approach to grain quality assessment using HSI combined with few-shot learning (FSL) techniques. Traditional methods for grain quality evaluation, while reliable, are invasive, time-consuming, and costly. HSI offers a non-invasive, real-time alternative by capturing both spatial and spectral information. However, a significant challenge in applying DCNNs for HSI-based grain classification is the need for large labelled databases, which are often difficult to obtain. To address this, we explore the use of FSL, which enables models to perform well with limited labelled data, making it a practical solution for real-world applications where rapid deployment is required. We also explored the application of FSL for the classification of hyperspectral images of bulk grains to enable rapid quality assessment at various receival points in the grain supply chain. We evaluated the performance of few-shot classifiers in two scenarios: first, classification of grain types seen during training, and second, generalisation to unseen grain types, a crucial feature for real-world applications. In the first scenario, we introduce a novel approach using pre-computed collective class prototypes (CCPs) to enhance inference efficiency and robustness. In the second scenario, we assess the model's ability to classify novel grain types using limited support examples. Our experimental results show that despite using very limited labelled data for training, our FSL classifiers accuracy is comparable to that of a fully trained classifier trained using a significantly larger labelled database.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "10 pages"
    },
    {
        "paper id": "2411.10941",
        "abstract url": "https://arxiv.org/abs/2411.10941",
        "title": "Efficient Estimation of Relaxed Model Parameters for Robust UAV Trajectory Optimization",
        "rating": "-3",
        "keywords": [
            [
                "Trajectory",
                "vehicle"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "Online trajectory optimization and optimal control methods are crucial for enabling sustainable unmanned aerial vehicle (UAV) services, such as agriculture, environmental monitoring, and transportation, where available actuation and energy are limited. However, optimal controllers are highly sensitive to model mismatch, which can occur due to loaded equipment, packages to be delivered, or pre-existing variability in fundamental structural and thrust-related parameters. To circumvent this problem, optimal controllers can be paired with parameter estimators to improve their trajectory planning performance and perform adaptive control. However, UAV platforms are limited in terms of onboard processing power, oftentimes making nonlinear parameter estimation too computationally expensive to consider. To address these issues, we propose a relaxed, affine-in-parameters multirotor model along with an efficient optimal parameter estimator. We convexify the nominal Moving Horizon Parameter Estimation (MHPE) problem into a linear-quadratic form (LQ-MHPE) via an affine-in-parameter relaxation on the nonlinear dynamics, resulting in fast quadratic programs (QPs) that facilitate adaptive Model Predictve Control (MPC) in real time. We compare this approach to the equivalent nonlinear estimator in Monte Carlo simulations, demonstrating a decrease in average solve time and trajectory optimality cost by 98.2% and 23.9-56.2%, respectively.",
        "subjects": [
            "math.OC",
            "cs.RO",
            "eess.SY"
        ],
        "comment": "8 pages, 5 figures, submitted to IEEE Sustech 2025"
    },
    {
        "paper id": "2411.10703",
        "abstract url": "https://arxiv.org/abs/2411.10703",
        "title": "Hybrid Attention Model Using Feature Decomposition and Knowledge Distillation for Glucose Forecasting",
        "rating": "-3.5",
        "keywords": [
            [
                "health",
                "physiological"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "The availability of continuous glucose monitors as over-the-counter commodities have created a unique opportunity to monitor a person's blood glucose levels, forecast blood glucose trajectories and provide automated interventions to prevent devastating chronic complications that arise from poor glucose control. However, forecasting blood glucose levels is challenging because blood glucose changes consistently in response to food intake, medication intake, physical activity, sleep, and stress. It is particularly difficult to accurately predict BGL from multimodal and irregularly sampled data and over long prediction horizons. Furthermore, these forecasting models must operate in real-time on edge devices to provide in-the-moment interventions. To address these challenges, we propose GlucoNet, an AI-powered sensor system for continuously monitoring behavioral and physiological health and robust forecasting of blood glucose patterns. GlucoNet devises a feature decomposition-based transformer model that incorporates patients' behavioral and physiological data and transforms sparse and irregular patient data (e.g., diet and medication intake data) into continuous features using a mathematical model, facilitating better integration with the BGL data. Given the non-linear and non-stationary nature of BG signals, we propose a decomposition method to extract both low and high-frequency components from the BGL signals, thus providing accurate forecasting. To reduce the computational complexity, we also propose to employ knowledge distillation to compress the transformer model. GlucoNet achieves a 60% improvement in RMSE and a 21% reduction in the number of parameters, using data obtained involving 12 participants with T1-Diabetes. These results underscore GlucoNet's potential as a compact and reliable tool for real-world diabetes prevention and management.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10716",
        "abstract url": "https://arxiv.org/abs/2411.10716",
        "title": "FlowScope: Enhancing Decision Making by Time Series Forecasting based on Prediction Optimization using HybridFlow Forecast Framework",
        "rating": "-3.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "Forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Time series forecasting is crucial in several sectors, such as meteorology, retail, healthcare, and finance. Accurately forecasting future trends and patterns is crucial for strategic planning and making well-informed decisions. In this case, it is crucial to include many forecasting methodologies. The strengths of Auto-regressive Integrated Moving Average (ARIMA) for linear time series, Seasonal ARIMA models (SARIMA) for seasonal time series, Exponential Smoothing State Space Models (ETS) for handling errors and trends, and Long Short-Term Memory (LSTM) Neural Network model for complex pattern recognition have been combined to create a comprehensive framework called FlowScope. SARIMA excels in capturing seasonal variations, whereas ARIMA ensures effective handling of linear time series. ETS models excel in capturing trends and correcting errors, whereas LSTM networks excel in reflecting intricate temporal connections. By combining these methods from both machine learning and deep learning, we propose a deep-hybrid learning approach FlowScope which offers a versatile and robust platform for predicting time series data. This empowers enterprises to make informed decisions and optimize long-term strategies for maximum performance. Keywords: Time Series Forecasting, HybridFlow Forecast Framework, Deep-Hybrid Learning, Informed Decisions.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "eess.SP"
        ],
        "comment": "12 pages and 6 figures"
    },
    {
        "paper id": "2411.10817",
        "abstract url": "https://arxiv.org/abs/2411.10817",
        "title": "Conformation Generation using Transformer Flows",
        "rating": "-4.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "biological"
            ],
            [
                "chemical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Estimating three-dimensional conformations of a molecular graph allows insight into the molecule's biological and chemical functions. Fast generation of valid conformations is thus central to molecular modeling. Recent advances in graph-based deep networks have accelerated conformation generation from hours to seconds. However, current network architectures do not scale well to large molecules. Here we present ConfFlow, a flow-based model for conformation generation based on transformer networks. In contrast with existing approaches, ConfFlow directly samples in the coordinate space without enforcing any explicit physical constraints. The generative procedure is highly interpretable and is akin to force field updates in molecular dynamics simulation. When applied to the generation of large molecule conformations, ConfFlow improve accuracy by up to $40\\%$ relative to state-of-the-art learning-based methods. The source code is made available at https://github.com/IntelLabs/ConfFlow.",
        "subjects": [
            "cs.LG",
            "q-bio.QM",
            "stat.ML"
        ],
        "comment": "Technical Report. Code available at https://github.com/IntelLabs/ConfFlow"
    },
    {
        "paper id": "2411.10918",
        "abstract url": "https://arxiv.org/abs/2411.10918",
        "title": "LLM-assisted Physical Invariant Extraction for Cyber-Physical Systems Anomaly Detection",
        "rating": "-5.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "attacks"
            ],
            [
                "industrial"
            ],
            [
                "physics"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Modern industrial infrastructures rely heavily on Cyber-Physical Systems (CPS), but these are vulnerable to cyber-attacks with potentially catastrophic effects. To reduce these risks, anomaly detection methods based on physical invariants have been developed. However, these methods often require domain-specific expertise to manually define invariants, making them costly and difficult to scale. To address this limitation, we propose a novel approach to extract physical invariants from CPS testbeds for anomaly detection. Our insight is that CPS design documentation often contains semantically rich descriptions of physical procedures, which can profile inter-correlated dynamics among system components. Leveraging the built-in physics and engineering knowledge of recent generative AI models, we aim to automate this traditionally manual process, improving scalability and reducing costs. This work focuses on designing and optimizing a Retrieval-Augmented-Generation (RAG) workflow with a customized prompting system tailored for CPS documentation, enabling accurate extraction of semantic information and inference of physical invariants from complex, multimodal content. Then, rather than directly applying the inferred invariants for anomaly detection, we introduce an innovative statistics-based learning approach that integrates these invariants into the training dataset. This method addresses limitations such as hallucination and concept drift, enhancing the reliability of the model. We evaluate our approach on real-world public CPS security dataset which contains 86 data points and 58 attacking cases. The results show that our approach achieves a high precision of 0.923, accurately detecting anomalies while minimizing false alarms.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10815",
        "abstract url": "https://arxiv.org/abs/2411.10815",
        "title": "Collaborative UAVs Multi-task Video Processing Optimization Based on Enhanced Distributed Actor-Critic Networks",
        "rating": "-6",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "IoT"
            ],
            [
                "UAV"
            ]
        ],
        "abstract": "With the rapid advancement of the Internet of Things (IoT) and Artificial Intelligence (AI), intelligent information services are being increasingly integrated across various sectors, including healthcare, industry, and transportation. Traditional solutions rely on centralized cloud processing, which encounters considerable challenges in fulfilling the Quality of Service (QoS) requirements of Computer Vision (CV) tasks generated in the resource-constrained infrastructure-less environments. In this paper, we introduce a distributed framework called CoUAV-Pro for multi-task video processing powered by Unmanned Aerial Vehicles (UAVs). This framework empowers multiple UAVs to meet the service demands of various computer vision (CV) tasks in infrastructure-less environments, thereby eliminating the need for centralized processing. Specifically, we develop a novel task allocation algorithm that leverages enhanced distributed actor-critic networks within CoUAV-Pro, aiming to optimize task processing efficiency while contending with constraints associated with UAV's energy, computational, and communication resources. Comprehensive experiments demonstrate that our proposed solution achieves satisfactory performance levels against those of centralized methods across key metrics including task acquisition rates, task latency, and energy consumption.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10707",
        "abstract url": "https://arxiv.org/abs/2411.10707",
        "title": "Differentiable Extensions with Rounding Guarantees for Combinatorial Optimization over Permutations",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present Birkhoff Extension (BE), an almost-everywhere-differentiable continuous polytime-computable extension of any real-valued function on permutations to doubly stochastic matrices. Our approach is based on Birkhoff decomposition (also referred to as Birkhoff von-Neumann decomposition) which allows construction of an extension that is always a convex combination of the objective's values at permutations. We show how to construct a specific family of Birkhoff decompositions that are continuous. In addition to continuity, our extension has several nice properties making it appealing for optimization problems. First, BE provides a rounding guarantee, namely any solution to the extension can be efficiently rounded to a permutation without increasing the function value. Furthermore, an approximate solution in the relaxed case (with extension) will give rise to an approximate solution in the space of permutations. Second, using BE, any real-valued optimization objective on permutations can be extended to an almost everywhere differentiable objective function over the space of doubly stochastic matrices. This makes our BE amenable to not only gradient-descent based optimizations, but also unsupervised neural combinatorial optimization where training often requires a differentiable loss. Third, based on the above properties, we present a simple optimization procedure which can be readily combined with existing optimization approaches to offer local improvements (i.e., the quality of the final solution is no worse than the initial solution). We present preliminary experimental results to verify our theoretical results on several combinatorial optimization problems related to permutations.",
        "subjects": [
            "cs.DS",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10714",
        "abstract url": "https://arxiv.org/abs/2411.10714",
        "title": "FlexFL: Flexible and Effective Fault Localization with Open-Source Large Language Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Due to the impressive code comprehension ability of Large Language Models (LLMs), a few studies have proposed to leverage LLMs to locate bugs, i.e., LLM-based FL, and demonstrated promising performance. However, first, these methods are limited in flexibility. They rely on bug-triggering test cases to perform FL and cannot make use of other available bug-related information, e.g., bug reports. Second, they are built upon proprietary LLMs, which are, although powerful, confronted with risks in data privacy. To address these limitations, we propose a novel LLM-based FL framework named FlexFL, which can flexibly leverage different types of bug-related information and effectively work with open-source LLMs. FlexFL is composed of two stages. In the first stage, FlexFL reduces the search space of buggy code using state-of-the-art FL techniques of different families and provides a candidate list of bug-related methods. In the second stage, FlexFL leverages LLMs to delve deeper to double-check the code snippets of methods suggested by the first stage and refine fault localization results. In each stage, FlexFL constructs agents based on open-source LLMs, which share the same pipeline that does not postulate any type of bug-related information and can interact with function calls without the out-of-the-box capability. Extensive experimental results on Defects4J demonstrate that FlexFL outperforms the baselines and can work with different open-source LLMs. Specifically, FlexFL with a lightweight open-source LLM Llama3-8B can locate 42 and 63 more bugs than two state-of-the-art LLM-based FL approaches AutoFL and AgentFL that both use GPT-3.5.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "14 pages, 3 figures"
    },
    {
        "paper id": "2411.10727",
        "abstract url": "https://arxiv.org/abs/2411.10727",
        "title": "Self-Triggered Control in Artificial Pancreas",
        "rating": "-10",
        "keywords": [],
        "abstract": "The management of type 1 diabetes has been revolutionized by the artificial pancreas system (APS), which automates insulin delivery based on continuous glucose monitor (CGM). While conventional closed-loop systems rely on CGM data, which leads to higher energy consumption at the sensors and increased data redundancy in the underlying communication network. In contrast, this paper proposes a self-triggered control mechanism that can potentially achieve lower latency and energy efficiency. The model for the APS consists of a state and input-constrained dynamical system affected by exogenous meal disturbances. Our self-triggered mechanism relies on restricting the state evolution within the robust control invariant of such a system at all times. To that end, using tools from reachability, we associate a safe time interval with such invariant sets, which denotes the maximum time for which the invariant set remains invariant, even without transmission of CGM data at all times.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10769",
        "abstract url": "https://arxiv.org/abs/2411.10769",
        "title": "Demonstrating Remote Synchronization: An Experimental Approach with Nonlinear Oscillators",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study investigates remote synchronization in arbitrary network clusters of coupled nonlinear oscillators, a phenomenon inspired by neural synchronization in the brain. Employing a multi-faceted approach encompassing analytical, numerical, and experimental methodologies, we leverage the Master Stability Function (MSF) to analyze network stability. We provide experimental evidence of remote synchronization between two clusters of nonlinear oscillators, where oscillators within each cluster are also remotely connected. This observation parallels the thalamus-mediated synchronization of neuronal populations in the brain. An electronic circuit testbed, supported by nonlinear ODE modeling and LT Spice simulation, was developed to validate our theoretical predictions. Future work will extend this investigation to encompass diverse network topologies and explore potential applications in neuroscience, communication networks, and power systems.",
        "subjects": [
            "eess.SY",
            "nlin.CD"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10770",
        "abstract url": "https://arxiv.org/abs/2411.10770",
        "title": "Task Offloading for Vehicular Edge Computing Based on Improved Hotstuff under Parking Assistance",
        "rating": "-10",
        "keywords": [],
        "abstract": "Parked-assisted vehicular edge computing (PVEC) fully leverages communication and computing resources of parking vehicles, thereby significantly alleviating the pressure on edge servers. However, resource sharing and trading for vehicular task offloading in the PVEC environment usually occur between untrustworthy entities, which compromises the security of data sharing and transactions by vehicles and edge devices. To address these concerns, blockchain is introduced to provide a secure and trustworthy environment for offloading and transactions in PVEC. Nevertheless, due to the mobility of the vehicles, the processes of computing offloading and blockchain transactions are interrupted, which greatly reduces the reliability of the blockchain in edge computing process. In this paper, we propose a blockchain-based PVEC (BPVEC) offloading framework to enhance the security and reliability of the task offloading and transaction. Specifically, a consensus node selection algorithm based on the connected dominating set (CDS) is designed to improve the Hotstuff consensus according to parking time, computing capability and communication quality, which enhances blockchain reliability in computing offloading and transactions. Meanwhile, a Stackelberg game model, establishing the roadside units (RSUs) and parking vehicles (PVs) as leaders and the requesting vehicles (RVs) as follower, is utilized to optimize the offloading strategy and pricing. Subsequently, a BPVEC offloading strategy algorithm with gradient descent method is designed to maximize system revenue. Simulation results show that the proposed BPVEC offloading scheme is secure and reliable while ensuring maximum benefits.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10791",
        "abstract url": "https://arxiv.org/abs/2411.10791",
        "title": "Optimal Fixed-Price Mechanism with Signaling",
        "rating": "-10",
        "keywords": [],
        "abstract": "Consider a trade market with one seller and multiple buyers. The seller aims to sell an indivisible item and maximize their revenue. This paper focuses on a simple and popular mechanism--the fixed-price mechanism. Unlike the standard setting, we assume there is information asymmetry between buyers and the seller. Specifically, we allow the seller to design information before setting the fixed price, which implies that we study the mechanism design problem in a broader space. We call this mechanism space the fixed-price signaling mechanism. We assume that buyers' valuation of the item depends on the quality of the item. The seller can privately observe the item's quality, whereas buyers only see its distribution. In this case, the seller can influence buyers' valuations by strategically disclosing information about the item's quality, thereby adjusting the fixed price. We consider two types of buyers with different levels of rationality: ex-post individual rational (IR) and ex-interim individual rational. We show that when the market has only one buyer, the optimal revenue generated by the fixed-price signaling mechanism is identical to that of the fixed-price mechanism, regardless of the level of rationality. Furthermore, when there are multiple buyers in the market and all of them are ex-post IR, we show that there is no fixed-price mechanism that is obedient for all buyers. However, if all buyers are ex-interim IR, we show that the optimal fixed-price signaling mechanism will generate more revenue for the seller than the fixed-price mechanism.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10805",
        "abstract url": "https://arxiv.org/abs/2411.10805",
        "title": "Existence of $\u03b5$-Nash Equilibria in Nonzero-Sum Borel Stochastic Games and Equilibria of Quantized Models",
        "rating": "-10",
        "keywords": [],
        "abstract": "Establishing the existence of exact or near Markov or stationary perfect Nash equilibria in nonzero-sum Markov games over Borel spaces remains a challenging problem, with few positive results to date. In this paper, we establish the existence of approximate Markov and stationary Nash equilibria for nonzero-sum stochastic games over Borel spaces, assuming only mild regularity conditions on the model. Our approach involves analyzing a quantized version of the game, for which we provide an explicit construction under both finite-horizon and discounted cost criteria. This work has significant implications for emerging applications such as multi-agent learning. Our results apply to both compact and non-compact state spaces. For the compact state space case, we first approximate the standard Borel model with a finite state-action model. Using the existence of Markov and stationary perfect Nash equilibria for these finite models under finite-horizon and discounted cost criteria, we demonstrate that these joint policies constitute approximate Markov and stationary perfect equilibria under mild continuity conditions on the one-stage costs and transition probabilities. For the non-compact state space case, we achieve similar results by first approximating the model with a compact-state model. Compared with previous results in the literature, which we comprehensively review, we provide more general and complementary conditions, along with explicit approximation models whose equilibria are $\u03b5$-equilibria for the original model.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10811",
        "abstract url": "https://arxiv.org/abs/2411.10811",
        "title": "Detecting collusion in procurement auctions",
        "rating": "-10",
        "keywords": [],
        "abstract": "The study aimed at detecting cartel collusion involved analyzing decisions of the Russian Federal Antimonopoly Service and data on auctions. As a result, a machine learning model was developed that predicts with 91% accuracy the signs of collusion between bidders based on their history after dividing 40 auctions into test and training samples in a 30/70 ratio. Decomposition of the model using the Shepley vector allowed the interpretation of the decision-making process. The behavior of honest companies in auctions was also studied, confirmed by independent simulation validation.",
        "subjects": [
            "cs.GT"
        ],
        "comment": "22 pages, 9 figures. in Russian language"
    },
    {
        "paper id": "2411.10820",
        "abstract url": "https://arxiv.org/abs/2411.10820",
        "title": "Molecular Dynamics Study of Liquid Condensation on Nano-structured Sinusoidal Hybrid Wetting Surfaces",
        "rating": "-10",
        "keywords": [],
        "abstract": "Although real surfaces exhibit intricate topologies at the nanoscale, rough surface consideration is often overlooked in nanoscale heat transfer studies. Superimposed sinusoidal functions effectively model the complexity of these surfaces. This study investigates the impact of sinusoidal roughness on liquid argon condensation over a functional gradient wetting (FGW) surface with 84% hydrophilic content using molecular dynamics simulations. Argon atoms are confined between two platinum substrates: a flat lower substrate heated to 130K and a rough upper substrate at 90K. Key metrics of the nanoscale condensation process, such as nucleation, surface heat flux, and total energy per atom, are analyzed. Rough surfaces significantly enhance nucleation, nearly doubling cluster counts compared to smooth surfaces and achieving a more extended atomic density profile with a peak of approximately and improved heat flux. Stronger atom-surface interactions also lead to more efficient energy dissipation. These findings underscore the importance of surface roughness in optimizing condensation and heat transfer, offering a more accurate representation of surface textures and a basis for designing surfaces that achieve superior heat transfer performance.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "eess.SY"
        ],
        "comment": "9 pages, 7 figures, conference"
    },
    {
        "paper id": "2411.10826",
        "abstract url": "https://arxiv.org/abs/2411.10826",
        "title": "Probabilistic Nets-within-Nets",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper we study Hornets extended with firing probabilities. Hornets are a Nets-within-Nets formalism, i.e., a Petri net formalism where the tokens are Petri nets again. Each of these net-tokens has its own firing rate, independent from the rates of other net-tokens. Hornets provide algebraic operations to modify net-tokens during the firing. For our stochastic extension these operators could also modify the net-token's firing rate. We use our model to analyse self-modifying systems quantitatively. Hornets are very well suited to model self-adaptive systems performing a MAPE-like loop (monitoring-analyse-plan-execute). Here, the system net describes the loop, and the net-tokens describe the adapted model elements.",
        "subjects": [
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10832",
        "abstract url": "https://arxiv.org/abs/2411.10832",
        "title": "Small-signal stability of power systems with voltage droop",
        "rating": "-10",
        "keywords": [],
        "abstract": "The small-signal stability of power grids is a well-studied topic. In this work, we give new sufficient conditions for highly heterogeneous mixes of grid-forming inverters (and other machines) that implement a $V$-$q$ droop to stabilize viable operating states of lossless grids. Assuming the edges are not overloaded, and static voltage limits are satisfied, our conditions are fully local: They can be evaluated bus by bus without information on the rest of the grid. Other than the presence of $V$-$q$ droop, we make no model assumptions. In particular, we do not assume a specific control strategy of the inverters, the number, or type, of their internal degrees of freedom, or that the control is homogeneous throughout the system. We achieve this by recasting the dynamics of the nodes as a complex frequency reaction to an active and reactive power signal coming from the grid. By working directly in terms of the node's linearized complex frequency response, the transfer functions capturing the linear response do not depend on arbitrary phases. Further, they are easily interpretable as the frequency/amplitude reaction to active/reactive power imbalance, and correspond directly to the typical design considerations for grid-forming control. By exploiting the presence of the $V$-$q$ droop, we can ensure that the grid's active/reactive power response to a frequency/amplitude change is semi-sectorial. This allows us to use an adapted small phase theorem to obtain local sufficient stability conditions for edges and nodes, which also yields novel results for established control designs.",
        "subjects": [
            "math.OC",
            "eess.SY",
            "math.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10860",
        "abstract url": "https://arxiv.org/abs/2411.10860",
        "title": "Hereditary First-Order Model Checking",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many computational problems can be modelled as the class of all finite relational structures $\\mathbb A$ that satisfy a fixed first-order sentence $\u03c6$ hereditarily, i.e., we require that every substructure of $\\mathbb A$ satisfies $\u03c6$. In this case, we say that the class is in HerFO. The problems in HerFO are always in coNP, and sometimes coNP-complete. HerFO also contains many interesting computational problems in P, including many constraint satisfaction problems (CSPs). We show that HerFO captures the class of complements of CSPs for reducts of finitely bounded structures, i.e., every such CSP is polynomial-time equivalent to the complement of a problem in HerFO. However, we also prove that HerFO does not have the full computational power of coNP: there are problems in coNP that are not polynomial-time equivalent to a problem in HerFO, unless E=NE. Another main result is a description of the quantifier-prefixes for $\u03c6$ such that hereditarily checking $\u03c6$ is in P; we show that for every other quantifier-prefix there exists a formula $\u03c6$ with this prefix such that hereditarily checking $\u03c6$ is coNP-complete.",
        "subjects": [
            "math.LO",
            "cs.CC",
            "cs.DM",
            "cs.LO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10870",
        "abstract url": "https://arxiv.org/abs/2411.10870",
        "title": "Near-Optimal Averaging Samplers and Matrix Samplers",
        "rating": "-10",
        "keywords": [],
        "abstract": "We present the first efficient averaging sampler that achieves asymptotically optimal randomness complexity and near-optimal sample complexity. For any $\u03b4< \\varepsilon$ and any constant $\u03b1> 0$, our sampler uses $m + O(\\log (1 / \u03b4))$ random bits to output $t = O((\\frac{1}{\\varepsilon^2} \\log \\frac{1}\u03b4)^{1 + \u03b1})$ samples $Z_1, \\dots, Z_t \\in \\{0, 1\\}^m$ such that for any function $f: \\{0, 1\\}^m \\to [0, 1]$, \\[ \\Pr\\left[\\left|\\frac{1}{t}\\sum_{i=1}^t f(Z_i) - \\mathbb{E}[f]\\right| \\leq \\varepsilon\\right] \\geq 1 - \u03b4. \\] The randomness complexity is optimal up to a constant factor, and the sample complexity is optimal up to the $O((\\frac{1}{\\varepsilon^2} \\log \\frac{1}\u03b4)^\u03b1)$ factor. Our technique generalizes to matrix samplers. A matrix sampler is defined similarly, except that $f: \\{0, 1\\}^m \\to \\mathbb{C}^{d \\times d}$ and the absolute value is replaced by the spectral norm. Our matrix sampler achieves randomness complexity $m + \\tilde O (\\log(d / \u03b4))$ and sample complexity $ O((\\frac{1}{\\varepsilon^2} \\log \\frac{d}\u03b4)^{1 + \u03b1})$ for any constant $\u03b1> 0$, both near-optimal with only a logarithmic factor in randomness complexity and an additional $\u03b1$ exponent on the sample complexity. We use known connections with randomness extractors and list-decodable codes to give applications to these objects. Specifically, we give the first extractor construction with optimal seed length up to an arbitrarily small constant factor above 1, when the min-entropy $k = \u03b2n$ for a large enough constant $\u03b2< 1$.",
        "subjects": [
            "cs.CC",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10890",
        "abstract url": "https://arxiv.org/abs/2411.10890",
        "title": "An Empirical Investigation on the Challenges in Scientific Workflow Systems Development",
        "rating": "-10",
        "keywords": [],
        "abstract": "Scientific Workflow Systems (SWSs) are advanced software frameworks that drive modern research by orchestrating complex computational tasks and managing extensive data pipelines. These systems offer a range of essential features, including modularity, abstraction, interoperability, workflow composition tools, resource management, error handling, and comprehensive documentation. Utilizing these frameworks accelerates the development of scientific computing, resulting in more efficient and reproducible research outcomes. However, developing a user-friendly, efficient, and adaptable SWS poses several challenges. This study explores these challenges through an in-depth analysis of interactions on Stack Overflow (SO) and GitHub, key platforms where developers and researchers discuss and resolve issues. In particular, we leverage topic modeling (BERTopic) to understand the topics SWSs developers discuss on these platforms. We identified 10 topics developers discuss on SO (e.g., Workflow Creation and Scheduling, Data Structures and Operations, Workflow Execution) and found that workflow execution is the most challenging. By analyzing GitHub issues, we identified 13 topics (e.g., Errors and Bug Fixing, Documentation, Dependencies) and discovered that data structures and operations is the most difficult. We also found common topics between SO and GitHub, such as data structures and operations, task management, and workflow scheduling. Additionally, we categorized each topic by type (How, Why, What, and Others). We observed that the How type consistently dominates across all topics, indicating a need for procedural guidance among developers. The dominance of the How type is also evident in domains like Chatbots and Mobile development. Our study will guide future research in proposing tools and techniques to help the community overcome the challenges developers face when developing SWSs.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "36 pages, 8 figures"
    },
    {
        "paper id": "2411.10892",
        "abstract url": "https://arxiv.org/abs/2411.10892",
        "title": "The Competition Complexity of Prophet Secretary",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the classic single-choice prophet secretary problem through a resource augmentation lens. Our goal is to bound the $(1-\u03b5)$-competition complexity for different classes of online algorithms. This metric asks for the smallest $k$ such that the expected value of the online algorithm on $k$ copies of the original instance, is at least a $(1 - \u03b5)$-approximation to the expected offline optimum on the original instance (without added copies). We consider four natural classes of online algorithms: single-threshold, time-based threshold, activation-based, and general algorithms. We show that for single-threshold algorithms the $(1-\u03b5)$-competition complexity is $\u0398(\\ln(\\frac{1}\u03b5))$ (as in the i.i.d. case). Additionally, we demonstrate that time-based threshold and activation-based algorithms (which cover all previous approaches for obtaining competitive-ratios for the classic prophet secretary problem) yield a sub-optimal $(1-\u03b5)$-competition complexity of $\u0398\\left(\\frac{\\ln(\\frac{1}\u03b5)}{\\ln\\ln(\\frac{1}\u03b5)}\\right)$, which is strictly better than the class of single-threshold algorithms. Finally, we find that the $(1-\u03b5)$-competition complexity of general adaptive algorithms is $\u0398(\\sqrt{\\ln(\\frac{1}\u03b5)})$, which is in sharp contrast to $\u0398(\\ln\\ln(\\frac{1}\u03b5))$ in the i.i.d. case.",
        "subjects": [
            "cs.GT"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10899",
        "abstract url": "https://arxiv.org/abs/2411.10899",
        "title": "Planning for Tabletop Object Rearrangement",
        "rating": "-10",
        "keywords": [],
        "abstract": "Finding an high-quality solution for the tabletop object rearrangement planning is a challenging problem. Compared to determining a goal arrangement, rearrangement planning is challenging due to the dependencies between objects and the buffer capacity available to hold objects. Although orla* has proposed an A* based searching strategy with lazy evaluation for the high-quality solution, it is not scalable, with the success rate decreasing as the number of objects increases. To overcome this limitation, we propose an enhanced A*-based algorithm that improves state representation and employs incremental goal attempts with lazy evaluation at each iteration. This approach aims to enhance scalability while maintaining solution quality. Our evaluation demonstrates that our algorithm can provide superior solutions compared to orla*, in a shorter time, for both stationary and mobile robots.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10929",
        "abstract url": "https://arxiv.org/abs/2411.10929",
        "title": "Wildfire Risk Metric Impact on Public Safety Power Shut-off Cost Savings",
        "rating": "-10",
        "keywords": [],
        "abstract": "Public Safety Power Shutoffs (PSPS) are a proactive strategy to mitigate fire hazards from power system infrastructure failures. System operators employ PSPS to deactivate portions of the electric grid with heightened wildfire risks to prevent wildfire ignition and redispatch generators to minimize load shedding. A measure of vegetation flammability, called the Wildland Fire Potential Index (WFPI), has been widely used to evaluate the risk of nearby wildfires to power system operation. However, the WFPI does not correlate as strongly to historically observed wildfire ignition probabilities (OWIP) as WFPI-based the Large Fire Probability (WLFP).Prior work chose not to incorporate wildfire-driven failure probabilities, such as the WLFP, because constraints with Bernoulli random variables to represent wildfire ignitions could require non-linear or non-convex constraints. This paper uses a deterministic equivalent of an otherwise complicating line de-energization constraint by quantifying the wildfire risk of operating transmission line as a sum of each energized line's wildfire ignition log probability (log(WIP)) rather than as a sum of each energized line's WFPI. A day-ahead unit commitment and line de-energization PSPS framework is used to assess the cost differences driven by the choice between the WFPI and WLFP risk metrics. Training the optimization on scenarios developed by mapping WLFP to log(WIP) rather than mapping the WFPI to log(WIP) leads to reductions in the total real-time costs. For the IEEE RTS 24-bus test system, mapping transmission line WLFP values to log(WIP) resulted in a 14.8 % (on average) decrease in expected real-time costs.",
        "subjects": [
            "eess.SY"
        ],
        "comment": "10 pages, 9 figures, 2 tables"
    },
    {
        "paper id": "2411.10943",
        "abstract url": "https://arxiv.org/abs/2411.10943",
        "title": "Generalist Virtual Agents: A Survey on Autonomous Agents Across Digital Platforms",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this paper, we introduce the Generalist Virtual Agent (GVA), an autonomous entity engineered to function across diverse digital platforms and environments, assisting users by executing a variety of tasks. This survey delves into the evolution of GVAs, tracing their progress from early intelligent assistants to contemporary implementations that incorporate large-scale models. We explore both the philosophical underpinnings and practical foundations of GVAs, addressing their developmental challenges and the methodologies currently employed in their design and operation. By presenting a detailed taxonomy of GVA environments, tasks, and capabilities, this paper aims to bridge the theoretical and practical aspects of GVAs, concluding those that operate in environments closely mirroring the real world are more likely to demonstrate human-like intelligence. We discuss potential future directions for GVA research, highlighting the necessity for realistic evaluation metrics and the enhancement of long-sequence decision-making capabilities to advance the field toward more systematic or embodied applications. This work not only synthesizes the existing body of literature but also proposes frameworks for future investigations, contributing significantly to the ongoing development of intelligent systems.",
        "subjects": [
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2411.10949",
        "abstract url": "https://arxiv.org/abs/2411.10949",
        "title": "Maximization of Approximately Submodular Functions",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the problem of maximizing a function that is approximately submodular under a cardinality constraint. Approximate submodularity implicitly appears in a wide range of applications as in many cases errors in evaluation of a submodular function break submodularity. Say that $F$ is $\\varepsilon$-approximately submodular if there exists a submodular function $f$ such that $(1-\\varepsilon)f(S) \\leq F(S)\\leq (1+\\varepsilon)f(S)$ for all subsets $S$. We are interested in characterizing the query-complexity of maximizing $F$ subject to a cardinality constraint $k$ as a function of the error level $\\varepsilon>0$. We provide both lower and upper bounds: for $\\varepsilon>n^{-1/2}$ we show an exponential query-complexity lower bound. In contrast, when $\\varepsilon< {1}/{k}$ or under a stronger bounded curvature assumption, we give constant approximation algorithms.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "comment": "12 pages"
    },
    {
        "paper id": "2411.10952",
        "abstract url": "https://arxiv.org/abs/2411.10952",
        "title": "To Adopt or Not to Adopt L4S-compatible Congestion Control? Understanding Performance in a Partial L4S Deployment",
        "rating": "-10",
        "keywords": [],
        "abstract": "With few exceptions, the path to deployment for any Internet technology requires that there be some benefit to unilateral adoption of the new technology. In an Internet where the technology is not fully deployed, is an individual better off sticking to the status quo, or adopting the new technology? This question is especially relevant in the context of the Low Latency, Low Loss, Scalable Throughput (L4S) architecture, where the full benefit is realized only when compatible protocols (scalable congestion control, accurate ECN, and flow isolation at queues) are adopted at both endpoints of a connection and also at the bottleneck router. In this paper, we consider the perspective of the sender of an L4S flow using scalable congestion control, without knowing whether the bottleneck router uses an L4S queue, or whether other flows sharing the bottleneck queue are also using scalable congestion control. We show that whether the sender uses TCP Prague or BBRv2 as the scalable congestion control, it cannot be assured that it will not harm or be harmed by another flow sharing the bottleneck link. We further show that the harm is not necessarily mitigated when a scalable flow shares a bottleneck with multiple classic flows. Finally, we evaluate the approach of BBRv3, where scalable congestion control is used only when the path delay is small, and ECN feedback is ignored otherwise, and we show that it is not effective for coexistence in this scenario.",
        "subjects": [
            "cs.NI"
        ],
        "comment": "Accepted to Passive and Active Measurement (PAM) International Conference, 2025"
    },
    {
        "paper id": "2411.12583",
        "abstract url": "https://arxiv.org/abs/2411.12583",
        "title": "Examem: Low-Overhead Memory Instrumentation for Intelligent Memory Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "Memory performance is often the main bottleneck in modern computing systems. In recent years, researchers have attempted to scale the memory wall by leveraging new technology such as CXL, HBM, and in- and near-memory processing. Developers optimizing for such hardware need to understand how target applications perform to fully take advantage of these systems. Existing software and hardware performance introspection techniques are ill-suited for this purpose due to one or more of the following factors: coarse-grained measurement, inability to offer data needed to debug key issues, high runtime overhead, and hardware dependence. The heightened integration between compute and memory in many proposed systems offers an opportunity to extend compiler support for this purpose. We have developed Examem, a memory performance introspection framework based on the LLVM compiler infrastructure. Examem supports developer annotated regions in code, allowing for targeted instrumentation of kernels. Examem supports hardware performance counters when available, in addition to software instrumentation. It statically records information about the instruction mix of the code and adds dynamic instrumentation to produce estimated memory bandwidth for an instrumented region at runtime. This combined approach keeps runtime overhead low while remaining accurate, with a geomean overhead under 10% and a geomean byte accuracy of 93%. Finally, our instrumentation is performed using an LLVM IR pass, which is target agnostic, and we have applied it to four ISAs.",
        "subjects": [
            "cs.PF",
            "cs.AR"
        ],
        "comment": "11 pages + references, 13 figures"
    }
]