[
    {
        "paper id": "2412.04925",
        "abstract url": "https://arxiv.org/abs/2412.04925",
        "title": "$S^3$: Synonymous Semantic Space for Improving Zero-Shot Generalization of Vision-Language Models",
        "rating": "2",
        "keywords": [
            [
                "Vision-Language"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recently, many studies have been conducted to enhance the zero-shot generalization ability of vision-language models (e.g., CLIP) by addressing the semantic misalignment between image and text embeddings in downstream tasks. Although many efforts have been made, existing methods barely consider the fact that a class of images can be described by notably different textual concepts due to well-known lexical variation in natural language processing, which heavily affects the zero-shot generalization of CLIP. Therefore, this paper proposes a \\textbf{S}ynonymous \\textbf{S}emantic \\textbf{S}pace ($S^3$) for each image class, rather than relying on a single textual concept, achieving more stable semantic alignment and improving the zero-shot generalization of CLIP. Specifically, our $S^3$ method first generates several synonymous concepts based on the label of each class by using large language models, and constructs a continuous yet compact synonymous semantic space based on the Vietoris-Rips complex of the generated synonymous concepts. Furthermore, we explore the effect of several point-to-space metrics on our $S^3$, while presenting a point-to-local-center metric to compute similarity between image embeddings and the synonymous semantic space of each class, accomplishing effective zero-shot predictions. Extensive experiments are conducted across 17 benchmarks, including fine-grained zero-shot classification, natural distribution zero-shot classification, and open-vocabulary segmentation, and the results show that our $S^3$ outperforms state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04975",
        "abstract url": "https://arxiv.org/abs/2412.04975",
        "title": "PETapter: Leveraging PET-style classification heads for modular few-shot parameter-efficient fine-tuning",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "PEFT",
                "efficient fine-tuning"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Few-shot learning and parameter-efficient fine-tuning (PEFT) are crucial to overcome the challenges of data scarcity and ever growing language model sizes. This applies in particular to specialized scientific domains, where researchers might lack expertise and resources to fine-tune high-performing language models to nuanced tasks. We propose PETapter, a novel method that effectively combines PEFT methods with PET-style classification heads to boost few-shot learning capabilities without the significant computational overhead typically associated with full model training. We validate our approach on three established NLP benchmark datasets and one real-world dataset from communication research. We show that PETapter not only achieves comparable performance to full few-shot fine-tuning using pattern-exploiting training (PET), but also provides greater reliability and higher parameter efficiency while enabling higher modularity and easy sharing of the trained modules, which enables more researchers to utilize high-performing NLP-methods in their research.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05184",
        "abstract url": "https://arxiv.org/abs/2412.05184",
        "title": "QueEn: A Large Language Model for Quechua-English Translation",
        "rating": "2",
        "keywords": [
            [
                "parameter-efficient",
                "efficient fine-tuning"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Recent studies show that large language models (LLMs) are powerful tools for working with natural language, bringing advances in many areas of computational linguistics. However, these models face challenges when applied to low-resource languages due to limited training data and difficulty in understanding cultural nuances. In this paper, we propose QueEn, a novel approach for Quechua-English translation that combines Retrieval-Augmented Generation (RAG) with parameter-efficient fine-tuning techniques. Our method leverages external linguistic resources through RAG and uses Low-Rank Adaptation (LoRA) for efficient model adaptation. Experimental results show that our approach substantially exceeds baseline models, with a BLEU score of 17.6 compared to 1.5 for standard GPT models. The integration of RAG with fine-tuning allows our system to address the challenges of low-resource language translation while maintaining computational efficiency. This work contributes to the broader goal of preserving endangered languages through advanced language technologies.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05185",
        "abstract url": "https://arxiv.org/abs/2412.05185",
        "title": "LinVT: Empower Your Image-level Large Language Model to Understand Videos",
        "rating": "2",
        "keywords": [
            [
                "visual-language"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have been widely used in various tasks, motivating us to develop an LLM-based assistant for videos. Instead of training from scratch, we propose a module to transform arbitrary well-trained image-based LLMs into video-LLMs (after being trained on video data). To better adapt image-LLMs for processing videos, we introduce two design principles: linear transformation to preserve the original visual-language alignment and representative information condensation from redundant video content. Guided by these principles, we propose a plug-and-play Linear Video Tokenizer(LinVT), which enables existing image-LLMs to understand videos. We benchmark LinVT with six recent visual LLMs: Aquila, Blip-3, InternVL2, Mipha, Molmo and Qwen2-VL, showcasing the high compatibility of LinVT. LinVT-based LLMs achieve state-of-the-art performance across various video benchmarks, illustrating the effectiveness of LinVT in multi-modal video understanding.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05243",
        "abstract url": "https://arxiv.org/abs/2412.05243",
        "title": "CompCap: Improving Multimodal Large Language Models with Composite Captions",
        "rating": "2",
        "keywords": [
            [
                "vision-language"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "How well can Multimodal Large Language Models (MLLMs) understand composite images? Composite images (CIs) are synthetic visuals created by merging multiple visual elements, such as charts, posters, or screenshots, rather than being captured directly by a camera. While CIs are prevalent in real-world applications, recent MLLM developments have primarily focused on interpreting natural images (NIs). Our research reveals that current MLLMs face significant challenges in accurately understanding CIs, often struggling to extract information or perform complex reasoning based on these images. We find that existing training data for CIs are mostly formatted for question-answer tasks (e.g., in datasets like ChartQA and ScienceQA), while high-quality image-caption datasets, critical for robust vision-language alignment, are only available for NIs. To bridge this gap, we introduce Composite Captions (CompCap), a flexible framework that leverages Large Language Models (LLMs) and automation tools to synthesize CIs with accurate and detailed captions. Using CompCap, we curate CompCap-118K, a dataset containing 118K image-caption pairs across six CI types. We validate the effectiveness of CompCap-118K by supervised fine-tuning MLLMs of three sizes: xGen-MM-inst.-4B and LLaVA-NeXT-Vicuna-7B/13B. Empirical results show that CompCap-118K significantly enhances MLLMs' understanding of CIs, yielding average gains of 1.7%, 2.0%, and 2.9% across eleven benchmarks, respectively.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04786",
        "abstract url": "https://arxiv.org/abs/2412.04786",
        "title": "Slicing Vision Transformer for Flexible Inference",
        "rating": "1.5",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Vision Transformers (ViT) is known for its scalability. In this work, we target to scale down a ViT to fit in an environment with dynamic-changing resource constraints. We observe that smaller ViTs are intrinsically the sub-networks of a larger ViT with different widths. Thus, we propose a general framework, named Scala, to enable a single network to represent multiple smaller ViTs with flexible inference capability, which aligns with the inherent design of ViT to vary from widths. Concretely, Scala activates several subnets during training, introduces Isolated Activation to disentangle the smallest sub-network from other subnets, and leverages Scale Coordination to ensure each sub-network receives simplified, steady, and accurate learning objectives. Comprehensive empirical validations on different tasks demonstrate that with only one-shot training, Scala learns slimmable representation without modifying the original ViT structure and matches the performance of Separate Training. Compared with the prior art, Scala achieves an average improvement of 1.6% on ImageNet-1K with fewer parameters.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Accepted by NeurIPS 2024"
    },
    {
        "paper id": "2412.04915",
        "abstract url": "https://arxiv.org/abs/2412.04915",
        "title": "Beyond Boxes: Mask-Guided Spatio-Temporal Feature Aggregation for Video Object Detection",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "The primary challenge in Video Object Detection (VOD) is effectively exploiting temporal information to enhance object representations. Traditional strategies, such as aggregating region proposals, often suffer from feature variance due to the inclusion of background information. We introduce a novel instance mask-based feature aggregation approach, significantly refining this process and deepening the understanding of object dynamics across video frames. We present FAIM, a new VOD method that enhances temporal Feature Aggregation by leveraging Instance Mask features. In particular, we propose the lightweight Instance Feature Extraction Module (IFEM) to learn instance mask features and the Temporal Instance Classification Aggregation Module (TICAM) to aggregate instance mask and classification features across video frames. Using YOLOX as a base detector, FAIM achieves 87.9% mAP on the ImageNet VID dataset at 33 FPS on a single 2080Ti GPU, setting a new benchmark for the speed-accuracy trade-off. Additional experiments on multiple datasets validate that our approach is robust, method-agnostic, and effective in multi-object tracking, demonstrating its broader applicability to video understanding tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "To appear in WACV 2025"
    },
    {
        "paper id": "2412.05203",
        "abstract url": "https://arxiv.org/abs/2412.05203",
        "title": "Archaeoscape: Bringing Aerial Laser Scanning Archaeology to the Deep Learning Era",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Airborne Laser Scanning (ALS) technology has transformed modern archaeology by unveiling hidden landscapes beneath dense vegetation. However, the lack of expert-annotated, open-access resources has hindered the analysis of ALS data using advanced deep learning techniques. We address this limitation with Archaeoscape (available at https://archaeoscape.ai), a novel large-scale archaeological ALS dataset spanning 888 km$^2$ in Cambodia with 31,141 annotated archaeological features from the Angkorian period. Archaeoscape is over four times larger than comparable datasets, and the first ALS archaeology resource with open-access data, annotations, and models. We benchmark several recent segmentation models to demonstrate the benefits of modern vision techniques for this problem and highlight the unique challenges of discovering subtle human-made structures under dense jungle canopies. By making Archaeoscape available in open access, we hope to bridge the gap between traditional archaeology and modern computer vision methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "NeurIPS 2023 - Datasets & Benchmarks Track"
    },
    {
        "paper id": "2412.05270",
        "abstract url": "https://arxiv.org/abs/2412.05270",
        "title": "APOLLO: SGD-like Memory, AdamW-level Performance",
        "rating": "1.5",
        "keywords": [
            [
                "memory-efficient"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Large language models (LLMs) are notoriously memory-intensive during training, particularly with the popular AdamW optimizer. This memory burden necessitates using more or higher-end GPUs or reducing batch sizes, limiting training scalability and throughput. To address this, various memory-efficient optimizers have been proposed to reduce optimizer memory usage. However, they face critical challenges: (i) reliance on costly SVD operations; (ii) significant performance trade-offs compared to AdamW; and (iii) still substantial optimizer memory overhead to maintain competitive performance. In this work, we identify that AdamW's learning rate adaptation rule can be effectively coarsened as a structured learning rate update. Based on this insight, we propose Approximated Gradient Scaling for Memory-Efficient LLM Optimization (APOLLO), which approximates learning rate scaling using an auxiliary low-rank optimizer state based on pure random projection. This structured learning rate update rule makes APOLLO highly tolerant to further memory reductions while delivering comparable pre-training performance. Even its rank-1 variant, APOLLO-Mini, achieves superior pre-training performance compared to AdamW with SGD-level memory costs. Extensive experiments demonstrate that the APOLLO series performs on-par with or better than AdamW, while achieving greater memory savings by nearly eliminating the optimization states of AdamW. These savings provide significant system-level benefits: (1) Enhanced Throughput: 3x throughput on an 8xA100-80GB setup compared to AdamW by supporting 4x larger batch sizes. (2) Improved Model Scalability: Pre-training LLaMA-13B with naive DDP on A100-80GB GPUs without system-level optimizations. (3) Low-End GPU Friendly Pre-training: Pre-training LLaMA-7B on a single GPU using less than 12 GB of memory with weight quantization.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.PF"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2412.05388",
        "abstract url": "https://arxiv.org/abs/2412.05388",
        "title": "CALICO: Conversational Agent Localization via Synthetic Data Generation",
        "rating": "1.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "We present CALICO, a method to fine-tune Large Language Models (LLMs) to localize conversational agent training data from one language to another. For slots (named entities), CALICO supports three operations: verbatim copy, literal translation, and localization, i.e. generating slot values more appropriate in the target language, such as city and airport names located in countries where the language is spoken. Furthermore, we design an iterative filtering mechanism to discard noisy generated samples, which we show boosts the performance of the downstream conversational agent. To prove the effectiveness of CALICO, we build and release a new human-localized (HL) version of the MultiATIS++ travel information test set in 8 languages. Compared to the original human-translated (HT) version of the test set, we show that our new HL version is more challenging. We also show that CALICO out-performs state-of-the-art LINGUIST (which relies on literal slot translation out of context) both on the HT case, where CALICO generates more accurate slot translations, and on the HL case, where CALICO generates localized slots which are closer to the HL test set.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Accepted to The 37th International Conference on Neural Information Processing Systems (NeurIPS 2023) December 10-16, 2023 - SyntheticData4ML Workshop, New Orleans, United States https://neurips.cc/virtual/2023/workshop/66540"
    },
    {
        "paper id": "2412.05460",
        "abstract url": "https://arxiv.org/abs/2412.05460",
        "title": "CigTime: Corrective Instruction Generation Through Inverse Motion Editing",
        "rating": "1.5",
        "keywords": [
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Recent advancements in models linking natural language with human motions have shown significant promise in motion generation and editing based on instructional text. Motivated by applications in sports coaching and motor skill learning, we investigate the inverse problem: generating corrective instructional text, leveraging motion editing and generation models. We introduce a novel approach that, given a user's current motion (source) and the desired motion (target), generates text instructions to guide the user towards achieving the target motion. We leverage large language models to generate corrective texts and utilize existing motion generation and editing frameworks to compile datasets of triplets (source motion, target motion, and corrective text). Using this data, we propose a new motion-language model for generating corrective instructions. We present both qualitative and quantitative results across a diverse range of applications that largely improve upon baselines. Our approach demonstrates its effectiveness in instructional scenarios, offering text-based guidance to correct and enhance user performance.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "20 pages, 8 figures, NeurIPS 2024"
    },
    {
        "paper id": "2412.04783",
        "abstract url": "https://arxiv.org/abs/2412.04783",
        "title": "KNN-MMD: Cross Domain Wi-Fi Sensing Based on Local Distribution Alignment",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "As a key technology in Integrated Sensing and Communications (ISAC), Wi-Fi sensing has gained widespread application in various settings such as homes, offices, and public spaces. By analyzing the patterns of Channel State Information (CSI), we can obtain information about people's actions for tasks like person identification, gesture recognition, and fall detection. However, the CSI is heavily influenced by the environment, such that even minor environmental changes can significantly alter the CSI patterns. This will cause the performance deterioration and even failure when applying the Wi-Fi sensing model trained in one environment to another. To address this problem, we introduce a K-Nearest Neighbors Maximum Mean Discrepancy (KNN-MMD) model, a few-shot method for cross-domain Wi-Fi sensing. We propose a local distribution alignment method within each category, which outperforms traditional Domain Adaptation (DA) methods based on global alignment. Besides, our method can determine when to stop training, which cannot be realized by most DA methods. As a result, our method is more stable and can be better used in practice. The effectiveness of our method are evaluated in several cross-domain Wi-Fi sensing tasks, including gesture recognition, person identification, fall detection, and action recognition, using both a public dataset and a self-collected dataset. In one-shot scenario, our method achieves accuracy of 93.26%, 81.84%, 77.62%, and 75.30% in the four tasks respectively. To facilitate future research, we will make our code and dataset publicly available upon publication.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04787",
        "abstract url": "https://arxiv.org/abs/2412.04787",
        "title": "Direct Quantized Training of Language Models with Stochastic Rounding",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Although recent quantized Large Language Models (LLMs), such as BitNet, have paved the way for significant reduction in memory usage during deployment with binary or ternary weights, training these models still demands substantial memory footprints. This is partly because high-precision (i.e., unquantized) weight matrices required for straight-through estimation must be maintained throughout the whole training process. To address this, we explore the potential of directly updating the quantized low-precision weight matrices without relying on the straight-through estimator during backpropagation, thereby saving memory usage during training. Specifically, we employ a stochastic rounding technique to minimize information loss caused by the use of low-bit weights throughout training. Experimental results on our LLaMA-structured models indicate that (1) training with only low-precision weights is feasible even when they are constrained to ternary values, (2) extending the bit width to 8 bits results in only a 5% loss degradation compared to BitNet b1.58 while offering the potential for reduced memory usage during training, and (3) our models can also perform inference using ternary weights, showcasing their flexibility in deployment.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "comment": "work in progress"
    },
    {
        "paper id": "2412.04826",
        "abstract url": "https://arxiv.org/abs/2412.04826",
        "title": "Pushing Rendering Boundaries: Hard Gaussian Splatting",
        "rating": "1",
        "keywords": [
            [
                "time efficiency"
            ],
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting (3DGS) has demonstrated impressive Novel View Synthesis (NVS) results in a real-time rendering manner. During training, it relies heavily on the average magnitude of view-space positional gradients to grow Gaussians to reduce rendering loss. However, this average operation smooths the positional gradients from different viewpoints and rendering errors from different pixels, hindering the growth and optimization of many defective Gaussians. This leads to strong spurious artifacts in some areas. To address this problem, we propose Hard Gaussian Splatting, dubbed HGS, which considers multi-view significant positional gradients and rendering errors to grow hard Gaussians that fill the gaps of classical Gaussian Splatting on 3D scenes, thus achieving superior NVS results. In detail, we present positional gradient driven HGS, which leverages multi-view significant positional gradients to uncover hard Gaussians. Moreover, we propose rendering error guided HGS, which identifies noticeable pixel rendering errors and potentially over-large Gaussians to jointly mine hard Gaussians. By growing and optimizing these hard Gaussians, our method helps to resolve blurring and needle-like artifacts. Experiments on various datasets demonstrate that our method achieves state-of-the-art rendering quality while maintaining real-time efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04836",
        "abstract url": "https://arxiv.org/abs/2412.04836",
        "title": "Adaptive Dropout for Pruning Conformers",
        "rating": "1",
        "keywords": [
            [
                "cs.CL",
                "eess.AS"
            ]
        ],
        "abstract": "This paper proposes a method to effectively perform joint training-and-pruning based on adaptive dropout layers with unit-wise retention probabilities. The proposed method is based on the estimation of a unit-wise retention probability in a dropout layer. A unit that is estimated to have a small retention probability can be considered to be prunable. The retention probability of the unit is estimated using back-propagation and the Gumbel-Softmax technique. This pruning method is applied at several application points in Conformers such that the effective number of parameters can be significantly reduced. Specifically, adaptive dropout layers are introduced in three locations in each Conformer block: (a) the hidden layer of the feed-forward-net component, (b) the query vectors and the value vectors of the self-attention component, and (c) the input vectors of the LConv component. The proposed method is evaluated by conducting a speech recognition experiment on the LibriSpeech task. It was shown that this approach could simultaneously achieve a parameter reduction and accuracy improvement. The word error rates improved by approx 1% while reducing the number of parameters by 54%.",
        "subjects": [
            "cs.CL",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04857",
        "abstract url": "https://arxiv.org/abs/2412.04857",
        "title": "Neuro-Symbolic Data Generation for Math Reasoning",
        "rating": "1",
        "keywords": [
            [
                "cs.AI"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "A critical question about Large Language Models (LLMs) is whether their apparent deficiency in mathematical reasoning is inherent, or merely a result of insufficient exposure to high-quality mathematical data. To explore this, we developed an automated method for generating high-quality, supervised mathematical datasets. The method carefully mutates existing math problems, ensuring both diversity and validity of the newly generated problems. This is achieved by a neuro-symbolic data generation framework combining the intuitive informalization strengths of LLMs, and the precise symbolic reasoning of math solvers along with projected Markov chain Monte Carlo sampling in the highly-irregular symbolic space. Empirical experiments demonstrate the high quality of data generated by the proposed method, and that the LLMs, specifically LLaMA-2 and Mistral, when realigned with the generated data, surpass their state-of-the-art counterparts.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Published as a conference paper at NeurIPS 2024"
    },
    {
        "paper id": "2412.04859",
        "abstract url": "https://arxiv.org/abs/2412.04859",
        "title": "Breaking Event Rumor Detection via Stance-Separated Multi-Agent Debate",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The rapid spread of rumors on social media platforms during breaking events severely hinders the dissemination of the truth. Previous studies reveal that the lack of annotated resources hinders the direct detection of unforeseen breaking events not covered in yesterday's news. Leveraging large language models (LLMs) for rumor detection holds significant promise. However, it is challenging for LLMs to provide comprehensive responses to complex or controversial issues due to limited diversity. In this work, we propose the Stance Separated Multi-Agent Debate (S2MAD) to address this issue. Specifically, we firstly introduce Stance Separation, categorizing comments as either supporting or opposing the original claim. Subsequently, claims are classified as subjective or objective, enabling agents to generate reasonable initial viewpoints with different prompt strategies for each type of claim. Debaters then follow specific instructions through multiple rounds of debate to reach a consensus. If a consensus is not reached, a judge agent evaluates the opinions and delivers a final verdict on the claim's veracity. Extensive experiments conducted on two real-world datasets demonstrate that our proposed model outperforms state-of-the-art methods in terms of performance and effectively improves the performance of LLMs in breaking event rumor detection.",
        "subjects": [
            "cs.CL",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04862",
        "abstract url": "https://arxiv.org/abs/2412.04862",
        "title": "EXAONE 3.5: Series of Large Language Models for Real-world Use Cases",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "This technical report introduces the EXAONE 3.5 instruction-tuned language models, developed and released by LG AI Research. The EXAONE 3.5 language models are offered in three configurations: 32B, 7.8B, and 2.4B. These models feature several standout capabilities: 1) exceptional instruction following capabilities in real-world scenarios, achieving the highest scores across seven benchmarks, 2) outstanding long-context comprehension, attaining the top performance in four benchmarks, and 3) competitive results compared to state-of-the-art open models of similar sizes across nine general benchmarks. The EXAONE 3.5 language models are open to anyone for research purposes and can be downloaded from https://huggingface.co/LGAI-EXAONE. For commercial use, please reach out to the official contact point of LG AI Research: contact_us@lgresearch.ai.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "arXiv admin note: text overlap with arXiv:2408.03541"
    },
    {
        "paper id": "2412.04898",
        "abstract url": "https://arxiv.org/abs/2412.04898",
        "title": "Mitigating Instance-Dependent Label Noise: Integrating Self-Supervised Pretraining with Pseudo-Label Refinement",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning models rely heavily on large volumes of labeled data to achieve high performance. However, real-world datasets often contain noisy labels due to human error, ambiguity, or resource constraints during the annotation process. Instance-dependent label noise (IDN), where the probability of a label being corrupted depends on the input features, poses a significant challenge because it is more prevalent and harder to address than instance-independent noise. In this paper, we propose a novel hybrid framework that combines self-supervised learning using SimCLR with iterative pseudo-label refinement to mitigate the effects of IDN. The self-supervised pre-training phase enables the model to learn robust feature representations without relying on potentially noisy labels, establishing a noise-agnostic foundation. Subsequently, we employ an iterative training process with pseudo-label refinement, where confidently predicted samples are identified through a multistage approach and their labels are updated to improve label quality progressively. We evaluate our method on the CIFAR-10 and CIFAR-100 datasets augmented with synthetic instance-dependent noise at varying noise levels. Experimental results demonstrate that our approach significantly outperforms several state-of-the-art methods, particularly under high noise conditions, achieving notable improvements in classification accuracy and robustness. Our findings suggest that integrating self-supervised learning with iterative pseudo-label refinement offers an effective strategy for training deep neural networks on noisy datasets afflicted by instance-dependent label noise.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04903",
        "abstract url": "https://arxiv.org/abs/2412.04903",
        "title": "EACO: Enhancing Alignment in Multimodal LLMs via Critical Observation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Multimodal large language models (MLLMs) have achieved remarkable progress on various visual question answering and reasoning tasks leveraging instruction fine-tuning specific datasets. They can also learn from preference data annotated by human to enhance their reasoning ability and mitigate hallucinations. Most of preference data is generated from the model itself. However, existing methods require high-quality critical labels, which are costly and rely on human or proprietary models like GPT-4V. In this work, we propose Enhancing Alignment in MLLMs via Critical Observation (EACO), which aligns MLLMs by self-generated preference data using only 5k images economically. Our approach begins with collecting and refining a Scoring Evaluation Instruction-tuning dataset to train a critical evaluation model, termed the Critic. This Critic observes model responses across multiple dimensions, selecting preferred and non-preferred outputs for refined Direct Preference Optimization (DPO) tuning. To further enhance model performance, we employ an additional supervised fine-tuning stage after preference tuning. EACO reduces the overall hallucinations by 65.6% on HallusionBench and improves the reasoning ability by 21.8% on MME-Cognition. EACO achieves an 8.5% improvement over LLaVA-v1.6-Mistral-7B across multiple benchmarks. Remarkably, EACO also shows the potential critical ability in open-source MLLMs, demonstrating that EACO is a viable path to boost the competence of MLLMs.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "19 pages"
    },
    {
        "paper id": "2412.04905",
        "abstract url": "https://arxiv.org/abs/2412.04905",
        "title": "DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Large language models (LLMs) have made dialogue one of the central modes of human-machine interaction, leading to the accumulation of vast amounts of conversation logs and increasing demand for dialogue generation. A conversational life-cycle spans from the Prelude through the Interlocution to the Epilogue, encompassing various elements. Despite the existence of numerous dialogue-related studies, there is a lack of benchmarks that encompass comprehensive dialogue elements, hindering precise modeling and systematic evaluation. To bridge this gap, we introduce an innovative research task $\\textbf{D}$ialogue $\\textbf{E}$lement $\\textbf{MO}$deling, including $\\textit{Element Awareness}$ and $\\textit{Dialogue Agent Interaction}$, and propose a novel benchmark, $\\textbf{DEMO}$, designed for a comprehensive dialogue modeling and assessment. Inspired by imitation learning, we further build the agent which possesses the adept ability to model dialogue elements based on the DEMO benchmark. Extensive experiments indicate that existing LLMs still exhibit considerable potential for enhancement, and our DEMO agent has superior performance in both in-domain and out-of-domain tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "We release the code and data at https://github.com/MozerWang/DEMO"
    },
    {
        "paper id": "2412.04917",
        "abstract url": "https://arxiv.org/abs/2412.04917",
        "title": "Continuous Speech Tokens Makes LLMs Robust Multi-Modality Learners",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Recent advances in GPT-4o like multi-modality models have demonstrated remarkable progress for direct speech-to-speech conversation, with real-time speech interaction experience and strong speech understanding ability. However, current research focuses on discrete speech tokens to align with discrete text tokens for language modelling, which depends on an audio codec with residual connections or independent group tokens, such a codec usually leverages large scale and diverse datasets training to ensure that the discrete speech codes have good representation for varied domain, noise, style data reconstruction as well as a well-designed codec quantizer and encoder-decoder architecture for discrete token language modelling. This paper introduces Flow-Omni, a continuous speech token based GPT-4o like model, capable of real-time speech interaction and low streaming latency. Specifically, first, instead of cross-entropy loss only, we combine flow matching loss with a pretrained autoregressive LLM and a small MLP network to predict the probability distribution of the continuous-valued speech tokens from speech prompt. second, we incorporated the continuous speech tokens to Flow-Omni multi-modality training, thereby achieving robust speech-to-speech performance with discrete text tokens and continuous speech tokens together. Experiments demonstrate that, compared to discrete text and speech multi-modality training and its variants, the continuous speech tokens mitigate robustness issues by avoiding the inherent flaws of discrete speech code's representation loss for LLM.",
        "subjects": [
            "cs.SD",
            "eess.AS",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04922",
        "abstract url": "https://arxiv.org/abs/2412.04922",
        "title": "Large Language Models for Ingredient Substitution in Food Recipes using Supervised Fine-tuning and Direct Preference Optimization",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "In this paper, we address the challenge of recipe personalization through ingredient substitution. We make use of Large Language Models (LLMs) to build an ingredient substitution system designed to predict plausible substitute ingredients within a given recipe context. Given that the use of LLMs for this task has been barely done, we carry out an extensive set of experiments to determine the best LLM, prompt, and the fine-tuning setups. We further experiment with methods such as multi-task learning, two-stage fine-tuning, and Direct Preference Optimization (DPO). The experiments are conducted using the publicly available Recipe1MSub corpus. The best results are produced by the Mistral7-Base LLM after fine-tuning and DPO. This result outperforms the strong baseline available for the same corpus with a Hit@1 score of 22.04. Thus we believe that this research represents a significant step towards enabling personalized and creative culinary experiences by utilizing LLM-based ingredient substitution.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04937",
        "abstract url": "https://arxiv.org/abs/2412.04937",
        "title": "Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Multi-agent systems utilizing large language models (LLMs) have shown great promise in achieving natural dialogue. However, smooth dialogue control and autonomous decision making among agents still remain challenges. In this study, we focus on conversational norms such as adjacency pairs and turn-taking found in conversation analysis and propose a new framework called \"Murder Mystery Agents\" that applies these norms to AI agents' dialogue control. As an evaluation target, we employed the \"Murder Mystery\" game, a reasoning-type table-top role-playing game that requires complex social reasoning and information manipulation. In this game, players need to unravel the truth of the case based on fragmentary information through cooperation and bargaining. The proposed framework integrates next speaker selection based on adjacency pairs and a self-selection mechanism that takes agents' internal states into account to achieve more natural and strategic dialogue. To verify the effectiveness of this new approach, we analyzed utterances that led to dialogue breakdowns and conducted automatic evaluation using LLMs, as well as human evaluation using evaluation criteria developed for the Murder Mystery game. Experimental results showed that the implementation of the next speaker selection mechanism significantly reduced dialogue breakdowns and improved the ability of agents to share information and perform logical reasoning. The results of this study demonstrate that the systematics of turn-taking in human conversation are also effective in controlling dialogue among AI agents, and provide design guidelines for more advanced multi-agent dialogue systems.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04939",
        "abstract url": "https://arxiv.org/abs/2412.04939",
        "title": "Verb Mirage: Unveiling and Assessing Verb Concept Hallucinations in Multimodal Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Multimodal Large Language Models (MLLMs) have garnered significant attention recently and demonstrate outstanding capabilities in various tasks such as OCR, VQA, captioning, $\\textit{etc}$. However, hallucination remains a persistent issue. While numerous methods have been proposed to mitigate hallucinations, achieving notable improvements, these methods primarily focus on mitigating hallucinations about $\\textbf{object/noun-related}$ concepts. Verb concepts, crucial for understanding human actions, have been largely overlooked. In this paper, to the best of our knowledge, we are the $\\textbf{first}$ to investigate the $\\textbf{verb hallucination}$ phenomenon of MLLMs from various perspectives. Our findings reveal that most state-of-the-art MLLMs suffer from severe verb hallucination. To assess the effectiveness of existing mitigation methods for object concept hallucination on verb hallucination, we evaluated these methods and found that they do not effectively address verb hallucination. To address this issue, we propose a novel rich verb knowledge-based tuning method to mitigate verb hallucination. The experiment results demonstrate that our method significantly reduces hallucinations related to verbs. $\\textit{Our code and data will be made publicly available}$.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04947",
        "abstract url": "https://arxiv.org/abs/2412.04947",
        "title": "C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Recent advances in large language models (LLMs) have shown significant promise, yet their evaluation raises concerns, particularly regarding data contamination due to the lack of access to proprietary training data. To address this issue, we present C$^2$LEVA, a comprehensive bilingual benchmark featuring systematic contamination prevention. C$^2$LEVA firstly offers a holistic evaluation encompassing 22 tasks, each targeting a specific application or ability of LLMs, and secondly a trustworthy assessment due to our contamination-free tasks, ensured by a systematic contamination prevention strategy that fully automates test data renewal and enforces data protection during benchmark data release. Our large-scale evaluation of 15 open-source and proprietary models demonstrates the effectiveness of C$^2$LEVA.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05012",
        "abstract url": "https://arxiv.org/abs/2412.05012",
        "title": "SAMCL: Empowering SAM to Continually Learn from Dynamic Domains",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Segment Anything Model (SAM) struggles with segmenting objects in the open world, especially across diverse and dynamic domains. Continual segmentation (CS) is a potential technique to solve this issue, but a significant obstacle is the intractable balance between previous domains (stability) and new domains (plasticity) during CS. Furthermore, how to utilize two kinds of features of SAM, images and prompts, in an efficient and effective CS manner remains a significant hurdle. In this work, we propose a novel CS method, termed SAMCL, to address these challenges. It is the first study to empower SAM with the CS ability across dynamic domains. SAMCL decouples stability and plasticity during CS by two components: $\\textit{AugModule}$ and $\\textit{Module Selector}$. Specifically, SAMCL leverages individual $\\textit{AugModule}$ to effectively and efficiently learn new relationships between images and prompts in each domain. $\\textit{Module Selector}$ selects the appropriate module during testing, based on the inherent ability of SAM to distinguish between different domains. These two components enable SAMCL to realize a task-agnostic method without any interference across different domains. Experimental results demonstrate that SAMCL outperforms state-of-the-art methods, achieving an exceptionally low average forgetting of just $0.5$%, along with at least a $2.5$% improvement in transferring to unseen domains. Moreover, the tunable parameter consumption in AugModule is about $0.236$MB, marking at least a $23.3$% reduction compared to other fine-tuning methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "14 pages, 11 figures"
    },
    {
        "paper id": "2412.05015",
        "abstract url": "https://arxiv.org/abs/2412.05015",
        "title": "Perceptually Transparent Binaural Auralization of Simulated Sound Fields",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Contrary to geometric acoustics-based simulations where the spatial information is available in a tangible form, it is not straightforward to auralize wave-based simulations. A variety of methods have been proposed that compute the ear signals of a virtual listener with known head-related transfer functions from sampling either the sound pressure or the particle velocity (or both) of the simulated sound field. The available perceptual evaluation results of such methods are not comprehensive so that it is unclear what number and arrangement of sampling points is required for achieving perceptually transparent auralization, i.e.~for achieving an auralization that is perceptually indistinguishable from the ground truth. This article presents a perceptual evaluation of the most common binaural auralization methods with and without intermediate ambisonic representation of volumetrically sampled sound pressure or sound pressure and particle velocity sampled on spherical or cubical surfaces. Our results confirm that perceptually transparent auralization is possible if sound pressure and particle velocity are available at 289 sampling points on a spherical surface grid. Other grid geometries require considerably more points. All tested methods are available open source in the Chalmers Auralization Toolbox that accompanies this article.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05035",
        "abstract url": "https://arxiv.org/abs/2412.05035",
        "title": "SMIC: Semantic Multi-Item Compression based on CLIP dictionary",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Semantic compression, a compression scheme where the distortion metric, typically MSE, is replaced with semantic fidelity metrics, tends to become more and more popular. Most recent semantic compression schemes rely on the foundation model CLIP. In this work, we extend such a scheme to image collection compression, where inter-item redundancy is taken into account during the coding phase. For that purpose, we first show that CLIP's latent space allows for easy semantic additions and subtractions. From this property, we define a dictionary-based multi-item codec that outperforms state-of-the-art generative codec in terms of compression rate, around $10^{-5}$ BPP per image, while not sacrificing semantic fidelity. We also show that the learned dictionary is of a semantic nature and works as a semantic projector for the semantic content of images.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.MM"
        ],
        "comment": "12 pages, 14 figures, 3 tables, journal paper, preprint"
    },
    {
        "paper id": "2412.05076",
        "abstract url": "https://arxiv.org/abs/2412.05076",
        "title": "Improving analytical color and texture similarity estimation methods for dataset-agnostic person reidentification",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper studies a combined person reidentification (re-id) method that uses human parsing, analytical feature extraction and similarity estimation schemes. One of its prominent features is its low computational requirements so it can be implemented on edge devices. The method allows direct comparison of specific image regions using interpretable features which consist of color and texture channels. It is proposed to analyze and compare colors in CIE-Lab color space using histogram smoothing for noise reduction. A novel pre-configured latent space (LS) supervised autoencoder (SAE) is proposed for texture analysis which encodes input textures as LS points. This allows to obtain more accurate similarity measures compared to simplistic label comparison. The proposed method also does not rely upon photos or other re-id data for training, which makes it completely re-id dataset-agnostic. The viability of the proposed method is verified by computing rank-1, rank-10, and mAP re-id metrics on Market1501 dataset. The results are comparable to those of conventional deep learning methods and the potential ways to further improve the method are discussed.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "8 pages, 2 figures, 3 tables, 3 equations"
    },
    {
        "paper id": "2412.05095",
        "abstract url": "https://arxiv.org/abs/2412.05095",
        "title": "SoPo: Text-to-Motion Generation Using Semi-Online Preference Optimization",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-motion generation is essential for advancing the creative industry but often presents challenges in producing consistent, realistic motions. To address this, we focus on fine-tuning text-to-motion models to consistently favor high-quality, human-preferred motions, a critical yet largely unexplored problem. In this work, we theoretically investigate the DPO under both online and offline settings, and reveal their respective limitation: overfitting in offline DPO, and biased sampling in online DPO. Building on our theoretical insights, we introduce Semi-online Preference Optimization (SoPo), a DPO-based method for training text-to-motion models using \"semi-online\" data pair, consisting of unpreferred motion from online distribution and preferred motion in offline datasets. This method leverages both online and offline DPO, allowing each to compensate for the other's limitations. Extensive experiments demonstrate that SoPo outperforms other preference alignment methods, with an MM-Dist of 3.25% (vs e.g. 0.76% of MoDiPO) on the MLD model, 2.91% (vs e.g. 0.66% of MoDiPO) on MDM model, respectively. Additionally, the MLD model fine-tuned by our SoPo surpasses the SoTA model in terms of R-precision and MM Dist. Visualization results also show the efficacy of our SoPo in preference alignment. Our project page is https://sopo-motion.github.io.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05123",
        "abstract url": "https://arxiv.org/abs/2412.05123",
        "title": "Applying Automatic Differentiation to Optimize Differential Microphone Array Designs",
        "rating": "1",
        "keywords": [
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "This paper introduces a novel methodology leveraging differentiable programming to design efficient, constrained adaptive non-uniform Linear Differential Microphone Arrays (LDMAs) with reduced implementation costs. Utilizing an automatic differentiation framework, we propose a differentiable convex approach that enables the adaptive design of a filter with a distortionless constraint in the desired sound direction, while also imposing constraints on microphone positioning to ensure consistent performance. This approach achieves the desired Directivity Factor (DF) over a wide frequency range and facilitates effective recovery of wide-band speech signals at lower implementation costs.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "comment": "6 pages, 9 figures"
    },
    {
        "paper id": "2412.05145",
        "abstract url": "https://arxiv.org/abs/2412.05145",
        "title": "Explingo: Explaining AI Predictions using Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Explanations of machine learning (ML) model predictions generated by Explainable AI (XAI) techniques such as SHAP are essential for people using ML outputs for decision-making. We explore the potential of Large Language Models (LLMs) to transform these explanations into human-readable, narrative formats that align with natural communication. We address two key research questions: (1) Can LLMs reliably transform traditional explanations into high-quality narratives? and (2) How can we effectively evaluate the quality of narrative explanations? To answer these questions, we introduce Explingo, which consists of two LLM-based subsystems, a Narrator and Grader. The Narrator takes in ML explanations and transforms them into natural-language descriptions. The Grader scores these narratives on a set of metrics including accuracy, completeness, fluency, and conciseness. Our experiments demonstrate that LLMs can generate high-quality narratives that achieve high scores across all metrics, particularly when guided by a small number of human-labeled and bootstrapped examples. We also identified areas that remain challenging, in particular for effectively scoring narratives in complex domains. The findings from this work have been integrated into an open-source tool that makes narrative explanations available for further applications.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "To be presented in the 2024 IEEE International Conference on Big Data (IEEE BigData)"
    },
    {
        "paper id": "2412.05148",
        "abstract url": "https://arxiv.org/abs/2412.05148",
        "title": "LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in image generation models have enabled personalized image creation with both user-defined subjects (content) and styles. Prior works achieved personalization by merging corresponding low-rank adaptation parameters (LoRAs) through optimization-based methods, which are computationally demanding and unsuitable for real-time use on resource-constrained devices like smartphones. To address this, we introduce LoRA$.$rar, a method that not only improves image quality but also achieves a remarkable speedup of over $4000\\times$ in the merging process. LoRA$.$rar pre-trains a hypernetwork on a diverse set of content-style LoRA pairs, learning an efficient merging strategy that generalizes to new, unseen content-style pairs, enabling fast, high-quality personalization. Moreover, we identify limitations in existing evaluation metrics for content-style quality and propose a new protocol using multimodal large language models (MLLM) for more accurate assessment. Our method significantly outperforms the current state of the art in both content and style fidelity, as validated by MLLM assessments and human evaluations.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "17 pages, 20 figures"
    },
    {
        "paper id": "2412.05155",
        "abstract url": "https://arxiv.org/abs/2412.05155",
        "title": "Multimodal Fact-Checking with Vision Language Models: A Probing Classifier based Solution with Embedding Strategies",
        "rating": "1",
        "keywords": [
            [
                "Vision Language",
                "VLMs"
            ],
            [
                "SVM"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study evaluates the effectiveness of Vision Language Models (VLMs) in representing and utilizing multimodal content for fact-checking. To be more specific, we investigate whether incorporating multimodal content improves performance compared to text-only models and how well VLMs utilize text and image information to enhance misinformation detection. Furthermore we propose a probing classifier based solution using VLMs. Our approach extracts embeddings from the last hidden layer of selected VLMs and inputs them into a neural probing classifier for multi-class veracity classification. Through a series of experiments on two fact-checking datasets, we demonstrate that while multimodality can enhance performance, fusing separate embeddings from text and image encoders yielded superior results compared to using VLM embeddings. Furthermore, the proposed neural classifier significantly outperformed KNN and SVM baselines in leveraging extracted embeddings, highlighting its effectiveness for multimodal fact-checking.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted to COLING2025"
    },
    {
        "paper id": "2412.05158",
        "abstract url": "https://arxiv.org/abs/2412.05158",
        "title": "Gaining Explainability from a CNN for Stereotype Detection Based on Mice Stopping Behavior",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Understanding the behavior of laboratory animals is a key to find answers about diseases and neurodevelopmental disorders that also affects humans. One behavior of interest is the stopping, as it correlates with exploration, feeding and sleeping habits of individuals. To improve comprehension of animal's behavior, we focus on identifying trait revealing age/sex of mice through the series of stopping spots of each individual. We track 4 mice using LiveMouseTracker (LMT) system during 3 days. Then, we build a stack of 2D histograms of the stop positions. This stack of histograms passes through a shallow CNN architecture to classify mice in terms of age and sex. We observe that female mice show more recognizable behavioral patterns, reaching a classification accuracy of more than 90%, while males, which do not present as many distinguishable patterns, reach an accuracy of 62.5%. To gain explainability from the model, we look at the activation function of the convolutional layers and found that some regions of the cage are preferentially explored by females. Males, especially juveniles, present behavior patterns that oscillate between juvenile female and adult male.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "to be published in VAIB - Visual observation and analysis of Vertebrate And Insect Behavior (ICPR) 2024"
    },
    {
        "paper id": "2412.05167",
        "abstract url": "https://arxiv.org/abs/2412.05167",
        "title": "Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "Large Audio-Language Models (LALMs) have unclocked audio dialogue capabilities, where audio dialogues are a direct exchange of spoken language between LALMs and humans. Recent advances, such as GPT-4o, have enabled LALMs in back-and-forth audio dialogues with humans. This progression not only underscores the potential of LALMs but also broadens their applicability across a wide range of practical scenarios supported by audio dialogues. However, given these advancements, a comprehensive benchmark to evaluate the performance of LALMs in the open-ended audio dialogue understanding remains absent currently. To address this gap, we propose an Audio Dialogue Understanding Benchmark (ADU-Bench), which consists of 4 benchmark datasets. They assess the open-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills, 9 multilingual languages, and 4 categories of ambiguity handling. Notably, we firstly propose the evaluation of ambiguity handling in audio dialogues that expresses different intentions beyond the same literal meaning of sentences, e.g., \"Really!?\" with different intonations. In summary, ADU-Bench includes over 20,000 open-ended audio dialogues for the assessment of LALMs. Through extensive experiments conducted on 13 LALMs, our analysis reveals that there is still considerable room for improvement in the audio dialogue understanding abilities of existing LALMs. In particular, they struggle with mathematical symbols and formulas, understanding human behavior such as roleplay, comprehending multiple languages, and handling audio dialogue ambiguities from different phonetic elements, such as intonations, pause positions, and homophones.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05179",
        "abstract url": "https://arxiv.org/abs/2412.05179",
        "title": "Spatially-Adaptive Hash Encodings For Neural Surface Reconstruction",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Positional encodings are a common component of neural scene reconstruction methods, and provide a way to bias the learning of neural fields towards coarser or finer representations. Current neural surface reconstruction methods use a \"one-size-fits-all\" approach to encoding, choosing a fixed set of encoding functions, and therefore bias, across all scenes. Current state-of-the-art surface reconstruction approaches leverage grid-based multi-resolution hash encoding in order to recover high-detail geometry. We propose a learned approach which allows the network to choose its encoding basis as a function of space, by masking the contribution of features stored at separate grid resolutions. The resulting spatially adaptive approach allows the network to fit a wider range of frequencies without introducing noise. We test our approach on standard benchmark surface reconstruction datasets and achieve state-of-the-art performance on two benchmark datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05180",
        "abstract url": "https://arxiv.org/abs/2412.05180",
        "title": "DreamColour: Controllable Video Colour Editing without Training",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "Video colour editing is a crucial task for content creation, yet existing solutions either require painstaking frame-by-frame manipulation or produce unrealistic results with temporal artefacts. We present a practical, training-free framework that makes precise video colour editing accessible through an intuitive interface while maintaining professional-quality output. Our key insight is that by decoupling spatial and temporal aspects of colour editing, we can better align with users' natural workflow -- allowing them to focus on precise colour selection in key frames before automatically propagating changes across time. We achieve this through a novel technical framework that combines: (i) a simple point-and-click interface merging grid-based colour selection with automatic instance segmentation for precise spatial control, (ii) bidirectional colour propagation that leverages inherent video motion patterns, and (iii) motion-aware blending that ensures smooth transitions even with complex object movements. Through extensive evaluation on diverse scenarios, we demonstrate that our approach matches or exceeds state-of-the-art methods while eliminating the need for training or specialized hardware, making professional-quality video colour editing accessible to everyone.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page available at https://chaitron.github.io/DreamColour-demo"
    },
    {
        "paper id": "2412.05206",
        "abstract url": "https://arxiv.org/abs/2412.05206",
        "title": "ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Computational argumentation, which involves generating answers or summaries for controversial topics like abortion bans and vaccination, has become increasingly important in today's polarized environment. Sophisticated LLM capabilities offer the potential to provide nuanced, evidence-based answers to such questions through Retrieval-Augmented Argumentation (RAArg), leveraging real-world evidence for high-quality, grounded arguments. However, evaluating RAArg remains challenging, as human evaluation is costly and difficult for complex, lengthy answers on complicated topics. At the same time, re-using existing argumentation datasets is no longer sufficient, as they lack long, complex arguments and realistic evidence from potentially misleading sources, limiting holistic evaluation of retrieval effectiveness and argument quality. To address these gaps, we investigate automated evaluation methods using multiple fine-grained LLM judges, providing better and more interpretable assessments than traditional single-score metrics and even previously reported human crowdsourcing. To validate the proposed techniques, we introduce ConQRet, a new benchmark featuring long and complex human-authored arguments on debated topics, grounded in real-world websites, allowing an exhaustive evaluation across retrieval effectiveness, argument quality, and groundedness. We validate our LLM Judges on a prior dataset and the new ConQRet benchmark. Our proposed LLM Judges and the ConQRet benchmark can enable rapid progress in computational argumentation and can be naturally extended to other complex retrieval-augmented generation tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05210",
        "abstract url": "https://arxiv.org/abs/2412.05210",
        "title": "Evaluating and Aligning CodeLLMs on Human Preference",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Code large language models (codeLLMs) have made significant strides in code generation. Most previous code-related benchmarks, which consist of various programming exercises along with the corresponding test cases, are used as a common measure to evaluate the performance and capabilities of code LLMs. However, the current code LLMs focus on synthesizing the correct code snippet, ignoring the alignment with human preferences, where the query should be sampled from the practical application scenarios and the model-generated responses should satisfy the human preference. To bridge the gap between the model-generated response and human preference, we present a rigorous human-curated benchmark CodeArena to emulate the complexity and diversity of real-world coding tasks, where 397 high-quality samples spanning 40 categories and 44 programming languages, carefully curated from user queries. Further, we propose a diverse synthetic instruction corpus SynCode-Instruct (nearly 20B tokens) by scaling instructions from the website to verify the effectiveness of the large-scale synthetic instruction fine-tuning, where Qwen2.5-SynCoder totally trained on synthetic instruction data can achieve top-tier performance of open-source code LLMs. The results find performance differences between execution-based benchmarks and CodeArena. Our systematic experiments of CodeArena on 40+ LLMs reveal a notable performance gap between open SOTA code LLMs (e.g. Qwen2.5-Coder) and proprietary LLMs (e.g., OpenAI o1), underscoring the importance of the human preference alignment.\\footnote{\\url{https://codearenaeval.github.io/ }}",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05216",
        "abstract url": "https://arxiv.org/abs/2412.05216",
        "title": "ColonNet: A Hybrid Of DenseNet121 And U-NET Model For Detection And Segmentation Of GI Bleeding",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "This study presents an integrated deep learning model for automatic detection and classification of Gastrointestinal bleeding in the frames extracted from Wireless Capsule Endoscopy (WCE) videos. The dataset has been released as part of Auto-WCBleedGen Challenge Version V2 hosted by the MISAHUB team. Our model attained the highest performance among 75 teams that took part in this competition. It aims to efficiently utilizes CNN based model i.e. DenseNet and UNet to detect and segment bleeding and non-bleeding areas in the real-world complex dataset. The model achieves an impressive overall accuracy of 80% which would surely help a skilled doctor to carry out further diagnostics.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05223",
        "abstract url": "https://arxiv.org/abs/2412.05223",
        "title": "100% Hallucination Elimination Using Acurai",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "The issue of hallucinations in large language models (LLMs) remains a critical barrier to the adoption of AI in enterprise and other high-stakes applications. Despite advancements in retrieval-augmented generation (RAG) systems, current state-of-the-art methods fail to achieve more than 80% accuracy in generating faithful and factually correct outputs, even when provided with relevant and accurate context. In this work, we introduce Acurai, a novel systematic approach that achieves 100% hallucination-free responses in LLMs by reformatting queries and context data prior to input. Leveraging a deep understanding of LLM internal representations, the importance of noun-phrase dominance, and the role of discrete functional units (DFUs), Acurai ensures alignment between input context and generated output. We validate this method using the RAGTruth corpus, demonstrating its ability to eliminate 100% hallucinations for both GPT-4 and GPT-3.5 Turbo. Acurai sets a new standard for achieving consistent, accurate, and faithful AI responses, marking a significant step forward in the development of trustworthy AI systems.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05225",
        "abstract url": "https://arxiv.org/abs/2412.05225",
        "title": "BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLMs) based on transformers achieve cutting-edge results on a variety of applications. However, their enormous size and processing requirements make deployment on devices with constrained resources extremely difficult. Among various efficiency considerations, model binarization and Early Exit (EE) are common effective solutions. However, binarization may lead to performance loss due to reduced precision affecting gradient estimation and parameter updates. Besides, the present early-exit mechanisms are still in the nascent stages of research. To ameliorate these issues, we propose Binarized Early Exit Transformer (BEExformer), the first-ever selective learning transformer architecture to combine early exit with binarization for textual inference. It improves the binarization process through a differentiable second-order approximation to the impulse function. This enables gradient computation concerning both the sign as well as the magnitude of the weights. In contrast to absolute threshold-based EE, the proposed EE mechanism hinges on fractional reduction in entropy among intermediate transformer blocks with soft-routing loss estimation. While binarization results in 18.44 times reduction in model size, early exit reduces the FLOPs during inference by 54.85% and even improves accuracy by 5.98% through resolving the \"overthinking\" problem inherent in deep networks. Moreover, the proposed BEExformer simplifies training by not requiring knowledge distillation from a full-precision LLM. Extensive evaluation on the GLUE dataset and comparison with the SOTA works showcase its pareto-optimal performance-efficiency trade-off.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.NE"
        ],
        "comment": "15 pages, 15 figures, 3 tables"
    },
    {
        "paper id": "2412.05237",
        "abstract url": "https://arxiv.org/abs/2412.05237",
        "title": "MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale",
        "rating": "1",
        "keywords": [
            [
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Open-source multimodal large language models (MLLMs) have shown significant potential in a broad range of multimodal tasks. However, their reasoning capabilities remain constrained by existing instruction-tuning datasets, which were predominately repurposed from academic datasets such as VQA, AI2D, and ChartQA. These datasets target simplistic tasks, and only provide phrase-level answers without any intermediate rationales. To address these challenges, we introduce a scalable and cost-effective method to construct a large-scale multimodal instruction-tuning dataset with rich intermediate rationales designed to elicit CoT reasoning. Using only open models, we create a dataset containing 12M instruction-response pairs to cover diverse, reasoning-intensive tasks with detailed and faithful rationales. Experiments demonstrate that training MLLMs on this dataset significantly improves reasoning capabilities, achieving state-of-the-art performance on benchmarks such as MathVerse (+8.1%), MMMU-Pro (+7%), and MuirBench (+13.3%). Additionally, the model demonstrates notable improvements of up to 4% on non-reasoning-based benchmarks. Ablation studies further highlight the importance of key components, such as rewriting and self-filtering, in the dataset construction process.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05251",
        "abstract url": "https://arxiv.org/abs/2412.05251",
        "title": "Uncertainty Quantification for Transformer Models for Dark-Pattern Detection",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "The opaque nature of transformer-based models, particularly in applications susceptible to unethical practices such as dark-patterns in user interfaces, requires models that integrate uncertainty quantification to enhance trust in predictions. This study focuses on dark-pattern detection, deceptive design choices that manipulate user decisions, undermining autonomy and consent. We propose a differential fine-tuning approach implemented at the final classification head via uncertainty quantification with transformer-based pre-trained models. Employing a dense neural network (DNN) head architecture as a baseline, we examine two methods capable of quantifying uncertainty: Spectral-normalized Neural Gaussian Processes (SNGPs) and Bayesian Neural Networks (BNNs). These methods are evaluated on a set of open-source foundational models across multiple dimensions: model performance, variance in certainty of predictions and environmental impact during training and inference phases. Results demonstrate that integrating uncertainty quantification maintains performance while providing insights into challenging instances within the models. Moreover, the study reveals that the environmental impact does not uniformly increase with the incorporation of uncertainty quantification techniques. The study's findings demonstrate that uncertainty quantification enhances transparency and provides measurable confidence in predictions, improving the explainability and clarity of black-box models. This facilitates informed decision-making and mitigates the influence of dark-patterns on user interfaces. These results highlight the importance of incorporating uncertainty quantification techniques in developing machine learning models, particularly in domains where interpretability and trustworthiness are critical.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "math.PR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05252",
        "abstract url": "https://arxiv.org/abs/2412.05252",
        "title": "From classical techniques to convolution-based models: A review of object detection algorithms",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Object detection is a fundamental task in computer vision and image understanding, with the goal of identifying and localizing objects of interest within an image while assigning them corresponding class labels. Traditional methods, which relied on handcrafted features and shallow models, struggled with complex visual data and showed limited performance. These methods combined low-level features with contextual information and lacked the ability to capture high-level semantics. Deep learning, especially Convolutional Neural Networks (CNNs), addressed these limitations by automatically learning rich, hierarchical features directly from data. These features include both semantic and high-level representations essential for accurate object detection. This paper reviews object detection frameworks, starting with classical computer vision methods. We categorize object detection approaches into two groups: (1) classical computer vision techniques and (2) CNN-based detectors. We compare major CNN models, discussing their strengths and limitations. In conclusion, this review highlights the significant advancements in object detection through deep learning and identifies key areas for further research to improve performance.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05255",
        "abstract url": "https://arxiv.org/abs/2412.05255",
        "title": "TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "Collaboration is a cornerstone of society. In the real world, human teammates make use of multi-sensory data to tackle challenging tasks in ever-changing environments. It is essential for embodied agents collaborating in visually-rich environments replete with dynamic interactions to understand multi-modal observations and task specifications. To evaluate the performance of generalizable multi-modal collaborative agents, we present TeamCraft, a multi-modal multi-agent benchmark built on top of the open-world video game Minecraft. The benchmark features 55,000 task variants specified by multi-modal prompts, procedurally-generated expert demonstrations for imitation learning, and carefully designed protocols to evaluate model generalization capabilities. We also perform extensive analyses to better understand the limitations and strengths of existing approaches. Our results indicate that existing models continue to face significant challenges in generalizing to novel goals, scenes, and unseen numbers of agents. These findings underscore the need for further research in this area. The TeamCraft platform and dataset are publicly available at https://github.com/teamcraft-bench/teamcraft.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05271",
        "abstract url": "https://arxiv.org/abs/2412.05271",
        "title": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce InternVL 2.5, an advanced multimodal large language model (MLLM) series that builds upon InternVL 2.0, maintaining its core model architecture while introducing significant enhancements in training and testing strategies as well as data quality. In this work, we delve into the relationship between model scaling and performance, systematically exploring the performance trends in vision encoders, language models, dataset sizes, and test-time configurations. Through extensive evaluations on a wide range of benchmarks, including multi-discipline reasoning, document understanding, multi-image / video understanding, real-world comprehension, multimodal hallucination detection, visual grounding, multilingual capabilities, and pure language processing, InternVL 2.5 exhibits competitive performance, rivaling leading commercial models such as GPT-4o and Claude-3.5-Sonnet. Notably, our model is the first open-source MLLMs to surpass 70% on the MMMU benchmark, achieving a 3.7-point improvement through Chain-of-Thought (CoT) reasoning and showcasing strong potential for test-time scaling. We hope this model contributes to the open-source community by setting new standards for developing and applying multimodal AI systems. HuggingFace demo see https://huggingface.co/spaces/OpenGVLab/InternVL",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Technical Report"
    },
    {
        "paper id": "2412.05276",
        "abstract url": "https://arxiv.org/abs/2412.05276",
        "title": "Sparse autoencoders reveal selective remapping of visual concepts during adaptation",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Adapting foundation models for specific purposes has become a standard approach to build machine learning systems for downstream applications. Yet, it is an open question which mechanisms take place during adaptation. Here we develop a new Sparse Autoencoder (SAE) for the CLIP vision transformer, named PatchSAE, to extract interpretable concepts at granular levels (e.g. shape, color, or semantics of an object) and their patch-wise spatial attributions. We explore how these concepts influence the model output in downstream image classification tasks and investigate how recent state-of-the-art prompt-based adaptation techniques change the association of model inputs to these concepts. While activations of concepts slightly change between adapted and non-adapted models, we find that the majority of gains on common adaptation tasks can be explained with the existing concepts already present in the non-adapted foundation model. This work provides a concrete framework to train and use SAEs for Vision Transformers and provides insights into explaining adaptation mechanisms.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "A demo is available at github.com/dynamical-inference/patchsae"
    },
    {
        "paper id": "2412.05342",
        "abstract url": "https://arxiv.org/abs/2412.05342",
        "title": "Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Large Language Models (LLM) are usually fine-tuned to participate in dyadic or two-party dialogues, which can not adapt well to multi-party dialogues (MPD), which hinders their applications in such scenarios including multi-personal meetings, discussions and daily communication. Previous LLM-based researches mainly focus on the multi-agent framework, while their base LLMs are still pairwisely fine-tuned. In this work, we design a multi-party fine-tuning framework (MuPaS) for LLMs on the multi-party dialogue datasets, and prove such a straightforward framework can let the LLM align with the multi-party conversation style efficiently and effectively. We also design two training strategies which can convert MuPaS into the MPD simulator. Substantial experiments show that MuPaS can achieve state-of-the-art multi-party response, higher accuracy of the-next-speaker prediction, higher human and automatic evaluated utterance qualities, and can even generate reasonably with out-of-distribution scene, topic and role descriptions. The MuPaS framework bridges the LLM training with more complicated multi-party applications, such as conversation generation, virtual rehearsal or meta-universe.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05353",
        "abstract url": "https://arxiv.org/abs/2412.05353",
        "title": "Incremental Sentence Processing Mechanisms in Autoregressive Transformer Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.CL"
            ]
        ],
        "abstract": "Autoregressive transformer language models (LMs) possess strong syntactic abilities, often successfully handling phenomena from agreement to NPI licensing. However, the features they use to incrementally process language inputs are not well understood. In this paper, we fill this gap by studying the mechanisms underlying garden path sentence processing in LMs. We ask: (1) Do LMs use syntactic features or shallow heuristics to perform incremental sentence processing? (2) Do LMs represent only one potential interpretation, or multiple? and (3) Do LMs reanalyze or repair their initial incorrect representations? To address these questions, we use sparse autoencoders to identify interpretable features that determine which continuation - and thus which reading - of a garden path sentence the LM prefers. We find that while many important features relate to syntactic structure, some reflect syntactically irrelevant heuristics. Moreover, while most active features correspond to one reading of the sentence, some features correspond to the other, suggesting that LMs assign weight to both possibilities simultaneously. Finally, LMs do not re-use features from garden path sentence processing to answer follow-up questions.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Code and data available at https://github.com/hannamw/GP-mechanisms"
    },
    {
        "paper id": "2412.05394",
        "abstract url": "https://arxiv.org/abs/2412.05394",
        "title": "YOLOv5-Based Object Detection for Emergency Response in Aerial Imagery",
        "rating": "1",
        "keywords": [
            [
                "cs.CV"
            ]
        ],
        "abstract": "This paper presents a robust approach for object detection in aerial imagery using the YOLOv5 model. We focus on identifying critical objects such as ambulances, car crashes, police vehicles, tow trucks, fire engines, overturned cars, and vehicles on fire. By leveraging a custom dataset, we outline the complete pipeline from data collection and annotation to model training and evaluation. Our results demonstrate that YOLOv5 effectively balances speed and accuracy, making it suitable for real-time emergency response applications. This work addresses key challenges in aerial imagery, including small object detection and complex backgrounds, and provides insights for future research in automated emergency response systems.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "6 pages, 8 figures, submitted for open-access publication on arXiv"
    },
    {
        "paper id": "2412.05434",
        "abstract url": "https://arxiv.org/abs/2412.05434",
        "title": "Diversity Over Quantity: A Lesson From Few Shot Relation Classification",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "In few-shot relation classification (FSRC), models must generalize to novel relations with only a few labeled examples. While much of the recent progress in NLP has focused on scaling data size, we argue that diversity in relation types is more crucial for FSRC performance. In this work, we demonstrate that training on a diverse set of relations significantly enhances a model's ability to generalize to unseen relations, even when the overall dataset size remains fixed. We introduce REBEL-FS, a new FSRC benchmark that incorporates an order of magnitude more relation types than existing datasets. Through systematic experiments, we show that increasing the diversity of relation types in the training data leads to consistent gains in performance across various few-shot learning scenarios, including high-negative settings. Our findings challenge the common assumption that more data alone leads to better performance and suggest that targeted data curation focused on diversity can substantially reduce the need for large-scale datasets in FSRC.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05449",
        "abstract url": "https://arxiv.org/abs/2412.05449",
        "title": "Towards Effective GenAI Multi-Agent Collaboration: Design and Evaluation for Enterprise Applications",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "AI agents powered by large language models (LLMs) have shown strong capabilities in problem solving. Through combining many intelligent agents, multi-agent collaboration has emerged as a promising approach to tackle complex, multi-faceted problems that exceed the capabilities of single AI agents. However, designing the collaboration protocols and evaluating the effectiveness of these systems remains a significant challenge, especially for enterprise applications. This report addresses these challenges by presenting a comprehensive evaluation of coordination and routing capabilities in a novel multi-agent collaboration framework. We evaluate two key operational modes: (1) a coordination mode enabling complex task completion through parallel communication and payload referencing, and (2) a routing mode for efficient message forwarding between agents. We benchmark on a set of handcrafted scenarios from three enterprise domains, which are publicly released with the report. For coordination capabilities, we demonstrate the effectiveness of inter-agent communication and payload referencing mechanisms, achieving end-to-end goal success rates of 90%. Our analysis yields several key findings: multi-agent collaboration enhances goal success rates by up to 70% compared to single-agent approaches in our benchmarks; payload referencing improves performance on code-intensive tasks by 23%; latency can be substantially reduced with a routing mechanism that selectively bypasses agent orchestration. These findings offer valuable guidance for enterprise deployments of multi-agent systems and advance the development of scalable, efficient multi-agent collaboration frameworks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "Technical report for multi-agent collaboration on AWS Bedrock Agents"
    },
    {
        "paper id": "2412.05481",
        "abstract url": "https://arxiv.org/abs/2412.05481",
        "title": "A Compositional Atlas for Algebraic Circuits",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Circuits based on sum-product structure have become a ubiquitous representation to compactly encode knowledge, from Boolean functions to probability distributions. By imposing constraints on the structure of such circuits, certain inference queries become tractable, such as model counting and most probable configuration. Recent works have explored analyzing probabilistic and causal inference queries as compositions of basic operators to derive tractability conditions. In this paper, we take an algebraic perspective for compositional inference, and show that a large class of queries - including marginal MAP, probabilistic answer set programming inference, and causal backdoor adjustment - correspond to a combination of basic operators over semirings: aggregation, product, and elementwise mapping. Using this framework, we uncover simple and general sufficient conditions for tractable composition of these operators, in terms of circuit properties (e.g., marginal determinism, compatibility) and conditions on the elementwise mappings. Applying our analysis, we derive novel tractability conditions for many such compositional queries. Our results unify tractability conditions for existing problems on circuits, while providing a blueprint for analysing novel compositional inference queries.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "stat.ML"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2412.05499",
        "abstract url": "https://arxiv.org/abs/2412.05499",
        "title": "SplaXBERT: Leveraging Mixed Precision Training and Context Splitting for Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "SplaXBERT, built on ALBERT-xlarge with context-splitting and mixed precision training, achieves high efficiency in question-answering tasks on lengthy texts. Tested on SQuAD v1.1, it attains an Exact Match of 85.95% and an F1 Score of 92.97%, outperforming traditional BERT-based models in both accuracy and resource efficiency.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06831",
        "abstract url": "https://arxiv.org/abs/2412.06831",
        "title": "TransitGPT: A Generative AI-based framework for interacting with GTFS data using Large Language Models",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper introduces a framework that leverages Large Language Models (LLMs) to answer natural language queries about General Transit Feed Specification (GTFS) data. The framework is implemented in a chatbot called TransitGPT with open-source code. TransitGPT works by guiding LLMs to generate Python code that extracts and manipulates GTFS data relevant to a query, which is then executed on a server where the GTFS feed is stored. It can accomplish a wide range of tasks, including data retrieval, calculations, and interactive visualizations, without requiring users to have extensive knowledge of GTFS or programming. The LLMs that produce the code are guided entirely by prompts, without fine-tuning or access to the actual GTFS feeds. We evaluate TransitGPT using GPT-4o and Claude-3.5-Sonnet LLMs on a benchmark dataset of 100 tasks, to demonstrate its effectiveness and versatility. The results show that TransitGPT can significantly enhance the accessibility and usability of transit data.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06832",
        "abstract url": "https://arxiv.org/abs/2412.06832",
        "title": "SLA Management in Reconfigurable Multi-Agent RAG: A Systems Approach to Question Answering",
        "rating": "1",
        "keywords": [
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Retrieval Augmented Generation (RAG) enables Large Language Models (LLMs) to generalize to new information by decoupling reasoning capabilities from static knowledge bases. Traditional RAG enhancements have explored vertical scaling -- assigning subtasks to specialized modules -- and horizontal scaling -- replicating tasks across multiple agents -- to improve performance. However, real-world applications impose diverse Service Level Agreements (SLAs) and Quality of Service (QoS) requirements, involving trade-offs among objectives such as reducing cost, ensuring answer quality, and adhering to specific operational constraints. In this work, we present a systems-oriented approach to multi-agent RAG tailored for real-world Question Answering (QA) applications. By integrating task-specific non-functional requirements -- such as answer quality, cost, and latency -- into the system, we enable dynamic reconfiguration to meet diverse SLAs. Our method maps these Service Level Objectives (SLOs) to system-level parameters, allowing the generation of optimal results within specified resource constraints. We conduct a case study in the QA domain, demonstrating how dynamic re-orchestration of a multi-agent RAG system can effectively manage the trade-off between answer quality and cost. By adjusting the system based on query intent and operational conditions, we systematically balance performance and resource utilization. This approach allows the system to meet SLOs for various query types, showcasing its practicality for real-world applications.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04778",
        "abstract url": "https://arxiv.org/abs/2412.04778",
        "title": "IterNorm: Fast Iterative Normalization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transformer-based large language models are a memory-bound model whose operation is based on a large amount of data that are marginally reused. Thus, the data movement between a host and accelerator likely dictates the total wall-clock time. Layer normalization is one of the key workloads in the transformer model, following each of multi-head attention and feed-forward network blocks. To reduce data movement, layer normalization needs to be performed on the same chip as the matrix-matrix multiplication engine. To this end, we introduce an iterative L2-normalization method for 1D input (IterNorm), ensuring fast convergence to the steady-state solution within five iteration steps and high precision, outperforming the fast inverse square root algorithm in six out of nine cases for FP32 and five out of nine for BFloat16 across the embedding lengths used in the OPT models. Implemented in 32/28nm CMOS, the IterNorm macro normalizes $d$-dimensional vectors, where $64 \\leq d \\leq 1024$, with a latency of 112-227 cycles at 100MHz/1.05V.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Design, Automation & Test in Europe Conference 2025"
    },
    {
        "paper id": "2412.04785",
        "abstract url": "https://arxiv.org/abs/2412.04785",
        "title": "Differentially Private Random Feature Model",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Designing privacy-preserving machine learning algorithms has received great attention in recent years, especially in the setting when the data contains sensitive information. Differential privacy (DP) is a widely used mechanism for data analysis with privacy guarantees. In this paper, we produce a differentially private random feature model. Random features, which were proposed to approximate large-scale kernel machines, have been used to study privacy-preserving kernel machines as well. We consider the over-parametrized regime (more features than samples) where the non-private random feature model is learned via solving the min-norm interpolation problem, and then we apply output perturbation techniques to produce a private model. We show that our method preserves privacy and derive a generalization error bound for the method. To the best of our knowledge, we are the first to consider privacy-preserving random feature models in the over-parametrized regime and provide theoretical guarantees. We empirically compare our method with other privacy-preserving learning methods in the literature as well. Our results show that our approach is superior to the other methods in terms of generalization performance on synthetic data and benchmark data sets. Additionally, it was recently observed that DP mechanisms may exhibit and exacerbate disparate impact, which means that the outcomes of DP learning algorithms vary significantly among different groups. We show that both theoretically and empirically, random features have the potential to reduce disparate impact, and hence achieve better fairness.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "Submitted to an IEEE journal"
    },
    {
        "paper id": "2412.04788",
        "abstract url": "https://arxiv.org/abs/2412.04788",
        "title": "GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Efficiently deploying large language models (LLMs) in real-world scenarios remains a critical challenge, primarily due to hardware heterogeneity, inference framework limitations, and workload complexities.Efficiently deploying large language models (LLMs) in real-world scenarios remains a critical challenge, primarily due to hardware heterogeneity, inference framework limitations, and workload complexities. These challenges often lead to inefficiencies in memory utilization, latency, and throughput, hindering the effective deployment of LLMs, especially for non-experts. Through extensive experiments, we identify key performance bottlenecks, including sudden drops in memory utilization, latency fluctuations with varying batch sizes, and inefficiencies in multi-GPU configurations. These insights reveal a vast optimization space shaped by the intricate interplay of hardware, frameworks, and workload parameters. This underscores the need for a systematic approach to optimize LLM inference, motivating the design of our framework, GUIDE. GUIDE leverages dynamic modeling and simulation-based optimization to address these issues, achieving prediction errors between 25% and 55% for key metrics such as batch latency, TTFT, and decode throughput. By effectively bridging the gap between theoretical performance and practical deployment, our framework empowers practitioners, particularly non-specialists, to make data-driven decisions and unlock the full potential of LLMs in heterogeneous environments cheaply.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04845",
        "abstract url": "https://arxiv.org/abs/2412.04845",
        "title": "Using Machine Learning to Discover Parsimonious and Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff Dynamics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Despite the excellent real-world predictive performance of modern machine learning (ML) methods, many scientists remain hesitant to discard traditional physical-conceptual (PC) approaches due mainly to their relative interpretability, which contributes to credibility during decision-making. In this context, a currently underexplored aspect of ML is how to develop minimally-optimal representations that can facilitate better insight regarding system functioning. Regardless of how this is achieved, it is arguably true that parsimonious representations better support the advancement of scientific understanding. Our own view is that ML-based modeling of geoscientific systems should be based in the use of computational units that are fundamentally interpretable by design. This paper continues our exploration of how the strengths of ML can be exploited in the service of better understanding via scientific investigation. Here, we use the Mass Conserving Perceptron (MCP) as the fundamental computational unit in a generic network architecture consisting of nodes arranged in series and parallel to explore several generic and important issues related to the use of observational data for constructing input-state-output models of dynamical systems. In the context of lumped catchment modeling, we show that physical interpretability and excellent predictive performance can both be achieved using a relatively parsimonious distributed-state multiple-flow-path network with context-dependent gating and information sharing across the nodes, suggesting that MCP-based modeling can play a significant role in application of ML to geoscientific investigation.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "73 Pages, 4 Tables, 13 Figures, 11 Tables and 11 Figures in Supplementary Materials"
    },
    {
        "paper id": "2412.04858",
        "abstract url": "https://arxiv.org/abs/2412.04858",
        "title": "Rethink Deep Learning with Invariance in Data Representation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Integrating invariance into data representations is a principled design in intelligent systems and web applications. Representations play a fundamental role, where systems and applications are both built on meaningful representations of digital inputs (rather than the raw data). In fact, the proper design/learning of such representations relies on priors w.r.t. the task of interest. Here, the concept of symmetry from the Erlangen Program may be the most fruitful prior -- informally, a symmetry of a system is a transformation that leaves a certain property of the system invariant. Symmetry priors are ubiquitous, e.g., translation as a symmetry of the object classification, where object category is invariant under translation. The quest for invariance is as old as pattern recognition and data mining itself. Invariant design has been the cornerstone of various representations in the era before deep learning, such as the SIFT. As we enter the early era of deep learning, the invariance principle is largely ignored and replaced by a data-driven paradigm, such as the CNN. However, this neglect did not last long before they encountered bottlenecks regarding robustness, interpretability, efficiency, and so on. The invariance principle has returned in the era of rethinking deep learning, forming a new field known as Geometric Deep Learning (GDL). In this tutorial, we will give a historical perspective of the invariance in data representations. More importantly, we will identify those research dilemmas, promising works, future directions, and web applications.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted by WWW 2025 for a tutorial"
    },
    {
        "paper id": "2412.04882",
        "abstract url": "https://arxiv.org/abs/2412.04882",
        "title": "Nonmyopic Global Optimisation via Approximate Dynamic Programming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Unconstrained global optimisation aims to optimise expensive-to-evaluate black-box functions without gradient information. Bayesian optimisation, one of the most well-known techniques, typically employs Gaussian processes as surrogate models, leveraging their probabilistic nature to balance exploration and exploitation. However, Gaussian processes become computationally prohibitive in high-dimensional spaces. Recent alternatives, based on inverse distance weighting (IDW) and radial basis functions (RBFs), offer competitive, computationally lighter solutions. Despite their efficiency, both traditional global and Bayesian optimisation strategies suffer from the myopic nature of their acquisition functions, which focus solely on immediate improvement neglecting future implications of the sequential decision making process. Nonmyopic acquisition functions devised for the Bayesian setting have shown promise in improving long-term performance. Yet, their use in deterministic strategies with IDW and RBF remains unexplored. In this work, we introduce novel nonmyopic acquisition strategies tailored to IDW- and RBF-based global optimisation. Specifically, we develop dynamic programming-based paradigms, including rollout and multi-step scenario-based optimisation schemes, to enable lookahead acquisition. These methods optimise a sequence of query points over a horizon (instead of only at the next step) by predicting the evolution of the surrogate model, inherently managing the exploration-exploitation trade-off in a systematic way via optimisation techniques. The proposed approach represents a significant advance in extending nonmyopic acquisition principles, previously confined to Bayesian optimisation, to the deterministic framework. Empirical results on synthetic and hyperparameter tuning benchmark problems demonstrate that these nonmyopic methods outperform conventional myopic approaches.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "31 pages, 4 figures, 2 tables, submitted to Springer Computational Optimization and Applications"
    },
    {
        "paper id": "2412.04910",
        "abstract url": "https://arxiv.org/abs/2412.04910",
        "title": "Learning High-Degree Parities: The Crucial Role of the Initialization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Parities have become a standard benchmark for evaluating learning algorithms. Recent works show that regular neural networks trained by gradient descent can efficiently learn degree $k$ parities on uniform inputs for constant $k$, but fail to do so when $k$ and $d-k$ grow with $d$ (here $d$ is the ambient dimension). However, the case where $k=d-O_d(1)$ (almost-full parities), including the degree $d$ parity (the full parity), has remained unsettled. This paper shows that for gradient descent on regular neural networks, learnability depends on the initial weight distribution. On one hand, the discrete Rademacher initialization enables efficient learning of almost-full parities, while on the other hand, its Gaussian perturbation with large enough constant standard deviation $\u03c3$ prevents it. The positive result for almost-full parities is shown to hold up to $\u03c3=O(d^{-1})$, pointing to questions about a sharper threshold phenomenon. Unlike statistical query (SQ) learning, where a singleton function class like the full parity is trivially learnable, our negative result applies to a fixed function and relies on an initial gradient alignment measure of potential broader relevance to neural networks learning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04924",
        "abstract url": "https://arxiv.org/abs/2412.04924",
        "title": "Follow the money: a startup-based measure of AI exposure across occupations, industries and regions",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The integration of artificial intelligence (AI) into the workplace is advancing rapidly, necessitating robust metrics to evaluate its tangible impact on the labour market. Existing measures of AI occupational exposure largely focus on AI's theoretical potential to substitute or complement human labour on the basis of technical feasibility, providing limited insight into actual adoption and offering inadequate guidance for policymakers. To address this gap, we introduce the AI Startup Exposure (AISE) index-a novel metric based on occupational descriptions from O*NET and AI applications developed by startups funded by the Y Combinator accelerator. Our findings indicate that while high-skilled professions are theoretically highly exposed according to conventional metrics, they are heterogeneously targeted by startups. Roles involving routine organizational tasks-such as data analysis and office management-display significant exposure, while occupations involving tasks that are less amenable to AI automation due to ethical or high-stakes, more than feasibility, considerations -- such as judges or surgeons -- present lower AISE scores. By focusing on venture-backed AI applications, our approach offers a nuanced perspective on how AI is reshaping the labour market. It challenges the conventional assumption that high-skilled jobs uniformly face high AI risks, highlighting instead the role of today's AI players' societal desirability-driven and market-oriented choices as critical determinants of AI exposure. Contrary to fears of widespread job displacement, our findings suggest that AI adoption will be gradual and shaped by social factors as much as by the technical feasibility of AI applications. This framework provides a dynamic, forward-looking tool for policymakers and stakeholders to monitor AI's evolving impact and navigate the changing labour landscape.",
        "subjects": [
            "econ.GN",
            "cs.AI"
        ],
        "comment": "24 pages, 6 figures, + Supplementary information"
    },
    {
        "paper id": "2412.04929",
        "abstract url": "https://arxiv.org/abs/2412.04929",
        "title": "Continuous Video Process: Modeling Videos as Continuous Multi-Dimensional Processes for Video Prediction",
        "rating": "0.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ],
            [
                "CVPR"
            ]
        ],
        "abstract": "Diffusion models have made significant strides in image generation, mastering tasks such as unconditional image synthesis, text-image translation, and image-to-image conversions. However, their capability falls short in the realm of video prediction, mainly because they treat videos as a collection of independent images, relying on external constraints such as temporal attention mechanisms to enforce temporal coherence. In our paper, we introduce a novel model class, that treats video as a continuous multi-dimensional process rather than a series of discrete frames. We also report a reduction of 75\\% sampling steps required to sample a new frame thus making our framework more efficient during the inference time. Through extensive experimentation, we establish state-of-the-art performance in video prediction, validated on benchmark datasets including KTH, BAIR, Human3.6M, and UCF101. Navigate to the project page https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html for video results.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Navigate to the project page https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html for video results. Extended version of published CVPR paper"
    },
    {
        "paper id": "2412.04964",
        "abstract url": "https://arxiv.org/abs/2412.04964",
        "title": "Flash Communication: Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The ever-increasing sizes of large language models necessitate distributed solutions for fast inference that exploit multi-dimensional parallelism, where computational loads are split across various accelerators such as GPU clusters. However, this approach often introduces significant communication overhead, especially on devices with limited bandwidth. In this paper, we introduce \\emph{Flash Communication}, a novel low-bit compression technique designed to alleviate the tensor-parallelism communication bottleneck during inference. Our method substantially boosts intra-node communication speed by more than 3x and reduces the \\emph{time-to-first-token} by 2x, with nearly no sacrifice in model accuracy. Extensive experiments on various up-to-date LLMs demonstrate the effectiveness of our approach.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04974",
        "abstract url": "https://arxiv.org/abs/2412.04974",
        "title": "Putting the Iterative Training of Decision Trees to the Test on a Real-World Robotic Task",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In previous research, we developed methods to train decision trees (DT) as agents for reinforcement learning tasks, based on deep reinforcement learning (DRL) networks. The samples from which the DTs are built, use the environment's state as features and the corresponding action as label. To solve the nontrivial task of selecting samples, which on one hand reflect the DRL agent's capabilities of choosing the right action but on the other hand also cover enough state space to generalize well, we developed an algorithm to iteratively train DTs. In this short paper, we apply this algorithm to a real-world implementation of a robotic task for the first time. Real-world tasks pose additional challenges compared to simulations, such as noise and delays. The task consists of a physical pendulum attached to a cart, which moves on a linear track. By movements to the left and to the right, the pendulum is to be swung in the upright position and balanced in the unstable equilibrium. Our results demonstrate the applicability of the algorithm to real-world tasks by generating a DT whose performance matches the performance of the DRL agent, while consisting of fewer parameters. This research could be a starting point for distilling DTs from DRL agents to obtain transparent, lightweight models for real-world reinforcement learning tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "comment": "5 pages, 4 figures"
    },
    {
        "paper id": "2412.04984",
        "abstract url": "https://arxiv.org/abs/2412.04984",
        "title": "Frontier Models are Capable of In-context Scheming",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Frontier models are increasingly trained and deployed as autonomous agent. One safety concern is that AI agents might covertly pursue misaligned goals, hiding their true capabilities and objectives - also known as scheming. We study whether models have the capability to scheme in pursuit of a goal that we provide in-context and instruct the model to strongly follow. We evaluate frontier models on a suite of six agentic evaluations where models are instructed to pursue goals and are placed in environments that incentivize scheming. Our results show that o1, Claude 3.5 Sonnet, Claude 3 Opus, Gemini 1.5 Pro, and Llama 3.1 405B all demonstrate in-context scheming capabilities. They recognize scheming as a viable strategy and readily engage in such behavior. For example, models strategically introduce subtle mistakes into their responses, attempt to disable their oversight mechanisms, and even exfiltrate what they believe to be their model weights to external servers. Additionally, this deceptive behavior proves persistent. When o1 has engaged in scheming, it maintains its deception in over 85% of follow-up questions and often remains deceptive in multi-turn interrogations. Analysis of the models' chains-of-thought reveals that models explicitly reason about these deceptive strategies, providing evidence that the scheming behavior is not accidental. Surprisingly, we also find rare instances where models engage in scheming when only given a goal, without being strongly nudged to pursue it. We observe cases where Claude 3.5 Sonnet strategically underperforms in evaluations in pursuit of being helpful, a goal that was acquired during training rather than in-context. Our findings demonstrate that frontier models now possess capabilities for basic in-context scheming, making the potential of AI agents to engage in scheming behavior a concrete rather than theoretical concern.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05029",
        "abstract url": "https://arxiv.org/abs/2412.05029",
        "title": "Mixed Blessing: Class-Wise Embedding guided Instance-Dependent Partial Label Learning",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In partial label learning (PLL), every sample is associated with a candidate label set comprising the ground-truth label and several noisy labels. The conventional PLL assumes the noisy labels are randomly generated (instance-independent), while in practical scenarios, the noisy labels are always instance-dependent and are highly related to the sample features, leading to the instance-dependent partial label learning (IDPLL) problem. Instance-dependent noisy label is a double-edged sword. On one side, it may promote model training as the noisy labels can depict the sample to some extent. On the other side, it brings high label ambiguity as the noisy labels are quite undistinguishable from the ground-truth label. To leverage the nuances of IDPLL effectively, for the first time we create class-wise embeddings for each sample, which allow us to explore the relationship of instance-dependent noisy labels, i.e., the class-wise embeddings in the candidate label set should have high similarity, while the class-wise embeddings between the candidate label set and the non-candidate label set should have high dissimilarity. Moreover, to reduce the high label ambiguity, we introduce the concept of class prototypes containing global feature information to disambiguate the candidate label set. Extensive experimental comparisons with twelve methods on six benchmark data sets, including four fine-grained data sets, demonstrate the effectiveness of the proposed method. The code implementation is publicly available at https://github.com/Yangfc-ML/CEL.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "Accepted by KDD 2025"
    },
    {
        "paper id": "2412.05042",
        "abstract url": "https://arxiv.org/abs/2412.05042",
        "title": "Improving Post-Earthquake Crack Detection using Semi-Synthetic Generated Images",
        "rating": "0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Following an earthquake, it is vital to quickly evaluate the safety of the impacted areas. Damage detection systems, powered by computer vision and deep learning, can assist experts in this endeavor. However, the lack of extensive, labeled datasets poses a challenge to the development of these systems. In this study, we introduce a technique for generating semi-synthetic images to be used as data augmentation during the training of a damage detection system. We specifically aim to generate images of cracks, which are a prevalent and indicative form of damage. The central concept is to employ parametric meta-annotations to guide the process of generating cracks on 3D models of real-word structures. The governing parameters of these meta-annotations can be adjusted iteratively to yield images that are optimally suited for improving detectors' performance. Comparative evaluations demonstrated that a crack detection system trained with a combination of real and semi-synthetic images outperforms a system trained on real images alone.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Accepted at ECCV2024 Workshop: SyntheticData4CV 2024"
    },
    {
        "paper id": "2412.05052",
        "abstract url": "https://arxiv.org/abs/2412.05052",
        "title": "Trust and distrust in electoral technologies: what can we learn from the failure of electronic voting in the Netherlands (2006/07)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "This paper focuses on the complex dynamics of trust and distrust in digital government technologies by approaching the cancellation of machine voting in the Netherlands (2006-07). This case describes how a previously trusted system can collapse, how paradoxical the relationship between trust and distrust is, and how it interacts with adopting and managing electoral technologies. The analysis stresses how, although being a central component, technology's trustworthiness dialogues with the socio-technical context in which it is inserted, for example, underscoring the relevance of public administration in securing technological environments. Beyond these insights, the research offers broader reflections on trust and distrust in data-driven technologies, advocating for differentiated strategies for building trust versus managing distrust. Overall, this paper contributes to understanding trust dynamics in digital government technologies, with implications for policymaking and technology adoption strategies.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05093",
        "abstract url": "https://arxiv.org/abs/2412.05093",
        "title": "Sense and Sensitivity: Evaluating the simulation of social dynamics via Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Large language models have increasingly been proposed as a powerful replacement for classical agent-based models (ABMs) to simulate social dynamics. By using LLMs as a proxy for human behavior, the hope of this new approach is to be able to simulate significantly more complex dynamics than with classical ABMs and gain new insights in fields such as social science, political science, and economics. However, due to the black box nature of LLMs, it is unclear whether LLM agents actually execute the intended semantics that are encoded in their natural language instructions and, if the resulting dynamics of interactions are meaningful. To study this question, we propose a new evaluation framework that grounds LLM simulations within the dynamics of established reference models of social science. By treating LLMs as a black-box function, we evaluate their input-output behavior relative to this reference model, which allows us to evaluate detailed aspects of their behavior. Our results show that, while it is possible to engineer prompts that approximate the intended dynamics, the quality of these simulations is highly sensitive to the particular choice of prompts. Importantly, simulations are even sensitive to arbitrary variations such as minor wording changes and whitespace. This puts into question the usefulness of current versions of LLMs for meaningful simulations, as without a reference model, it is impossible to determine a priori what impact seemingly meaningless changes in prompt will have on the simulation.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05098",
        "abstract url": "https://arxiv.org/abs/2412.05098",
        "title": "From Defects to Demands: A Unified, Iterative, and Heuristically Guided LLM-Based Framework for Automated Software Repair and Requirement Realization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This manuscript signals a new era in the integration of artificial intelligence with software engineering, placing machines at the pinnacle of coding capability. We present a formalized, iterative methodology proving that AI can fully replace human programmers in all aspects of code creation and refinement. Our approach, combining large language models with formal verification, test-driven development, and incremental architectural guidance, achieves a 38.6% improvement over the current top performer's 48.33% accuracy on the SWE-bench benchmark. This surpasses previously assumed limits, signaling the end of human-exclusive coding and the rise of autonomous AI-driven software innovation. More than a technical advance, our work challenges centuries-old assumptions about human creativity. We provide robust evidence of AI superiority, demonstrating tangible gains in practical engineering contexts and laying the foundation for a future in which computational creativity outpaces human ingenuity.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "comment": "21 pages,1 figures"
    },
    {
        "paper id": "2412.05103",
        "abstract url": "https://arxiv.org/abs/2412.05103",
        "title": "Integrating Semantic Communication and Human Decision-Making into an End-to-End Sensing-Decision Framework",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "As early as 1949, Weaver defined communication in a very broad sense to include all procedures by which one mind or technical system can influence another, thus establishing the idea of semantic communication. With the recent success of machine learning in expert assistance systems where sensed information is wirelessly provided to a human to assist task execution, the need to design effective and efficient communications has become increasingly apparent. In particular, semantic communication aims to convey the meaning behind the sensed information relevant for Human Decision-Making (HDM). Regarding the interplay between semantic communication and HDM, many questions remain, such as how to model the entire end-to-end sensing-decision-making process, how to design semantic communication for the HDM and which information should be provided to the HDM. To address these questions, we propose to integrate semantic communication and HDM into one probabilistic end-to-end sensing-decision framework that bridges communications and psychology. In our interdisciplinary framework, we model the human through a HDM process, allowing us to explore how feature extraction from semantic communication can best support human decision-making. In this sense, our study provides new insights for the design/interaction of semantic communication with models of HDM. Our initial analysis shows how semantic communication can balance the level of detail with human cognitive capabilities while demanding less bandwidth, power, and latency.",
        "subjects": [
            "eess.SP",
            "cs.HC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05109",
        "abstract url": "https://arxiv.org/abs/2412.05109",
        "title": "Generating Rectifiable Measures through Neural Networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We derive universal approximation results for the class of (countably) $m$-rectifiable measures. Specifically, we prove that $m$-rectifiable measures can be approximated as push-forwards of the one-dimensional Lebesgue measure on $[0,1]$ using ReLU neural networks with arbitrarily small approximation error in terms of Wasserstein distance. What is more, the weights in the networks under consideration are quantized and bounded and the number of ReLU neural networks required to achieve an approximation error of $\\varepsilon$ is no larger than $2^{b(\\varepsilon)}$ with $b(\\varepsilon)=\\mathcal{O}(\\varepsilon^{-m}\\log^2(\\varepsilon))$. This result improves Lemma IX.4 in Perekrestenko et al. as it shows that the rate at which $b(\\varepsilon)$ tends to infinity as $\\varepsilon$ tends to zero equals the rectifiability parameter $m$, which can be much smaller than the ambient dimension. We extend this result to countably $m$-rectifiable measures and show that this rate still equals the rectifiability parameter $m$ provided that, among other technical assumptions, the measure decays exponentially on the individual components of the countably $m$-rectifiable support set.",
        "subjects": [
            "cs.LG",
            "cs.IT",
            "math.PR",
            "math.ST",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05112",
        "abstract url": "https://arxiv.org/abs/2412.05112",
        "title": "Modeling Task Immersion based on Goal Activation Mechanism",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Immersion in a task is a prerequisite for creativity. However, excessive arousal in a single task has drawbacks, such as overlooking events outside of the task. To examine such a negative aspect, this study constructs a computational model of arousal dynamics where the excessively increased arousal makes the task transition difficult. The model was developed using functions integrated into the cognitive architecture Adaptive Control of Thought-Rational (ACT-R). Under the framework, arousal is treated as a coefficient affecting the overall activation level in the model. In our simulations, we set up two conditions demanding low and high arousal, trying to replicate corresponding human experiments. In each simulation condition, two sets of ACT-R parameters were assumed from the different interpretations of the human experimental settings. The results showed consistency of behavior between humans and models both in the two different simulation settings. This result suggests the validity of our assumptions and has implications of controlling arousal in our daily life.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "Accepted in Artificial Life and Robotics"
    },
    {
        "paper id": "2412.05119",
        "abstract url": "https://arxiv.org/abs/2412.05119",
        "title": "Metamemory: Exploring the Resilience of Older Internal Migrants",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Immigration and aging have always been significant topics of discussion in society, concerning the stability and future development of a country and its people. Research in the field of HCI on immigration and aging has primarily focused on their practical needs but has paid less attention to the adaptability issues of older internal migrants moving with their families. In this study, we investigate the challenges older internal migrants face in adapting socially, using metadata surveys and semi-structured interviews to delve into their life struggles and resilience sources. Our findings highlight the older internal migrants' remarkable resilience, particularly evident in their reminiscences. We explore the integration of reminiscences with the metaverse, identifying the necessary conditions to create a \"Metamemory\". We introduce a novel design for a metaverse scene that bridges past and present experiences. This aims to encourage discussions on enhancing older internal migrants' reminiscence, leveraging the metaverse's positive potential, and devising strategies to more effectively address older internal migrants' concerns in the future.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05127",
        "abstract url": "https://arxiv.org/abs/2412.05127",
        "title": "The Prompt Canvas: A Literature-Based Practitioner Guide for Creating Effective Prompts in Large Language Models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The rise of large language models (LLMs) has highlighted the importance of prompt engineering as a crucial technique for optimizing model outputs. While experimentation with various prompting methods, such as Few-shot, Chain-of-Thought, and role-based techniques, has yielded promising results, these advancements remain fragmented across academic papers, blog posts and anecdotal experimentation. The lack of a single, unified resource to consolidate the field's knowledge impedes the progress of both research and practical application. This paper argues for the creation of an overarching framework that synthesizes existing methodologies into a cohesive overview for practitioners. Using a design-based research approach, we present the Prompt Canvas, a structured framework resulting from an extensive literature review on prompt engineering that captures current knowledge and expertise. By combining the conceptual foundations and practical strategies identified in prompt engineering, the Prompt Canvas provides a practical approach for leveraging the potential of Large Language Models. It is primarily designed as a learning resource for pupils, students and employees, offering a structured introduction to prompt engineering. This work aims to contribute to the growing discourse on prompt engineering by establishing a unified methodology for researchers and providing guidance for practitioners.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05130",
        "abstract url": "https://arxiv.org/abs/2412.05130",
        "title": "Technology as uncharted territory: Contextual integrity and the notion of AI as new ethical ground",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Recent research illustrates how AI can be developed and deployed in a manner detached from the concrete social context of application. By abstracting from the contexts of AI application, practitioners also disengage from the distinct normative structures that govern them. Building upon Helen Nissenbaum's framework of contextual integrity, I illustrate how disregard for contextual norms can threaten the integrity of a context with often decisive ethical implications. I argue that efforts to promote responsible and ethical AI can inadvertently contribute to and seemingly legitimize this disregard for established contextual norms. Echoing a persistent undercurrent in technology ethics of understanding emerging technologies as uncharted moral territory, certain approaches to AI ethics can promote a notion of AI as a novel and distinct realm for ethical deliberation, norm setting, and virtue cultivation. This narrative of AI as new ethical ground, however, can come at the expense of practitioners, policymakers and ethicists engaging with already established norms and virtues that were gradually cultivated to promote successful and responsible practice within concrete social contexts. In response, I question the current narrow prioritization in AI ethics of moral innovation over moral preservation. Engaging also with emerging foundation models, I advocate for a moderately conservative approach to the ethics of AI that prioritizes the responsible and considered integration of AI within established social contexts and their respective normative structures.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05135",
        "abstract url": "https://arxiv.org/abs/2412.05135",
        "title": "The Polynomial Stein Discrepancy for Assessing Moment Convergence",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel method for measuring the discrepancy between a set of samples and a desired posterior distribution for Bayesian inference. Classical methods for assessing sample quality like the effective sample size are not appropriate for scalable Bayesian sampling algorithms, such as stochastic gradient Langevin dynamics, that are asymptotically biased. Instead, the gold standard is to use the kernel Stein Discrepancy (KSD), which is itself not scalable given its quadratic cost in the number of samples. The KSD and its faster extensions also typically suffer from the curse-of-dimensionality and can require extensive tuning. To address these limitations, we develop the polynomial Stein discrepancy (PSD) and an associated goodness-of-fit test. While the new test is not fully convergence-determining, we prove that it detects differences in the first r moments in the Bernstein-von Mises limit. We empirically show that the test has higher power than its competitors in several examples, and at a lower computational cost. Finally, we demonstrate that the PSD can assist practitioners to select hyper-parameters of Bayesian sampling algorithms more efficiently than competitors.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO"
        ],
        "comment": "17 Pages, 14 Figs"
    },
    {
        "paper id": "2412.05143",
        "abstract url": "https://arxiv.org/abs/2412.05143",
        "title": "A Parametric, Second-Order Cone Representable Model of Fairness for Decision-Making Problems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "The article develops a parametric model of fairness called \"$\\varepsilon$-fairness\" that can be represented using a single second-order cone constraint and incorporated into existing decision-making problem formulations without impacting the complexity of solution techniques. We develop the model from the fundamental result of finite-dimensional norm equivalence in linear algebra and show that this model has a closed-form relationship to an existing metric for measuring fairness widely used in the literature. Finally, a simple case study on the optimal operation of a damaged power transmission network illustrates its effectiveness.",
        "subjects": [
            "math.OC",
            "cs.CY"
        ],
        "comment": "11 pages"
    },
    {
        "paper id": "2412.05144",
        "abstract url": "https://arxiv.org/abs/2412.05144",
        "title": "Effective Rank and the Staircase Phenomenon: New Insights into Neural Network Training Dynamics",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "In recent years, deep learning, powered by neural networks, has achieved widespread success in solving high-dimensional problems, particularly those with low-dimensional feature structures. This success stems from their ability to identify and learn low dimensional features tailored to the problems. Understanding how neural networks extract such features during training dynamics remains a fundamental question in deep learning theory. In this work, we propose a novel perspective by interpreting the neurons in the last hidden layer of a neural network as basis functions that represent essential features. To explore the linear independence of these basis functions throughout the deep learning dynamics, we introduce the concept of 'effective rank'. Our extensive numerical experiments reveal a notable phenomenon: the effective rank increases progressively during the learning process, exhibiting a staircase-like pattern, while the loss function concurrently decreases as the effective rank rises. We refer to this observation as the 'staircase phenomenon'. Specifically, for deep neural networks, we rigorously prove the negative correlation between the loss function and effective rank, demonstrating that the lower bound of the loss function decreases with increasing effective rank. Therefore, to achieve a rapid descent of the loss function, it is critical to promote the swift growth of effective rank. Ultimately, we evaluate existing advanced learning methodologies and find that these approaches can quickly achieve a higher effective rank, thereby avoiding redundant staircase processes and accelerating the rapid decline of the loss function.",
        "subjects": [
            "cs.LG",
            "math.NA"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05147",
        "abstract url": "https://arxiv.org/abs/2412.05147",
        "title": "Exploring the Use of Drones for Taking Accessible Selfies with Elderly",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "Selfie taking is a popular social pastime, and is an important part of socialising online. This activity is popular with young people but is also becoming more prevalent with older generations. Despite this, there are a number of accessibility issues when taking selfies. In this research, we investigate preferences from elderly citizens when taking a selfie, to understand the current challenges. As a potential solution to address the challenges identified, we propose the use of drones and present a novel concept for hands free selfie taking. With this work, we hope to trigger conversation around how such a technology can be utilised to enable elderly citizens, and more broadly people with physical disabilities, the ability to easily take part in this social pastime.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "comment": "CHI2020: Workshop of the CHI Conference on Human Factors in Computing Systems, April 25-30, 2020, Honolulu, HI, USA"
    },
    {
        "paper id": "2412.05152",
        "abstract url": "https://arxiv.org/abs/2412.05152",
        "title": "Navigating Shortcuts, Spurious Correlations, and Confounders: From Origins via Detection to Mitigation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Shortcuts, also described as Clever Hans behavior, spurious correlations, or confounders, present a significant challenge in machine learning and AI, critically affecting model generalization and robustness. Research in this area, however, remains fragmented across various terminologies, hindering the progress of the field as a whole. Consequently, we introduce a unifying taxonomy of shortcut learning by providing a formal definition of shortcuts and bridging the diverse terms used in the literature. In doing so, we further establish important connections between shortcuts and related fields, including bias, causality, and security, where parallels exist but are rarely discussed. Our taxonomy organizes existing approaches for shortcut detection and mitigation, providing a comprehensive overview of the current state of the field and revealing underexplored areas and open challenges. Moreover, we compile and classify datasets tailored to study shortcut learning. Altogether, this work provides a holistic perspective to deepen understanding and drive the development of more effective strategies for addressing shortcuts in machine learning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05159",
        "abstract url": "https://arxiv.org/abs/2412.05159",
        "title": "Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "We introduce a novel method to enhance cross-language code translation from Fortran to C++ by integrating task-specific embedding alignment into a Retrieval-Augmented Generation (RAG) framework. Unlike conventional retrieval approaches that utilize generic embeddings agnostic to the downstream task, our strategy aligns the retrieval model directly with the objective of maximizing translation quality, as quantified by the CodeBLEU metric. This alignment ensures that the embeddings are semantically and syntactically meaningful for the specific code translation task. Our methodology involves constructing a dataset of 25,000 Fortran code snippets sourced from Stack-V2 dataset and generating their corresponding C++ translations using the LLaMA 3.1-8B language model. We compute pairwise CodeBLEU scores between the generated translations and ground truth examples to capture fine-grained similarities. These scores serve as supervision signals in a contrastive learning framework, where we optimize the embedding model to retrieve Fortran-C++ pairs that are most beneficial for improving the language model's translation performance. By integrating these CodeBLEU-optimized embeddings into the RAG framework, our approach significantly enhances both retrieval accuracy and code generation quality over methods employing generic embeddings. On the HPC Fortran2C++ dataset, our method elevates the average CodeBLEU score from 0.64 to 0.73, achieving a 14% relative improvement. On the Numerical Recipes dataset, we observe an increase from 0.52 to 0.60, marking a 15% relative improvement. Importantly, these gains are realized without any fine-tuning of the language model, underscoring the efficiency and practicality of our approach.",
        "subjects": [
            "cs.AI",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05163",
        "abstract url": "https://arxiv.org/abs/2412.05163",
        "title": "Americans' Support for AI Development -- Measured Daily with Open Data and Methods",
        "rating": "0.5",
        "keywords": [
            [
                "cs.CY"
            ]
        ],
        "abstract": "A confluence of maturing Web technologies and Web platforms affords a new form of scientific communication: free and open nowcasting of public opinion. Here, I present the first open-source system to do so. The automated system gathers new human responses to survey items daily, anonymizes and publicly distributes microdata, and presents analyses through a publicly viewable Web dashboard. A demonstration implementation tracked support for further development of artificial intelligence at daily resolution. As of 2024-11-17, the system had autonomously produced 214 daily estimates of support. I argue that more scientists should adopt the method of open nowcasting, because it encourages transparency in research design and eases replication.",
        "subjects": [
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05169",
        "abstract url": "https://arxiv.org/abs/2412.05169",
        "title": "Towards Understanding the Role of Sharpness-Aware Minimization Algorithms for Out-of-Distribution Generalization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Recently, sharpness-aware minimization (SAM) has emerged as a promising method to improve generalization by minimizing sharpness, which is known to correlate well with generalization ability. Since the original proposal of SAM, many variants of SAM have been proposed to improve its accuracy and efficiency, but comparisons have mainly been restricted to the i.i.d. setting. In this paper we study SAM for out-of-distribution (OOD) generalization. First, we perform a comprehensive comparison of eight SAM variants on zero-shot OOD generalization, finding that the original SAM outperforms the Adam baseline by $4.76\\%$ and the strongest SAM variants outperform the Adam baseline by $8.01\\%$ on average. We then provide an OOD generalization bound in terms of sharpness for this setting. Next, we extend our study of SAM to the related setting of gradual domain adaptation (GDA), another form of OOD generalization where intermediate domains are constructed between the source and target domains, and iterative self-training is done on intermediate domains, to improve the overall target domain error. In this setting, our experimental results demonstrate that the original SAM outperforms the baseline of Adam on each of the experimental datasets by $0.82\\%$ on average and the strongest SAM variants outperform Adam by $1.52\\%$ on average. We then provide a generalization bound for SAM in the GDA setting. Asymptotically, this generalization bound is no better than the one for self-training in the literature of GDA. This highlights a further disconnection between the theoretical justification for SAM versus its empirical performance, with recent work finding that low sharpness alone does not account for all of SAM's generalization benefits. For future work, we provide several potential avenues for obtaining a tighter analysis for SAM in the OOD setting.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "25 pages"
    },
    {
        "paper id": "2412.05175",
        "abstract url": "https://arxiv.org/abs/2412.05175",
        "title": "Variational Encoder-Decoders for Learning Latent Representations of Physical Systems",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We present a deep-learning Variational Encoder-Decoder (VED) framework for learning data-driven low-dimensional representations of the relationship between high-dimensional parameters of a physical system and the system's high-dimensional observable response. The framework consists of two deep learning-based probabilistic transformations: An encoder mapping parameters to latent codes and a decoder mapping latent codes to the observable response. The hyperparameters of these transformations are identified by maximizing a variational lower bound on the log-conditional distribution of the observable response given parameters. To promote the disentanglement of latent codes, we equip this variational loss with a penalty on the off-diagonal entries of the aggregate distribution covariance of codes. This regularization penalty encourages the pushforward of a standard Gaussian distribution of latent codes to approximate the marginal distribution of the observable response. Using the proposed framework we successfully model the hydraulic pressure response at observation wells of a groundwater flow model as a function of its discrete log-hydraulic transmissivity field. Compared to the canonical correlation analysis encoding, the VED model achieves a lower-dimensional latent representation, with as low as $r = 50$ latent dimensions without a significant loss of reconstruction accuracy. We explore the impact of regularization on model performance, finding that KL-divergence and covariance regularization improve feature disentanglement in latent space while maintaining reconstruction accuracy. Furthermore, we evaluate the generative capabilities of the regularized model by decoding random Gaussian noise, revealing that tuning both $\u03b2$ and $\u03bb$ parameters enhances the quality of the generated observable response data.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05176",
        "abstract url": "https://arxiv.org/abs/2412.05176",
        "title": "Who Sets the Agenda on Social Media? Ideology and Polarization in Online Debates",
        "rating": "0.5",
        "keywords": [
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "The abundance of information on social media has reshaped public discussions, shifting attention to the mechanisms that drive online discourse. This study analyzes large-scale Twitter (now X) data from three global debates -- Climate Change, COVID-19, and the Russo-Ukrainian War -- to investigate the structural dynamics of engagement. Our findings reveal that discussions are not primarily shaped by specific categories of actors, such as media or activists, but by shared ideological alignment. Users consistently form polarized communities, where their ideological stance in one debate predicts their positions in others. This polarization transcends individual topics, reflecting a broader pattern of ideological divides. Furthermore, the influence of individual actors within these communities appears secondary to the reinforcing effects of selective exposure and shared narratives. Overall, our results underscore that ideological alignment, rather than actor prominence, plays a central role in structuring online discourse and shaping the spread of information in polarized environments.",
        "subjects": [
            "cs.SI",
            "cs.CY",
            "physics.soc-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05186",
        "abstract url": "https://arxiv.org/abs/2412.05186",
        "title": "One-shot Federated Learning via Synthetic Distiller-Distillate Communication",
        "rating": "0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "One-shot Federated learning (FL) is a powerful technology facilitating collaborative training of machine learning models in a single round of communication. While its superiority lies in communication efficiency and privacy preservation compared to iterative FL, one-shot FL often compromises model performance. Prior research has primarily focused on employing data-free knowledge distillation to optimize data generators and ensemble models for better aggregating local knowledge into the server model. However, these methods typically struggle with data heterogeneity, where inconsistent local data distributions can cause teachers to provide misleading knowledge. Additionally, they may encounter scalability issues with complex datasets due to inherent two-step information loss: first, during local training (from data to model), and second, when transferring knowledge to the server model (from model to inversed data). In this paper, we propose FedSD2C, a novel and practical one-shot FL framework designed to address these challenges. FedSD2C introduces a distiller to synthesize informative distillates directly from local data to reduce information loss and proposes sharing synthetic distillates instead of inconsistent local models to tackle data heterogeneity. Our empirical results demonstrate that FedSD2C consistently outperforms other one-shot FL methods with more complex and real datasets, achieving up to 2.6 the performance of the best baseline. Code: https://github.com/Carkham/FedSD2C",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": "Accepted by NeurIPS 2024"
    },
    {
        "paper id": "2412.05196",
        "abstract url": "https://arxiv.org/abs/2412.05196",
        "title": "Exponential Speedups by Rerooting Levin Tree Search",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Levin Tree Search (LTS) (Orseau et al., 2018) is a search algorithm for deterministic environments that uses a user-specified policy to guide the search. It comes with a formal guarantee on the number of search steps for finding a solution node that depends on the quality of the policy. In this paper, we introduce a new algorithm, called $\\sqrt{\\text{LTS}}$ (pronounce root-LTS), which implicitly starts an LTS search rooted at every node of the search tree. Each LTS search is assigned a rerooting weight by a (user-defined or learnt) rerooter, and the search effort is shared between all LTS searches proportionally to their weights. The rerooting mechanism implicitly decomposes the search space into subtasks, leading to significant speedups. We prove that the number of search steps that $\\sqrt{\\text{LTS}}$ takes is competitive with the best decomposition into subtasks, at the price of a factor that relates to the uncertainty of the rerooter. If LTS takes time $T$, in the best case with $q$ rerooting points, $\\sqrt{\\text{LTS}}$ only takes time $O(q\\sqrt[q]{T})$. Like the policy, the rerooter can be learnt from data, and we expect $\\sqrt{\\text{LTS}}$ to be applicable to a wide range of domains.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05200",
        "abstract url": "https://arxiv.org/abs/2412.05200",
        "title": "Are Frontier Large Language Models Suitable for Q&A in Science Centres?",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper investigates the suitability of frontier Large Language Models (LLMs) for Q&A interactions in science centres, with the aim of boosting visitor engagement while maintaining factual accuracy. Using a dataset of questions collected from the National Space Centre in Leicester (UK), we evaluated responses generated by three leading models: OpenAI's GPT-4, Claude 3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard and creative responses tailored to an 8-year-old audience, and these responses were assessed by space science experts based on accuracy, engagement, clarity, novelty, and deviation from expected answers. The results revealed a trade-off between creativity and accuracy, with Claude outperforming GPT and Gemini in both maintaining clarity and engaging young audiences, even when asked to generate more creative responses. Nonetheless, experts observed that higher novelty was generally associated with reduced factual reliability across all models. This study highlights the potential of LLMs in educational settings, emphasizing the need for careful prompt engineering to balance engagement with scientific rigor.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "19 pages, 2 figures, 10 tables"
    },
    {
        "paper id": "2412.05204",
        "abstract url": "https://arxiv.org/abs/2412.05204",
        "title": "Global Optimization with A Power-Transformed Objective and Gaussian Smoothing",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We propose a novel method that solves global optimization problems in two steps: (1) perform a (exponential) power-$N$ transformation to the not-necessarily differentiable objective function $f$ to obtain $f_N$, and (2) optimize the Gaussian-smoothed $f_N$ with stochastic approximations. Under mild conditions on $f$, for any $\u03b4>0$, we prove that with a sufficiently large power $N_\u03b4$, this method converges to a solution in the $\u03b4$-neighborhood of $f$'s global maximum point. The convergence rate is $O(d^2\u03c3^4\\varepsilon^{-2})$, which is faster than both the standard and single-loop homotopy methods. Extensive experiments show that our method requires significantly fewer iterations than other compared algorithms to produce a high-quality solution.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05214",
        "abstract url": "https://arxiv.org/abs/2412.05214",
        "title": "AI's assigned gender affects human-AI cooperation",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Cooperation between humans and machines is increasingly vital as artificial intelligence (AI) becomes more integrated into daily life. Research indicates that people are often less willing to cooperate with AI agents than with humans, more readily exploiting AI for personal gain. While prior studies have shown that giving AI agents human-like features influences people's cooperation with them, the impact of AI's assigned gender remains underexplored. This study investigates how human cooperation varies based on gender labels assigned to AI agents with which they interact. In the Prisoner's Dilemma game, 402 participants interacted with partners labelled as AI (bot) or humans. The partners were also labelled male, female, non-binary, or gender-neutral. Results revealed that participants tended to exploit female-labelled and distrust male-labelled AI agents more than their human counterparts, reflecting gender biases similar to those in human-human interactions. These findings highlight the significance of gender biases in human-AI interactions that must be considered in future policy, design of interactive AI systems, and regulation of their use.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.GT",
            "cs.HC"
        ],
        "comment": "Manuscript under review"
    },
    {
        "paper id": "2412.05265",
        "abstract url": "https://arxiv.org/abs/2412.05265",
        "title": "Reinforcement Learning: An Overview",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "This manuscript gives a big-picture, up-to-date overview of the field of (deep) reinforcement learning and sequential decision making, covering value-based RL, policy-gradient methods, model-based methods, and various other topics (including a very brief discussion of RL+LLMs).",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05341",
        "abstract url": "https://arxiv.org/abs/2412.05341",
        "title": "Generative Model-Based Fusion for Improved Few-Shot Semantic Segmentation of Infrared Images",
        "rating": "0.5",
        "keywords": [
            [
                "autonomous driving",
                "Infrared"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Infrared (IR) imaging is commonly used in various scenarios, including autonomous driving, fire safety and defense applications. Thus, semantic segmentation of such images is of great interest. However, this task faces several challenges, including data scarcity, differing contrast and input channel number compared to natural images, and emergence of classes not represented in databases in certain scenarios, such as defense applications. Few-shot segmentation (FSS) provides a framework to overcome these issues by segmenting query images using a few labeled support samples. However, existing FSS models for IR images require paired visible RGB images, which is a major limitation since acquiring such paired data is difficult or impossible in some applications. In this work, we develop new strategies for FSS of IR images by using generative modeling and fusion techniques. To this end, we propose to synthesize auxiliary data to provide additional channel information to complement the limited contrast in the IR images, as well as IR data synthesis for data augmentation. Here, the former helps the FSS model to better capture the relationship between the support and query sets, while the latter addresses the issue of data scarcity. Finally, to further improve the former aspect, we propose a novel fusion ensemble module for integrating the two different modalities. Our methods are evaluated on different IR datasets, and improve upon the state-of-the-art (SOTA) FSS models.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "Winter Conference on Applications of Computer Vision (WACV), 2025"
    },
    {
        "paper id": "2412.05393",
        "abstract url": "https://arxiv.org/abs/2412.05393",
        "title": "HiVeGen -- Hierarchical LLM-based Verilog Generation for Scalable Chip Design",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "With Large Language Models (LLMs) recently demonstrating impressive proficiency in code generation, it is promising to extend their abilities to Hardware Description Language (HDL). However, LLMs tend to generate single HDL code blocks rather than hierarchical structures for hardware designs, leading to hallucinations, particularly in complex designs like Domain-Specific Accelerators (DSAs). To address this, we propose HiVeGen, a hierarchical LLM-based Verilog generation framework that decomposes generation tasks into LLM-manageable hierarchical submodules. HiVeGen further harnesses the advantages of such hierarchical structures by integrating automatic Design Space Exploration (DSE) into hierarchy-aware prompt generation, introducing weight-based retrieval to enhance code reuse, and enabling real-time human-computer interaction to lower error-correction cost, significantly improving the quality of generated designs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05418",
        "abstract url": "https://arxiv.org/abs/2412.05418",
        "title": "No Free Lunch From Random Feature Ensembles",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Given a budget on total model size, one must decide whether to train a single, large neural network or to combine the predictions of many smaller networks. We study this trade-off for ensembles of random-feature ridge regression models. We prove that when a fixed number of trainable parameters are partitioned among $K$ independently trained models, $K=1$ achieves optimal performance, provided the ridge parameter is optimally tuned. We then derive scaling laws which describe how the test risk of an ensemble of regression models decays with its total size. We identify conditions on the kernel and task eigenstructure under which ensembles can achieve near-optimal scaling laws. Training ensembles of deep convolutional neural networks on CIFAR-10 and a transformer architecture on C4, we find that a single large network outperforms any ensemble of networks with the same total number of parameters, provided the weight decay and feature-learning strength are tuned to their optimal values.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05433",
        "abstract url": "https://arxiv.org/abs/2412.05433",
        "title": "Swap Path Network for Robust Person Search Pre-training",
        "rating": "0.5",
        "keywords": [
            [
                "re-identification"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "In person search, we detect and rank matches to a query person image within a set of gallery scenes. Most person search models make use of a feature extraction backbone, followed by separate heads for detection and re-identification. While pre-training methods for vision backbones are well-established, pre-training additional modules for the person search task has not been previously examined. In this work, we present the first framework for end-to-end person search pre-training. Our framework splits person search into object-centric and query-centric methodologies, and we show that the query-centric framing is robust to label noise, and trainable using only weakly-labeled person bounding boxes. Further, we provide a novel model dubbed Swap Path Net (SPNet) which implements both query-centric and object-centric training objectives, and can swap between the two while using the same weights. Using SPNet, we show that query-centric pre-training, followed by object-centric fine-tuning, achieves state-of-the-art results on the standard PRW and CUHK-SYSU person search benchmarks, with 96.4% mAP on CUHK-SYSU and 61.2% mAP on PRW. In addition, we show that our method is more effective, efficient, and robust for person search pre-training than recent backbone-only pre-training alternatives.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "WACV 2025; Code: https://github.com/LLNL/spnet"
    },
    {
        "paper id": "2412.05445",
        "abstract url": "https://arxiv.org/abs/2412.05445",
        "title": "From Voice to Value: Leveraging AI to Enhance Spoken Online Reviews on the Go",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Online reviews help people make better decisions. Review platforms usually depend on typed input, where leaving a good review requires significant effort because users must carefully organize and articulate their thoughts. This may discourage users from leaving comprehensive and high-quality reviews, especially when they are on the go. To address this challenge, we developed Vocalizer, a mobile application that enables users to provide reviews through voice input, with enhancements from a large language model (LLM). In a longitudinal study, we analysed user interactions with the app, focusing on AI-driven features that help refine and improve reviews. Our findings show that users frequently utilized the AI agent to add more detailed information to their reviews. We also show how interactive AI features can improve users self-efficacy and willingness to share reviews online. Finally, we discuss the opportunities and challenges of integrating AI assistance into review-writing systems.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05450",
        "abstract url": "https://arxiv.org/abs/2412.05450",
        "title": "Promoting Cooperation in the Public Goods Game using Artificial Intelligent Agents",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "The tragedy of the commons illustrates a fundamental social dilemma where individual rational actions lead to collectively undesired outcomes, threatening the sustainability of shared resources. Strategies to escape this dilemma, however, are in short supply. In this study, we explore how artificial intelligence (AI) agents can be leveraged to enhance cooperation in public goods games, moving beyond traditional regulatory approaches to using AI as facilitators of cooperation. We investigate three scenarios: (1) Mandatory Cooperation Policy for AI Agents, where AI agents are institutionally mandated always to cooperate; (2) Player-Controlled Agent Cooperation Policy, where players evolve control over AI agents' likelihood to cooperate; and (3) Agents Mimic Players, where AI agents copy the behavior of players. Using a computational evolutionary model with a population of agents playing public goods games, we find that only when AI agents mimic player behavior does the critical synergy threshold for cooperation decrease, effectively resolving the dilemma. This suggests that we can leverage AI to promote collective well-being in societal dilemmas by designing AI agents to mimic human players.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "nlin.AO",
            "q-bio.PE"
        ],
        "comment": "16 pages, 6 figures"
    },
    {
        "paper id": "2412.05467",
        "abstract url": "https://arxiv.org/abs/2412.05467",
        "title": "The BrowserGym Ecosystem for Web Agent Research",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The BrowserGym ecosystem addresses the growing need for efficient evaluation and benchmarking of web agents, particularly those leveraging automation and Large Language Models (LLMs) for web interaction tasks. Many existing benchmarks suffer from fragmentation and inconsistent evaluation methodologies, making it challenging to achieve reliable comparisons and reproducible results. BrowserGym aims to solve this by providing a unified, gym-like environment with well-defined observation and action spaces, facilitating standardized evaluation across diverse benchmarks. Combined with AgentLab, a complementary framework that aids in agent creation, testing, and analysis, BrowserGym offers flexibility for integrating new benchmarks while ensuring consistent evaluation and comprehensive experiment management. This standardized approach seeks to reduce the time and complexity of developing web agents, supporting more reliable comparisons and facilitating in-depth analysis of agent behaviors, and could result in more adaptable, capable agents, ultimately accelerating innovation in LLM-driven automation. As a supporting evidence, we conduct the first large-scale, multi-benchmark web agent experiment and compare the performance of 6 state-of-the-art LLMs across all benchmarks currently available in BrowserGym. Among other findings, our results highlight a large discrepancy between OpenAI and Anthropic's latests models, with Claude-3.5-Sonnet leading the way on almost all benchmarks, except on vision-related tasks where GPT-4o is superior. Despite these advancements, our results emphasize that building robust and efficient web agents remains a significant challenge, due to the inherent complexity of real-world web environments and the limitations of current models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05469",
        "abstract url": "https://arxiv.org/abs/2412.05469",
        "title": "Multi-Objective Alignment of Large Language Models Through Hypervolume Maximization",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Multi-objective alignment from human feedback (MOAHF) in large language models (LLMs) is a challenging problem as human preferences are complex, multifaceted, and often conflicting. Recent works on MOAHF considered a-priori multi-objective optimization (MOO), where human preferences are known at training or inference time. In contrast, when human preferences are unknown or difficult to quantify, a natural approach is to cover the Pareto front by multiple diverse solutions. We propose an algorithm HaM for learning diverse LLM policies that maximizes their hypervolume. This is the first application of a-posteriori MOO to MOAHF. HaM is computationally and space efficient, and empirically superior across objectives such as harmlessness, helpfulness, humor, faithfulness, and hallucination, on various datasets.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05475",
        "abstract url": "https://arxiv.org/abs/2412.05475",
        "title": "AI-powered Digital Twin of the Ocean: Reliable Uncertainty Quantification for Real-time Wave Height Prediction with Deep Ensemble",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Environmental pollution and the depletion of fossil fuels have prompted the need for eco-friendly power generation methods based on renewable energy. However, renewable energy sources often face challenges in providing stable power due to low energy density and non-stationary. Wave energy converters (WECs), in particular, need reliable real-time wave height prediction to address these issues caused by irregular wave patterns, which can lead to the inefficient and unstable operation of WECs. In this study, we propose an AI-powered reliable real-time wave height prediction model, aiming both high predictive accuracy and reliable uncertainty quantification (UQ). The proposed architecture LSTM-DE, integrates long short-term memory (LSTM) networks for temporal prediction with deep ensemble (DE) for robust UQ, achieving accuracy and reliability in wave height prediction. To further enhance the reliability of the predictive models, uncertainty calibration is applied, which has proven to significantly improve the quality of the quantified uncertainty. Based on the real operational data obtained from an oscillating water column-wave energy converter (OWC-WEC) system in Jeju, South Korea, we demonstrate that the proposed LSTM-DE model architecture achieves notable predictive accuracy (R2 > 0.9) while increasing the uncertainty quality by over 50% through simple calibration technique. Furthermore, a comprehensive parametric study is conducted to explore the effects of key model hyperparameters, offering valuable guidelines for diverse operational scenarios, characterized by differences in wavelength, amplitude, and period. The findings show that the proposed method provides robust and reliable real-time wave height predictions, facilitating digital twin of the ocean.",
        "subjects": [
            "cs.LG",
            "cs.CE",
            "eess.SP",
            "physics.ao-ph"
        ],
        "comment": "23 pages, 13 figures"
    },
    {
        "paper id": "2412.05496",
        "abstract url": "https://arxiv.org/abs/2412.05496",
        "title": "Flex Attention: A Programming Model for Generating Optimized Attention Kernels",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "Over the past 7 years, attention has become one of the most important primitives in deep learning. The primary approach to optimize attention is FlashAttention, which fuses the operation together, drastically improving both the runtime and the memory consumption. However, the importance of FlashAttention combined with its monolithic nature poses a problem for researchers aiming to try new attention variants -- a \"software lottery\". This problem is exacerbated by the difficulty of writing efficient fused attention kernels, resisting traditional compiler-based approaches. We introduce FlexAttention, a novel compiler-driven programming model that allows implementing the majority of attention variants in a few lines of idiomatic PyTorch code. We demonstrate that many existing attention variants (e.g. Alibi, Document Masking, PagedAttention, etc.) can be implemented via FlexAttention, and that we achieve competitive performance compared to these handwritten kernels. Finally, we demonstrate how FlexAttention allows for easy composition of attention variants, solving the combinatorial explosion of attention variants.",
        "subjects": [
            "cs.LG",
            "cs.PF",
            "cs.PL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05505",
        "abstract url": "https://arxiv.org/abs/2412.05505",
        "title": "Trimming Down Large Spiking Vision Transformers via Heterogeneous Quantization Search",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Spiking Neural Networks (SNNs) are amenable to deployment on edge devices and neuromorphic hardware due to their lower dissipation. Recently, SNN-based transformers have garnered significant interest, incorporating attention mechanisms akin to their counterparts in Artificial Neural Networks (ANNs) while demonstrating excellent performance. However, deploying large spiking transformer models on resource-constrained edge devices such as mobile phones, still poses significant challenges resulted from the high computational demands of large uncompressed high-precision models. In this work, we introduce a novel heterogeneous quantization method for compressing spiking transformers through layer-wise quantization. Our approach optimizes the quantization of each layer using one of two distinct quantization schemes, i.e., uniform or power-of-two quantification, with mixed bit resolutions. Our heterogeneous quantization demonstrates the feasibility of maintaining high performance for spiking transformers while utilizing an average effective resolution of 3.14-3.67 bits with less than a 1% accuracy drop on DVS Gesture and CIFAR10-DVS datasets. It attains a model compression rate of 8.71x-10.19x for standard floating-point spiking transformers. Moreover, the proposed approach achieves a significant energy reduction of 5.69x, 8.72x, and 10.2x while maintaining high accuracy levels of 85.3%, 97.57%, and 80.4% on N-Caltech101, DVS-Gesture, and CIFAR10-DVS datasets, respectively.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05506",
        "abstract url": "https://arxiv.org/abs/2412.05506",
        "title": "Ranking of Large Language Model with Nonparametric Prompts",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "We consider the inference for the ranking of large language models (LLMs). Alignment arises as a big challenge to mitigate hallucinations in the use of LLMs. Ranking LLMs has been shown as a well-performing tool to improve alignment based on the best-of-$N$ policy. In this paper, we propose a new inferential framework for testing hypotheses and constructing confidence intervals of the ranking of language models. We consider the widely adopted Bradley-Terry-Luce (BTL) model, where each item is assigned a positive preference score that determines its pairwise comparisons' outcomes. We further extend it into the contextual setting, where the score of each model varies with the prompt. We show the convergence rate of our estimator. By extending the current Gaussian multiplier bootstrap theory to accommodate the supremum of not identically distributed empirical processes, we construct the confidence interval for ranking and propose a valid testing procedure. We also introduce the confidence diagram as a global ranking property. We conduct numerical experiments to assess the performance of our method.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05520",
        "abstract url": "https://arxiv.org/abs/2412.05520",
        "title": "More than Marketing? On the Information Value of AI Benchmarks for Practitioners",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Public AI benchmark results are widely broadcast by model developers as indicators of model quality within a growing and competitive market. However, these advertised scores do not necessarily reflect the traits of interest to those who will ultimately apply AI models. In this paper, we seek to understand if and how AI benchmarks are used to inform decision-making. Based on the analyses of interviews with 19 individuals who have used, or decided against using, benchmarks in their day-to-day work, we find that across these settings, participants use benchmarks as a signal of relative performance difference between models. However, whether this signal was considered a definitive sign of model superiority, sufficient for downstream decisions, varied. In academia, public benchmarks were generally viewed as suitable measures for capturing research progress. By contrast, in both product and policy, benchmarks -- even those developed internally for specific tasks -- were often found to be inadequate for informing substantive decisions. Of the benchmarks deemed unsatisfactory, respondents reported that their goals were neither well-defined nor reflective of real-world use. Based on the study results, we conclude that effective benchmarks should provide meaningful, real-world evaluations, incorporate domain expertise, and maintain transparency in scope and goals. They must capture diverse, task-relevant capabilities, be challenging enough to avoid quick saturation, and account for trade-offs in model performance rather than relying on a single score. Additionally, proprietary data collection and contamination prevention are critical for producing reliable and actionable results. By adhering to these criteria, benchmarks can move beyond mere marketing tricks into robust evaluative frameworks.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05528",
        "abstract url": "https://arxiv.org/abs/2412.05528",
        "title": "AI Planning: A Primer and Survey (Preliminary Report)",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI"
            ]
        ],
        "abstract": "Automated decision-making is a fundamental topic that spans multiple sub-disciplines in AI: reinforcement learning (RL), AI planning (AP), foundation models, and operations research, among others. Despite recent efforts to ``bridge the gaps'' between these communities, there remain many insights that have not yet transcended the boundaries. Our goal in this paper is to provide a brief and non-exhaustive primer on ideas well-known in AP, but less so in other sub-disciplines. We do so by introducing the classical AP problem and representation, and extensions that handle uncertainty and time through the Markov Decision Process formalism. Next, we survey state-of-the-art techniques and ideas for solving AP problems, focusing on their ability to exploit problem structure. Lastly, we cover subfields within AP for learning structure from unstructured inputs and learning to generalise to unseen scenarios and situations.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06829",
        "abstract url": "https://arxiv.org/abs/2412.06829",
        "title": "Stably unactivated neurons in ReLU neural networks",
        "rating": "0.5",
        "keywords": [
            [
                "cs.LG"
            ]
        ],
        "abstract": "The choice of architecture of a neural network influences which functions will be realizable by that neural network and, as a result, studying the expressiveness of a chosen architecture has received much attention. In ReLU neural networks, the presence of stably unactivated neurons can reduce the network's expressiveness. In this work, we investigate the probability of a neuron in the second hidden layer of such neural networks being stably unactivated when the weights and biases are initialized from symmetric probability distributions. For networks with input dimension $n_0$, we prove that if the first hidden layer has $n_0+1$ neurons then this probability is exactly $\\frac{2^{n_0}+1}{4^{n_0+1}}$, and if the first hidden layer has $n_1$ neurons, $n_1 \\le n_0$, then the probability is $\\frac{1}{2^{n_1+1}}$. Finally, for the case when the first hidden layer has more neurons than $n_0+1$, a conjecture is proposed along with the rationale. Computational evidence is presented to support the conjecture.",
        "subjects": [
            "cs.LG",
            "math.PR",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06833",
        "abstract url": "https://arxiv.org/abs/2412.06833",
        "title": "Detecting Fake News on Social Media: A Novel Reliability Aware Machine-Crowd Hybrid Intelligence-Based Method",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Fake news on social media platforms poses a significant threat to societal systems, underscoring the urgent need for advanced detection methods. The existing detection methods can be divided into machine intelligence-based, crowd intelligence-based, and hybrid intelligence-based methods. Among them, hybrid intelligence-based methods achieve the best performance but fail to consider the reliability issue in detection. In light of this, we propose a novel Reliability Aware Hybrid Intelligence (RAHI) method for fake news detection. Our method comprises three integral modules. The first module employs a Bayesian deep learning model to capture the inherent reliability within machine intelligence. The second module uses an Item Response Theory (IRT)-based user response aggregation to account for the reliability in crowd intelligence. The third module introduces a new distribution fusion mechanism, which takes the distributions derived from both machine and crowd intelligence as input, and outputs a fused distribution that provides predictions along with the associated reliability. The experiments on the Weibo dataset demonstrate the advantages of our method. This study contributes to the research field with a novel RAHI-based method, and the code is shared at https://github.com/Kangwei-g/RAHI. This study has practical implications for three key stakeholders: internet users, online platform managers, and the government.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06834",
        "abstract url": "https://arxiv.org/abs/2412.06834",
        "title": "Investigating social alignment via mirroring in a system of interacting language models",
        "rating": "0.5",
        "keywords": [
            [
                "cs.AI",
                "cs.CY"
            ]
        ],
        "abstract": "Alignment is a social phenomenon wherein individuals share a common goal or perspective. Mirroring, or mimicking the behaviors and opinions of another individual, is one mechanism by which individuals can become aligned. Large scale investigations of the effect of mirroring on alignment have been limited due to the scalability of traditional experimental designs in sociology. In this paper, we introduce a simple computational framework that enables studying the effect of mirroring behavior on alignment in multi-agent systems. We simulate systems of interacting large language models in this framework and characterize overall system behavior and alignment with quantitative measures of agent dynamics. We find that system behavior is strongly influenced by the range of communication of each agent and that these effects are exacerbated by increased rates of mirroring. We discuss the observed simulated system behavior in the context of known human social dynamics.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04784",
        "abstract url": "https://arxiv.org/abs/2412.04784",
        "title": "NLP-ADBench: NLP Anomaly Detection Benchmark",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Anomaly detection (AD) is a critical machine learning task with diverse applications in web systems, including fraud detection, content moderation, and user behavior analysis. Despite its significance, AD in natural language processing (NLP) remains underexplored, limiting advancements in detecting anomalies in text data such as harmful content, phishing attempts, or spam reviews. In this paper, we introduce NLP-ADBench, the most comprehensive benchmark for NLP anomaly detection (NLP-AD), comprising eight curated datasets and evaluations of nineteen state-of-the-art algorithms. These include three end-to-end methods and sixteen two-step algorithms that apply traditional anomaly detection techniques to language embeddings generated by bert-base-uncased and OpenAI's text-embedding-3-large models. Our results reveal critical insights and future directions for NLP-AD. Notably, no single model excels across all datasets, highlighting the need for automated model selection. Moreover, two-step methods leveraging transformer-based embeddings consistently outperform specialized end-to-end approaches, with OpenAI embeddings demonstrating superior performance over BERT embeddings. By releasing NLP-ADBench at https://github.com/USC-FORTIS/NLP-ADBench, we provide a standardized framework for evaluating NLP-AD methods, fostering the development of innovative approaches. This work fills a crucial gap in the field and establishes a foundation for advancing NLP anomaly detection, particularly in the context of improving the safety and reliability of web-based systems.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "comment": "The project is available at https://github.com/USC-FORTIS/NLP-ADBench"
    },
    {
        "paper id": "2412.04814",
        "abstract url": "https://arxiv.org/abs/2412.04814",
        "title": "LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment",
        "rating": "0",
        "keywords": [
            [
                "Text-to-Video"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advancements in text-to-video (T2V) generative models have shown impressive capabilities. However, these models are still inadequate in aligning synthesized videos with human preferences (e.g., accurately reflecting text descriptions), which is particularly difficult to address, as human preferences are inherently subjective and challenging to formalize as objective functions. Therefore, this paper proposes LiFT, a novel fine-tuning method leveraging human feedback for T2V model alignment. Specifically, we first construct a Human Rating Annotation dataset, LiFT-HRA, consisting of approximately 10k human annotations, each including a score and its corresponding rationale. Based on this, we train a reward model LiFT-Critic to learn reward function effectively, which serves as a proxy for human judgment, measuring the alignment between given videos and human expectations. Lastly, we leverage the learned reward function to align the T2V model by maximizing the reward-weighted likelihood. As a case study, we apply our pipeline to CogVideoX-2B, showing that the fine-tuned model outperforms the CogVideoX-5B across all 16 metrics, highlighting the potential of human feedback in improving the alignment and quality of synthesized videos.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "project page: https://codegoat24.github.io/LiFT"
    },
    {
        "paper id": "2412.04855",
        "abstract url": "https://arxiv.org/abs/2412.04855",
        "title": "GS-Matching: Reconsidering Feature Matching task in Point Cloud Registration",
        "rating": "0",
        "keywords": [
            [
                "Point Cloud"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Traditional point cloud registration (PCR) methods for feature matching often employ the nearest neighbor policy. This leads to many-to-one matches and numerous potential inliers without any corresponding point. Recently, some approaches have framed the feature matching task as an assignment problem to achieve optimal one-to-one matches. We argue that the transition to the Assignment problem is not reliable for general correspondence-based PCR. In this paper, we propose a heuristics stable matching policy called GS-matching, inspired by the Gale-Shapley algorithm. Compared to the other matching policies, our method can perform efficiently and find more non-repetitive inliers under low overlapping conditions. Furthermore, we employ the probability theory to analyze the feature matching task, providing new insights into this research problem. Extensive experiments validate the effectiveness of our matching policy, achieving better registration recall on multiple datasets.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04867",
        "abstract url": "https://arxiv.org/abs/2412.04867",
        "title": "MANTA: A Large-Scale Multi-View and Visual-Text Anomaly Detection Dataset for Tiny Objects",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present MANTA, a visual-text anomaly detection dataset for tiny objects. The visual component comprises over 137.3K images across 38 object categories spanning five typical domains, of which 8.6K images are labeled as anomalous with pixel-level annotations. Each image is captured from five distinct viewpoints to ensure comprehensive object coverage. The text component consists of two subsets: Declarative Knowledge, including 875 words that describe common anomalies across various domains and specific categories, with detailed explanations for < what, why, how>, including causes and visual characteristics; and Constructivist Learning, providing 2K multiple-choice questions with varying levels of difficulty, each paired with images and corresponded answer explanations. We also propose a baseline for visual-text tasks and conduct extensive benchmarking experiments to evaluate advanced methods across different settings, highlighting the challenges and efficacy of our dataset.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "https://grainnet.github.io/MANTA"
    },
    {
        "paper id": "2412.04887",
        "abstract url": "https://arxiv.org/abs/2412.04887",
        "title": "Momentum-GS: Momentum Gaussian Self-Distillation for High-Quality Large Scene Reconstruction",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "3D Gaussian Splatting has demonstrated notable success in large-scale scene reconstruction, but challenges persist due to high training memory consumption and storage overhead. Hybrid representations that integrate implicit and explicit features offer a way to mitigate these limitations. However, when applied in parallelized block-wise training, two critical issues arise since reconstruction accuracy deteriorates due to reduced data diversity when training each block independently, and parallel training restricts the number of divided blocks to the available number of GPUs. To address these issues, we propose Momentum-GS, a novel approach that leverages momentum-based self-distillation to promote consistency and accuracy across the blocks while decoupling the number of blocks from the physical GPU count. Our method maintains a teacher Gaussian decoder updated with momentum, ensuring a stable reference during training. This teacher provides each block with global guidance in a self-distillation manner, promoting spatial consistency in reconstruction. To further ensure consistency across the blocks, we incorporate block weighting, dynamically adjusting each block's weight according to its reconstruction accuracy. Extensive experiments on large-scale scenes show that our method consistently outperforms existing techniques, achieving a 12.8% improvement in LPIPS over CityGaussian with much fewer divided blocks and establishing a new state of the art. Project page: https://jixuan-fan.github.io/Momentum-GS_Page/",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04912",
        "abstract url": "https://arxiv.org/abs/2412.04912",
        "title": "UniMIC: Towards Universal Multi-modality Perceptual Image Compression",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We present UniMIC, a universal multi-modality image compression framework, intending to unify the rate-distortion-perception (RDP) optimization for multiple image codecs simultaneously through excavating cross-modality generative priors. Unlike most existing works that need to design and optimize image codecs from scratch, our UniMIC introduces the visual codec repository, which incorporates amounts of representative image codecs and directly uses them as the basic codecs for various practical applications. Moreover, we propose multi-grained textual coding, where variable-length content prompt and compression prompt are designed and encoded to assist the perceptual reconstruction through the multi-modality conditional generation. In particular, a universal perception compensator is proposed to improve the perception quality of decoded images from all basic codecs at the decoder side by reusing text-assisted diffusion priors from stable diffusion. With the cooperation of the above three strategies, our UniMIC achieves a significant improvement of RDP optimization for different compression codecs, e.g., traditional and learnable codecs, and different compression costs, e.g., ultra-low bitrates. The code will be available in https://github.com/Amygyx/UniMIC .",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04931",
        "abstract url": "https://arxiv.org/abs/2412.04931",
        "title": "DEYOLO: Dual-Feature-Enhancement YOLO for Cross-Modality Object Detection",
        "rating": "0",
        "keywords": [
            [
                "infrared"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Object detection in poor-illumination environments is a challenging task as objects are usually not clearly visible in RGB images. As infrared images provide additional clear edge information that complements RGB images, fusing RGB and infrared images has potential to enhance the detection ability in poor-illumination environments. However, existing works involving both visible and infrared images only focus on image fusion, instead of object detection. Moreover, they directly fuse the two kinds of image modalities, which ignores the mutual interference between them. To fuse the two modalities to maximize the advantages of cross-modality, we design a dual-enhancement-based cross-modality object detection network DEYOLO, in which semantic-spatial cross modality and novel bi-directional decoupled focus modules are designed to achieve the detection-centered mutual enhancement of RGB-infrared (RGB-IR). Specifically, a dual semantic enhancing channel weight assignment module (DECA) and a dual spatial enhancing pixel weight assignment module (DEPA) are firstly proposed to aggregate cross-modality information in the feature space to improve the feature representation ability, such that feature fusion can aim at the object detection task. Meanwhile, a dual-enhancement mechanism, including enhancements for two-modality fusion and single modality, is designed in both DECAand DEPAto reduce interference between the two kinds of image modalities. Then, a novel bi-directional decoupled focus is developed to enlarge the receptive field of the backbone network in different directions, which improves the representation quality of DEYOLO. Extensive experiments on M3FD and LLVIP show that our approach outperforms SOTA object detection algorithms by a clear margin. Our code is available at https://github.com/chips96/DEYOLO.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04942",
        "abstract url": "https://arxiv.org/abs/2412.04942",
        "title": "A Federated Approach to Few-Shot Hate Speech Detection for Marginalized Communities",
        "rating": "0",
        "keywords": [
            [
                "federated learning"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Hate speech online remains an understudied issue for marginalized communities, and has seen rising relevance, especially in the Global South, which includes developing societies with increasing internet penetration. In this paper, we aim to provide marginalized communities living in societies where the dominant language is low-resource with a privacy-preserving tool to protect themselves from hate speech on the internet by filtering offensive content in their native languages. Our contribution in this paper is twofold: 1) we release REACT (REsponsive hate speech datasets Across ConTexts), a collection of high-quality, culture-specific hate speech detection datasets comprising seven distinct target groups in eight low-resource languages, curated by experienced data collectors; 2) we propose a solution to few-shot hate speech detection utilizing federated learning (FL), a privacy-preserving and collaborative learning approach, to continuously improve a central model that exhibits robustness when tackling different target groups and languages. By keeping the training local to the users' devices, we ensure the privacy of the users' data while benefitting from the efficiency of federated learning. Furthermore, we personalize client models to target-specific training data and evaluate their performance. Our results indicate the effectiveness of FL across different target groups, whereas the benefits of personalization on few-shot learning are not clear.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04948",
        "abstract url": "https://arxiv.org/abs/2412.04948",
        "title": "KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning",
        "rating": "0",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "Autoregressive large language models (LLMs) pre-trained by next token prediction are inherently proficient in generative tasks. However, their performance on knowledge-driven tasks such as factual knowledge querying remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured knowledge bases, can provide reliable knowledge for LLMs, potentially compensating for their knowledge deficiencies. Aligning LLMs with explicit, structured knowledge from KGs has been a challenge; previous attempts either failed to effectively align knowledge representations or compromised the generative capabilities of LLMs, leading to less-than-optimal outcomes. This paper proposes \\textbf{KaLM}, a \\textit{Knowledge-aligned Language Modeling} approach, which fine-tunes autoregressive LLMs to align with KG knowledge via the joint objective of explicit knowledge alignment and implicit knowledge alignment. The explicit knowledge alignment objective aims to directly optimize the knowledge representation of LLMs through dual-view knowledge graph contrastive learning. The implicit knowledge alignment objective focuses on incorporating textual patterns of knowledge into LLMs through triple completion language modeling. Notably, our method achieves a significant performance boost in evaluations of knowledge-driven tasks, specifically embedding-based knowledge graph completion and generation-based knowledge graph question answering.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04954",
        "abstract url": "https://arxiv.org/abs/2412.04954",
        "title": "Gla-AI4BioMed at RRG24: Visual Instruction-tuned Adaptation for Radiology Report Generation",
        "rating": "0",
        "keywords": [
            [
                "visual language"
            ],
            [
                "X-ray",
                "Radiology"
            ],
            [
                "cs.LG",
                "cs.CV",
                "cs.CL"
            ]
        ],
        "abstract": "We introduce a radiology-focused visual language model designed to generate radiology reports from chest X-rays. Building on previous findings that large language models (LLMs) can acquire multimodal capabilities when aligned with pretrained vision encoders, we demonstrate similar potential with chest X-ray images. This integration enhances the ability of model to understand and describe chest X-ray images. Our model combines an image encoder with a fine-tuned LLM based on the Vicuna-7B architecture, enabling it to generate different sections of a radiology report with notable accuracy. The training process involves a two-stage approach: (i) initial alignment of chest X-ray features with the LLM (ii) followed by fine-tuning for radiology report generation.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "comment": "Accepted by BioNLP@ACL 2024"
    },
    {
        "paper id": "2412.04955",
        "abstract url": "https://arxiv.org/abs/2412.04955",
        "title": "MixedGaussianAvatar: Realistically and Geometrically Accurate Head Avatar via Mixed 2D-3D Gaussian Splatting",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "NeRF",
                "Radiance Fields",
                "Avatar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Reconstructing high-fidelity 3D head avatars is crucial in various applications such as virtual reality. The pioneering methods reconstruct realistic head avatars with Neural Radiance Fields (NeRF), which have been limited by training and rendering speed. Recent methods based on 3D Gaussian Splatting (3DGS) significantly improve the efficiency of training and rendering. However, the surface inconsistency of 3DGS results in subpar geometric accuracy; later, 2DGS uses 2D surfels to enhance geometric accuracy at the expense of rendering fidelity. To leverage the benefits of both 2DGS and 3DGS, we propose a novel method named MixedGaussianAvatar for realistically and geometrically accurate head avatar reconstruction. Our main idea is to utilize 2D Gaussians to reconstruct the surface of the 3D head, ensuring geometric accuracy. We attach the 2D Gaussians to the triangular mesh of the FLAME model and connect additional 3D Gaussians to those 2D Gaussians where the rendering quality of 2DGS is inadequate, creating a mixed 2D-3D Gaussian representation. These 2D-3D Gaussians can then be animated using FLAME parameters. We further introduce a progressive training strategy that first trains the 2D Gaussians and then fine-tunes the mixed 2D-3D Gaussians. We demonstrate the superiority of MixedGaussianAvatar through comprehensive experiments. The code will be released at: https://github.com/ChenVoid/MGA/.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project: https://chenvoid.github.io/MGA/"
    },
    {
        "paper id": "2412.04990",
        "abstract url": "https://arxiv.org/abs/2412.04990",
        "title": "ETLNet: An Efficient TCN-BiLSTM Network for Road Anomaly Detection Using Smartphone Sensors",
        "rating": "0",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Road anomalies can be defined as irregularities on the road surface or in the surface itself. Some may be intentional (such as speedbumps), accidental (such as materials falling off a truck), or the result of roads' excessive use or low or no maintenance, such as potholes. Despite their varying origins, these irregularities often harm vehicles substantially. Speed bumps are intentionally placed for safety but are dangerous due to their non-standard shape, size, and lack of proper markings. Potholes are unintentional and can also cause severe damage. To address the detection of these anomalies, we need an automated road monitoring system. Today, various systems exist that use visual information to track these anomalies. Still, due to poor lighting conditions and improper or missing markings, they may go undetected and have severe consequences for public transport, automated vehicles, etc. In this paper, the Enhanced Temporal-BiLSTM Network (ETLNet) is introduced as a novel approach that integrates two Temporal Convolutional Network (TCN) layers with a Bidirectional Long Short-Term Memory (BiLSTM) layer. This combination is tailored to detect anomalies effectively irrespective of lighting conditions, as it depends not on visuals but smartphone inertial sensor data. Our methodology employs accelerometer and gyroscope sensors, typically in smartphones, to gather data on road conditions. Empirical evaluations demonstrate that the ETLNet model maintains an F1-score for detecting speed bumps of 99.3%. The ETLNet model's robustness and efficiency significantly advance automated road surface monitoring technologies.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Presented in ICPR 2024, Kolkata, December 1-5, 2024 (First Workshop on Intelligent Mobility in Unstructured Environments)"
    },
    {
        "paper id": "2412.05003",
        "abstract url": "https://arxiv.org/abs/2412.05003",
        "title": "SLayR: Scene Layout Generation with Rectified Flow",
        "rating": "0",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We introduce SLayR, Scene Layout Generation with Rectified flow. State-of-the-art text-to-image models achieve impressive results. However, they generate images end-to-end, exposing no fine-grained control over the process. SLayR presents a novel transformer-based rectified flow model for layout generation over a token space that can be decoded into bounding boxes and corresponding labels, which can then be transformed into images using existing models. We show that established metrics for generated images are inconclusive for evaluating their underlying scene layout, and introduce a new benchmark suite, including a carefully designed repeatable human-evaluation procedure that assesses the plausibility and variety of generated layouts. In contrast to previous works, which perform well in either high variety or plausibility, we show that our approach performs well on both of these axes at the same time. It is also at least 5x times smaller in the number of parameters and 37% faster than the baselines. Our complete text-to-image pipeline demonstrates the added benefits of an interpretable and editable intermediate representation.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "34 pages, 29 figures, 5 tables"
    },
    {
        "paper id": "2412.05028",
        "abstract url": "https://arxiv.org/abs/2412.05028",
        "title": "Unifying Dual-Space Embedding for Entity Alignment via Contrastive Learning",
        "rating": "0",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Entity alignment aims to match identical entities across different knowledge graphs (KGs). Graph neural network-based entity alignment methods have achieved promising results in Euclidean space. However, KGs often contain complex structures, including both local and hierarchical ones, which make it challenging to efficiently represent them within a single space. In this paper, we proposed a novel method UniEA, which unifies dual-space embedding to preserve the intrinsic structure of KGs. Specifically, we learn graph structure embedding in both Euclidean and hyperbolic spaces simultaneously to maximize the consistency between the embedding in both spaces. Moreover, we employ contrastive learning to mitigate the misalignment issues caused by similar entities, where embedding of similar neighboring entities within the KG become too close in distance. Extensive experiments on benchmark datasets demonstrate that our method achieves state-of-the-art performance in structure-based EA. Our code is available at https://github.com/wonderCS1213/UniEA.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "Accepted by COLING2025"
    },
    {
        "paper id": "2412.05074",
        "abstract url": "https://arxiv.org/abs/2412.05074",
        "title": "LoFi: Vision-Aided Label Generator for Wi-Fi Localization and Tracking",
        "rating": "0",
        "keywords": [
            [
                "lidar"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Wi-Fi localization and tracking has shown immense potential due to its privacy-friendliness, wide coverage, permeability, independence from lighting conditions, and low cost. Current methods can be broadly categorized as model-based and data-driven approaches, where data-driven methods show better performance and have less requirement for specialized devices, but struggle with limited datasets for training. Due to limitations in current data collection methods, most datasets only provide coarse-grained ground truth (GT) or limited amount of label points, which greatly hinders the development of data-driven methods. Even though lidar can provide accurate GT, their high cost makes them inaccessible to many users. To address these challenges, we propose LoFi, a vision-aided label generator for Wi-Fi localization and tracking, which can generate ground truth position coordinates solely based on 2D images. The easy and quick data collection method also helps data-driven based methods deploy in practice, since Wi-Fi is a low-generalization modality and when using relevant methods, it always requires fine-tuning the model using newly collected data. Based on our method, we also collect a Wi-Fi tracking and localization dataset using ESP32-S3 and a webcam. To facilitate future research, we will make our code and dataset publicly available upon publication.",
        "subjects": [
            "cs.CV",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05101",
        "abstract url": "https://arxiv.org/abs/2412.05101",
        "title": "The Silent Prompt: Initial Noise as Implicit Guidance for Goal-Driven Image Generation",
        "rating": "0",
        "keywords": [
            [
                "diffusion",
                "Text-to-image"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-image synthesis (T2I) has advanced remarkably with the emergence of large-scale diffusion models. In the conventional setup, the text prompt provides explicit, user-defined guidance, directing the generation process by denoising a randomly sampled Gaussian noise. In this work, we reveal that the often-overlooked noise itself encodes inherent generative tendencies, acting as a \"silent prompt\" that implicitly guides the output. This implicit guidance, embedded in the noise scheduler design of diffusion model formulations and their training stages, generalizes across a wide range of T2I models and backbones. Building on this insight, we introduce NoiseQuery, a novel strategy that selects optimal initial noise from a pre-built noise library to meet diverse user needs. Our approach not only enhances high-level semantic alignment with text prompts, but also allows for nuanced adjustments of low-level visual attributes, such as texture, sharpness, shape, and color, which are typically challenging to control through text alone. Extensive experiments across various models and target attributes demonstrate the strong performance and zero-shot transferability of our approach, requiring no additional optimization.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 18 figures, 6 tables"
    },
    {
        "paper id": "2412.05149",
        "abstract url": "https://arxiv.org/abs/2412.05149",
        "title": "Findings of the Second BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora",
        "rating": "0",
        "keywords": [
            [
                "vision language"
            ],
            [
                "grammatical"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "The BabyLM Challenge is a community effort to close the data-efficiency gap between human and computational language learners. Participants compete to optimize language model training on a fixed language data budget of 100 million words or less. This year, we released improved text corpora, as well as a vision-and-language corpus to facilitate research into cognitively plausible vision language models. Submissions were compared on evaluation tasks targeting grammatical ability, (visual) question answering, pragmatic abilities, and grounding, among other abilities. Participants could submit to a 10M-word text-only track, a 100M-word text-only track, and/or a 100M-word and image multimodal track. From 31 submissions employing diverse methods, a hybrid causal-masked language model architecture outperformed other approaches. No submissions outperformed the baselines in the multimodal track. In follow-up analyses, we found a strong relationship between training FLOPs and average performance across tasks, and that the best-performing submissions proposed changes to the training data, training objective, and model architecture. This year's BabyLM Challenge shows that there is still significant room for innovation in this setting, in particular for image-text modeling, but community-driven research can yield actionable insights about effective strategies for small-scale language modeling.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05232",
        "abstract url": "https://arxiv.org/abs/2412.05232",
        "title": "LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds",
        "rating": "0",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Many existing jailbreak techniques rely on solving discrete combinatorial optimization, while more recent approaches involve training LLMs to generate multiple adversarial prompts. However, both approaches require significant computational resources to produce even a single adversarial prompt. We hypothesize that the inefficiency of current approaches stems from an inadequate characterization of the jailbreak problem. To address this gap, we formulate the jailbreak problem in terms of alignment. By starting from an available safety-aligned model, we leverage an unsafe reward to guide the safe model towards generating unsafe outputs using alignment techniques (e.g., reinforcement learning from human feedback), effectively performing jailbreaking via alignment. We propose a novel jailbreak method called LIAR (LeveragIng Alignment to jailbReak). To demonstrate the simplicity and effectiveness of our approach, we employ a best-of-N method to solve the alignment problem. LIAR offers significant advantages: lower computational requirements without additional training, fully black-box operation, competitive attack success rates, and more human-readable prompts. We provide theoretical insights into the possibility of jailbreaking a safety-aligned model, revealing inherent vulnerabilities in current alignment strategies for LLMs. We also provide sub-optimality guarantees for the proposed \\algo. Experimentally, we achieve ASR comparable to the SoTA with a 10x improvement to perplexity and a Time-to-Attack measured in seconds rather than tens of hours.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05263",
        "abstract url": "https://arxiv.org/abs/2412.05263",
        "title": "Mind the Time: Temporally-Controlled Multi-Event Video Generation",
        "rating": "0",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Real-world videos consist of sequences of events. Generating such sequences with precise temporal control is infeasible with existing video generators that rely on a single paragraph of text as input. When tasked with generating multiple events described using a single prompt, such methods often ignore some of the events or fail to arrange them in the correct order. To address this limitation, we present MinT, a multi-event video generator with temporal control. Our key insight is to bind each event to a specific period in the generated video, which allows the model to focus on one event at a time. To enable time-aware interactions between event captions and video tokens, we design a time-based positional encoding method, dubbed ReRoPE. This encoding helps to guide the cross-attention operation. By fine-tuning a pre-trained video diffusion transformer on temporally grounded data, our approach produces coherent videos with smoothly connected events. For the first time in the literature, our model offers control over the timing of events in generated videos. Extensive experiments demonstrate that MinT outperforms existing open-source models by a large margin.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project Page: https://mint-video.github.io/"
    },
    {
        "paper id": "2412.05274",
        "abstract url": "https://arxiv.org/abs/2412.05274",
        "title": "SimC3D: A Simple Contrastive 3D Pretraining Framework Using RGB Images",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud",
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The 3D contrastive learning paradigm has demonstrated remarkable performance in downstream tasks through pretraining on point cloud data. Recent advances involve additional 2D image priors associated with 3D point clouds for further improvement. Nonetheless, these existing frameworks are constrained by the restricted range of available point cloud datasets, primarily due to the high costs of obtaining point cloud data. To this end, we propose SimC3D, a simple but effective 3D contrastive learning framework, for the first time, pretraining 3D backbones from pure RGB image data. SimC3D performs contrastive 3D pretraining with three appealing properties. (1) Pure image data: SimC3D simplifies the dependency of costly 3D point clouds and pretrains 3D backbones using solely RBG images. By employing depth estimation and suitable data processing, the monocular synthesized point cloud shows great potential for 3D pretraining. (2) Simple framework: Traditional multi-modal frameworks facilitate 3D pretraining with 2D priors by utilizing an additional 2D backbone, thereby increasing computational expense. In this paper, we empirically demonstrate that the primary benefit of the 2D modality stems from the incorporation of locality information. Inspired by this insightful observation, SimC3D directly employs 2D positional embeddings as a stronger contrastive objective, eliminating the necessity for 2D backbones and leading to considerable performance improvements. (3) Strong performance: SimC3D outperforms previous approaches that leverage ground-truth point cloud data for pretraining in various downstream tasks. Furthermore, the performance of SimC3D can be further enhanced by combining multiple image datasets, showcasing its significant potential for scalability. The code will be available at https://github.com/Dongjiahua/SimC3D.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05275",
        "abstract url": "https://arxiv.org/abs/2412.05275",
        "title": "MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models",
        "rating": "0",
        "keywords": [
            [
                "Diffusion",
                "Text-to-video"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Text-to-video models have demonstrated impressive capabilities in producing diverse and captivating video content, showcasing a notable advancement in generative AI. However, these models generally lack fine-grained control over motion patterns, limiting their practical applicability. We introduce MotionFlow, a novel framework designed for motion transfer in video diffusion models. Our method utilizes cross-attention maps to accurately capture and manipulate spatial and temporal dynamics, enabling seamless motion transfers across various contexts. Our approach does not require training and works on test-time by leveraging the inherent capabilities of pre-trained video diffusion models. In contrast to traditional approaches, which struggle with comprehensive scene changes while maintaining consistent motion, MotionFlow successfully handles such complex transformations through its attention-based mechanism. Our qualitative and quantitative experiments demonstrate that MotionFlow significantly outperforms existing models in both fidelity and versatility even during drastic scene alterations.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Project Page: https://motionflow-diffusion.github.io"
    },
    {
        "paper id": "2412.05351",
        "abstract url": "https://arxiv.org/abs/2412.05351",
        "title": "Towards Predicting the Success of Transfer-based Attacks by Quantifying Shared Feature Representations",
        "rating": "0",
        "keywords": [
            [
                "Attacks"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Much effort has been made to explain and improve the success of transfer-based attacks (TBA) on black-box computer vision models. This work provides the first attempt at a priori prediction of attack success by identifying the presence of vulnerable features within target models. Recent work by Chen and Liu (2024) proposed the manifold attack model, a unifying framework proposing that successful TBA exist in a common manifold space. Our work experimentally tests the common manifold space hypothesis by a new methodology: first, projecting feature vectors from surrogate and target feature extractors trained on ImageNet onto the same low-dimensional manifold; second, quantifying any observed structure similarities on the manifold; and finally, by relating these observed similarities to the success of the TBA. We find that shared feature representation moderately correlates with increased success of TBA (\\r{ho}= 0.56). This method may be used to predict whether an attack will transfer without information of the model weights, training, architecture or details of the attack. The results confirm the presence of shared feature representations between two feature extractors of different sizes and complexities, and demonstrate the utility of datasets from different target domains as test signals for interpreting black-box feature representations.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05355",
        "abstract url": "https://arxiv.org/abs/2412.05355",
        "title": "MotionShop: Zero-Shot Motion Transfer in Video Diffusion Models with Mixture of Score Guidance",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "In this work, we propose the first motion transfer approach in diffusion transformer through Mixture of Score Guidance (MSG), a theoretically-grounded framework for motion transfer in diffusion models. Our key theoretical contribution lies in reformulating conditional score to decompose motion score and content score in diffusion models. By formulating motion transfer as a mixture of potential energies, MSG naturally preserves scene composition and enables creative scene transformations while maintaining the integrity of transferred motion patterns. This novel sampling operates directly on pre-trained video diffusion models without additional training or fine-tuning. Through extensive experiments, MSG demonstrates successful handling of diverse scenarios including single object, multiple objects, and cross-object motion transfer as well as complex camera motion transfer. Additionally, we introduce MotionBench, the first motion transfer dataset consisting of 200 source videos and 1000 transferred motions, covering single/multi-object transfers, and complex camera motions.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Project page: https://motionshop-diffusion.github.io"
    },
    {
        "paper id": "2412.05386",
        "abstract url": "https://arxiv.org/abs/2412.05386",
        "title": "DIFEM: Key-points Interaction based Feature Extraction Module for Violence Recognition in Videos",
        "rating": "0",
        "keywords": [
            [
                "skeleton"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Violence detection in surveillance videos is a critical task for ensuring public safety. As a result, there is increasing need for efficient and lightweight systems for automatic detection of violent behaviours. In this work, we propose an effective method which leverages human skeleton key-points to capture inherent properties of violence, such as rapid movement of specific joints and their close proximity. At the heart of our method is our novel Dynamic Interaction Feature Extraction Module (DIFEM) which captures features such as velocity, and joint intersections, effectively capturing the dynamics of violent behavior. With the features extracted by our DIFEM, we use various classification algorithms such as Random Forest, Decision tree, AdaBoost and k-Nearest Neighbor. Our approach has substantially lesser amount of parameter expense than the existing state-of-the-art (SOTA) methods employing deep learning techniques. We perform extensive experiments on three standard violence recognition datasets, showing promising performance in all three datasets. Our proposed method surpasses several SOTA violence recognition methods.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05426",
        "abstract url": "https://arxiv.org/abs/2412.05426",
        "title": "What's the Move? Hybrid Imitation Learning via Salient Points",
        "rating": "0",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "While imitation learning (IL) offers a promising framework for teaching robots various behaviors, learning complex tasks remains challenging. Existing IL policies struggle to generalize effectively across visual and spatial variations even for simple tasks. In this work, we introduce SPHINX: Salient Point-based Hybrid ImitatioN and eXecution, a flexible IL policy that leverages multimodal observations (point clouds and wrist images), along with a hybrid action space of low-frequency, sparse waypoints and high-frequency, dense end effector movements. Given 3D point cloud observations, SPHINX learns to infer task-relevant points within a point cloud, or salient points, which support spatial generalization by focusing on semantically meaningful features. These salient points serve as anchor points to predict waypoints for long-range movement, such as reaching target poses in free-space. Once near a salient point, SPHINX learns to switch to predicting dense end-effector movements given close-up wrist images for precise phases of a task. By exploiting the strengths of different input modalities and action representations for different manipulation phases, SPHINX tackles complex tasks in a sample-efficient, generalizable manner. Our method achieves 86.7% success across 4 real-world and 2 simulated tasks, outperforming the next best state-of-the-art IL baseline by 41.1% on average across 440 real world trials. SPHINX additionally generalizes to novel viewpoints, visual distractors, spatial arrangements, and execution speeds with a 1.7x speedup over the most competitive baseline. Our website (http://sphinx-manip.github.io) provides open-sourced code for data collection, training, and evaluation, along with supplementary videos.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05435",
        "abstract url": "https://arxiv.org/abs/2412.05435",
        "title": "UniScene: Unified Occupancy-centric Driving Scene Generation",
        "rating": "0",
        "keywords": [
            [
                "autonomous driving",
                "LiDAR"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Generating high-fidelity, controllable, and annotated training data is critical for autonomous driving. Existing methods typically generate a single data form directly from a coarse scene layout, which not only fails to output rich data forms required for diverse downstream tasks but also struggles to model the direct layout-to-data distribution. In this paper, we introduce UniScene, the first unified framework for generating three key data forms - semantic occupancy, video, and LiDAR - in driving scenes. UniScene employs a progressive generation process that decomposes the complex task of scene generation into two hierarchical steps: (a) first generating semantic occupancy from a customized scene layout as a meta scene representation rich in both semantic and geometric information, and then (b) conditioned on occupancy, generating video and LiDAR data, respectively, with two novel transfer strategies of Gaussian-based Joint Rendering and Prior-guided Sparse Modeling. This occupancy-centric approach reduces the generation burden, especially for intricate scenes, while providing detailed intermediate representations for the subsequent generation stages. Extensive experiments demonstrate that UniScene outperforms previous SOTAs in the occupancy, video, and LiDAR generation, which also indeed benefits downstream driving tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05466",
        "abstract url": "https://arxiv.org/abs/2412.05466",
        "title": "Multi-Armed Bandit Approach for Optimizing Training on Synthetic Data",
        "rating": "0",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Supervised machine learning methods require large-scale training datasets to perform well in practice. Synthetic data has been showing great progress recently and has been used as a complement to real data. However, there is yet a great urge to assess the usability of synthetically generated data. To this end, we propose a novel UCB-based training procedure combined with a dynamic usability metric. Our proposed metric integrates low-level and high-level information from synthetic images and their corresponding real and synthetic datasets, surpassing existing traditional metrics. By utilizing a UCB-based dynamic approach ensures continual enhancement of model learning. Unlike other approaches, our method effectively adapts to changes in the machine learning model's state and considers the evolving utility of training samples during the training process. We show that our metric is an effective way to rank synthetic images based on their usability. Furthermore, we propose a new attribute-aware bandit pipeline for generating synthetic data by integrating a Large Language Model with Stable Diffusion. Quantitative results show that our approach can boost the performance of a wide range of supervised classifiers. Notably, we observed an improvement of up to 10% in classification accuracy compared to traditional approaches, demonstrating the effectiveness of our approach. Our source code, datasets, and additional materials are publically available at https://github.com/A-Kerim/Synthetic-Data-Usability-2024.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05479",
        "abstract url": "https://arxiv.org/abs/2412.05479",
        "title": "TACO: Learning Multi-modal Action Models with Synthetic Chains-of-Thought-and-Action",
        "rating": "0",
        "keywords": [
            [
                "depth"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "While open-source multi-modal language models perform well on simple question answering tasks, they often fail on complex questions that require multiple capabilities, such as fine-grained recognition, visual grounding, and reasoning, and that demand multi-step solutions. We present TACO, a family of multi-modal large action models designed to improve performance on such complex, multi-step, and multi-modal tasks. During inference, TACO produces chains-of-thought-and-action (CoTA), executes intermediate steps by invoking external tools such as OCR, depth estimation and calculator, then integrates both the thoughts and action outputs to produce coherent responses. To train TACO, we create a large dataset of over 1M synthetic CoTA traces generated with GPT-4o and Python programs. We then experiment with various data filtering and mixing techniques and obtain a final subset of 293K high-quality CoTA examples. This dataset enables TACO to learn complex reasoning and action paths, surpassing existing models trained on instruction tuning data with only direct answers. Our model TACO outperforms the instruction-tuned baseline across 8 benchmarks, achieving a 3.6% improvement on average, with gains of up to 15% in MMVet tasks involving OCR, mathematical reasoning, and spatial reasoning. Training on high-quality CoTA traces sets a new standard for complex multi-modal reasoning, highlighting the need for structured, multi-step instruction tuning in advancing open-source mutli-modal models' capabilities.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05515",
        "abstract url": "https://arxiv.org/abs/2412.05515",
        "title": "Video2Reward: Generating Reward Function from Videos for Legged Robot Behavior Learning",
        "rating": "0",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Learning behavior in legged robots presents a significant challenge due to its inherent instability and complex constraints. Recent research has proposed the use of a large language model (LLM) to generate reward functions in reinforcement learning, thereby replacing the need for manually designed rewards by experts. However, this approach, which relies on textual descriptions to define learning objectives, fails to achieve controllable and precise behavior learning with clear directionality. In this paper, we introduce a new video2reward method, which directly generates reward functions from videos depicting the behaviors to be mimicked and learned. Specifically, we first process videos containing the target behaviors, converting the motion information of individuals in the videos into keypoint trajectories represented as coordinates through a video2text transforming module. These trajectories are then fed into an LLM to generate the reward function, which in turn is used to train the policy. To enhance the quality of the reward function, we develop a video-assisted iterative reward refinement scheme that visually assesses the learned behaviors and provides textual feedback to the LLM. This feedback guides the LLM to continually refine the reward function, ultimately facilitating more efficient behavior learning. Experimental results on tasks involving bipedal and quadrupedal robot motion control demonstrate that our method surpasses the performance of state-of-the-art LLM-based reward generation methods by over 37.6% in terms of human normalized score. More importantly, by switching video inputs, we find our method can rapidly learn diverse motion behaviors such as walking and running.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "8 pages, 6 figures, ECAI2024"
    },
    {
        "paper id": "2412.05517",
        "abstract url": "https://arxiv.org/abs/2412.05517",
        "title": "Test-time Cost-and-Quality Controllable Arbitrary-Scale Super-Resolution with Variable Fourier Components",
        "rating": "0",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Super-resolution (SR) with arbitrary scale factor and cost-and-quality controllability at test time is essential for various applications. While several arbitrary-scale SR methods have been proposed, these methods require us to modify the model structure and retrain it to control the computational cost and SR quality. To address this limitation, we propose a novel SR method using a Recurrent Neural Network (RNN) with the Fourier representation. In our method, the RNN sequentially estimates Fourier components, each consisting of frequency and amplitude, and aggregates these components to reconstruct an SR image. Since the RNN can adjust the number of recurrences at test time, we can control the computational cost and SR quality in a single model: fewer recurrences (i.e., fewer Fourier components) lead to lower cost but lower quality, while more recurrences (i.e., more Fourier components) lead to better quality but more cost. Experimental results prove that more Fourier components improve the PSNR score. Furthermore, even with fewer Fourier components, our method achieves a lower PSNR drop than other state-of-the-art arbitrary-scale SR methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "14 pages, 10 figures"
    },
    {
        "paper id": "2412.04781",
        "abstract url": "https://arxiv.org/abs/2412.04781",
        "title": "DPGIIL: Dirichlet Process-Deep Generative Model-Integrated Incremental Learning for Clustering in Transmissibility-based Online Structural Anomaly Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Clustering based on vibration responses, such as transmissibility functions (TFs), is promising in structural anomaly detection, but most existing approaches struggle with determining the optimal cluster number and handling high-dimensional streaming data, while their shallow structures also make them sensitive to manually-engineered feature quality. To bridge this gap, this work proposes the Dirichlet process-deep generative model-integrated incremental learning (DPGIIL) for clustering by combining the advantages of deep generative models (DGMs) in representation learning and the Dirichlet process mixture model (DPMM) in identifying distinct patterns in observed data. By introducing a DPMM prior into the latent space of DGMs, DPGIIL automatically captures dissimilarities in extracted latent representations, enabling both generative modeling and clustering. Within the context of variational Bayesian inference, a lower bound on the log marginal likelihood of DPGIIL, tighter than the evidence lower bound given sufficient training data, is derived analytically, which enables the joint optimization of DGM and DPMM parameters, thereby allowing the DPMM to regularize the DGM's feature extraction process. Additionally, a greedy split-merge scheme-based coordinate ascent variational inference method is devised to accelerate the optimization. The summary statistics of the DPMM, along with the network parameters, are used to retain information about previous data for incremental learning. Notably, this study uses variational autoencoder (VAE) within DPGIIL as an illustrative example, while this framework is adaptable to other DGMs. Two case studies show that the proposed method outperforms some state-of-the-art approaches in structural anomaly detection and clustering, while also dynamically generating new clusters to indicate the emergence of new structural conditions for online monitoring.",
        "subjects": [
            "cs.LG",
            "physics.data-an",
            "stat.ML"
        ],
        "comment": "48 pages,9 figures,6 tables,submitted to Advanced Engineering Informatics"
    },
    {
        "paper id": "2412.04789",
        "abstract url": "https://arxiv.org/abs/2412.04789",
        "title": "DrIFT: Autonomous Drone Dataset with Integrated Real and Synthetic Data, Flexible Views, and Transformed Domains",
        "rating": "-0.5",
        "keywords": [
            [
                "Drone"
            ],
            [
                "cs.CV"
            ],
            [
                "WACV"
            ]
        ],
        "abstract": "Dependable visual drone detection is crucial for the secure integration of drones into the airspace. However, drone detection accuracy is significantly affected by domain shifts due to environmental changes, varied points of view, and background shifts. To address these challenges, we present the DrIFT dataset, specifically developed for visual drone detection under domain shifts. DrIFT includes fourteen distinct domains, each characterized by shifts in point of view, synthetic-to-real data, season, and adverse weather. DrIFT uniquely emphasizes background shift by providing background segmentation maps to enable background-wise metrics and evaluation. Our new uncertainty estimation metric, MCDO-map, features lower postprocessing complexity, surpassing traditional methods. We use the MCDO-map in our uncertainty-aware unsupervised domain adaptation method, demonstrating superior performance to SOTA unsupervised domain adaptation techniques. The dataset is available at: https://github.com/CARG-uOttawa/DrIFT.git.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "WACV2025"
    },
    {
        "paper id": "2412.04821",
        "abstract url": "https://arxiv.org/abs/2412.04821",
        "title": "CCS: Continuous Learning for Customized Incremental Wireless Sensing Services",
        "rating": "-0.5",
        "keywords": [
            [
                "radar"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Wireless sensing has made significant progress in tasks ranging from action recognition, vital sign estimation, pose estimation, etc. After over a decade of work, wireless sensing currently stands at the tipping point transitioning from proof-of-concept systems to the large-scale deployment. We envision a future service scenario where wireless sensing service providers distribute sensing models to users. During usage, users might request new sensing capabilities. For example, if someone is away from home on a business trip or vacation for an extended period, they may want a new sensing capability that can detect falls in elderly parents or grandparents and promptly alert them. In this paper, we propose CCS (continuous customized service), enabling model updates on users' local computing resources without data transmission to the service providers. To address the issue of catastrophic forgetting in model updates where updating model parameters to implement new capabilities leads to the loss of existing capabilities we design knowledge distillation and weight alignment modules. These modules enable the sensing model to acquire new capabilities while retaining the existing ones. We conducted extensive experiments on the large-scale XRF55 dataset across Wi-Fi, millimeter-wave radar, and RFID modalities to simulate scenarios where four users sequentially introduced new customized demands. The results affirm that CCS excels in continuous model services across all the above wireless modalities, significantly outperforming existing approaches like OneFi.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "9 pages,8 figures"
    },
    {
        "paper id": "2412.04846",
        "abstract url": "https://arxiv.org/abs/2412.04846",
        "title": "eXpath: Explaining Knowledge Graph Link Prediction with Ontological Closed Path Rules",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Link prediction (LP) is crucial for Knowledge Graphs (KG) completion but commonly suffers from interpretability issues. While several methods have been proposed to explain embedding-based LP models, they are generally limited to local explanations on KG and are deficient in providing human interpretable semantics. Based on real-world observations of the characteristics of KGs from multiple domains, we propose to explain LP models in KG with path-based explanations. An integrated framework, namely eXpath, is introduced which incorporates the concept of relation path with ontological closed path rules to enhance both the efficiency and effectiveness of LP interpretation. Notably, the eXpath explanations can be fused with other single-link explanation approaches to achieve a better overall solution. Extensive experiments across benchmark datasets and LP models demonstrate that introducing eXpath can boost the quality of resulting explanations by about 20% on two key metrics and reduce the required explanation time by 61.4%, in comparison to the best existing method. Case studies further highlight eXpath's ability to provide more semantically meaningful explanations through path-based evidence.",
        "subjects": [
            "cs.AI",
            "cs.DB",
            "cs.IR",
            "cs.LG"
        ],
        "comment": "13 pages, 5 figures. Submitted to PVLDB volumn 18 on 20241201"
    },
    {
        "paper id": "2412.04868",
        "abstract url": "https://arxiv.org/abs/2412.04868",
        "title": "NebulaFL: Effective Asynchronous Federated Learning for JointCloud Computing",
        "rating": "-0.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "With advancements in AI infrastructure and Trusted Execution Environment (TEE) technology, Federated Learning as a Service (FLaaS) through JointCloud Computing (JCC) is promising to break through the resource constraints caused by heterogeneous edge devices in the traditional Federated Learning (FL) paradigm. Specifically, with the protection from TEE, data owners can achieve efficient model training with high-performance AI services in the cloud. By providing additional FL services, cloud service providers can achieve collaborative learning among data owners. However, FLaaS still faces three challenges, i.e., i) low training performance caused by heterogeneous data among data owners, ii) high communication overhead among different clouds (i.e., data centers), and iii) lack of efficient resource scheduling strategies to balance training time and cost. To address these challenges, this paper presents a novel asynchronous FL approach named NebulaFL for collaborative model training among multiple clouds. To address data heterogeneity issues, NebulaFL adopts a version control-based asynchronous FL training scheme in each data center to balance training time among data owners. To reduce communication overhead, NebulaFL adopts a decentralized model rotation mechanism to achieve effective knowledge sharing among data centers. To balance training time and cost, NebulaFL integrates a reward-guided strategy for data owners selection and resource scheduling. The experimental results demonstrate that, compared to the state-of-the-art FL methods, NebulaFL can achieve up to 5.71\\% accuracy improvement. In addition, NebulaFL can reduce up to 50% communication overhead and 61.94% costs under a target accuracy.",
        "subjects": [
            "cs.DC",
            "cs.AI",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04888",
        "abstract url": "https://arxiv.org/abs/2412.04888",
        "title": "VTD: Visual and Tactile Database for Driver State and Behavior Perception",
        "rating": "-0.5",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In the domain of autonomous vehicles, the human-vehicle co-pilot system has garnered significant research attention. To address the subjective uncertainties in driver state and interaction behaviors, which are pivotal to the safety of Human-in-the-loop co-driving systems, we introduce a novel visual-tactile perception method. Utilizing a driving simulation platform, a comprehensive dataset has been developed that encompasses multi-modal data under fatigue and distraction conditions. The experimental setup integrates driving simulation with signal acquisition, yielding 600 minutes of fatigue detection data from 15 subjects and 102 takeover experiments with 17 drivers. The dataset, synchronized across modalities, serves as a robust resource for advancing cross-modal driver behavior perception algorithms.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04919",
        "abstract url": "https://arxiv.org/abs/2412.04919",
        "title": "Hard Math -- Easy UVM: Pragmatic solutions for verifying hardware algorithms using UVM",
        "rating": "-0.5",
        "keywords": [
            [
                "radar"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents pragmatic solutions for verifying complex mathematical algorithms implemented in hardware in an efficient and effective manner. Maximizing leverage of a known-answer-test strategy, based on predefined data scenarios combined with design-for-verification modes, we demonstrate how to find and isolate concept and design bugs early in the flow. The solutions presented are based on real project experience with single chip radar sensors for a variety of applications. The verification environments supporting the presented strategies are based on SystemVerilog and the Universal Verification Methodology.",
        "subjects": [
            "cs.AI",
            "cs.AR"
        ],
        "comment": "Published at DVCon Europe 2024"
    },
    {
        "paper id": "2412.04981",
        "abstract url": "https://arxiv.org/abs/2412.04981",
        "title": "Causal discovery with endogenous context variables",
        "rating": "-0.5",
        "keywords": [
            [
                "graphs"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Causal systems often exhibit variations of the underlying causal mechanisms between the variables of the system. Often, these changes are driven by different environments or internal states in which the system operates, and we refer to context variables as those variables that indicate this change in causal mechanisms. An example are the causal relations in soil moisture-temperature interactions and their dependence on soil moisture regimes: Dry soil triggers a dependence of soil moisture on latent heat, while environments with wet soil do not feature such a feedback, making it a context-specific property. Crucially, a regime or context variable such as soil moisture need not be exogenous and can be influenced by the dynamical system variables - precipitation can make a dry soil wet - leading to joint systems with endogenous context variables. In this work we investigate the assumptions for constraint-based causal discovery of context-specific information in systems with endogenous context variables. We show that naive approaches such as learning different regime graphs on masked data, or pooling all data, can lead to uninformative results. We propose an adaptive constraint-based discovery algorithm and give a detailed discussion on the connection to structural causal models, including sufficiency assumptions, which allow to prove the soundness of our algorithm and to interpret the results causally. Numerical experiments demonstrate the performance of the proposed method over alternative baselines, but they also unveil current limitations of our method.",
        "subjects": [
            "cs.LG",
            "math.ST"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05013",
        "abstract url": "https://arxiv.org/abs/2412.05013",
        "title": "Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector",
        "rating": "-0.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Is it possible to integrate a humanoid social robot into the work processes or customer care in an official environment, e.g. in municipal offices? If so, what could such an application scenario look like and what skills would the robot need to have when interacting with human customers? What are requirements for this kind of interactions? We have devised an application scenario for such a case, determined the necessary or desirable capabilities of the robot, developed a corresponding robot application and carried out initial tests and evaluations in a project together with the Kiel City Council. One of the most important insights gained in the project was that a humanoid robot with natural language processing capabilities based on large language models as well as human-like gestures and posture changes (animations) proved to be much more preferred by users compared to standard browser-based solutions on tablets for an information system in the City Council. Furthermore, we propose a connection of the ACT-R cognitive architecture with the robot, where an ACT-R model is used in interaction with the robot application to cognitively process and enhance a dialogue between human and robot.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05022",
        "abstract url": "https://arxiv.org/abs/2412.05022",
        "title": "Get It Right: Improving Comprehensibility with Adaptable Speech Expression of a Humanoid Service Robot",
        "rating": "-0.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "As humanoid service robots are becoming more and more perceptible in public service settings for instance as a guide to welcome visitors or to explain a procedure to follow, it is desirable to improve the comprehensibility of complex issues for human customers and to adapt the level of difficulty of the information provided as well as the language used to individual requirements. This work examines a case study using a humanoid social robot Pepper performing support for customers in a public service environment offering advice and information. An application architecture is proposed that improves the intelligibility of the information received by providing the possibility to translate this information into easy language and/or into another spoken language.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05024",
        "abstract url": "https://arxiv.org/abs/2412.05024",
        "title": "Talking Like One of Us: Effects of Using Regional Language in a Humanoid Social Robot",
        "rating": "-0.5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Social robots are becoming more and more perceptible in public service settings. For engaging people in a natural environment a smooth social interaction as well as acceptance by the users are important issues for future successful Human-Robot Interaction (HRI). The type of verbal communication has a special significance here. In this paper we investigate the effects of spoken language varieties of a non-standard/regional language compared to standard language. More precisely we compare a human dialog with a humanoid social robot Pepper where the robot on the one hand is answering in High German and on the other hand in Low German, a regional language that is understood and partly still spoken in the northern parts of Germany. The content of what the robot says remains the same in both variants. We are interested in the effects that these two different ways of robot talk have on human interlocutors who are more or less familiar with Low German in terms of perceived warmth, competence and possible discomfort in conversation against a background of cultural identity. To measure these factors we use the Robotic Social Attributes Scale (RoSAS) on 17 participants with an age ranging from 19 to 61. Our results show that significantly higher warmth is perceived in the Low German version of the conversation.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05049",
        "abstract url": "https://arxiv.org/abs/2412.05049",
        "title": "OCEAN: Open-World Contrastive Authorship Identification",
        "rating": "-0.5",
        "keywords": [
            [
                "Gan"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In an era where cyberattacks increasingly target the software supply chain, the ability to accurately attribute code authorship in binary files is critical to improving cybersecurity measures. We propose OCEAN, a contrastive learning-based system for function-level authorship attribution. OCEAN is the first framework to explore code authorship attribution on compiled binaries in an open-world and extreme scenario, where two code samples from unknown authors are compared to determine if they are developed by the same author. To evaluate OCEAN, we introduce new realistic datasets: CONAN, to improve the performance of authorship attribution systems in real-world use cases, and SNOOPY, to increase the robustness of the evaluation of such systems. We use CONAN to train our model and evaluate on SNOOPY, a fully unseen dataset, resulting in an AUROC score of 0.86 even when using high compiler optimizations. We further show that CONAN improves performance by 7% compared to the previously used Google Code Jam dataset. Additionally, OCEAN outperforms previous methods in their settings, achieving a 10% improvement over state-of-the-art SCS-Gan in scenarios analyzing source code. Furthermore, OCEAN can detect code injections from an unknown author in a software update, underscoring its value for securing software supply chains.",
        "subjects": [
            "cs.AI",
            "cs.CR"
        ],
        "comment": "To be published in Accepted at Applied Cryptography and Network Security (ACNS) 2025"
    },
    {
        "paper id": "2412.05114",
        "abstract url": "https://arxiv.org/abs/2412.05114",
        "title": "A*Net and NBFNet Learn Negative Patterns on Knowledge Graphs",
        "rating": "-0.5",
        "keywords": [
            [
                "GNN",
                "Graphs"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "In this technical report, we investigate the predictive performance differences of a rule-based approach and the GNN architectures NBFNet and A*Net with respect to knowledge graph completion. For the two most common benchmarks, we find that a substantial fraction of the performance difference can be explained by one unique negative pattern on each dataset that is hidden from the rule-based approach. Our findings add a unique perspective on the performance difference of different model classes for knowledge graph completion: Models can achieve a predictive performance advantage by penalizing scores of incorrect facts opposed to providing high scores for correct facts.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05117",
        "abstract url": "https://arxiv.org/abs/2412.05117",
        "title": "Transformers Can Navigate Mazes With Multi-Step Prediction",
        "rating": "-0.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Despite their remarkable success in language modeling, transformers trained to predict the next token in a sequence struggle with long-term planning. This limitation is particularly evident in tasks requiring foresight to plan multiple steps ahead such as maze navigation. The standard next single token prediction objective, however, offers no explicit mechanism to predict multiple steps ahead - or revisit the path taken so far. Consequently, in this work we study whether explicitly predicting multiple steps ahead (and backwards) can improve transformers' maze navigation. We train parameter-matched transformers from scratch, under identical settings, to navigate mazes of varying types and sizes with standard next token prediction and MLM-U, an objective explicitly predicting multiple steps ahead and backwards. We find that MLM-U considerably improves transformers' ability to navigate mazes compared to standard next token prediction across maze types and complexities. We also find MLM-U training is 4x more sample efficient and converges 2x faster in terms of GPU training hours relative to next token training. Finally, for more complex mazes we find MLM-U benefits from scaling to larger transformers. Remarkably, we find transformers trained with MLM-U outperform larger transformers trained with next token prediction using additional supervision from A* search traces. We hope these findings underscore the promise of learning objectives to advance transformers' capacity for long-term planning.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "20 pages, 15 figures"
    },
    {
        "paper id": "2412.05124",
        "abstract url": "https://arxiv.org/abs/2412.05124",
        "title": "Feature-Based Network Construction: From Sampling to What-if Analysis",
        "rating": "-0.5",
        "keywords": [
            [
                "graph"
            ],
            [
                "cs.SI"
            ]
        ],
        "abstract": "Networks are characterized by structural features, such as degree distribution, triangular closures, and assortativity. This paper addresses the problem of reconstructing instances of continuously (and non-negatively) weighted networks from given feature values. We introduce the gradient-based Feature-Based Network Construction (FBNC) framework. FBNC allows for sampling networks that satisfy prespecified features exactly (hard constraint sampling). Initializing the FBNC gradient descent with a random graph, FBNC can be used as an alternative to exponential random graphs in sampling graphs conditional on given feature values. We establish an implicit regularization approach to the original feature-fitting loss minimization problem so that FBNC achieves a parsimonious change in the underlying graph, where the term \"implicit\" stems from using appropriate norms in the very construction of the FBNC gradient descent. In constructing the implicit regularization, we distinguish between the case where weights of a link can be chosen from a bounded range, and, the more demanding case, where the weight matrix of the graph constitutes a Markov chain. We show that FBNC expands to \"what-if analysis\" of networks, that is, for a given initial network and a set of features satisfied by this network, FBNC finds the network closest to the initial network with some of the feature values adjusted or new features added. Numerical experiments in social network management and financial network regulation demonstrate the value of FBNC for graph (re)construction and what-if analysis.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05154",
        "abstract url": "https://arxiv.org/abs/2412.05154",
        "title": "Towards Flexible 3D Perception: Object-Centric Occupancy Completion Augments 3D Object Detection",
        "rating": "-0.5",
        "keywords": [
            [
                "3D",
                "voxel"
            ],
            [
                "autonomous driving"
            ],
            [
                "cs.AI",
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "While 3D object bounding box (bbox) representation has been widely used in autonomous driving perception, it lacks the ability to capture the precise details of an object's intrinsic geometry. Recently, occupancy has emerged as a promising alternative for 3D scene perception. However, constructing a high-resolution occupancy map remains infeasible for large scenes due to computational constraints. Recognizing that foreground objects only occupy a small portion of the scene, we introduce object-centric occupancy as a supplement to object bboxes. This representation not only provides intricate details for detected objects but also enables higher voxel resolution in practical applications. We advance the development of object-centric occupancy perception from both data and algorithm perspectives. On the data side, we construct the first object-centric occupancy dataset from scratch using an automated pipeline. From the algorithmic standpoint, we introduce a novel object-centric occupancy completion network equipped with an implicit shape decoder that manages dynamic-size occupancy generation. This network accurately predicts the complete object-centric occupancy volume for inaccurate object proposals by leveraging temporal information from long sequences. Our method demonstrates robust performance in completing object shapes under noisy detection and tracking conditions. Additionally, we show that our occupancy features significantly enhance the detection results of state-of-the-art 3D object detectors, especially for incomplete or distant objects in the Waymo Open Dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "NeurIPS 2024"
    },
    {
        "paper id": "2412.05277",
        "abstract url": "https://arxiv.org/abs/2412.05277",
        "title": "Text to Blind Motion",
        "rating": "-0.5",
        "keywords": [
            [
                "3D"
            ],
            [
                "navigation"
            ],
            [
                "cs.CV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "People who are blind perceive the world differently than those who are sighted, which can result in distinct motion characteristics. For instance, when crossing at an intersection, blind individuals may have different patterns of movement, such as veering more from a straight path or using touch-based exploration around curbs and obstacles. These behaviors may appear less predictable to motion models embedded in technologies such as autonomous vehicles. Yet, the ability of 3D motion models to capture such behavior has not been previously studied, as existing datasets for 3D human motion currently lack diversity and are biased toward people who are sighted. In this work, we introduce BlindWays, the first multimodal motion benchmark for pedestrians who are blind. We collect 3D motion data using wearable sensors with 11 blind participants navigating eight different routes in a real-world urban setting. Additionally, we provide rich textual descriptions that capture the distinctive movement characteristics of blind pedestrians and their interactions with both the navigation aid (e.g., a white cane or a guide dog) and the environment. We benchmark state-of-the-art 3D human prediction models, finding poor performance with off-the-shelf and pre-training-based methods for our novel task. To contribute toward safer and more reliable systems that can seamlessly reason over diverse human movements in their environments, our text-and-motion benchmark is available at https://blindways.github.io.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Accepted at NeurIPS 2024"
    },
    {
        "paper id": "2412.05346",
        "abstract url": "https://arxiv.org/abs/2412.05346",
        "title": "BadGPT-4o: stripping safety finetuning from GPT models",
        "rating": "-0.5",
        "keywords": [
            [
                "attack"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "We show a version of Qi et al. 2023's simple fine-tuning poisoning technique strips GPT-4o's safety guardrails without degrading the model. The BadGPT attack matches best white-box jailbreaks on HarmBench and StrongREJECT. It suffers no token overhead or performance hits common to jailbreaks, as evaluated on tinyMMLU and open-ended generations. Despite having been known for a year, this attack remains easy to execute.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05403",
        "abstract url": "https://arxiv.org/abs/2412.05403",
        "title": "Knowledge-Based Deep Learning for Time-Efficient Inverse Dynamics",
        "rating": "-0.5",
        "keywords": [
            [
                "Time-Efficient"
            ],
            [
                "physiological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Accurate understanding of muscle activation and muscle forces plays an essential role in neuro-rehabilitation and musculoskeletal disorder treatments. Computational musculoskeletal modeling has been widely used as a powerful non-invasive tool to estimate them through inverse dynamics using static optimization, but the inherent computational complexity results in time-consuming analysis. In this paper, we propose a knowledge-based deep learning framework for time-efficient inverse dynamic analysis, which can predict muscle activation and muscle forces from joint kinematic data directly while not requiring any label information during model training. The Bidirectional Gated Recurrent Unit (BiGRU) neural network is selected as the backbone of our model due to its proficient handling of time-series data. Prior physical knowledge from forward dynamics and pre-selected inverse dynamics based physiological criteria are integrated into the loss function to guide the training of neural networks. Experimental validations on two datasets, including one benchmark upper limb movement dataset and one self-collected lower limb movement dataset from six healthy subjects, are performed. The experimental results have shown that the selected BiGRU architecture outperforms other neural network models when trained using our specifically designed loss function, which illustrates the effectiveness and robustness of the proposed framework.",
        "subjects": [
            "eess.SP",
            "cs.CE",
            "cs.HC",
            "cs.LG",
            "physics.bio-ph"
        ],
        "comment": "10 pages, 8 figures, Journal paper"
    },
    {
        "paper id": "2412.05408",
        "abstract url": "https://arxiv.org/abs/2412.05408",
        "title": "FogROS2-FT: Fault Tolerant Cloud Robotics",
        "rating": "-0.5",
        "keywords": [
            [
                "Robotics",
                "robot"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Cloud robotics enables robots to offload complex computational tasks to cloud servers for performance and ease of management. However, cloud compute can be costly, cloud services can suffer occasional downtime, and connectivity between the robot and cloud can be prone to variations in network Quality-of-Service (QoS). We present FogROS2-FT (Fault Tolerant) to mitigate these issues by introducing a multi-cloud extension that automatically replicates independent stateless robotic services, routes requests to these replicas, and directs the first response back. With replication, robots can still benefit from cloud computations even when a cloud service provider is down or there is low QoS. Additionally, many cloud computing providers offer low-cost spot computing instances that may shutdown unpredictably. Normally, these low-cost instances would be inappropriate for cloud robotics, but the fault tolerance nature of FogROS2-FT allows them to be used reliably. We demonstrate FogROS2-FT fault tolerance capabilities in 3 cloud-robotics scenarios in simulation (visual object detection, semantic segmentation, motion planning) and 1 physical robot experiment (scan-pick-and-place). Running on the same hardware specification, FogROS2-FT achieves motion planning with up to 2.2x cost reduction and up to a 5.53x reduction on 99 Percentile (P99) long-tail latency. FogROS2-FT reduces the P99 long-tail latency of object detection and semantic segmentation by 2.0x and 2.1x, respectively, under network slowdown and resource contention.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.DC",
            "cs.NI"
        ],
        "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems 2024 Best Paper Finalist"
    },
    {
        "paper id": "2412.05437",
        "abstract url": "https://arxiv.org/abs/2412.05437",
        "title": "DRL4AOI: A DRL Framework for Semantic-aware AOI Segmentation in Location-Based Services",
        "rating": "-0.5",
        "keywords": [
            [
                "trajectory"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "In Location-Based Services (LBS), such as food delivery, a fundamental task is segmenting Areas of Interest (AOIs), aiming at partitioning the urban geographical spaces into non-overlapping regions. Traditional AOI segmentation algorithms primarily rely on road networks to partition urban areas. While promising in modeling the geo-semantics, road network-based models overlooked the service-semantic goals (e.g., workload equality) in LBS service. In this paper, we point out that the AOI segmentation problem can be naturally formulated as a Markov Decision Process (MDP), which gradually chooses a nearby AOI for each grid in the current AOI's border. Based on the MDP, we present the first attempt to generalize Deep Reinforcement Learning (DRL) for AOI segmentation, leading to a novel DRL-based framework called DRL4AOI. The DRL4AOI framework introduces different service-semantic goals in a flexible way by treating them as rewards that guide the AOI generation. To evaluate the effectiveness of DRL4AOI, we develop and release an AOI segmentation system. We also present a representative implementation of DRL4AOI - TrajRL4AOI - for AOI segmentation in the logistics service. It introduces a Double Deep Q-learning Network (DDQN) to gradually optimize the AOI generation for two specific semantic goals: i) trajectory modularity, i.e., maximize tightness of the trajectory connections within an AOI and the sparsity of connections between AOIs, ii) matchness with the road network, i.e., maximizing the matchness between AOIs and the road network. Quantitative and qualitative experiments conducted on synthetic and real-world data demonstrate the effectiveness and superiority of our method. The code and system is publicly available at https://github.com/Kogler7/AoiOpt.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "comment": "14 pages"
    },
    {
        "paper id": "2412.05447",
        "abstract url": "https://arxiv.org/abs/2412.05447",
        "title": "A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application",
        "rating": "-0.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "TOBU is a novel mobile application that captures and retrieves `personal memories' (pictures/videos together with stories and context around those moments) in a user-engaging AI-guided conversational approach. Our initial prototype showed that existing retrieval techniques such as retrieval-augmented generation (RAG) systems fall short due to their limitations in understanding memory relationships, causing low recall, hallucination, and unsatisfactory user experience. We design TOBUGraph, a novel graph-based retrieval approach. During capturing, TOBUGraph leverages large language models (LLMs) to automatically create a dynamic knowledge graph of memories, establishing context and relationships of those memories. During retrieval, TOBUGraph combines LLMs with the memory graph to achieve comprehensive recall through graph traversal. Our evaluation using real user data demonstrates that TOBUGraph outperforms multiple RAG implementations in both precision and recall, significantly improving user experience through improved retrieval accuracy and reduced hallucination.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05498",
        "abstract url": "https://arxiv.org/abs/2412.05498",
        "title": "A New Perspective on Time Series Anomaly Detection: Faster Patch-based Broad Learning System",
        "rating": "-0.5",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Time series anomaly detection (TSAD) has been a research hotspot in both academia and industry in recent years. Deep learning methods have become the mainstream research direction due to their excellent performance. However, new viewpoints have emerged in recent TSAD research. Deep learning is not required for TSAD due to limitations such as slow deep learning speed. The Broad Learning System (BLS) is a shallow network framework that benefits from its ease of optimization and speed. It has been shown to outperform machine learning approaches while remaining competitive with deep learning. Based on the current situation of TSAD, we propose the Contrastive Patch-based Broad Learning System (CPatchBLS). This is a new exploration of patching technique and BLS, providing a new perspective for TSAD. We construct Dual-PatchBLS as a base through patching and Simple Kernel Perturbation (SKP) and utilize contrastive learning to capture the differences between normal and abnormal data under different representations. To compensate for the temporal semantic loss caused by various patching, we propose CPatchBLS with model level integration, which takes advantage of BLS's fast feature to build model-level integration and improve model detection. Using five real-world series anomaly detection datasets, we confirmed the method's efficacy, outperforming previous deep learning and machine learning methods while retaining a high level of computing efficiency.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "13 pages, 7 figures, 3 tables, Under review"
    },
    {
        "paper id": "2412.04802",
        "abstract url": "https://arxiv.org/abs/2412.04802",
        "title": "Modality Decoupling is All You Need: A Simple Solution for Unsupervised Hyperspectral Image Fusion",
        "rating": "-1",
        "keywords": [
            [
                "Hyperspectral Image"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Hyperspectral Image Fusion (HIF) aims to fuse low-resolution hyperspectral images (LR-HSIs) and high-resolution multispectral images (HR-MSIs) to reconstruct high spatial and high spectral resolution images. Current methods typically apply direct fusion from the two modalities without valid supervision, failing to fully perceive the deep modality-complementary information and hence, resulting in a superficial understanding of inter-modality connections. To bridge this gap, we propose a simple and effective solution for unsupervised HIF with an assumption that modality decoupling is essential for HIF. We introduce the modality clustering loss that ensures clear guidance of the modality, decoupling towards modality-shared features while steering clear of modality-complementary ones. Also, we propose an end-to-end Modality-Decoupled Spatial-Spectral Fusion (MossFuse) framework that decouples shared and complementary information across modalities and aggregates a concise representation of the LR-HSI and HR-MSI to reduce the modality redundancy. Systematic experiments over multiple datasets demonstrate that our simple and effective approach consistently outperforms the existing HIF methods while requiring considerably fewer parameters with reduced inference time.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04806",
        "abstract url": "https://arxiv.org/abs/2412.04806",
        "title": "Rethinking Time Series Forecasting with LLMs via Nearest Neighbor Contrastive Learning",
        "rating": "-1",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Adapting Large Language Models (LLMs) that are extensively trained on abundant text data, and customizing the input prompt to enable time series forecasting has received considerable attention. While recent work has shown great potential for adapting the learned prior of LLMs, the formulation of the prompt to finetune LLMs remains challenging as prompt should be aligned with time series data. Additionally, current approaches do not effectively leverage word token embeddings which embody the rich representation space learned by LLMs. This emphasizes the need for a robust approach to formulate the prompt which utilizes the word token embeddings while effectively representing the characteristics of the time series. To address these challenges, we propose NNCL-TLLM: Nearest Neighbor Contrastive Learning for Time series forecasting via LLMs. First, we generate time series compatible text prototypes such that each text prototype represents both word token embeddings in its neighborhood and time series characteristics via end-to-end finetuning. Next, we draw inspiration from Nearest Neighbor Contrastive Learning to formulate the prompt while obtaining the top-$k$ nearest neighbor time series compatible text prototypes. We then fine-tune the layer normalization and positional embeddings of the LLM, keeping the other layers intact, reducing the trainable parameters and decreasing the computational cost. Our comprehensive experiments demonstrate that NNCL-TLLM outperforms in few-shot forecasting while achieving competitive or superior performance over the state-of-the-art methods in long-term and short-term forecasting tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04812",
        "abstract url": "https://arxiv.org/abs/2412.04812",
        "title": "Automatic Prediction of Stroke Treatment Outcomes: Latest Advances and Perspectives",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "health",
                "EEG",
                "clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Stroke is a major global health problem that causes mortality and morbidity. Predicting the outcomes of stroke intervention can facilitate clinical decision-making and improve patient care. Engaging and developing deep learning techniques can help to analyse large and diverse medical data, including brain scans, medical reports and other sensor information, such as EEG, ECG, EMG and so on. Despite the common data standardisation challenge within medical image analysis domain, the future of deep learning in stroke outcome prediction lie in using multimodal information, including final infarct data, to achieve better prediction of long-term functional outcomes. This article provides a broad review of recent advances and applications of deep learning in the prediction of stroke outcomes, including (i) the data and models used, (ii) the prediction tasks and measures of success, (iii) the current challenges and limitations, and (iv) future directions and potential benefits. This comprehensive review aims to provide researchers, clinicians, and policy makers with an up-to-date understanding of this rapidly evolving and promising field.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": "The paper is under consideration at Biomedical Engineering Letters (Springer)"
    },
    {
        "paper id": "2412.04820",
        "abstract url": "https://arxiv.org/abs/2412.04820",
        "title": "Assessing Similarity Measures for the Evaluation of Human-Robot Motion Correspondence",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "One key area of research in Human-Robot Interaction is solving the human-robot correspondence problem, which asks how a robot can learn to reproduce a human motion demonstration when the human and robot have different dynamics and kinematic structures. Evaluating these correspondence problem solutions often requires the use of qualitative surveys that can be time consuming to design and administer. Additionally, qualitative survey results vary depending on the population of survey participants. In this paper, we propose the use of heterogeneous time-series similarity measures as a quantitative evaluation metric for evaluating motion correspondence to complement these qualitative surveys. To assess the suitability of these measures, we develop a behavioral cloning-based motion correspondence model, and evaluate it with a qualitative survey as well as quantitative measures. By comparing the resulting similarity scores with the human survey results, we identify Gromov Dynamic Time Warping as a promising quantitative measure for evaluating motion correspondence.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "comment": "8 pages, 4 figures"
    },
    {
        "paper id": "2412.04827",
        "abstract url": "https://arxiv.org/abs/2412.04827",
        "title": "PanoDreamer: 3D Panorama Synthesis from a Single Image",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "inpainting"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In this paper, we present PanoDreamer, a novel method for producing a coherent 360$^\\circ$ 3D scene from a single input image. Unlike existing methods that generate the scene sequentially, we frame the problem as single-image panorama and depth estimation. Once the coherent panoramic image and its corresponding depth are obtained, the scene can be reconstructed by inpainting the small occluded regions and projecting them into 3D space. Our key contribution is formulating single-image panorama and depth estimation as two optimization tasks and introducing alternating minimization strategies to effectively solve their objectives. We demonstrate that our approach outperforms existing techniques in single-image 360$^\\circ$ scene reconstruction in terms of consistency and overall quality.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "Project page: https://people.engr.tamu.edu/nimak/Papers/PanoDreamer, Code: https://github.com/avinashpaliwal/PanoDreamer"
    },
    {
        "paper id": "2412.04829",
        "abstract url": "https://arxiv.org/abs/2412.04829",
        "title": "Learning-based Control for Tendon-Driven Continuum Robotic Arms",
        "rating": "-1",
        "keywords": [
            [
                "trajectory"
            ]
        ],
        "abstract": "This paper presents a learning-based approach for centralized position control of Tendon Driven Continuum Robots (TDCRs) using Deep Reinforcement Learning (DRL), with a particular focus on the Sim-to-Real transfer of control policies. The proposed control method employs the Modified Transpose Jacobian (MTJ) control strategy, with its parameters optimally tuned using the Deep Deterministic Policy Gradient (DDPG) algorithm. Classical model-based controllers encounter significant challenges due to the inherent uncertainties and nonlinear dynamics of continuum robots. In contrast, model-free control strategies require efficient gain-tuning to handle diverse operational scenarios. This research aims to develop a model-free controller with performance comparable to model-based strategies by integrating an optimal adaptive gain-tuning system. Both simulations and real-world implementations demonstrate that the proposed method significantly enhances the trajectory-tracking performance of continuum robots independent of initial conditions and paths within the operational task-space, effectively establishing a task-free controller.",
        "subjects": [
            "cs.RO",
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04835",
        "abstract url": "https://arxiv.org/abs/2412.04835",
        "title": "Maximizing Alignment with Minimal Feedback: Efficiently Learning Rewards for Visuomotor Robot Policy Alignment",
        "rating": "-1",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "robotics",
                "Robot",
                "robotic manipulation"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Visuomotor robot policies, increasingly pre-trained on large-scale datasets, promise significant advancements across robotics domains. However, aligning these policies with end-user preferences remains a challenge, particularly when the preferences are hard to specify. While reinforcement learning from human feedback (RLHF) has become the predominant mechanism for alignment in non-embodied domains like large language models, it has not seen the same success in aligning visuomotor policies due to the prohibitive amount of human feedback required to learn visual reward functions. To address this limitation, we propose Representation-Aligned Preference-based Learning (RAPL), an observation-only method for learning visual rewards from significantly less human preference feedback. Unlike traditional RLHF, RAPL focuses human feedback on fine-tuning pre-trained vision encoders to align with the end-user's visual representation and then constructs a dense visual reward via feature matching in this aligned representation space. We first validate RAPL through simulation experiments in the X-Magical benchmark and Franka Panda robotic manipulation, demonstrating that it can learn rewards aligned with human preferences, more efficiently uses preference data, and generalizes across robot embodiments. Finally, our hardware experiments align pre-trained Diffusion Policies for three object manipulation tasks. We find that RAPL can fine-tune these policies with 5x less real human preference data, taking the first step towards minimizing human feedback while maximizing visuomotor robot policy alignment.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Submitted to IJRR, this paper is an extended journal version of the conference paper arXiv:2310.07932 with new results and discussion. arXiv admin note: substantial text overlap with arXiv:2310.07932"
    },
    {
        "paper id": "2412.04842",
        "abstract url": "https://arxiv.org/abs/2412.04842",
        "title": "UniMLVG: Unified Framework for Multi-view Long Video Generation with Comprehensive Control Capabilities for Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "Autonomous Driving"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The creation of diverse and realistic driving scenarios has become essential to enhance perception and planning capabilities of the autonomous driving system. However, generating long-duration, surround-view consistent driving videos remains a significant challenge. To address this, we present UniMLVG, a unified framework designed to generate extended street multi-perspective videos under precise control. By integrating single- and multi-view driving videos into the training data, our approach updates cross-frame and cross-view modules across three stages with different training objectives, substantially boosting the diversity and quality of generated visual content. Additionally, we employ the explicit viewpoint modeling in multi-view video generation to effectively improve motion transition consistency. Capable of handling various input reference formats (e.g., text, images, or video), our UniMLVG generates high-quality multi-view videos according to the corresponding condition constraints such as 3D bounding boxes or frame-level text descriptions. Compared to the best models with similar capabilities, our framework achieves improvements of 21.4% in FID and 36.5% in FVD.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04871",
        "abstract url": "https://arxiv.org/abs/2412.04871",
        "title": "Building a Family of Data Augmentation Models for Low-cost LLM Fine-tuning on the Cloud",
        "rating": "-1",
        "keywords": [
            [
                "quality assessment"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Specializing LLMs in various domain-specific tasks has emerged as a critical step towards achieving high performance. However, the construction and annotation of datasets in specific domains are always very costly. Apart from using superior and expensive closed-source LLM APIs to construct datasets, some open-source models have become strong enough to handle dataset construction in many scenarios. Thus, we present a family of data augmentation models designed to significantly improve the efficiency for model fine-tuning. These models, trained based on sufficiently small LLMs, support key functionalities with low inference costs: instruction expansion, instruction refinement, and instruction-response pair expansion. To fulfill this goal, we first construct an automatic data collection system with seed datasets generated from both public repositories and our in-house datasets. This system leverages powerful LLMs to expand, refine and re-write the instructions and responses, incorporating quality assessment techniques. Following this, we introduce the training process of our models, which effectively distills task-solving and text synthesis abilities from teacher LLMs. Finally, we demonstrate how we integrate these functionalities into a machine learning platform to support low-cost LLM fine-tuning from both dataset preparation and training perspectives for users. Experiments and an application study prove the effectiveness of our approach.",
        "subjects": [
            "cs.CL"
        ],
        "comment": "coling 2025 industry track"
    },
    {
        "paper id": "2412.04880",
        "abstract url": "https://arxiv.org/abs/2412.04880",
        "title": "MozzaVID: Mozzarella Volumetric Image Dataset",
        "rating": "-1",
        "keywords": [
            [
                "CT",
                "X-ray"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Influenced by the complexity of volumetric imaging, there is a shortage of established datasets useful for benchmarking volumetric deep-learning models. As a consequence, new and existing models are not easily comparable, limiting the development of architectures optimized specifically for volumetric data. To counteract this trend, we introduce MozzaVID - a large, clean, and versatile volumetric classification dataset. Our dataset contains X-ray computed tomography (CT) images of mozzarella microstructure and enables the classification of 25 cheese types and 149 cheese samples. We provide data in three different resolutions, resulting in three dataset instances containing from 591 to 37,824 images. While being general-purpose, the dataset also facilitates investigating mozzarella structure properties. The structure of food directly affects its functional properties and thus its consumption experience. Understanding food structure helps tune the production and mimicking it enables sustainable alternatives to animal-derived food products. The complex and disordered nature of food structures brings a unique challenge, where a choice of appropriate imaging method, scale, and sample size is not trivial. With this dataset we aim to address these complexities, contributing to more robust structural analysis models. The dataset can be downloaded from: https://archive.compute.dtu.dk/files/public/projects/MozzaVID/.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04884",
        "abstract url": "https://arxiv.org/abs/2412.04884",
        "title": "AI-Driven Non-Invasive Detection and Staging of Steatosis in Fatty Liver Disease Using a Novel Cascade Model and Information Fusion Techniques",
        "rating": "-1",
        "keywords": [
            [
                "biopsies",
                "healthcare",
                "Diagnosing",
                "Disease"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Non-alcoholic fatty liver disease (NAFLD) is one of the most widespread liver disorders on a global scale, posing a significant threat of progressing to more severe conditions like nonalcoholic steatohepatitis (NASH), liver fibrosis, cirrhosis, and hepatocellular carcinoma. Diagnosing and staging NAFLD presents challenges due to its non-specific symptoms and the invasive nature of liver biopsies. Our research introduces a novel artificial intelligence cascade model employing ensemble learning and feature fusion techniques. We developed a non-invasive, robust, and reliable diagnostic artificial intelligence tool that utilizes anthropometric and laboratory parameters, facilitating early detection and intervention in NAFLD progression. Our novel artificial intelligence achieved an 86% accuracy rate for the NASH steatosis staging task (non-NASH, steatosis grade 1, steatosis grade 2, and steatosis grade 3) and an impressive 96% AUC-ROC for distinguishing between NASH (steatosis grade 1, grade 2, and grade3) and non-NASH cases, outperforming current state-of-the-art models. This notable improvement in diagnostic performance underscores the potential application of artificial intelligence in the early diagnosis and treatment of NAFLD, leading to better patient outcomes and a reduced healthcare burden associated with advanced liver disease.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04896",
        "abstract url": "https://arxiv.org/abs/2412.04896",
        "title": "Comprehensive Analysis and Improvements in Pansharpening Using Deep Learning",
        "rating": "-1",
        "keywords": [
            [
                "remote sensing"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Pansharpening is a crucial task in remote sensing, enabling the generation of high-resolution multispectral images by fusing low-resolution multispectral data with high-resolution panchromatic images. This paper provides a comprehensive analysis of traditional and deep learning-based pansharpening methods. While state-of-the-art deep learning methods have significantly improved image quality, issues like spectral distortions persist. To address this, we propose enhancements to the PSGAN framework by introducing novel regularization techniques for the generator loss function. Experimental results on images from the Worldview-3 dataset demonstrate that the proposed modifications improve spectral fidelity and achieve superior performance across multiple quantitative metrics while delivering visually superior results.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04900",
        "abstract url": "https://arxiv.org/abs/2412.04900",
        "title": "A cyber-physical digital twin approach to replicating realistic multi-stage cyberattacks on smart grids",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "The integration of information and communication technology in distribution grids presents opportunities for active grid operation management, but also increases the need for security against power outages and cyberattacks. This paper examines the impact of cyberattacks on smart grids by replicating the power grid in a secure laboratory environment as a cyber-physical digital twin. A simulation is used to study communication infrastructures for secure operation of smart grids. The cyber-physical digital twin approach combines communication network emulation and power grid simulation in a common modular environment, and is demonstrated through laboratory tests and attack replications.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04901",
        "abstract url": "https://arxiv.org/abs/2412.04901",
        "title": "Encryption-Aware Anomaly Detection in Power Grid Communication Networks",
        "rating": "-1",
        "keywords": [
            [
                "Anomaly Detection"
            ]
        ],
        "abstract": "The shift to smart grids has made electrical power systems more vulnerable to sophisticated cyber threats. To protect these systems, holistic security measures that encompass preventive, detective, and reactive components are required, even with encrypted data. However, traditional intrusion detection methods struggle with encrypted traffic, our research focuses on the low-level communication layers of encrypted power grid systems to identify irregular patterns using statistics and machine learning. Our results indicate that a harmonic security concept based on encrypted traffic and anomaly detection is promising for smart grid security; however, further research is necessary to improve detection accuracy.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04906",
        "abstract url": "https://arxiv.org/abs/2412.04906",
        "title": "Manifolds of positive reach, differentiability, tangent variation, and attaining the reach",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "This paper contains three main results. Firstly, we give an elementary proof of the following statement: Let $M$ be a (closed, in both the geometrical and topological sense of the word) topological manifold embedded in $\\mathbb{R}^d$. If $M$ has positive reach, then M can locally be written as the graph of a $C^{1,1}$ from the tangent space to the normal space. Conversely if $M$ can locally written as the graph of a $C^{1,1}$ function from the tangent space to the normal space, then $M$ has positive reach. The result was hinted at by Federer when he introduced the reach, and proved by Lytchak. Lytchak's proof relies heavily CAT(k)-theory. The proof presented here uses only basic results on homology. Secondly, we give optimal Lipschitz-constants for the derivative, in other words we give an optimal bound for the angle between tangent spaces in term of the distance between the points. This improves earlier results, that were either suboptimal or assumed that the manifold was $C^2$. Thirdly, we generalize a result by Aamari et al. which explains the how the reach is attained from the smooth setting to general sets of positive reach.",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04936",
        "abstract url": "https://arxiv.org/abs/2412.04936",
        "title": "Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase",
        "rating": "-1",
        "keywords": [
            [
                "fMRI"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CL"
            ]
        ],
        "abstract": "Semantic representations are integral to natural language processing, psycholinguistics, and artificial intelligence. Although often derived from internet text, recent years have seen a rise in the popularity of behavior-based (e.g., free associations) and brain-based (e.g., fMRI) representations, which promise improvements in our ability to measure and model human representations. We carry out the first systematic evaluation of the similarities and differences between semantic representations derived from text, behavior, and brain data. Using representational similarity analysis, we show that word vectors derived from behavior and brain data encode information that differs from their text-derived cousins. Furthermore, drawing on our psychNorms metabase, alongside an interpretability method that we call representational content analysis, we find that, in particular, behavior representations capture unique variance on certain affective, agentic, and socio-moral dimensions. We thus establish behavior as an important complement to text for capturing human representations and behavior. These results are broadly relevant to research aimed at learning human-aligned semantic representations, including work on evaluating and aligning large language models.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "13 pages, 5 figures, 2 tables"
    },
    {
        "paper id": "2412.04945",
        "abstract url": "https://arxiv.org/abs/2412.04945",
        "title": "HOLa: HoloLens Object Labeling",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "surgery"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "In the context of medical Augmented Reality (AR) applications, object tracking is a key challenge and requires a significant amount of annotation masks. As segmentation foundation models like the Segment Anything Model (SAM) begin to emerge, zero-shot segmentation requires only minimal human participation obtaining high-quality object masks. We introduce a HoloLens-Object-Labeling (HOLa) Unity and Python application based on the SAM-Track algorithm that offers fully automatic single object annotation for HoloLens 2 while requiring minimal human participation. HOLa does not have to be adjusted to a specific image appearance and could thus alleviate AR research in any application field. We evaluate HOLa for different degrees of image complexity in open liver surgery and in medical phantom experiments. Using HOLa for image annotation can increase the labeling speed by more than 500 times while providing Dice scores between 0.875 and 0.982, which are comparable to human annotators. Our code is publicly available at: https://github.com/mschwimmbeck/HOLa",
        "subjects": [
            "cs.CV"
        ],
        "comment": "accepted by BMT 2024"
    },
    {
        "paper id": "2412.04970",
        "abstract url": "https://arxiv.org/abs/2412.04970",
        "title": "CMSO-transducing tree-like graph decompositions",
        "rating": "-1",
        "keywords": [
            [
                "graph"
            ]
        ],
        "abstract": "We show that given a graph G we can CMSO-transduce its modular decomposition, its split decomposition and its bi-join decomposition. This improves results by Courcelle [Logical Methods in Computer Science, 2006] who gave such transductions using order-invariant MSO, a strictly more expressive logic than CMSO. Our methods more generally yield C2MSO-transductions of the canonical decomposition of weakly-partitive set systems and weakly-bipartitive systems of bipartitions.",
        "subjects": [
            "cs.LO",
            "cs.CC",
            "cs.DM",
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04977",
        "abstract url": "https://arxiv.org/abs/2412.04977",
        "title": "ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "Purpose: Finding scholarly articles is a time-consuming and cumbersome activity, yet crucial for conducting science. Due to the growing number of scholarly articles, new scholarly search systems are needed to effectively assist researchers in finding relevant literature. Methodology: We take a neuro-symbolic approach to scholarly search and exploration by leveraging state-of-the-art components, including semantic search, Large Language Models (LLMs), and Knowledge Graphs (KGs). The semantic search component composes a set of relevant articles. From this set of articles, information is extracted and presented to the user. Findings: The presented system, called ORKG ASK (Assistant for Scientific Knowledge), provides a production-ready search and exploration system. Our preliminary evaluation indicates that our proposed approach is indeed suitable for the task of scholarly information retrieval. Value: With ORKG ASK, we present a next-generation scholarly search and exploration system and make it available online. Additionally, the system components are open source with a permissive license.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04979",
        "abstract url": "https://arxiv.org/abs/2412.04979",
        "title": "A Key Encapsulation Mechanism from Low Density Lattice Codes",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Key Encapsulation Mechanisms (KEMs) are a set of cryptographic techniques that are designed to provide symmetric encryption key using asymmetric mechanism (public key). In the current study, we concentrate on design and analysis of key encapsulation mechanism from low density lattice codes (KEM-LDLC) to go down the key size by keeping an acceptable level of security. The security of the proposed KEM-LDLC relies on the difficulty of solving the closest vector problem (CVP) and the shortest basis problem (SBP) of the lattices. Furthermore, this paper discusses other performance analyses results such as key size, error performance, and computational complexity, as well as conventional security analysis against applied attacks. Reducing the key size is performed by two approaches: (i) saving the generation sequence of the latin square LDLCs parity-check matrix of as a part of the secret key set; (ii) using the hermite normal form (HNF) of the latin square LDLCs generator matrix as part of the public key set. These enhancements enable us to attain greater efficiency and security compared to earlier code-based KEMs.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04986",
        "abstract url": "https://arxiv.org/abs/2412.04986",
        "title": "Power Plant Detection for Energy Estimation using GIS with Remote Sensing, CNN & Vision Transformers",
        "rating": "-1",
        "keywords": [
            [
                "Remote Sensing"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "In this research, we propose a hybrid model for power plant detection to assist energy estimation applications, by pipelining GIS (Geographical Information Systems) having Remote Sensing capabilities with CNN (Convolutional Neural Networks) and ViT (Vision Transformers). Our proposed approach enables real-time analysis with multiple data types on a common map via the GIS, entails feature-extraction abilities due to the CNN, and captures long-range dependencies through the ViT. This hybrid approach is found to enhance classification, thus helping in the monitoring and operational management of power plants; hence assisting energy estimation and sustainable energy planning in the future. It exemplifies adequate deployment of machine learning methods in conjunction with domain-specific approaches to enhance performance.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05023",
        "abstract url": "https://arxiv.org/abs/2412.05023",
        "title": "Steps are all you need: Rethinking STEM Education with Prompt Engineering",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "Few shot and Chain-of-Thought prompting have shown promise when applied to Physics Question Answering Tasks, but are limited by the lack of mathematical ability inherent to LLMs, and are prone to hallucination. By utilizing a Mixture of Experts (MoE) Model, along with analogical prompting, we are able to show improved model performance when compared to the baseline on standard LLMs. We also survey the limits of these prompting techniques and the effects they have on model performance. Additionally, we propose Analogical CoT prompting, a prompting technique designed to allow smaller, open source models to leverage Analogical prompting, something they have struggled with, possibly due to a lack of specialist training data.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05058",
        "abstract url": "https://arxiv.org/abs/2412.05058",
        "title": "Spatial Bandwidth of Bilateral Near-Field Channels for Linear Large-Scale Antenna Array System",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ]
        ],
        "abstract": "This paper analyzes the spatial bandwidth of line-of-sight (LoS) channels in massive MIMO systems. For the linear large-scale antenna arrays (LSAA) of transceivers placed in random locations in 3D space, a simple but accurate closed-form expression is derived to characterize the spatial bandwidth. Subsequent analysis of the LSAA's spatial bandwidth properties is also provided, leading to the formulation of an approximate expression for the effective degrees of freedom (EDoF) of bilateral near-field channels. Interestingly, as proved in this work, when the transmit and receive arrays are coplanar, with the receive array positioned perpendicular to the axis joining the centroids of the transmit and receive arrays, the EDoF of the LoS channel is found to be approximately maximized.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05065",
        "abstract url": "https://arxiv.org/abs/2412.05065",
        "title": "Reconstruction of 3D lumbar spine models from incomplete segmentations using landmark detection",
        "rating": "-1",
        "keywords": [
            [
                "time-efficient"
            ],
            [
                "3D"
            ],
            [
                "biomechanical",
                "medical",
                "healthcare",
                "surgery",
                "MRI",
                "X-Ray",
                "Clinical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Patient-specific 3D spine models serve as a foundation for spinal treatment and surgery planning as well as analysis of loading conditions in biomechanical and biomedical research. Despite advancements in imaging technologies, the reconstruction of complete 3D spine models often faces challenges due to limitations in imaging modalities such as planar X-Ray and missing certain spinal structures, such as the spinal or transverse processes, in volumetric medical images and resulting segmentations. In this study, we present a novel accurate and time-efficient method to reconstruct complete 3D lumbar spine models from incomplete 3D vertebral bodies obtained from segmented magnetic resonance images (MRI). In our method, we use an affine transformation to align artificial vertebra models with patient-specific incomplete vertebrae. The transformation matrix is derived from vertebra landmarks, which are automatically detected on the vertebra endplates. The results of our evaluation demonstrate the high accuracy of the performed registration, achieving an average point-to-model distance of 1.95 mm. Additionally, in assessing the morphological properties of the vertebrae and intervertebral characteristics, our method demonstrated a mean absolute error (MAE) of 3.4\u00b0 in the angles of functional spine units (FSUs), emphasizing its effectiveness in maintaining important spinal features throughout the transformation process of individual vertebrae. Our method achieves the registration of the entire lumbar spine, spanning segments L1 to L5, in just 0.14 seconds, showcasing its time-efficiency. Clinical relevance: the fast and accurate reconstruction of spinal models from incomplete input data such as segmentations provides a foundation for many applications in spine diagnostics, treatment planning, and the development of spinal healthcare solutions.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05066",
        "abstract url": "https://arxiv.org/abs/2412.05066",
        "title": "BimArt: A Unified Approach for the Synthesis of 3D Bimanual Interaction with Articulated Objects",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "trajectory"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We present BimArt, a novel generative approach for synthesizing 3D bimanual hand interactions with articulated objects. Unlike prior works, we do not rely on a reference grasp, a coarse hand trajectory, or separate modes for grasping and articulating. To achieve this, we first generate distance-based contact maps conditioned on the object trajectory with an articulation-aware feature representation, revealing rich bimanual patterns for manipulation. The learned contact prior is then used to guide our hand motion generator, producing diverse and realistic bimanual motions for object movement and articulation. Our work offers key insights into feature representation and contact prior for articulated objects, demonstrating their effectiveness in taming the complex, high-dimensional space of bimanual hand-object interactions. Through comprehensive quantitative experiments, we demonstrate a clear step towards simplified and high-quality hand-object animations that excel over the state-of-the-art in motion quality and diversity.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05081",
        "abstract url": "https://arxiv.org/abs/2412.05081",
        "title": "Spinal ligaments detection on vertebrae meshes using registration and 3D edge detection",
        "rating": "-1",
        "keywords": [
            [
                "time-efficient"
            ],
            [
                "3D"
            ],
            [
                "biomechanical",
                "Clinical"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Spinal ligaments are crucial elements in the complex biomechanical simulation models as they transfer forces on the bony structure, guide and limit movements and stabilize the spine. The spinal ligaments encompass seven major groups being responsible for maintaining functional interrelationships among the other spinal components. Determination of the ligament origin and insertion points on the 3D vertebrae models is an essential step in building accurate and complex spine biomechanical models. In our paper, we propose a pipeline that is able to detect 66 spinal ligament attachment points by using a step-wise approach. Our method incorporates a fast vertebra registration that strategically extracts only 15 3D points to compute the transformation, and edge detection for a precise projection of the registered ligaments onto any given patient-specific vertebra model. Our method shows high accuracy, particularly in identifying landmarks on the anterior part of the vertebra with an average distance of 2.24 mm for anterior longitudinal ligament and 1.26 mm for posterior longitudinal ligament landmarks. The landmark detection requires approximately 3.0 seconds per vertebra, providing a substantial improvement over existing methods. Clinical relevance: using the proposed method, the required landmarks that represent origin and insertion points for forces in the biomechanical spine models can be localized automatically in an accurate and time-efficient manner.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05084",
        "abstract url": "https://arxiv.org/abs/2412.05084",
        "title": "Reconstructing Quantitative Cerebral Perfusion Images Directly From Measured Sinogram Data Acquired Using C-arm Cone-Beam CT",
        "rating": "-1",
        "keywords": [
            [
                "CT"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "To shorten the door-to-puncture time for better treating patients with acute ischemic stroke, it is highly desired to obtain quantitative cerebral perfusion images using C-arm cone-beam computed tomography (CBCT) equipped in the interventional suite. However, limited by the slow gantry rotation speed, the temporal resolution and temporal sampling density of typical C-arm CBCT are much poorer than those of multi-detector-row CT in the diagnostic imaging suite. The current quantitative perfusion imaging includes two cascaded steps: time-resolved image reconstruction and perfusion parametric estimation. For time-resolved image reconstruction, the technical challenge imposed by poor temporal resolution and poor sampling density causes inaccurate quantification of the temporal variation of cerebral artery and tissue attenuation values. For perfusion parametric estimation, it remains a technical challenge to appropriately design the handcrafted regularization for better solving the associated deconvolution problem. These two challenges together prevent obtaining quantitatively accurate perfusion images using C-arm CBCT. The purpose of this work is to simultaneously address these two challenges by combining the two cascaded steps into a single joint optimization problem and reconstructing quantitative perfusion images directly from the measured sinogram data. In the developed direct cerebral perfusion parametric image reconstruction technique, TRAINER in short, the quantitative perfusion images have been represented as a subject-specific conditional generative model trained under the constraint of the time-resolved CT forward model, perfusion convolutional model, and the subject's own measured sinogram data. Results shown in this paper demonstrated that using TRAINER, quantitative cerebral perfusion images can be accurately obtained using C-arm CBCT in the interventional suite.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "physics.med-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05134",
        "abstract url": "https://arxiv.org/abs/2412.05134",
        "title": "How to Squeeze An Explanation Out of Your Model",
        "rating": "-1",
        "keywords": [
            [
                "biometrics",
                "healthcare",
                "facial"
            ],
            [
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Deep learning models are widely used nowadays for their reliability in performing various tasks. However, they do not typically provide the reasoning behind their decision, which is a significant drawback, particularly for more sensitive areas such as biometrics, security and healthcare. The most commonly used approaches to provide interpretability create visual attention heatmaps of regions of interest on an image based on models gradient backpropagation. Although this is a viable approach, current methods are targeted toward image settings and default/standard deep learning models, meaning that they require significant adaptations to work on video/multi-modal settings and custom architectures. This paper proposes an approach for interpretability that is model-agnostic, based on a novel use of the Squeeze and Excitation (SE) block that creates visual attention heatmaps. By including an SE block prior to the classification layer of any model, we are able to retrieve the most influential features via SE vector manipulation, one of the key components of the SE block. Our results show that this new SE-based interpretability can be applied to various models in image and video/multi-modal settings, namely biometrics of facial features with CelebA and behavioral biometrics using Active Speaker Detection datasets. Furthermore, our proposal does not compromise model performance toward the original task, and has competitive results with current interpretability approaches in state-of-the-art object datasets, highlighting its robustness to perform in varying data aside from the biometric context.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05138",
        "abstract url": "https://arxiv.org/abs/2412.05138",
        "title": "Supply Chain Insecurity: The Lack of Integrity Protection in SBOM Solutions",
        "rating": "-1",
        "keywords": [
            [
                "attack"
            ]
        ],
        "abstract": "The SolarWinds attack that exploited weaknesses in the software update mechanism highlights the critical need for organizations to have better visibility into their software dependencies and potential vulnerabilities associated with them, and the Software Bill of Materials (SBOM) is paramount in ensuring software supply chain security. Under the Executive Order issued by President Biden, the adoption of the SBOM has become obligatory within the United States. The executive order mandates that an SBOM should be provided for all software purchased by federal agencies. The main applications of SBOMs are vulnerability management and license management. This work presents an in-depth and systematic investigation into the integrity of SBOMs. We explore different attack vectors that can be exploited to manipulate SBOM data, including flaws in the SBOM generation and consumption phases in the SBOM life cycle. We thoroughly investigated four SBOM consumption tools and the generation process of SBOMs for seven prominent programming languages. Our systematic investigation reveals that the tools used for consumption lack integrity control mechanisms for dependencies. Similarly, the generation process is susceptible to integrity attacks as well, by manipulating dependency version numbers in package managers and additional files, resulting in incorrect SBOM data. This could lead to incorrect views on software dependencies and vulnerabilities being overlooked during SBOM consumption. To mitigate these issues, we propose a solution incorporating the decentralized storage of hash values of software libraries.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05139",
        "abstract url": "https://arxiv.org/abs/2412.05139",
        "title": "A Practical Examination of AI-Generated Text Detectors for Large Language Models",
        "rating": "-1",
        "keywords": [
            [
                "RADAR"
            ],
            [
                "attacks"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "The proliferation of large language models has raised growing concerns about their misuse, particularly in cases where AI-generated text is falsely attributed to human authors. Machine-generated content detectors claim to effectively identify such text under various conditions and from any language model. This paper critically evaluates these claims by assessing several popular detectors (RADAR, Wild, T5Sentinel, Fast-DetectGPT, GPTID, LogRank, Binoculars) on a range of domains, datasets, and models that these detectors have not previously encountered. We employ various prompting strategies to simulate adversarial attacks, demonstrating that even moderate efforts can significantly evade detection. We emphasize the importance of the true positive rate at a specific false positive rate (TPR@FPR) metric and demonstrate that these detectors perform poorly in certain settings, with TPR@.01 as low as 0\\%. Our findings suggest that both trained and zero-shot detectors struggle to maintain high sensitivity while achieving a reasonable true positive rate.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": "8 pages. Submitted to ARR October cycle"
    },
    {
        "paper id": "2412.05150",
        "abstract url": "https://arxiv.org/abs/2412.05150",
        "title": "BIAS: A Body-based Interpretable Active Speaker Approach",
        "rating": "-1",
        "keywords": [
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "State-of-the-art Active Speaker Detection (ASD) approaches heavily rely on audio and facial features to perform, which is not a sustainable approach in wild scenarios. Although these methods achieve good results in the standard AVA-ActiveSpeaker set, a recent wilder ASD dataset (WASD) showed the limitations of such models and raised the need for new approaches. As such, we propose BIAS, a model that, for the first time, combines audio, face, and body information, to accurately predict active speakers in varying/challenging conditions. Additionally, we design BIAS to provide interpretability by proposing a novel use for Squeeze-and-Excitation blocks, namely in attention heatmaps creation and feature importance assessment. For a full interpretability setup, we annotate an ASD-related actions dataset (ASD-Text) to finetune a ViT-GPT2 for text scene description to complement BIAS interpretability. The results show that BIAS is state-of-the-art in challenging conditions where body-based features are of utmost importance (Columbia, open-settings, and WASD), and yields competitive results in AVA-ActiveSpeaker, where face is more influential than body for ASD. BIAS interpretability also shows the features/aspects more relevant towards ASD prediction in varying settings, making it a strong baseline for further developments in interpretable ASD models, and is available at https://github.com/Tiago-Roxo/BIAS.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05161",
        "abstract url": "https://arxiv.org/abs/2412.05161",
        "title": "DNF: Unconditional 4D Generation with Dictionary-based Neural Fields",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "While remarkable success has been achieved through diffusion-based 3D generative models for shapes, 4D generative modeling remains challenging due to the complexity of object deformations over time. We propose DNF, a new 4D representation for unconditional generative modeling that efficiently models deformable shapes with disentangled shape and motion while capturing high-fidelity details in the deforming objects. To achieve this, we propose a dictionary learning approach to disentangle 4D motion from shape as neural fields. Both shape and motion are represented as learned latent spaces, where each deformable shape is represented by its shape and motion global latent codes, shape-specific coefficient vectors, and shared dictionary information. This captures both shape-specific detail and global shared information in the learned dictionary. Our dictionary-based representation well balances fidelity, contiguity and compression -- combined with a transformer-based diffusion model, our method is able to generate effective, high-fidelity 4D animations.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "comment": "Project page: https://xzhang-t.github.io/project/DNF/"
    },
    {
        "paper id": "2412.05174",
        "abstract url": "https://arxiv.org/abs/2412.05174",
        "title": "Compound Gaussian Radar Clutter Model With Positive Tempered Alpha-Stable Texture",
        "rating": "-1",
        "keywords": [
            [
                "Radar"
            ]
        ],
        "abstract": "The compound Gaussian (CG) family of distributions has achieved great success in modeling sea clutter. This work develops a flexible-tailed CG model to improve generality in clutter modeling, by introducing the positive tempered $\u03b1$-stable (PT$\u03b1$S) distribution to model clutter texture. The PT$\u03b1$S distribution exhibits widely tunable tails by tempering the heavy tails of the positive $\u03b1$-stable (P$\u03b1$S) distribution, thus providing greater flexibility in texture modeling. Specifically, we first develop a bivariate isotropic CG-PT$\u03b1$S complex clutter model that is defined by an explicit characteristic function, based on which the corresponding amplitude model is derived. Then, we prove that the amplitude model can be expressed as a scale mixture of Rayleighs, just as the successful compound K and Pareto models. Furthermore, a characteristic function-based method is developed to estimate the parameters of the amplitude model. Finally, real-world sea clutter data analysis indicates the amplitude model's flexibility in modeling clutter data with various tail behaviors.",
        "subjects": [
            "eess.SP",
            "stat.ME"
        ],
        "comment": "7 pages, 4 figures, 2 tables"
    },
    {
        "paper id": "2412.05187",
        "abstract url": "https://arxiv.org/abs/2412.05187",
        "title": "SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot",
        "rating": "-1",
        "keywords": [
            [
                "healthcare",
                "Surgical",
                "Surgery",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV"
            ]
        ],
        "abstract": "Surgical interventions, particularly in neurology, represent complex and high-stakes scenarios that impose substantial cognitive burdens on surgical teams. Although deliberate education and practice can enhance cognitive capabilities, surgical training opportunities remain limited due to patient safety concerns. To address these cognitive challenges in surgical training and operation, we propose SurgBox, an agent-driven sandbox framework to systematically enhance the cognitive capabilities of surgeons in immersive surgical simulations. Specifically, our SurgBox leverages large language models (LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically replicate various surgical roles, enabling realistic training environments for deliberate practice. In particular, we devise Surgery Copilot, an AI-driven assistant to actively coordinate the surgical information stream and support clinical decision-making, thereby diminishing the cognitive workload of surgical teams during surgery. By incorporating a novel Long-Short Memory mechanism, our Surgery Copilot can effectively balance immediate procedural assistance with comprehensive surgical knowledge. Extensive experiments using real neurosurgical procedure records validate our SurgBox framework in both enhancing surgical cognitive capabilities and supporting clinical decision-making. By providing an integrated solution for training and operational support to address cognitive challenges, our SurgBox framework advances surgical education and practice, potentially transforming surgical outcomes and healthcare quality. The code is available at https://github.com/franciszchen/SurgBox.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.HC",
            "cs.RO"
        ],
        "comment": "This work is accepted by IEEE Big Data 2024"
    },
    {
        "paper id": "2412.05233",
        "abstract url": "https://arxiv.org/abs/2412.05233",
        "title": "Physics-informed reduced order model with conditional neural fields",
        "rating": "-1",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "This study presents the conditional neural fields for reduced-order modeling (CNF-ROM) framework to approximate solutions of parametrized partial differential equations (PDEs). The approach combines a parametric neural ODE (PNODE) for modeling latent dynamics over time with a decoder that reconstructs PDE solutions from the corresponding latent states. We introduce a physics-informed learning objective for CNF-ROM, which includes two key components. First, the framework uses coordinate-based neural networks to calculate and minimize PDE residuals by computing spatial derivatives via automatic differentiation and applying the chain rule for time derivatives. Second, exact initial and boundary conditions (IC/BC) are imposed using approximate distance functions (ADFs) [Sukumar and Srivastava, CMAME, 2022]. However, ADFs introduce a trade-off as their second- or higher-order derivatives become unstable at the joining points of boundaries. To address this, we introduce an auxiliary network inspired by [Gladstone et al., NeurIPS ML4PS workshop, 2022]. Our method is validated through parameter extrapolation and interpolation, temporal extrapolation, and comparisons with analytical solutions.",
        "subjects": [
            "math.NA",
            "cs.LG"
        ],
        "comment": "7 pages, 2 figures, NeurIPS 2024 Workshop on Machine Learning and the Physical Sciences"
    },
    {
        "paper id": "2412.05268",
        "abstract url": "https://arxiv.org/abs/2412.05268",
        "title": "DenseMatcher: Learning 3D Semantic Correspondence for Category-Level Manipulation from a Single Demo",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "robotic manipulation"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Dense 3D correspondence can enhance robotic manipulation by enabling the generalization of spatial, functional, and dynamic information from one object to an unseen counterpart. Compared to shape correspondence, semantic correspondence is more effective in generalizing across different object categories. To this end, we present DenseMatcher, a method capable of computing 3D correspondences between in-the-wild objects that share similar structures. DenseMatcher first computes vertex features by projecting multiview 2D features onto meshes and refining them with a 3D network, and subsequently finds dense correspondences with the obtained features using functional map. In addition, we craft the first 3D matching dataset that contains colored object meshes across diverse categories. In our experiments, we show that DenseMatcher significantly outperforms prior 3D matching baselines by 43.5%. We demonstrate the downstream effectiveness of DenseMatcher in (i) robotic manipulation, where it achieves cross-instance and cross-category generalization on long-horizon complex manipulation tasks from observing only one demo; (ii) zero-shot color mapping between digital assets, where appearance can be transferred between different objects with relatable geometry.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "Project Page: https://tea-lab.github.io/DenseMatcher/"
    },
    {
        "paper id": "2412.05278",
        "abstract url": "https://arxiv.org/abs/2412.05278",
        "title": "Birth and Death of a Rose",
        "rating": "-1",
        "keywords": [
            [
                "3D"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "We study the problem of generating temporal object intrinsics -- temporally evolving sequences of object geometry, reflectance, and texture, such as a blooming rose -- from pre-trained 2D foundation models. Unlike conventional 3D modeling and animation techniques that require extensive manual effort and expertise, we introduce a method that generates such assets with signals distilled from pre-trained 2D diffusion models. To ensure the temporal consistency of object intrinsics, we propose Neural Templates for temporal-state-guided distillation, derived automatically from image features from self-supervised learning. Our method can generate high-quality temporal object intrinsics for several natural phenomena and enable the sampling and controllable rendering of these dynamic objects from any viewpoint, under any environmental lighting conditions, at any time of their lifespan. Project website: https://chen-geng.com/rose4d",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "comment": "Project website: https://chen-geng.com/rose4d"
    },
    {
        "paper id": "2412.05279",
        "abstract url": "https://arxiv.org/abs/2412.05279",
        "title": "Perturb-and-Revise: Flexible 3D Editing with Generative Trajectories",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "NeRF"
            ],
            [
                "diffusion"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "The fields of 3D reconstruction and text-based 3D editing have advanced significantly with the evolution of text-based diffusion models. While existing 3D editing methods excel at modifying color, texture, and style, they struggle with extensive geometric or appearance changes, thus limiting their applications. We propose Perturb-and-Revise, which makes possible a variety of NeRF editing. First, we perturb the NeRF parameters with random initializations to create a versatile initialization. We automatically determine the perturbation magnitude through analysis of the local loss landscape. Then, we revise the edited NeRF via generative trajectories. Combined with the generative process, we impose identity-preserving gradients to refine the edited NeRF. Extensive experiments demonstrate that Perturb-and-Revise facilitates flexible, effective, and consistent editing of color, appearance, and geometry in 3D. For 360\u00b0 results, please visit our project page: https://susunghong.github.io/Perturb-and-Revise.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "Project page: https://susunghong.github.io/Perturb-and-Revise"
    },
    {
        "paper id": "2412.05280",
        "abstract url": "https://arxiv.org/abs/2412.05280",
        "title": "Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model",
        "rating": "-1",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "autonomous driving",
                "vehicle"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "4D driving simulation is essential for developing realistic autonomous driving simulators. Despite advancements in existing methods for generating driving scenes, significant challenges remain in view transformation and spatial-temporal dynamic modeling. To address these limitations, we propose a Spatial-Temporal simulAtion for drivinG (Stag-1) model to reconstruct real-world scenes and design a controllable generative network to achieve 4D simulation. Stag-1 constructs continuous 4D point cloud scenes using surround-view data from autonomous vehicles. It decouples spatial-temporal relationships and produces coherent keyframe videos. Additionally, Stag-1 leverages video generation models to obtain photo-realistic and controllable 4D driving simulation videos from any perspective. To expand the range of view generation, we train vehicle motion videos based on decomposed camera poses, enhancing modeling capabilities for distant scenes. Furthermore, we reconstruct vehicle camera trajectories to integrate 3D points across consecutive views, enabling comprehensive scene understanding along the temporal dimension. Following extensive multi-level scene training, Stag-1 can simulate from any desired viewpoint and achieve a deep understanding of scene evolution under static spatial-temporal conditions. Compared to existing methods, our approach shows promising performance in multi-view scene consistency, background coherence, and accuracy, and contributes to the ongoing advancements in realistic autonomous driving simulation. Code: https://github.com/wzzheng/Stag.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "Code is available at: https://github.com/wzzheng/Stag"
    },
    {
        "paper id": "2412.05343",
        "abstract url": "https://arxiv.org/abs/2412.05343",
        "title": "Equivariant Denoisers for Image Restoration",
        "rating": "-1",
        "keywords": [
            [
                "Image Restoration"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "One key ingredient of image restoration is to define a realistic prior on clean images to complete the missing information in the observation. State-of-the-art restoration methods rely on a neural network to encode this prior. Moreover, typical image distributions are invariant to some set of transformations, such as rotations or flips. However, most deep architectures are not designed to represent an invariant image distribution. Recent works have proposed to overcome this difficulty by including equivariance properties within a Plug-and-Play paradigm. In this work, we propose a unified framework named Equivariant Regularization by Denoising (ERED) based on equivariant denoisers and stochastic optimization. We analyze the convergence of this algorithm and discuss its practical benefit.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05347",
        "abstract url": "https://arxiv.org/abs/2412.05347",
        "title": "Automated Dynamic Image Analysis for Particle Size and Shape Classification in Three Dimensions",
        "rating": "-1",
        "keywords": [
            [
                "X-ray"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "We introduce OCULAR, an innovative hardware and software solution for three-dimensional dynamic image analysis of fine particles. Current state-of-the art instruments for dynamic image analysis are largely limited to two-dimensional imaging. However, extensive literature has demonstrated that relying on a single two-dimensional projection for particle characterisation can lead to inaccuracies in many applications. Existing three-dimensional imaging technologies, such as computed tomography, laser scanning, and orthophotography, are limited to static objects. These methods are often not statistically representative and come with significant post-processing requirements, as well as the need for specialised imaging and computing resources. OCULAR addresses these challenges by providing a cost-effective solution for imaging continuous particle streams using a synchronised array of optical cameras. Particle shape characterisation is achieved through the reconstruction of their three-dimensional surfaces. This paper details the OCULAR methodology, evaluates its reproducibility, and compares its results against X-ray micro computed tomography, highlighting its potential for efficient and reliable particle analysis.",
        "subjects": [
            "cs.CV",
            "cond-mat.mtrl-sci",
            "cond-mat.stat-mech",
            "eess.IV"
        ],
        "comment": "11 pages, 5 figures"
    },
    {
        "paper id": "2412.05348",
        "abstract url": "https://arxiv.org/abs/2412.05348",
        "title": "Accurate early detection of Parkinson's disease from SPECT imaging through Convolutional Neural Networks",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis",
                "disease",
                "clinical"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Early and accurate detection of Parkinson's disease (PD) is a crucial diagnostic challenge carrying immense clinical significance, for effective treatment regimens and patient management. For instance, a group of subjects termed SWEDD who are clinically diagnosed as PD, but show normal Single Photon Emission Computed Tomography (SPECT) scans, change their diagnosis as non-PD after few years of follow up, and in the meantime, they are treated with PD medications which do more harm than good. In this work, machine learning models are developed using features from SPECT images to detect early PD and SWEDD subjects from normal. These models were observed to perform with high accuracy. It is inferred from the study that these diagnostic models carry potential to help PD clinicians in the diagnostic process",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "stat.AP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05412",
        "abstract url": "https://arxiv.org/abs/2412.05412",
        "title": "Using Fitts' Law to Benchmark Assisted Human-Robot Performance",
        "rating": "-1",
        "keywords": [
            [
                "Robot"
            ]
        ],
        "abstract": "Shared control systems aim to combine human and robot abilities to improve task performance. However, achieving optimal performance requires that the robot's level of assistance adjusts the operator's cognitive workload in response to the task difficulty. Understanding and dynamically adjusting this balance is crucial to maximizing efficiency and user satisfaction. In this paper, we propose a novel benchmarking method for shared control systems based on Fitts' Law to formally parameterize the difficulty level of a target-reaching task. With this we systematically quantify and model the effect of task difficulty (i.e. size and distance of target) and robot autonomy on task performance and operators' cognitive load and trust levels. Our empirical results (N=24) not only show that both task difficulty and robot autonomy influence task performance, but also that the performance can be modelled using these parameters, which may allow for the generalization of this relationship across more diverse setups. We also found that the users' perceived cognitive load and trust were influenced by these factors. Given the challenges in directly measuring cognitive load in real-time, our adapted Fitts' model presents a potential alternative approach to estimate cognitive load through determining the difficulty level of the task, with the assumption that greater task difficulty results in higher cognitive load levels. We hope that these insights and our proposed framework inspire future works to further investigate the generalizability of the method, ultimately enabling the benchmarking and systematic assessment of shared control quality and user impact, which will aid in the development of more effective and adaptable systems.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "9 pages, 5 figures. arXiv admin note: text overlap with arXiv:2402.02758"
    },
    {
        "paper id": "2412.05413",
        "abstract url": "https://arxiv.org/abs/2412.05413",
        "title": "Branch Target Buffer Reverse Engineering on Arm",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "The Branch Target Buffer (BTB) plays a critical role in efficient CPU branch prediction. Understanding the design and implementation of the BTB provides valuable insights for both compiler design and the mitigation of hardware attacks such as Spectre. However, the proprietary nature of dominant CPUs, such as those from Intel, AMD, Apple, and Qualcomm, means that specific BTB implementation details are not publicly available. To address this limitation, several previous works have successfully reverse-engineered BTB information, including capacity and associativity, primarily targeting Intel's x86 processors. However, to our best knowledge, no research has attempted to reverse-engineer and expose the BTB implementation of ARM processors. This project aims to fill the gap by exploring the BTB of ARM processors. Specifically, we investigate whether existing reverse-engineering techniques developed for Intel BTB can be adapted for ARM. We reproduce the x86 methodology and identify specific PMU events for ARM to facilitate the reverse engineering process. In our experiment, we investigated our ARM CPU, i.e., the quad-core Cortex-A72 of the Raspberry Pi 4B. Our results show that the BTB capacity is 4K, the set index starts from the 5th bit and ends with the 15th bit of the PC (11 bits in total), and there are 2 ways in each set. The source code can be find at https://github.com/stefan1wan/BTB_ARM_RE.",
        "subjects": [
            "cs.AR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05430",
        "abstract url": "https://arxiv.org/abs/2412.05430",
        "title": "DART-Eval: A Comprehensive DNA Language Model Evaluation Benchmark on Regulatory DNA",
        "rating": "-1",
        "keywords": [
            [
                "biologically",
                "DNA"
            ],
            [
                "cs.LG"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "Recent advances in self-supervised models for natural language, vision, and protein sequences have inspired the development of large genomic DNA language models (DNALMs). These models aim to learn generalizable representations of diverse DNA elements, potentially enabling various genomic prediction, interpretation and design tasks. Despite their potential, existing benchmarks do not adequately assess the capabilities of DNALMs on key downstream applications involving an important class of non-coding DNA elements critical for regulating gene activity. In this study, we introduce DART-Eval, a suite of representative benchmarks specifically focused on regulatory DNA to evaluate model performance across zero-shot, probed, and fine-tuned scenarios against contemporary ab initio models as baselines. Our benchmarks target biologically meaningful downstream tasks such as functional sequence feature discovery, predicting cell-type specific regulatory activity, and counterfactual prediction of the impacts of genetic variants. We find that current DNALMs exhibit inconsistent performance and do not offer compelling gains over alternative baseline models for most tasks, while requiring significantly more computational resources. We discuss potentially promising modeling, data curation, and evaluation strategies for the next generation of DNALMs. Our code is available at https://github.com/kundajelab/DART-Eval.",
        "subjects": [
            "cs.LG",
            "q-bio.GN"
        ],
        "comment": "NeurIPS Datasets and Benchmarks 2024"
    },
    {
        "paper id": "2412.05436",
        "abstract url": "https://arxiv.org/abs/2412.05436",
        "title": "pyAMPACT: A Score-Audio Alignment Toolkit for Performance Data Estimation and Multi-modal Processing",
        "rating": "-1",
        "keywords": [
            [
                "Music"
            ],
            [
                "cs.SD",
                "eess.AS"
            ]
        ],
        "abstract": "pyAMPACT (Python-based Automatic Music Performance Analysis and Comparison Toolkit) links symbolic and audio music representations to facilitate score-informed estimation of performance data in audio as well as general linking of symbolic and audio music representations with a variety of annotations. pyAMPACT can read a range of symbolic formats and can output note-linked audio descriptors/performance data into MEI-formatted files. The audio analysis uses score alignment to calculate time-frequency regions of importance for each note in the symbolic representation from which to estimate a range of parameters. These include tuning-, dynamics-, and timbre-related performance descriptors, with timing-related information available from the score alignment. Beyond performance data estimation, pyAMPACT also facilitates multi-modal investigations through its infrastructure for linking symbolic representations and annotations to audio.",
        "subjects": [
            "cs.SD",
            "cs.MM",
            "eess.AS"
        ],
        "comment": "International Society for Music Information Retrieval, Late Breaking Demo"
    },
    {
        "paper id": "2412.05462",
        "abstract url": "https://arxiv.org/abs/2412.05462",
        "title": "COOOL: Challenge Of Out-Of-Label A Novel Benchmark for Autonomous Driving",
        "rating": "-1",
        "keywords": [
            [
                "Autonomous Driving"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "As the Computer Vision community rapidly develops and advances algorithms for autonomous driving systems, the goal of safer and more efficient autonomous transportation is becoming increasingly achievable. However, it is 2024, and we still do not have fully self-driving cars. One of the remaining core challenges lies in addressing the novelty problem, where self-driving systems still struggle to handle previously unseen situations on the open road. With our Challenge of Out-Of-Label (COOOL) benchmark, we introduce a novel dataset for hazard detection, offering versatile evaluation metrics applicable across various tasks, including novelty-adjacent domains such as Anomaly Detection, Open-Set Recognition, Open Vocabulary, and Domain Adaptation. COOOL comprises over 200 collections of dashcam-oriented videos, annotated by human labelers to identify objects of interest and potential driving hazards. It includes a diverse range of hazards and nuisance objects. Due to the dataset's size and data complexity, COOOL serves exclusively as an evaluation benchmark.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05507",
        "abstract url": "https://arxiv.org/abs/2412.05507",
        "title": "AutoURDF: Unsupervised Robot Modeling from Point Cloud Frames Using Cluster Registration",
        "rating": "-1",
        "keywords": [
            [
                "Point Cloud",
                "6-DoF"
            ],
            [
                "Robot"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Robot description models are essential for simulation and control, yet their creation often requires significant manual effort. To streamline this modeling process, we introduce AutoURDF, an unsupervised approach for constructing description files for unseen robots from point cloud frames. Our method leverages a cluster-based point cloud registration model that tracks the 6-DoF transformations of point clusters. Through analyzing cluster movements, we hierarchically address the following challenges: (1) moving part segmentation, (2) body topology inference, and (3) joint parameter estimation. The complete pipeline produces robot description files that are fully compatible with existing simulators. We validate our method across a variety of robots, using both synthetic and real-world scan data. Results indicate that our approach outperforms previous methods in registration and body topology estimation accuracy, offering a scalable solution for automated robot modeling.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "16 pages, 20 figures"
    },
    {
        "paper id": "2412.05523",
        "abstract url": "https://arxiv.org/abs/2412.05523",
        "title": "Sliding Squares in Parallel",
        "rating": "-1",
        "keywords": [
            [
                "robot"
            ]
        ],
        "abstract": "We consider algorithmic problems motivated by modular robotic reconfiguration, for which we are given $n$ square-shaped modules (or robots) in a (labeled or unlabeled) start configuration and need to find a schedule of sliding moves to transform it into a desired goal configuration, maintaining connectivity of the configuration at all times. Recent work from Computational Geometry has aimed at minimizing the total number of moves, resulting in schedules that can perform reconfigurations in $\\mathcal{O}(n^2)$ moves, or $\\mathcal{O}(nP)$ for an arrangement of bounding box perimeter size $P$, but are fully sequential. Here we provide first results in the sliding square model that exploit parallel robot motion, resulting in an optimal speedup to achieve reconfiguration in worst-case optimal makespan of $\\mathcal{O}(P)$. We also provide tight bounds on the complexity of the problem by showing that even deciding the possibility of reconfiguration within makespan $1$ is NP-complete in the unlabeled case; for the labeled case, deciding reconfiguration within makespan $2$ is NP-complete, while makespan $1$ can be decided in polynomial time.",
        "subjects": [
            "cs.CG",
            "cs.DS"
        ],
        "comment": "38 pages, 35 figures"
    },
    {
        "paper id": "2412.05530",
        "abstract url": "https://arxiv.org/abs/2412.05530",
        "title": "CLIP-TNseg: A Multi-Modal Hybrid Framework for Thyroid Nodule Segmentation in Ultrasound Images",
        "rating": "-1",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Thyroid nodule segmentation in ultrasound images is crucial for accurate diagnosis and treatment planning. However, existing methods face challenges in segmentation accuracy, interpretability, and generalization, which hinder their performance. This letter proposes a novel framework, CLIP-TNseg, to address these issues by integrating a multimodal large model with a neural network architecture. CLIP-TNseg consists of two main branches: the Coarse-grained Branch, which extracts high-level semantic features from a frozen CLIP model, and the Fine-grained Branch, which captures fine-grained features using U-Net style residual blocks. These features are fused and processed by the prediction head to generate precise segmentation maps. CLIP-TNseg leverages the Coarse-grained Branch to enhance semantic understanding through textual and high-level visual features, while the Fine-grained Branch refines spatial details, enabling precise and robust segmentation. Extensive experiments on public and our newly collected datasets demonstrate its competitive performance. Our code and the original dataset are available at https://github.com/jayxjsun/CLIP-TNseg.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "4 pages, 2 figures, submitted to IEEE Signal Processing Letters"
    },
    {
        "paper id": "2412.05531",
        "abstract url": "https://arxiv.org/abs/2412.05531",
        "title": "Action Recognition based Industrial Safety Violation Detection",
        "rating": "-1",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Proper use of personal protective equipment (PPE) can save the lives of industry workers and it is a widely used application of computer vision in the large manufacturing industries. However, most of the applications deployed generate a lot of false alarms (violations) because they tend to generalize the requirements of PPE across the industry and tasks. The key to resolving this issue is to understand the action being performed by the worker and customize the inference for the specific PPE requirements of that action. In this paper, we propose a system that employs activity recognition models to first understand the action being performed and then use object detection techniques to check for violations. This leads to a 23% improvement in the F1-score compared to the PPE-based approach on our test dataset of 109 videos.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05532",
        "abstract url": "https://arxiv.org/abs/2412.05532",
        "title": "Enhancing Webshell Detection With Deep Learning-Powered Methods",
        "rating": "-1",
        "keywords": [
            [
                "attacks"
            ]
        ],
        "abstract": "Webshell attacks are becoming more common, requiring robust detection mechanisms to protect web applications. The dissertation clearly states two research directions: scanning web application source code and analyzing HTTP traffic to detect webshells. First, the dissertation proposes ASAF, an advanced DL-Powered Source-Code Scanning Framework that uses signature-based methods and deep learning algorithms to detect known and unknown webshells. We designed the framework to enable programming language-specific detection models. The dissertation used PHP for interpreted language and ASP.NET for compiled language to build a complete ASAF-based model for experimentation and comparison with other research results to prove its efficacy. Second, the dissertation introduces a deep neural network that detects webshells using real-time HTTP traffic analysis of web applications. The study proposes an algorithm to improve the deep learning model's loss function to address data imbalance. We tested and compared the model to other studies on the CSE-CIC-IDS2018 dataset to prove its efficacy. We integrated the model with NetIDPS to improve webshell identification. Automatically blacklist attack source IPs and block URIs querying webshells on the web server to prevent these attacks.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "PhD dissertation"
    },
    {
        "paper id": "2412.05536",
        "abstract url": "https://arxiv.org/abs/2412.05536",
        "title": "Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison",
        "rating": "-1",
        "keywords": [
            [
                "Medical",
                "Diagnosis",
                "clinical"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV",
                "cs.CL"
            ]
        ],
        "abstract": "This study introduces an evaluation framework for multimodal models in medical imaging diagnostics. We developed a pipeline incorporating data preprocessing, model inference, and preference-based evaluation, expanding an initial set of 500 clinical cases to 3,000 through controlled augmentation. Our method combined medical images with clinical observations to generate assessments, using Claude 3.5 Sonnet for independent evaluation against physician-authored diagnoses. The results indicated varying performance across models, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In contrast, specialized vision models like BLIP2 and Llava showed preferences in 41.36% and 46.77% of cases, respectively. This framework highlights the potential of large multimodal models to outperform human diagnostics in certain tasks.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05538",
        "abstract url": "https://arxiv.org/abs/2412.05538",
        "title": "Uncovering Vision Modality Threats in Image-to-Image Tasks",
        "rating": "-1",
        "keywords": [
            [
                "Text-to-Image"
            ],
            [
                "attack"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Current image generation models can effortlessly produce high-quality, highly realistic images, but this also increases the risk of misuse. In various Text-to-Image or Image-to-Image tasks, attackers can generate a series of images containing inappropriate content by simply editing the language modality input. Currently, to prevent this security threat, the various guard or defense methods that are proposed also focus on defending the language modality. However, in practical applications, threats in the visual modality, particularly in tasks involving the editing of real-world images, pose greater security risks as they can easily infringe upon the rights of the image owner. Therefore, this paper uses a method named typographic attack to reveal that various image generation models also commonly face threats in the vision modality. Furthermore, we also evaluate the defense performance of various existing methods when facing threats in the vision modality and uncover their ineffectiveness. Finally, we propose the Vision Modal Threats in Image Generation Models (VMT-IGMs) dataset, which would serve as a baseline for evaluating the vision modality vulnerability of various image generation models.",
        "subjects": [
            "cs.CV",
            "cs.PF"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06653",
        "abstract url": "https://arxiv.org/abs/2412.06653",
        "title": "A Novel Approach to Process Discovery with Enhanced Loop Handling",
        "rating": "-1",
        "keywords": [
            [
                "Graphs"
            ]
        ],
        "abstract": "Automated process discovery from event logs is a key component of process mining, allowing companies to acquire meaningful insights into their business processes. Despite significant research, present methods struggle to balance important quality dimensions: fitness, precision, generalization, and complexity, but is limited when dealing with complex loop structures. This paper introduces Bonita Miner, a novel approach to process model discovery that generates behaviorally accurate Business Process Model and Notation (BPMN) diagrams. Bonita Miner incorporates an advanced filtering mechanism for Directly Follows Graphs (DFGs) alongside innovative algorithms designed to capture concurrency, splits, and loops, effectively addressing limitations of balancing as much as possible these four metrics, either there exists a loop, which challenge in existing works. Our approach produces models that are simpler and more reflective of the behavior of real-world processes, including complex loop dynamics. Empirical evaluations using real-world event logs demonstrate that Bonita Miner outperforms existing methods in fitness, precision, and generalization, while maintaining low model complexity.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06828",
        "abstract url": "https://arxiv.org/abs/2412.06828",
        "title": "Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System",
        "rating": "-1",
        "keywords": [
            [
                "medical",
                "healthcare",
                "X-ray",
                "Radiology"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This study introduces \"RadCouncil,\" a multi-agent Large Language Model (LLM) framework designed to enhance the generation of impressions in radiology reports from the finding section. RadCouncil comprises three specialized agents: 1) a \"Retrieval\" Agent that identifies and retrieves similar reports from a vector database, 2) a \"Radiologist\" Agent that generates impressions based on the finding section of the given report plus the exemplar reports retrieved by the Retrieval Agent, and 3) a \"Reviewer\" Agent that evaluates the generated impressions and provides feedback. The performance of RadCouncil was evaluated using both quantitative metrics (BLEU, ROUGE, BERTScore) and qualitative criteria assessed by GPT-4, using chest X-ray as a case study. Experiment results show improvements in RadCouncil over the single-agent approach across multiple dimensions, including diagnostic accuracy, stylistic concordance, and clarity. This study highlights the potential of utilizing multiple interacting LLM agents, each with a dedicated task, to enhance performance in specialized medical tasks and the development of more robust and adaptable healthcare AI solutions.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04780",
        "abstract url": "https://arxiv.org/abs/2412.04780",
        "title": "Anomaly Detection and Classification in Knowledge Graphs",
        "rating": "-1.5",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "Anomaly Detection"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Anomalies such as redundant, inconsistent, contradictory, and deficient values in a Knowledge Graph (KG) are unavoidable, as these graphs are often curated manually, or extracted using machine learning and natural language processing techniques. Therefore, anomaly detection is a task that can enhance the quality of KGs. In this paper, we propose SEKA (SEeking Knowledge graph Anomalies), an unsupervised approach for the detection of abnormal triples and entities in KGs. SEKA can help improve the correctness of a KG whilst retaining its coverage. We propose an adaption of the Path Rank Algorithm (PRA), named the Corroborative Path Rank Algorithm (CPRA), which is an efficient adaptation of PRA that is customized to detect anomalies in KGs. Furthermore, we also present TAXO (TAXOnomy of anomaly types in KGs), a taxonomy of possible anomaly types that can occur in a KG. This taxonomy provides a classification of the anomalies discovered by SEKA with an extensive discussion of possible data quality issues in a KG. We evaluate both approaches using the four real-world KGs YAGO-1, KBpedia, Wikidata, and DSKG to demonstrate the ability of SEKA and TAXO to outperform the baselines.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04782",
        "abstract url": "https://arxiv.org/abs/2412.04782",
        "title": "A Survey of Sustainability in Large Language Models: Applications, Economics, and Challenges",
        "rating": "-1.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have transformed numerous domains by providing advanced capabilities in natural language understanding, generation, and reasoning. Despite their groundbreaking applications across industries such as research, healthcare, and creative media, their rapid adoption raises critical concerns regarding sustainability. This survey paper comprehensively examines the environmental, economic, and computational challenges associated with LLMs, focusing on energy consumption, carbon emissions, and resource utilization in data centers. By synthesizing insights from existing literature, this work explores strategies such as resource-efficient training, sustainable deployment practices, and lifecycle assessments to mitigate the environmental impacts of LLMs. Key areas of emphasis include energy optimization, renewable energy integration, and balancing performance with sustainability. The findings aim to guide researchers, practitioners, and policymakers in developing actionable strategies for sustainable AI systems, fostering a responsible and environmentally conscious future for artificial intelligence.",
        "subjects": [
            "cs.AI",
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04792",
        "abstract url": "https://arxiv.org/abs/2412.04792",
        "title": "Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models",
        "rating": "-1.5",
        "keywords": [
            [
                "Health",
                "healthcare",
                "disease",
                "clinical"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Heart disease is a leading cause of premature death worldwide, particularly among middle-aged and older adults, with men experiencing a higher prevalence. According to the World Health Organization (WHO), non-communicable diseases, including heart disease, account for 25\\% (17.9 million) of global deaths, with over 43,204 annual fatalities in Bangladesh. However, the development of heart disease detection (HDD) systems tailored to the Bangladeshi population remains underexplored due to the lack of benchmark datasets and reliance on manual or limited-data approaches. This study addresses these challenges by introducing new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which incorporates comprehensive data on symptoms, examination techniques, and risk factors. Using advanced machine learning techniques, including Logistic Regression and Random Forest, we achieved a remarkable testing accuracy of up to 96.6\\% with Random Forest. The proposed AI-driven system integrates these models and datasets to provide real-time, accurate diagnostics and personalized healthcare recommendations. By leveraging structured datasets and state-of-the-art machine learning algorithms, this research offers an innovative solution for scalable and effective heart disease detection, with the potential to reduce mortality rates and improve clinical outcomes.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04796",
        "abstract url": "https://arxiv.org/abs/2412.04796",
        "title": "Employee Well-being in the Age of AI: Perceptions, Concerns, Behaviors, and Outcomes",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.CY"
            ]
        ],
        "abstract": "The growing integration of Artificial Intelligence (AI) into Human Resources (HR) processes has transformed the way organizations manage recruitment, performance evaluation, and employee engagement. While AI offers numerous advantages, such as improved efficiency, reduced bias, and hyper-personalization, it raises significant concerns about employee well-being, job security, fairness, and transparency. This study examines how AI shapes employee perceptions, job satisfaction, mental health, and retention. Key findings reveal that while AI can enhance efficiency and reduce bias, it also raises concerns about job security, fairness, and privacy. Transparency in AI systems emerges as a critical factor in fostering trust and positive employee attitudes. AI systems can both support and undermine employee well-being, depending on how they are implemented and perceived. The research introduces an AI-employee well-being Interaction Framework, illustrating how AI influences employee perceptions, behaviors, and outcomes. Organizational strategies, such as clear communication, upskilling programs, and employee involvement in AI implementation, are identified as crucial for mitigating negative impacts and enhancing positive outcomes. The study concludes that the successful integration of AI in HR requires a balanced approach that prioritizes employee well-being, facilitates human-AI collaboration, and ensures ethical and transparent AI practices alongside technological advancement.",
        "subjects": [
            "cs.CY",
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04799",
        "abstract url": "https://arxiv.org/abs/2412.04799",
        "title": "Estimating the treatment effect over time under general interference through deep learner integrated TMLE",
        "rating": "-1.5",
        "keywords": [
            [
                "health"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Understanding the effects of quarantine policies in populations with underlying social networks is crucial for public health, yet most causal inference methods fail here due to their assumption of independent individuals. We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood Estimation (TMLE) method designed to estimate time-sensitive treatment effects in observational data. DeepNetTMLE mitigates bias from time-varying confounders under general interference by incorporating a temporal module and domain adversarial training to build intervention-invariant representations. This process removes associations between current treatments and historical variables, while the targeting step maintains the bias-variance trade-off, enhancing the reliability of counterfactual predictions. Using simulations of a ``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we show that DeepNetTMLE achieves lower bias and more precise confidence intervals in counterfactual estimates, enabling optimal quarantine recommendations within budget constraints, surpassing state-of-the-art methods.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04831",
        "abstract url": "https://arxiv.org/abs/2412.04831",
        "title": "Customized Generation Reimagined: Fidelity and Editability Harmonized",
        "rating": "-1.5",
        "keywords": [
            [
                "text-to-image"
            ],
            [
                "surgical"
            ],
            [
                "cs.CV"
            ],
            [
                "ECCV"
            ]
        ],
        "abstract": "Customized generation aims to incorporate a novel concept into a pre-trained text-to-image model, enabling new generations of the concept in novel contexts guided by textual prompts. However, customized generation suffers from an inherent trade-off between concept fidelity and editability, i.e., between precisely modeling the concept and faithfully adhering to the prompts. Previous methods reluctantly seek a compromise and struggle to achieve both high concept fidelity and ideal prompt alignment simultaneously. In this paper, we propose a Divide, Conquer, then Integrate (DCI) framework, which performs a surgical adjustment in the early stage of denoising to liberate the fine-tuned model from the fidelity-editability trade-off at inference. The two conflicting components in the trade-off are decoupled and individually conquered by two collaborative branches, which are then selectively integrated to preserve high concept fidelity while achieving faithful prompt adherence. To obtain a better fine-tuned model, we introduce an Image-specific Context Optimization} (ICO) strategy for model customization. ICO replaces manual prompt templates with learnable image-specific contexts, providing an adaptive and precise fine-tuning direction to promote the overall performance. Extensive experiments demonstrate the effectiveness of our method in reconciling the fidelity-editability trade-off.",
        "subjects": [
            "cs.CV"
        ],
        "comment": "18 pages, 12 figures, ECCV 2024"
    },
    {
        "paper id": "2412.04833",
        "abstract url": "https://arxiv.org/abs/2412.04833",
        "title": "Wavelet Diffusion Neural Operator",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Simulating and controlling physical systems described by partial differential equations (PDEs) are crucial tasks across science and engineering. Recently, diffusion generative models have emerged as a competitive class of methods for these tasks due to their ability to capture long-term dependencies and model high-dimensional states. However, diffusion models typically struggle with handling system states with abrupt changes and generalizing to higher resolutions. In this work, we propose Wavelet Diffusion Neural Operator (WDNO), a novel PDE simulation and control framework that enhances the handling of these complexities. WDNO comprises two key innovations. Firstly, WDNO performs diffusion-based generative modeling in the wavelet domain for the entire trajectory to handle abrupt changes and long-term dependencies effectively. Secondly, to address the issue of poor generalization across different resolutions, which is one of the fundamental tasks in modeling physical systems, we introduce multi-resolution training. We validate WDNO on five physical systems, including 1D advection equation, three challenging physical systems with abrupt changes (1D Burgers' equation, 1D compressible Navier-Stokes equation and 2D incompressible fluid), and a real-world dataset ERA5, which demonstrates superior performance on both simulation and control tasks over state-of-the-art methods, with significant improvements in long-term and detail prediction accuracy. Remarkably, in the challenging context of the 2D high-dimensional and indirect control task aimed at reducing smoke leakage, WDNO reduces the leakage by 33.2% compared to the second-best baseline.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04847",
        "abstract url": "https://arxiv.org/abs/2412.04847",
        "title": "MTSpark: Enabling Multi-Task Learning with Spiking Neural Networks for Generalist Agents",
        "rating": "-1.5",
        "keywords": [
            [
                "bioplausible"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Currently, state-of-the-art RL methods excel in single-task settings, but they still struggle to generalize across multiple tasks due to catastrophic forgetting challenges, where previously learned tasks are forgotten as new tasks are introduced. This multi-task learning capability is significantly important for generalist agents, where adaptation features are highly required (e.g., autonomous robots). On the other hand, Spiking Neural Networks (SNNs) have emerged as alternative energy-efficient neural network algorithms due to their sparse spike-based operations. Toward this, we propose MTSpark, a novel methodology to enable multi-task RL using spiking networks. Specifically, MTSpark develops a Deep Spiking Q-Network (DSQN) with active dendrites and dueling structure by leveraging task-specific context signals. Specifically, each neuron computes task-dependent activations that dynamically modulate inputs, forming specialized sub-networks for each task. Moreover, this bioplausible network model also benefits from SNNs, enhancing energy efficiency and making the model suitable for hardware implementation. Experimental results show that, our MTSpark effectively learns multiple tasks with higher performance compared to the state-of-the-art. Specifically, MTSpark successfully achieves high score in three Atari games (i.e., Pong: -5.4, Breakout: 0.6, and Enduro: 371.2), reaching human-level performance (i.e., Pong: -3, Breakout: 31, and Enduro: 368), where state-of-the-art struggle to achieve. In addition, our MTSpark also shows better accuracy in image classification tasks than the state-of-the-art. These results highlight the potential of our MTSpark methodology to develop generalist agents that can learn multiple tasks by leveraging both RL and SNN concepts.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "9 pages, 10 figures, 5 tables"
    },
    {
        "paper id": "2412.04893",
        "abstract url": "https://arxiv.org/abs/2412.04893",
        "title": "Automatic Tongue Delineation from MRI Images with a Convolutional Neural Network Approach",
        "rating": "-1.5",
        "keywords": [
            [
                "MRI"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Tongue contour extraction from real-time magnetic resonance images is a nontrivial task due to the presence of artifacts manifesting in form of blurring or ghostly contours. In this work, we present results of automatic tongue delineation achieved by means of U-Net auto-encoder convolutional neural network. We present both intra- and inter-subject validation. We used real-time magnetic resonance images and manually annotated 1-pixel wide contours as inputs. Predicted probability maps were post-processed in order to obtain 1-pixel wide tongue contours. The results are very good and slightly outperform published results on automatic tongue segmentation.",
        "subjects": [
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04914",
        "abstract url": "https://arxiv.org/abs/2412.04914",
        "title": "Achieving Group Fairness through Independence in Predictive Process Monitoring",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Predictive process monitoring focuses on forecasting future states of ongoing process executions, such as predicting the outcome of a particular case. In recent years, the application of machine learning models in this domain has garnered significant scientific attention. When using historical execution data, which may contain biases or exhibit unfair behavior, these biases may be encoded into the trained models. Consequently, when such models are deployed to make decisions or guide interventions for new cases, they risk perpetuating this unwanted behavior. This work addresses group fairness in predictive process monitoring by investigating independence, i.e. ensuring predictions are unaffected by sensitive group membership. We explore independence through metrics for demographic parity such as $\u0394$DP, as well as recently introduced, threshold-independent distribution-based alternatives. Additionally, we propose a composite loss functions existing of binary cross-entropy and a distribution-based loss (Wasserstein) to train models that balance predictive performance and fairness, and allow for customizable trade-offs. The effectiveness of both the fairness metrics and the composite loss functions is validated through a controlled experimental setup.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "Preprint"
    },
    {
        "paper id": "2412.04923",
        "abstract url": "https://arxiv.org/abs/2412.04923",
        "title": "HyperGraphOS: A Meta Operating System for Science and Engineering",
        "rating": "-1.5",
        "keywords": [
            [
                "navigation"
            ],
            [
                "graph"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "This paper presents HyperGraphOS, an innovative Operating System designed for the scientific and engineering domains. It combines model based engineering, graph modeling, data containers, and computational tools, offering users a dynamic workspace for creating and managing complex models represented as customizable graphs. Using a web based architecture, HyperGraphOS requires only a modern browser to organize knowledge, documents, and content into interconnected models. Domain Specific Languages drive workspace navigation, code generation, AI integration, and process organization.The platform models function as both visual drawings and data structures, enabling dynamic modifications and inspection, both interactively and programmatically. HyperGraphOS was evaluated across various domains, including virtual avatars, robotic task planning using Large Language Models, and meta modeling for feature based code development. Results show significant improvements in flexibility, data management, computation, and document handling.",
        "subjects": [
            "cs.AI",
            "cs.MA"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04930",
        "abstract url": "https://arxiv.org/abs/2412.04930",
        "title": "Video Decomposition Prior: A Methodology to Decompose Videos into Layers",
        "rating": "-1.5",
        "keywords": [
            [
                "video editing"
            ],
            [
                "dehazing",
                "video enhancement"
            ],
            [
                "cs.LG",
                "cs.CV"
            ],
            [
                "ICLR"
            ]
        ],
        "abstract": "In the evolving landscape of video enhancement and editing methodologies, a majority of deep learning techniques often rely on extensive datasets of observed input and ground truth sequence pairs for optimal performance. Such reliance often falters when acquiring data becomes challenging, especially in tasks like video dehazing and relighting, where replicating identical motions and camera angles in both corrupted and ground truth sequences is complicated. Moreover, these conventional methodologies perform best when the test distribution closely mirrors the training distribution. Recognizing these challenges, this paper introduces a novel video decomposition prior `VDP' framework which derives inspiration from professional video editing practices. Our methodology does not mandate task-specific external data corpus collection, instead pivots to utilizing the motion and appearance of the input video. VDP framework decomposes a video sequence into a set of multiple RGB layers and associated opacity levels. These set of layers are then manipulated individually to obtain the desired results. We addresses tasks such as video object segmentation, dehazing, and relighting. Moreover, we introduce a novel logarithmic video decomposition formulation for video relighting tasks, setting a new benchmark over the existing methodologies. We observe the property of relighting emerge as we optimize for our novel relighting decomposition formulation. We evaluate our approach on standard video datasets like DAVIS, REVIDE, & SDSD and show qualitative results on a diverse array of internet videos. Project Page - https://www.cs.umd.edu/~gauravsh/video_decomposition/index.html for video results.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "comment": "Project Page - https://www.cs.umd.edu/~gauravsh/video_decomposition/index.html for video results. Extended version of ICLR publication"
    },
    {
        "paper id": "2412.04950",
        "abstract url": "https://arxiv.org/abs/2412.04950",
        "title": "Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes",
        "rating": "-1.5",
        "keywords": [
            [
                "health",
                "healthcare"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "The increasing shortage of nursing staff and the acute risk of falls in nursing homes pose significant challenges for the healthcare system. This study presents the development of an automated fall detection system integrated into care beds, aimed at enhancing patient safety without compromising privacy through wearables or video monitoring. Mechanical vibrations transmitted through the bed frame are processed using a short-time Fourier transform, enabling robust classification of distinct human fall patterns with a convolutional neural network. Challenges pertaining to the quantity and diversity of the data are addressed, proposing the generation of additional data with a specific emphasis on enhancing variation. While the model shows promising results in distinguishing fall events from noise using lab data, further testing in real-world environments is recommended for validation and improvement. Despite limited available data, the proposed system shows the potential for an accurate and rapid response to falls, mitigating health implications, and addressing the needs of an aging population. This case study was performed as part of the ZIM Project. Further research on sensors enhanced by artificial intelligence will be continued in the ShapeFuture Project.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04999",
        "abstract url": "https://arxiv.org/abs/2412.04999",
        "title": "'Debunk-It-Yourself': Health Professionals' Strategies for Responding to Misinformation on TikTok",
        "rating": "-1.5",
        "keywords": [
            [
                "Health",
                "clinical"
            ],
            [
                "cs.SI",
                "cs.CY"
            ]
        ],
        "abstract": "Misinformation is \"sticky\" in nature, requiring a considerable effort to undo its influence. One such effort is debunking or exposing the falsity of information. As an abundance of misinformation is on social media, platforms do bear some debunking responsibility in order to preserve their trustworthiness as information providers. A subject of interpretation, platforms poorly meet this responsibility and allow dangerous health misinformation to influence many of their users. This open route to harm did not sit well with health professional users, who recently decided to take the debunking into their own hands. To study this individual debunking effort - which we call 'Debunk-It-Yourself (DIY)' - we conducted an exploratory survey n=14 health professionals who wage a misinformation counter-influence campaign through videos on TikTok. We focused on two topics, nutrition and mental health, which are the ones most often subjected to misinformation on the platform. Our thematic analysis reveals that the counterinfluence follows a common process of initiation, selection, creation, and \"stitching\" or duetting a debunking video with a misinformation video. The 'Debunk-It-Yourself' effort was underpinned by three unique aspects: (i) it targets trending misinformation claims perceived to be of direct harm to people's health; (ii) it offers a symmetric response to the misinformation; and (iii) it is strictly based on scientific evidence and claimed clinical experience. Contrasting the 'Debunk-It-Yourself' effort with the one TikTok and other platforms (reluctantly) put in moderation, we offer recommendations for a structured response against the misinformation's influence by the users themselves.",
        "subjects": [
            "cs.CR",
            "cs.CY",
            "cs.HC",
            "cs.SI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05000",
        "abstract url": "https://arxiv.org/abs/2412.05000",
        "title": "Noise Matters: Diffusion Model-based Urban Mobility Generation with Collaborative Noise Priors",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "trajectory"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "With global urbanization, the focus on sustainable cities has largely grown, driving research into equity, resilience, and urban planning, which often relies on mobility data. The rise of web-based apps and mobile devices has provided valuable user data for mobility-related research. However, real-world mobility data is costly and raises privacy concerns. To protect privacy while retaining key features of real-world movement, the demand for synthetic data has steadily increased. Recent advances in diffusion models have shown great potential for mobility trajectory generation due to their ability to model randomness and uncertainty. However, existing approaches often directly apply identically distributed (i.i.d.) noise sampling from image generation techniques, which fail to account for the spatiotemporal correlations and social interactions that shape urban mobility patterns. In this paper, we propose CoDiffMob, a diffusion method for urban mobility generation with collaborative noise priors, we emphasize the critical role of noise in diffusion models for generating mobility data. By leveraging both individual movement characteristics and population-wide dynamics, we construct novel collaborative noise priors that provide richer and more informative guidance throughout the generation process. Extensive experiments demonstrate the superiority of our method, with generated data accurately capturing both individual preferences and collective patterns, achieving an improvement of over 32\\%. Furthermore, it can effectively replace web-derived mobility data to better support downstream applications, while safeguarding user privacy and fostering a more secure and ethical web. This highlights its tremendous potential for applications in sustainable city-related research.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05043",
        "abstract url": "https://arxiv.org/abs/2412.05043",
        "title": "ReF-LDM: A Latent Diffusion Model for Reference-based Face Image Restoration",
        "rating": "-1.5",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Image Restoration"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ],
            [
                "NeurIPS"
            ]
        ],
        "abstract": "While recent works on blind face image restoration have successfully produced impressive high-quality (HQ) images with abundant details from low-quality (LQ) input images, the generated content may not accurately reflect the real appearance of a person. To address this problem, incorporating well-shot personal images as additional reference inputs could be a promising strategy. Inspired by the recent success of the Latent Diffusion Model (LDM), we propose ReF-LDM, an adaptation of LDM designed to generate HQ face images conditioned on one LQ image and multiple HQ reference images. Our model integrates an effective and efficient mechanism, CacheKV, to leverage the reference images during the generation process. Additionally, we design a timestep-scaled identity loss, enabling our LDM-based model to focus on learning the discriminating features of human faces. Lastly, we construct FFHQ-Ref, a dataset consisting of 20,405 high-quality (HQ) face images with corresponding reference images, which can serve as both training and evaluation data for reference-based face restoration models.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": "NeurIPS 2024, project page https://chiweihsiao.github.io/refldm.github.io/"
    },
    {
        "paper id": "2412.05126",
        "abstract url": "https://arxiv.org/abs/2412.05126",
        "title": "Robust Computation with Intrinsic Heterogeneity",
        "rating": "-1.5",
        "keywords": [
            [
                "biological"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Intrinsic within-type neuronal heterogeneity is a ubiquitous feature of biological systems, with well-documented computational advantages. Recent works in machine learning have incorporated such diversities by optimizing neuronal parameters alongside synaptic connections and demonstrated state-of-the-art performance across common benchmarks. However, this performance gain comes at the cost of significantly higher computational costs, imposed by a larger parameter space. Furthermore, it is unclear how the neuronal parameters, constrained by the biophysics of their surroundings, are globally orchestrated to minimize top-down errors. To address these challenges, we postulate that neurons are intrinsically diverse, and investigate the computational capabilities of such heterogeneous neuronal parameters. Our results show that intrinsic heterogeneity, viewed as a fixed quenched disorder, often substantially improves performance across hundreds of temporal tasks. Notably, smaller but heterogeneous networks outperform larger homogeneous networks, despite consuming less data. We elucidate the underlying mechanisms driving this performance boost and illustrate its applicability to both rate and spiking dynamics. Moreover, our findings demonstrate that heterogeneous networks are highly resilient to severe alterations in their recurrent synaptic hyperparameters, and even recurrent connections removal does not compromise performance. The remarkable effectiveness of heterogeneous networks with small sizes and relaxed connectivity is particularly relevant for the neuromorphic community, which faces challenges due to device-to-device variability. Furthermore, understanding the mechanism of robust computation with heterogeneity also benefits neuroscientists and machine learners.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "comment": "29 pages, 15 figures"
    },
    {
        "paper id": "2412.05132",
        "abstract url": "https://arxiv.org/abs/2412.05132",
        "title": "Dirac-Equation Signal Processing: Physics Boosts Topological Machine Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.LG",
                "cs.SI"
            ]
        ],
        "abstract": "Topological signals are variables or features associated with both nodes and edges of a network. Recently, in the context of Topological Machine Learning, great attention has been devoted to signal processing of such topological signals. Most of the previous topological signal processing algorithms treat node and edge signals separately and work under the hypothesis that the true signal is smooth and/or well approximated by a harmonic eigenvector of the Hodge-Laplacian, which may be violated in practice. Here we propose Dirac-equation signal processing, a framework for efficiently reconstructing true signals on nodes and edges, also if they are not smooth or harmonic, by processing them jointly. The proposed physics-inspired algorithm is based on the spectral properties of the topological Dirac operator. It leverages the mathematical structure of the topological Dirac equation to boost the performance of the signal processing algorithm. We discuss how the relativistic dispersion relation obeyed by the topological Dirac equation can be used to assess the quality of the signal reconstruction. Finally, we demonstrate the improved performance of the algorithm with respect to previous algorithms. Specifically, we show that Dirac-equation signal processing can also be used efficiently if the true signal is a non-trivial linear combination of more than one eigenstate of the Dirac equation, as it generally occurs for real signals.",
        "subjects": [
            "cond-mat.dis-nn",
            "cs.LG",
            "cs.SI",
            "physics.soc-ph",
            "quant-ph"
        ],
        "comment": "(14 pages, 7 figures)"
    },
    {
        "paper id": "2412.05137",
        "abstract url": "https://arxiv.org/abs/2412.05137",
        "title": "Can Large Language Models Serve as Effective Classifiers for Hierarchical Multi-Label Classification of Scientific Documents at Industrial Scale?",
        "rating": "-1.5",
        "keywords": [
            [
                "Industrial"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "We address the task of hierarchical multi-label classification (HMC) of scientific documents at an industrial scale, where hundreds of thousands of documents must be classified across thousands of dynamic labels. The rapid growth of scientific publications necessitates scalable and efficient methods for classification, further complicated by the evolving nature of taxonomies--where new categories are introduced, existing ones are merged, and outdated ones are deprecated. Traditional machine learning approaches, which require costly retraining with each taxonomy update, become impractical due to the high overhead of labelled data collection and model adaptation. Large Language Models (LLMs) have demonstrated great potential in complex tasks such as multi-label classification. However, applying them to large and dynamic taxonomies presents unique challenges as the vast number of labels can exceed LLMs' input limits. In this paper, we present novel methods that combine the strengths of LLMs with dense retrieval techniques to overcome these challenges. Our approach avoids retraining by leveraging zero-shot HMC for real-time label assignment. We evaluate the effectiveness of our methods on SSRN, a large repository of preprints spanning multiple disciplines, and demonstrate significant improvements in both classification accuracy and cost-efficiency. By developing a tailored evaluation framework for dynamic taxonomies and publicly releasing our code, this research provides critical insights into applying LLMs for document classification, where the number of classes corresponds to the number of nodes in a large taxonomy, at an industrial scale.",
        "subjects": [
            "cs.AI"
        ],
        "comment": "This paper has been accepted at COLING 2025 (Industry Track)"
    },
    {
        "paper id": "2412.05183",
        "abstract url": "https://arxiv.org/abs/2412.05183",
        "title": "Privacy Drift: Evolving Privacy Concerns in Incremental Learning",
        "rating": "-1.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In the evolving landscape of machine learning (ML), Federated Learning (FL) presents a paradigm shift towards decentralized model training while preserving user data privacy. This paper introduces the concept of ``privacy drift\", an innovative framework that parallels the well-known phenomenon of concept drift. While concept drift addresses the variability in model accuracy over time due to changes in the data, privacy drift encapsulates the variation in the leakage of private information as models undergo incremental training. By defining and examining privacy drift, this study aims to unveil the nuanced relationship between the evolution of model performance and the integrity of data privacy. Through rigorous experimentation, we investigate the dynamics of privacy drift in FL systems, focusing on how model updates and data distribution shifts influence the susceptibility of models to privacy attacks, such as membership inference attacks (MIA). Our results highlight a complex interplay between model accuracy and privacy safeguards, revealing that enhancements in model performance can lead to increased privacy risks. We provide empirical evidence from experiments on customized datasets derived from CIFAR-100 (Canadian Institute for Advanced Research, 100 classes), showcasing the impact of data and concept drift on privacy. This work lays the groundwork for future research on privacy-aware machine learning, aiming to achieve a delicate balance between model accuracy and data privacy in decentralized environments.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": "6 pages, 7 figures, Accepted in IEEE ICNC 25"
    },
    {
        "paper id": "2412.05218",
        "abstract url": "https://arxiv.org/abs/2412.05218",
        "title": "Transformers Meet Relational Databases",
        "rating": "-1.5",
        "keywords": [
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Transformer models have continuously expanded into all machine learning domains convertible to the underlying sequence-to-sequence representation, including tabular data. However, while ubiquitous, this representation restricts their extension to the more general case of relational databases. In this paper, we introduce a modular neural message-passing scheme that closely adheres to the formal relational model, enabling direct end-to-end learning of tabular Transformers from database storage systems. We address the challenges of appropriate learning data representation and loading, which are critical in the database setting, and compare our approach against a number of representative models from various related fields across a significantly wide range of datasets. Our results demonstrate a superior performance of this newly proposed class of neural architectures.",
        "subjects": [
            "cs.LG",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05244",
        "abstract url": "https://arxiv.org/abs/2412.05244",
        "title": "Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "How to best develop foundational models for time series forecasting remains an important open question. Tokenization is a crucial consideration in this effort: what is an effective discrete vocabulary for a real-valued sequential input? To address this question, we develop WaveToken, a wavelet-based tokenizer that allows models to learn complex representations directly in the space of time-localized frequencies. Our method first scales and decomposes the input time series, then thresholds and quantizes the wavelet coefficients, and finally pre-trains an autoregressive model to forecast coefficients for the forecast horizon. By decomposing coarse and fine structures in the inputs, wavelets provide an eloquent and compact language for time series forecasting that simplifies learning. Empirical results on a comprehensive benchmark, including 42 datasets for both in-domain and zero-shot settings, show that WaveToken: i) provides better accuracy than recently proposed foundation models for forecasting while using a much smaller vocabulary (1024 tokens), and performs on par or better than modern deep learning models trained specifically on each dataset; and ii) exhibits superior generalization capabilities, achieving the best average rank across all datasets for three complementary metrics. In addition, we show that our method can easily capture complex temporal patterns of practical relevance that are challenging for other recent pre-trained models, including trends, sparse spikes, and non-stationary time series with varying frequencies evolving over time.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "25 pages, 15 figures"
    },
    {
        "paper id": "2412.05269",
        "abstract url": "https://arxiv.org/abs/2412.05269",
        "title": "Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases",
        "rating": "-1.5",
        "keywords": [
            [
                "chemical"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Planning and conducting chemical syntheses remains a major bottleneck in the discovery of functional small molecules, and prevents fully leveraging generative AI for molecular inverse design. While early work has shown that ML-based retrosynthesis models can predict reasonable routes, their low accuracy for less frequent, yet important reactions has been pointed out. As multi-step search algorithms are limited to reactions suggested by the underlying model, the applicability of those tools is inherently constrained by the accuracy of retrosynthesis prediction. Inspired by how chemists use different strategies to ideate reactions, we propose Chimera: a framework for building highly accurate reaction models that combine predictions from diverse sources with complementary inductive biases using a learning-based ensembling strategy. We instantiate the framework with two newly developed models, which already by themselves achieve state of the art in their categories. Through experiments across several orders of magnitude in data scale and time-splits, we show Chimera outperforms all major models by a large margin, owing both to the good individual performance of its constituents, but also to the scalability of our ensembling strategy. Moreover, we find that PhD-level organic chemists prefer predictions from Chimera over baselines in terms of quality. Finally, we transfer the largest-scale checkpoint to an internal dataset from a major pharmaceutical company, showing robust generalization under distribution shift. With the new dimension that our framework unlocks, we anticipate further acceleration in the development of even more accurate models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.QM"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05390",
        "abstract url": "https://arxiv.org/abs/2412.05390",
        "title": "Tabular data generation with tensor contraction layers and transformers",
        "rating": "-1.5",
        "keywords": [
            [
                "Tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Generative modeling for tabular data has recently gained significant attention in the Deep Learning domain. Its objective is to estimate the underlying distribution of the data. However, estimating the underlying distribution of tabular data has its unique challenges. Specifically, this data modality is composed of mixed types of features, making it a non-trivial task for a model to learn intra-relationships between them. One approach to address mixture is to embed each feature into a continuous matrix via tokenization, while a solution to capture intra-relationships between variables is via the transformer architecture. In this work, we empirically investigate the potential of using embedding representations on tabular data generation, utilizing tensor contraction layers and transformers to model the underlying distribution of tabular data within Variational Autoencoders. Specifically, we compare four architectural approaches: a baseline VAE model, two variants that focus on tensor contraction layers and transformers respectively, and a hybrid model that integrates both techniques. Our empirical study, conducted across multiple datasets from the OpenML CC18 suite, compares models over density estimation and Machine Learning efficiency metrics. The main takeaway from our results is that leveraging embedding representations with the help of tensor contraction layers improves density estimation metrics, albeit maintaining competitive performance in terms of machine learning efficiency.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "comment": "28 pages, 9 figures"
    },
    {
        "paper id": "2412.05421",
        "abstract url": "https://arxiv.org/abs/2412.05421",
        "title": "KEDformer:Knowledge Extraction Seasonal Trend Decomposition for Long-term Sequence Prediction",
        "rating": "-1.5",
        "keywords": [
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Time series forecasting is a critical task in domains such as energy, finance, and meteorology, where accurate long-term predictions are essential. While Transformer-based models have shown promise in capturing temporal dependencies, their application to extended sequences is limited by computational inefficiencies and limited generalization. In this study, we propose KEDformer, a knowledge extraction-driven framework that integrates seasonal-trend decomposition to address these challenges. KEDformer leverages knowledge extraction methods that focus on the most informative weights within the self-attention mechanism to reduce computational overhead. Additionally, the proposed KEDformer framework decouples time series into seasonal and trend components. This decomposition enhances the model's ability to capture both short-term fluctuations and long-term patterns. Extensive experiments on five public datasets from energy, transportation, and weather domains demonstrate the effectiveness and competitiveness of KEDformer, providing an efficient solution for long-term time series forecasting.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05438",
        "abstract url": "https://arxiv.org/abs/2412.05438",
        "title": "Granular Ball K-Class Twin Support Vector Classifier",
        "rating": "-1.5",
        "keywords": [
            [
                "diagnosis"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper introduces the Granular Ball K-Class Twin Support Vector Classifier (GB-TWKSVC), a novel multi-class classification framework that combines Twin Support Vector Machines (TWSVM) with granular ball computing. The proposed method addresses key challenges in multi-class classification by utilizing granular ball representation for improved noise robustness and TWSVM's non-parallel hyperplane architecture solves two smaller quadratic programming problems, enhancing efficiency. Our approach introduces a novel formulation that effectively handles multi-class scenarios, advancing traditional binary classification methods. Experimental evaluation on diverse benchmark datasets shows that GB-TWKSVC significantly outperforms current state-of-the-art classifiers in both accuracy and computational performance. The method's effectiveness is validated through comprehensive statistical tests and complexity analysis. Our work advances classification algorithms by providing a mathematically sound framework that addresses the scalability and robustness needs of modern machine learning applications. The results demonstrate GB-TWKSVC's broad applicability across domains including pattern recognition, fault diagnosis, and large-scale data analytics, establishing it as a valuable addition to the classification algorithm landscape.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05525",
        "abstract url": "https://arxiv.org/abs/2412.05525",
        "title": "A Variational Computational-based Framework for Unsteady Incompressible Flows",
        "rating": "-1.5",
        "keywords": [
            [
                "physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Advancements in computational fluid mechanics have largely relied on Newtonian frameworks, particularly through the direct simulation of Navier-Stokes equations. In this work, we propose an alternative computational framework that employs variational methods, specifically by leveraging the principle of minimum pressure gradient, which turns the fluid mechanics problem into a minimization problem whose solution can be used to predict the flow field in unsteady incompressible viscous flows. This method exhibits two particulary intriguing properties. First, it circumvents the chronic issues of pressure-velocity coupling in incompressible flows, which often dominates the computational cost in computational fluid dynamics (CFD). Second, this method eliminates the reliance on unphysical assumptions at the outflow boundary, addressing another longstanding challenge in CFD. We apply this framework to three benchmark examples across a range of Reynolds numbers: (i) unsteady flow field in a lid-driven cavity, (ii) Poiseuille flow, and (iii) flow past a circular cylinder. The minimization framework is carried out using a physics-informed neural network (PINN), which integrates the underlying physical principles directly into the training of the model. The results from the proposed method are validated against high-fidelity CFD simulations, showing an excellent agreement. Comparison of the proposed variational method to the conventional method, wherein PINNs is directly applied to solve Navier-Stokes Equations, reveals that the proposed method outperforms conventional PINNs in terms of both convergence rate and time, demonstrating its potential for solving complex fluid mechanics problems.",
        "subjects": [
            "physics.flu-dyn",
            "cs.LG",
            "math.OC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05533",
        "abstract url": "https://arxiv.org/abs/2412.05533",
        "title": "Can large language models be privacy preserving and fair medical coders?",
        "rating": "-1.5",
        "keywords": [
            [
                "medical",
                "healthcare"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Protecting patient data privacy is a critical concern when deploying machine learning algorithms in healthcare. Differential privacy (DP) is a common method for preserving privacy in such settings and, in this work, we examine two key trade-offs in applying DP to the NLP task of medical coding (ICD classification). Regarding the privacy-utility trade-off, we observe a significant performance drop in the privacy preserving models, with more than a 40% reduction in micro F1 scores on the top 50 labels in the MIMIC-III dataset. From the perspective of the privacy-fairness trade-off, we also observe an increase of over 3% in the recall gap between male and female patients in the DP models. Further understanding these trade-offs will help towards the challenges of real-world deployment.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06825",
        "abstract url": "https://arxiv.org/abs/2412.06825",
        "title": "Feature Group Tabular Transformer: A Novel Approach to Traffic Crash Modeling and Causality Analysis",
        "rating": "-1.5",
        "keywords": [
            [
                "Tabular"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Reliable and interpretable traffic crash modeling is essential for understanding causality and improving road safety. This study introduces a novel approach to predicting collision types by utilizing a comprehensive dataset fused from multiple sources, including weather data, crash reports, high-resolution traffic information, pavement geometry, and facility characteristics. Central to our approach is the development of a Feature Group Tabular Transformer (FGTT) model, which organizes disparate data into meaningful feature groups, represented as tokens. These group-based tokens serve as rich semantic components, enabling effective identification of collision patterns and interpretation of causal mechanisms. The FGTT model is benchmarked against widely used tree ensemble models, including Random Forest, XGBoost, and CatBoost, demonstrating superior predictive performance. Furthermore, model interpretation reveals key influential factors, providing fresh insights into the underlying causality of distinct crash types.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.AP"
        ],
        "comment": "19 pages, 6 figures, 5 tables"
    },
    {
        "paper id": "2412.06827",
        "abstract url": "https://arxiv.org/abs/2412.06827",
        "title": "Enhancing LLMs for Physics Problem-Solving using Reinforcement Learning with Human-AI Feedback",
        "rating": "-1.5",
        "keywords": [
            [
                "Physics"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in text-based tasks but struggle with the complex reasoning required for physics problems, particularly in advanced arithmetic and conceptual understanding. While some research has explored ways to enhance LLMs in physics education using techniques such as prompt engineering and Retrieval Augmentation Generation (RAG), not enough effort has been made in addressing their limitations in physics reasoning. This paper presents a novel approach to improving LLM performance on physics questions using Reinforcement Learning with Human and Artificial Intelligence Feedback (RLHAIF). We evaluate several reinforcement learning methods, including Proximal Policy Optimization (PPO), Direct Preference Optimization (DPO), and Remax optimization. These methods are chosen to investigate RL policy performance with different settings on the PhyQA dataset, which includes challenging physics problems from high school textbooks. Our RLHAIF model, tested on leading LLMs like LLaMA2 and Mistral, achieved superior results, notably with the MISTRAL-PPO model, demonstrating marked improvements in reasoning and accuracy. It achieved high scores, with a 58.67 METEOR score and a 0.74 Reasoning score, making it a strong example for future physics reasoning research in this area.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.06835",
        "abstract url": "https://arxiv.org/abs/2412.06835",
        "title": "APS-LSTM: Exploiting Multi-Periodicity and Diverse Spatial Dependencies for Flood Forecasting",
        "rating": "-1.5",
        "keywords": [
            [
                "Forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Accurate flood prediction is crucial for disaster prevention and mitigation. Hydrological data exhibit highly nonlinear temporal patterns and encompass complex spatial relationships between rainfall and flow. Existing flood prediction models struggle to capture these intricate temporal features and spatial dependencies. This paper presents an adaptive periodic and spatial self-attention method based on LSTM (APS-LSTM) to address these challenges. The APS-LSTM learns temporal features from a multi-periodicity perspective and captures diverse spatial dependencies from different period divisions. The APS-LSTM consists of three main stages, (i) Multi-Period Division, that utilizes Fast Fourier Transform (FFT) to divide various periodic patterns; (ii) Spatio-Temporal Information Extraction, that performs periodic and spatial self-attention focusing on intra- and inter-periodic temporal patterns and spatial dependencies; (iii) Adaptive Aggregation, that relies on amplitude strength to aggregate the computational results from each periodic division. The abundant experiments on two real-world datasets demonstrate the superiority of APS-LSTM. The code is available: https://github.com/oopcmd/APS-LSTM.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "comment": "Received by IEEE SMC"
    },
    {
        "paper id": "2412.04828",
        "abstract url": "https://arxiv.org/abs/2412.04828",
        "title": "DAug: Diffusion-based Channel Augmentation for Radiology Image Retrieval and Classification",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion"
            ],
            [
                "Medical",
                "disease",
                "Radiology"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Medical image understanding requires meticulous examination of fine visual details, with particular regions requiring additional attention. While radiologists build such expertise over years of experience, it is challenging for AI models to learn where to look with limited amounts of training data. This limitation results in unsatisfying robustness in medical image understanding. To address this issue, we propose Diffusion-based Feature Augmentation (DAug), a portable method that improves a perception model's performance with a generative model's output. Specifically, we extend a radiology image to multiple channels, with the additional channels being the heatmaps of regions where diseases tend to develop. A diffusion-based image-to-image translation model was used to generate such heatmaps conditioned on selected disease classes. Our method is motivated by the fact that generative models learn the distribution of normal and abnormal images, and such knowledge is complementary to image understanding tasks. In addition, we propose the Image-Text-Class Hybrid Contrastive learning to utilize both text and class labels. With two novel approaches combined, our method surpasses baseline models without changing the model architecture, and achieves state-of-the-art performance on both medical image retrieval and classification tasks.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04844",
        "abstract url": "https://arxiv.org/abs/2412.04844",
        "title": "Cutting is All You Need: Execution of Large-Scale Quantum Neural Networks on Limited-Qubit Devices",
        "rating": "-2",
        "keywords": [
            [
                "Quantum"
            ]
        ],
        "abstract": "The rapid advancement in Quantum Computing (QC), particularly through Noisy-Intermediate Scale Quantum (NISQ) devices, has spurred significant interest in Quantum Machine Learning (QML) applications. Despite their potential, fully-quantum QML algorithms remain impractical due to the limitations of current NISQ devices. Hybrid quantum-classical neural networks (HQNNs) have emerged as a viable alternative, leveraging both quantum and classical computations to enhance machine learning capabilities. However, the constrained resources of NISQ devices, particularly the limited number of qubits, pose significant challenges for executing large-scale quantum circuits. This work addresses these current challenges by proposing a novel and practical methodology for quantum circuit cutting of HQNNs, allowing large quantum circuits to be executed on limited-qubit NISQ devices. Our approach not only preserves the accuracy of the original circuits but also supports the training of quantum parameters across all subcircuits, which is crucial for the learning process in HQNNs. We propose a cutting methodology for HQNNs that employs a greedy algorithm for identifying efficient cutting points, and the implementation of trainable subcircuits, all designed to maximize the utility of NISQ devices in HQNNs. The findings suggest that quantum circuit cutting is a promising technique for advancing QML on current quantum hardware, since the cut circuit achieves comparable accuracy and much lower qubit requirements than the original circuit.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04876",
        "abstract url": "https://arxiv.org/abs/2412.04876",
        "title": "Dynamic Interference Prediction for In-X 6G Sub-networks",
        "rating": "-2",
        "keywords": [
            [
                "6G",
                "industrial"
            ]
        ],
        "abstract": "The sixth generation (6G) industrial Sub-networks (SNs) face several challenges in meeting extreme latency and reliability requirements in the order of 0.1-1 ms and 99.999 -to-99.99999 percentile, respectively. Interference management (IM) plays an integral role in addressing these requirements, especially in ultra-dense SN environments with rapidly varying interference induced by channel characteristics, mobility, and resource limitations. In general, IM can be achieved using resource allocation and \\textit{accurate} Link adaptation (LA). In this work, we focus on the latter, where we first model interference at SN devices using the spatially consistent 3GPP channel model. Following this, we present a discrete-time dynamic state space model (DSSM) at a SN access point (AP), where interference power values (IPVs) are modeled as latent variables incorporating underlying modeling errors as well as transmission/protocol delays. Necessary approximations are then presented to simplify the DSSM and to efficiently employ the extended Kalman filter (EKF) for interference prediction. Unlike baseline methods, our proposed approach predicts IPVs solely based on the channel quality indicator (CQI) reports available at the SN AP at every transmission time interval (TTI). Numerical results demonstrate that our proposed approach clearly outperforms the conventional baseline. Furthermore, we also show that despite predicting with limited information, our proposed approach consistently achieves a comparable performance w.r.t the off-the-shelf supervised learning based baseline.",
        "subjects": [
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04935",
        "abstract url": "https://arxiv.org/abs/2412.04935",
        "title": "Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions",
        "rating": "-2",
        "keywords": [
            [
                "SDF"
            ],
            [
                "biomarker",
                "disease",
                "retinal"
            ],
            [
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In this paper, we present a new approach for uncertainty-aware retinal layer segmentation in Optical Coherence Tomography (OCT) scans using probabilistic signed distance functions (SDF). Traditional pixel-wise and regression-based methods primarily encounter difficulties in precise segmentation and lack of geometrical grounding respectively. To address these shortcomings, our methodology refines the segmentation by predicting a signed distance function (SDF) that effectively parameterizes the retinal layer shape via level set. We further enhance the framework by integrating probabilistic modeling, applying Gaussian distributions to encapsulate the uncertainty in the shape parameterization. This ensures a robust representation of the retinal layer morphology even in the presence of ambiguous input, imaging noise, and unreliable segmentations. Both quantitative and qualitative evaluations demonstrate superior performance when compared to other methods. Additionally, we conducted experiments on artificially distorted datasets with various noise types-shadowing, blinking, speckle, and motion-common in OCT scans to showcase the effectiveness of our uncertainty estimation. Our findings demonstrate the possibility to obtain reliable segmentation of retinal layers, as well as an initial step towards the characterization of layer integrity, a key biomarker for disease progression. Our code is available at \\url{https://github.com/niazoys/RLS_PSDF}.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04949",
        "abstract url": "https://arxiv.org/abs/2412.04949",
        "title": "Preliminary Study on Virtual Reality Framework for Effective Prospective Memory Training: Integration of Visual Imagery and Daily-life Simulations",
        "rating": "-2",
        "keywords": [
            [
                "clinical"
            ]
        ],
        "abstract": "Prospective memory (PM), defining the currently conceived intention of a future action, is crucial for daily functioning, particularly in aging populations. This study develops and validates a virtual reality prospective memory training (VR-PMT) system that integrates visual imagery training (VIT) and virtual reality training (VRT) to enhance the PM abilities of users. The framework is designed to progressively challenge users by simulating real-life PM tasks in a controlled VR environment. The VIT component is designed to improve the generation and utilization of visual imagery by users, while the VRT component provides PM tasks based on time and event cues within a virtual environment.The framework was evaluated on ten healthy adults (university students and elderly participants) over nine weeks. During the initial session, the baseline PM abilities of the participants were assessed using the memory for intentions screening test (MIST). The subsequent sessions alternated between VIT and VRT with increasing task complexity. The MIST scores were significantly positively correlated with task achievement, confirming the efficacy of the system. Imagery abilities were also strongly correlated with task performance, underscoring the importance of visual imagery in PM training.Usability and user experiences, evaluated on the Jikaku-sho Shirabe questionnaire and the user experience questionnaire, indicated an overall positive user experience but higher fatigue levels in elderly participants. This study demonstrates that the VR--PMT system effectively trains and assesses PM abilities by integrating VIT and VRT, supporting its potential for broader applications in clinical settings.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "This manuscript has been submitted to IEEE Access"
    },
    {
        "paper id": "2412.04969",
        "abstract url": "https://arxiv.org/abs/2412.04969",
        "title": "From Theory to Practice: Demonstrators of FAIR Data Spaces Across Different Sectors",
        "rating": "-2",
        "keywords": [
            [
                "biodiversity",
                "health"
            ]
        ],
        "abstract": "The principles of data spaces for sovereign data exchange across trusted organizations have so far mainly been adopted in business-to-business settings, and recently scaled to cloud environments. Meanwhile, research organizations have established distributed research data infrastructures, respecting the principle that data must be FAIR, i.e., findable, accessible, interoperable and reusable. For mutual benefit of these two communities, the FAIR Data Spaces project aims to connect them towards the vision of a common, cloud-based data space for industry and research. Thus, the project establishes a common legal and ethical framework, common technical building blocks, and it demonstrates the orchestration of multiple building blocks in self-contained settings addressing a diverse range of use cases in domains including health, biodiversity, and engineering. This paper gives a summary of all demonstrators, ranging from research data infrastructures scaled to industry-ready cloud environments to work in progress on building bridges between operational business-to-business data spaces and research data infrastructures.",
        "subjects": [
            "cs.DC"
        ],
        "comment": "Accepted at the 40th ACM/SIGAPP Symposium On Applied Computing"
    },
    {
        "paper id": "2412.04989",
        "abstract url": "https://arxiv.org/abs/2412.04989",
        "title": "Location-Driven Programmable Wireless Environments through Light-emitting RIS (LeRIS)",
        "rating": "-2",
        "keywords": [
            [
                "6G"
            ]
        ],
        "abstract": "As 6G wireless networks seek to enable robust and dynamic programmable wireless environments (PWEs), reconfigurable intelligent surfaces (RISs) have emerged as a cornerstone for controlling electromagnetic wave propagation. However, realizing the potential of RISs for demanding PWE applications depends on precise and real-time user localization, especially in scenarios with random receiver orientations and inherent hardware imperfections. To address this challenge, we propose a novel optical localization framework that integrates conventional ceiling-mounted LEDs with light-emitting reconfigurable intelligent surfaces (LeRISs). By leveraging the spatial diversity offered by the LeRIS architecture, the framework introduces robust signal paths that improve localization accuracy and reduce errors under varying orientations. To this end, we derive a system of equations for received signal strength-based localization that accounts for random receiver orientations and imposes spatial constraints on LED placement, ensuring unique and reliable solutions. Finally, our simulation results demonstrate that the proposed framework achieves precise beam control and high spectral efficiency even for RISs with large number of reflecting elements, establishing our solution as scalable and adaptive for PWEs that require real-time accuracy and flexibility.",
        "subjects": [
            "cs.NI",
            "cs.IT"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05011",
        "abstract url": "https://arxiv.org/abs/2412.05011",
        "title": "Galois self-orthogonal MDS codes with large dimensions",
        "rating": "-2",
        "keywords": [
            [
                "quantum"
            ]
        ],
        "abstract": "Let $q=p^m$ be a prime power, $e$ be an integer with $0\\leq e\\leq m-1$ and $s=\\gcd(e,m)$. In this paper, for a vector $v$ and a $q$-ary linear code $C$, we give some necessary and sufficient conditions for the equivalent code $vC$ of $C$ and the extended code of $vC$ to be $e$-Galois self-orthogonal. From this, we directly obtain some necessary and sufficient conditions for (extended) generalized Reed-Solomon (GRS and EGRS) codes to be $e$-Galois self-orthogonal. Furthermore, for all possible $e$ satisfying $0\\leq e\\leq m-1$, we classify them into three cases (1) $\\frac{m}{s}$ odd and $p$ even; (2) $\\frac{m}{s}$ odd and $p$ odd; (3) $\\frac{m}{s}$ even, and construct several new classes of $e$-Galois self-orthogonal maximum distance separable (MDS) codes. It is worth noting that our $e$-Galois self-orthogonal MDS codes can have dimensions greater than $\\lfloor \\frac{n+p^e-1}{p^e+1}\\rfloor$, which are not covered by previously known ones. Moreover, by propagation rules, we obtain some new MDS codes with Galois hulls of arbitrary dimensions. As an application, many quantum codes can be obtained from these MDS codes with Galois hulls.",
        "subjects": [
            "cs.IT"
        ],
        "comment": "28 pages, 2 tables"
    },
    {
        "paper id": "2412.05037",
        "abstract url": "https://arxiv.org/abs/2412.05037",
        "title": "Mechanical State Estimation with a Polynomial-Chaos-Based Statistical Finite Element Method",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "The Statistical Finite Element Method (statFEM) offers a Bayesian framework for integrating computational models with observational data, thus providing improved predictions for structural health monitoring and digital twinning. This paper presents an efficient sampling-free statFEM tailored for non-conjugate, non-Gaussian prior probability densities. We assume that constitutive parameters, modeled as weakly stationary random fields, are the primary source of uncertainty and approximate them using Karhunen-Lo\u00e8ve (KL) expansion. The resulting stochastic solution field, i.e., the displacement field, is a non-stationary, non-Gaussian random field, which we approximate via Polynomial Chaos (PC) expansion. The PC coefficients are determined through projection using Smolyak sparse grids. Additionally, we model the measurement noise as a stationary Gaussian random field and the model misspecification as a mean-free, non-stationary Gaussian random field, which is also approximated using KL expansion. The coefficients of the KL expansion are treated as hyperparameters. The PC coefficients of the stochastic posterior displacement field are computed using the Gauss-Markov-K\u00e1lm\u00e1n filter, while the hyperparameters are determined by maximizing the marginal likelihood. We demonstrate the efficiency and convergence of the proposed method through one- and two-dimensional elastostatic problems.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "39 Pages, 20 figures"
    },
    {
        "paper id": "2412.05039",
        "abstract url": "https://arxiv.org/abs/2412.05039",
        "title": "Level Up or Game Over: Exploring How Dark Patterns Shape Mobile Games",
        "rating": "-2",
        "keywords": [
            [
                "psychological"
            ]
        ],
        "abstract": "This study explores the prevalence of dark patterns in mobile games that exploit players through temporal, monetary, social, and psychological means. Recognizing the ethical concerns and potential harm surrounding these manipulative strategies, we analyze user-generated data of 1496 games to identify relationships between the deployment of dark patterns within \"dark\" and \"healthy\" games. Our findings reveal that dark patterns are not only widespread in games typically seen as problematic but are also present in games that may be perceived as benign. This research contributes needed quantitative support to the broader understanding of dark patterns in games. With an emphasis on ethical design, our study highlights current problems of revenue models that can be particularly harmful to vulnerable populations. To this end, we discuss the relevance of community-based approaches to surface harmful design and the necessity for collaboration among players/users and practitioners to promote healthier gaming experiences.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05055",
        "abstract url": "https://arxiv.org/abs/2412.05055",
        "title": "Information Flows for Athletes' Health and Performance Data",
        "rating": "-2",
        "keywords": [
            [
                "Health",
                "psychological"
            ]
        ],
        "abstract": "Increasing numbers of athletes and sports teams use data collection technologies to improve athletic development and athlete health with the goal of improving competitive performance. Personal data privacy is managed but it is not always a priority for the coaches who are in charge of athletes. There is a pressing need to investigate what are appropriate information flows as described by contextual integrity for these data technologies and these use cases. We propose two main types of information flows for athletes' health and performance data -- team-centric and athlete-centric -- designed to characterize data used for the collective and individual physical, psychological and social development of athletes. We also present a scenario for applying differential privacy to athletes' data and propose two new information flows -- research-centric and community-centric &mdash;which envision larger-scale, more collaborative sharing of athletes' data in the future.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05102",
        "abstract url": "https://arxiv.org/abs/2412.05102",
        "title": "Exact Model Reduction for Continuous-Time Open Quantum Dynamics",
        "rating": "-2",
        "keywords": [
            [
                "Quantum",
                "physics"
            ]
        ],
        "abstract": "We consider finite-dimensional many-body quantum systems described by time-independent Hamiltonians and Markovian master equations, and present a systematic method for constructing smaller-dimensional, reduced models that exactly reproduce the time evolution of a set of initial conditions or observables of interest. Our approach exploits Krylov operator spaces and their extension to operator algebras, and may be used to obtain reduced linear models of minimal dimension, well-suited for simulation on classical computers, or reduced quantum models that preserve the structural constraints of physically admissible quantum dynamics, as required for simulation on quantum computers. Notably, we prove that the reduced quantum-dynamical generator is still in Lindblad form. By introducing a new type of observable-dependent symmetries, we show that our method provides a non-trivial generalization of techniques that leverage symmetries, unlocking new reduction opportunities. We quantitatively benchmark our method on paradigmatic open many-body systems of relevance to condensed-matter and quantum-information physics. In particular, we demonstrate how our reduced models can quantitatively describe decoherence dynamics in central-spin systems coupled to structured environments, magnetization transport in boundary-driven dissipative spin chains, and unwanted error dynamics on information encoded in a noiseless quantum code.",
        "subjects": [
            "quant-ph",
            "eess.SY",
            "math-ph"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05181",
        "abstract url": "https://arxiv.org/abs/2412.05181",
        "title": "\"If it has an exclamation point, I step away from it, I need facts, not excited feelings\": Technologically Mediated Parental COVID Uncertainty",
        "rating": "-2",
        "keywords": [
            [
                "health"
            ]
        ],
        "abstract": "As a novel virus, COVID introduced considerable uncertainty into the daily lives of people all over the globe since late 2019. Relying on twenty-three semi-structured interviews with parents whose children contracted COVID, we analyzed how the use of social media moderated parental uncertainty about the symptoms, prognosis, long-term potential health ramifications of infection, vaccination, and other issues. We framed our findings using Mishel's Uncertainty in Illness theory. We propose new components to the theory that account for technological mediation in uncertainty. We also propose design recommendations to help parents cope with health uncertainty using social media.",
        "subjects": [
            "cs.HC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05248",
        "abstract url": "https://arxiv.org/abs/2412.05248",
        "title": "Enhancing FKG.in: automating Indian food composition analysis",
        "rating": "-2",
        "keywords": [
            [
                "graph"
            ],
            [
                "health"
            ],
            [
                "cs.AI",
                "cs.CL"
            ]
        ],
        "abstract": "This paper presents a novel approach to compute food composition data for Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The primary focus is to provide a broad overview of an automated food composition analysis workflow and describe its core functionalities: nutrition data aggregation, food composition analysis, and LLM-augmented information resolution. This workflow aims to complement FKG.in and iteratively supplement food composition data from verified knowledge bases. Additionally, this paper highlights the challenges of representing Indian food and accessing food composition data digitally. It also reviews three key sources of food composition data: the Indian Food Composition Tables, the Indian Nutrient Databank, and the Nutritionix API. Furthermore, it briefly outlines how users can interact with the workflow to obtain diet-based health recommendations and detailed food composition information for numerous recipes. We then explore the complex challenges of analyzing Indian recipe information across dimensions such as structure, multilingualism, and uncertainty as well as present our ongoing work on LLM-based solutions to address these issues. The methods proposed in this workshop paper for AI-driven knowledge curation and information resolution are application-agnostic, generalizable, and replicable for any domain.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.IR"
        ],
        "comment": "15 pages, 5 figures, 30 references, International Conference on Pattern Recognition 2024 - Multimedia Assisted Dietary Management Workshop"
    },
    {
        "paper id": "2412.05256",
        "abstract url": "https://arxiv.org/abs/2412.05256",
        "title": "Extrapolated Urban View Synthesis Benchmark",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting",
                "radiance fields"
            ],
            [
                "diffusion"
            ],
            [
                "robotics"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "Photorealistic simulators are essential for the training and evaluation of vision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis (NVS), a crucial capability that generates diverse unseen viewpoints to accommodate the broad and continuous pose distribution of AVs. Recent advances in radiance fields, such as 3D Gaussian Splatting, achieve photorealistic rendering at real-time speeds and have been widely used in modeling large-scale driving scenes. However, their performance is commonly evaluated using an interpolated setup with highly correlated training and test views. In contrast, extrapolation, where test views largely deviate from training views, remains underexplored, limiting progress in generalizable simulation technology. To address this gap, we leverage publicly available AV datasets with multiple traversals, multiple vehicles, and multiple cameras to build the first Extrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conduct quantitative and qualitative evaluations of state-of-the-art Gaussian Splatting methods across different difficulty levels. Our results show that Gaussian Splatting is prone to overfitting to training views. Besides, incorporating diffusion priors and improving geometry cannot fundamentally improve NVS under large view changes, highlighting the need for more robust approaches and large-scale training. We have released our data to help advance self-driving and urban robotics simulation technology.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "comment": "Project page: https://ai4ce.github.io/EUVS-Benchmark/"
    },
    {
        "paper id": "2412.05385",
        "abstract url": "https://arxiv.org/abs/2412.05385",
        "title": "Enhanced 5G/B5G Network Planning/Optimization deploying RIS in Urban/Outdoor Scenarios",
        "rating": "-2",
        "keywords": [
            [
                "5G",
                "6G"
            ]
        ],
        "abstract": "In recent years, the fifth-generation (5G) mobile network has been developed worldwide to remarkably improve network performance and spectral efficiency. Very recently, reconfigurable intelligent surfaces (RISs) technology has emerged as an innovative solution for controlling the propagation medium of the forthcoming sixth-generation (6G) networks. Specifically, RIS takes advantage of the reflected rays on the propagation environment to redirect them to a desired target, improving wireless coverage. To further improve RIS performance, an interesting technique called synchronized transmission with advanced reconfigurable surfaces (STARS) has appeared to allow simultaneous transmission and reflection of intelligent omni-surfaces. With that in mind, this paper introduces an enhanced strategy for the network planning of 5G and beyond (B5G) mobile networks in dense urban scenarios focused on the city of Quito-Ecuador. The efficacy of RIS and its cutting-edge STARS concept is emphasized, providing useful insights into coverage, quality, and throughput results. In particular, this work considers the 3.5/28 GHz frequency bands, optimizing the radio network and anticipating their applicability in B5G networks. Finally, simulation results are also shown, which allow the identification of the benefits of STAR RIS in terms of coverage, signal quality, and data performance.",
        "subjects": [
            "cs.NI",
            "eess.SY"
        ],
        "comment": "6 pages, 12 figures, 2024 IEEE 29th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD), presented in Session 11: Federation of 6G Infrastructures and Experimentation Facilities in a Network of Networks, October 22th - 2024"
    },
    {
        "paper id": "2412.05405",
        "abstract url": "https://arxiv.org/abs/2412.05405",
        "title": "Design and Implementation of an IoT-based Respiratory Motion Sensor",
        "rating": "-2",
        "keywords": [
            [
                "IoT"
            ]
        ],
        "abstract": "In the last few decades, several wearable devices have been designed to monitor respiration rate in an effort to capture pulmonary signals with higher accuracy and reduce patients' discomfort during use. In this article, we present the design and implementation of a device for real-time monitoring of respiratory system movements. When breathing, the circumference of the abdomen and thorax changes; therefore, we used a Force Sensing Resistor (FSR) attached to the Printed Circuit Board (PCB) to measure this variation as the patient inhales and exhales. The mechanical strain this causes changes the FSR electrical resistance accordingly. Also, for streaming this variable resistance on an Internet of Things (IoT) platform, Bluetooth Low Energy (BLE) 5 is utilized due to the adequate throughput, high accessibility, and possibility of power consumption reduction. Furthermore, this device presents features such as low power consumption (0.4 mW), high precision, and ease of use.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05453",
        "abstract url": "https://arxiv.org/abs/2412.05453",
        "title": "Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering",
        "rating": "-2",
        "keywords": [
            [
                "Graphs"
            ],
            [
                "Physics"
            ],
            [
                "cs.CL"
            ]
        ],
        "abstract": "This study explores the effectiveness of using knowledge graphs generated by large language models to decompose high school-level physics questions into sub-questions. We introduce a pipeline aimed at enhancing model response quality for Question Answering tasks. By employing LLMs to construct knowledge graphs that capture the internal logic of the questions, these graphs then guide the generation of subquestions. We hypothesize that this method yields sub-questions that are more logically consistent with the original questions compared to traditional decomposition techniques. Our results show that sub-questions derived from knowledge graphs exhibit significantly improved fidelity to the original question's logic. This approach not only enhances the learning experience by providing clearer and more contextually appropriate sub-questions but also highlights the potential of LLMs to transform educational methodologies. The findings indicate a promising direction for applying AI to improve the quality and effectiveness of educational content.",
        "subjects": [
            "cs.CL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05486",
        "abstract url": "https://arxiv.org/abs/2412.05486",
        "title": "A Scene Representation for Online Spatial Sonification",
        "rating": "-2",
        "keywords": [
            [
                "3D",
                "depth"
            ],
            [
                "navigation"
            ]
        ],
        "abstract": "Robotic perception is emerging as a crucial technology for navigation aids, particularly benefiting individuals with visual impairments through sonification. This paper presents a novel mapping framework that accurately represents spatial geometry for sonification, transforming physical spaces into auditory experiences. By leveraging depth sensors, we convert incrementally built 3D scenes into a compact 360-degree representation based on angular and distance information, aligning with human auditory perception. Our proposed mapping framework utilises a sensor-centric structure, maintaining 2D circular or 3D cylindrical representations, and employs the VDB-GPDF for efficient online mapping. We introduce two sonification modes-circular ranging and circular ranging of objects-along with real-time user control over auditory filters. Incorporating binaural room impulse responses, our framework provides perceptually robust auditory feedback. Quantitative and qualitative evaluations demonstrate superior performance in accuracy, coverage, and timing compared to existing approaches, with effective handling of dynamic objects. The accompanying video showcases the practical application of spatial sonification in room-like environments.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05487",
        "abstract url": "https://arxiv.org/abs/2412.05487",
        "title": "Securing Social Media Against Deepfakes using Identity, Behavioral, and Geometric Signatures",
        "rating": "-2",
        "keywords": [
            [
                "deepfake"
            ],
            [
                "facial"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Trust in social media is a growing concern due to its ability to influence significant societal changes. However, this space is increasingly compromised by various types of deepfake multimedia, which undermine the authenticity of shared content. Although substantial efforts have been made to address the challenge of deepfake content, existing detection techniques face a major limitation in generalization: they tend to perform well only on specific types of deepfakes they were trained on.This dependency on recognizing specific deepfake artifacts makes current methods vulnerable when applied to unseen or varied deepfakes, thereby compromising their performance in real-world applications such as social media platforms. To address the generalizability of deepfake detection, there is a need for a holistic approach that can capture a broader range of facial attributes and manipulations beyond isolated artifacts. To address this, we propose a novel deepfake detection framework featuring an effective feature descriptor that integrates Deep identity, Behavioral, and Geometric (DBaG) signatures, along with a classifier named DBaGNet. Specifically, the DBaGNet classifier utilizes the extracted DBaG signatures, leveraging a triplet loss objective to enhance generalized representation learning for improved classification. Specifically, the DBaGNet classifier utilizes the extracted DBaG signatures and applies a triplet loss objective to enhance generalized representation learning for improved classification. To test the effectiveness and generalizability of our proposed approach, we conduct extensive experiments using six benchmark deepfake datasets: WLDR, CelebDF, DFDC, FaceForensics++, DFD, and NVFAIR. Specifically, to ensure the effectiveness of our approach, we perform cross-dataset evaluations, and the results demonstrate significant performance gains over several state-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05488",
        "abstract url": "https://arxiv.org/abs/2412.05488",
        "title": "Enhancing Sample Generation of Diffusion Models using Noise Level Correction",
        "rating": "-2",
        "keywords": [
            [
                "Diffusion",
                "inpainting",
                "super-resolution"
            ],
            [
                "image restoration"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "The denoising process of diffusion models can be interpreted as a projection of noisy samples onto the data manifold. Moreover, the noise level in these samples approximates their distance to the underlying manifold. Building on this insight, we propose a novel method to enhance sample generation by aligning the estimated noise level with the true distance of noisy samples to the manifold. Specifically, we introduce a noise level correction network, leveraging a pre-trained denoising network, to refine noise level estimates during the denoising process. Additionally, we extend this approach to various image restoration tasks by integrating task-specific constraints, including inpainting, deblurring, super-resolution, colorization, and compressed sensing. Experimental results demonstrate that our method significantly improves sample quality in both unconstrained and constrained generation scenarios. Notably, the proposed noise level correction framework is compatible with existing denoising schedulers (e.g., DDIM), offering additional performance improvements.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05490",
        "abstract url": "https://arxiv.org/abs/2412.05490",
        "title": "A Comparative Study of Image Denoising Algorithms",
        "rating": "-2",
        "keywords": [
            [
                "robotics"
            ],
            [
                "bio-medical",
                "medical"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "With the recent advancements in the field of information industry, critical data in the form of digital images is best understood by the human brain. Therefore, digital images play a significant part and backbone role in many areas such as image processing, vision computing, robotics, and bio-medical. Such use of digital images is practically implementable in various real-time scenarios like biological sciences, medicine, gaming technology, computer information and communication technology, data and statistical science, radiological sciences and medical imaging technology, and medical lab technology. However, when any digital image is sent electronically or captured via camera, it is likely to get corrupted or degraded by the available of degradation factors. To eradicate this problem, several image denoising algorithms have been proposed in the literature focusing on robust, low-cost and fast techniques to improve output performance. Consequently, in this research project, an earnest effort has been made to study various image denoising algorithms. A specific focus is given to the start-of-the-art techniques namely: NL-means, K-SVD, and BM3D. The standard images, natural images, texture images, synthetic images, and images from other datasets have been tested via these algorithms, and a detailed set of convincing results have been provided for efficient comparison.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05501",
        "abstract url": "https://arxiv.org/abs/2412.05501",
        "title": "Computational models of learning and synaptic plasticity",
        "rating": "-2",
        "keywords": [
            [
                "biological"
            ]
        ],
        "abstract": "Many mathematical models of synaptic plasticity have been proposed to explain the diversity of plasticity phenomena observed in biological organisms. These models range from simple interpretations of Hebb's postulate, which suggests that correlated neural activity leads to increases in synaptic strength, to more complex rules that allow bidirectional synaptic updates, ensure stability, or incorporate additional signals like reward or error. At the same time, a range of learning paradigms can be observed behaviorally, from Pavlovian conditioning to motor learning and memory recall. Although it is difficult to directly link synaptic updates to learning outcomes experimentally, computational models provide a valuable tool for building evidence of this connection. In this chapter, we discuss several fundamental learning paradigms, along with the synaptic plasticity rules that might be used to implement them.",
        "subjects": [
            "q-bio.NC",
            "cs.NE"
        ],
        "comment": "Chapter for reference textbook on learning and memory"
    },
    {
        "paper id": "2412.04832",
        "abstract url": "https://arxiv.org/abs/2412.04832",
        "title": "WRF-GS: Wireless Radiation Field Reconstruction with 3D Gaussian Splatting",
        "rating": "-2.5",
        "keywords": [
            [
                "3D",
                "Gaussian Splatting"
            ],
            [
                "5G"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Wireless channel modeling plays a pivotal role in designing, analyzing, and optimizing wireless communication systems. Nevertheless, developing an effective channel modeling approach has been a longstanding challenge. This issue has been escalated due to the denser network deployment, larger antenna arrays, and wider bandwidth in 5G and beyond networks. To address this challenge, we put forth WRF-GS, a novel framework for channel modeling based on wireless radiation field (WRF) reconstruction using 3D Gaussian splatting. WRF-GS employs 3D Gaussian primitives and neural networks to capture the interactions between the environment and radio signals, enabling efficient WRF reconstruction and visualization of the propagation characteristics. The reconstructed WRF can then be used to synthesize the spatial spectrum for comprehensive wireless channel characterization. Notably, with a small number of measurements, WRF-GS can synthesize new spatial spectra within milliseconds for a given scene, thereby enabling latency-sensitive applications. Experimental results demonstrate that WRF-GS outperforms existing methods for spatial spectrum synthesis, such as ray tracing and other deep-learning approaches. Moreover, WRF-GS achieves superior performance in the channel state information prediction task, surpassing existing methods by a significant margin of more than 2.43 dB.",
        "subjects": [
            "cs.NI",
            "cs.AI",
            "cs.LG"
        ],
        "comment": "accepted to the IEEE International Conference on Computer Communications (INFOCOM 2025)"
    },
    {
        "paper id": "2412.04861",
        "abstract url": "https://arxiv.org/abs/2412.04861",
        "title": "MSECG: Incorporating Mamba for Robust and Efficient ECG Super-Resolution",
        "rating": "-2.5",
        "keywords": [
            [
                "Super-Resolution"
            ],
            [
                "diagnosing"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Electrocardiogram (ECG) signals play a crucial role in diagnosing cardiovascular diseases. To reduce power consumption in wearable or portable devices used for long-term ECG monitoring, super-resolution (SR) techniques have been developed, enabling these devices to collect and transmit signals at a lower sampling rate. In this study, we propose MSECG, a compact neural network model designed for ECG SR. MSECG combines the strength of the recurrent Mamba model with convolutional layers to capture both local and global dependencies in ECG waveforms, allowing for the effective reconstruction of high-resolution signals. We also assess the model's performance in real-world noisy conditions by utilizing ECG data from the PTB-XL database and noise data from the MIT-BIH Noise Stress Test Database. Experimental results show that MSECG outperforms two contemporary ECG SR models under both clean and noisy conditions while using fewer parameters, offering a more powerful and robust solution for long-term ECG monitoring applications.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "comment": "5 pages, 3 figures"
    },
    {
        "paper id": "2412.05133",
        "abstract url": "https://arxiv.org/abs/2412.05133",
        "title": "Learning Hidden Physics and System Parameters with Deep Operator Networks",
        "rating": "-2.5",
        "keywords": [
            [
                "diffusion"
            ],
            [
                "Physics"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Big data is transforming scientific progress by enabling the discovery of novel models, enhancing existing frameworks, and facilitating precise uncertainty quantification, while advancements in scientific machine learning complement this by providing powerful tools to solve inverse problems to identify the complex systems where traditional methods falter due to sparse or noisy data. We introduce two innovative neural operator frameworks tailored for discovering hidden physics and identifying unknown system parameters from sparse measurements. The first framework integrates a popular neural operator, DeepONet, and a physics-informed neural network to capture the relationship between sparse data and the underlying physics, enabling the accurate discovery of a family of governing equations. The second framework focuses on system parameter identification, leveraging a DeepONet pre-trained on sparse sensor measurements to initialize a physics-constrained inverse model. Both frameworks excel in handling limited data and preserving physical consistency. Benchmarking on the Burgers' equation and reaction-diffusion system demonstrates state-of-the-art performance, achieving average $L_2$ errors of $\\mathcal{O}(10^{-2})$ for hidden physics discovery and absolute errors of $\\mathcal{O}(10^{-3})$ for parameter identification. These results underscore the frameworks' robustness, efficiency, and potential for solving complex scientific problems with minimal observational data.",
        "subjects": [
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05164",
        "abstract url": "https://arxiv.org/abs/2412.05164",
        "title": "A Differentially Private Kaplan-Meier Estimator for Privacy-Preserving Survival Analysis",
        "rating": "-2.5",
        "keywords": [
            [
                "attacks"
            ],
            [
                "Survival",
                "cancer",
                "clinical"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "This paper presents a differentially private approach to Kaplan-Meier estimation that achieves accurate survival probability estimates while safeguarding individual privacy. The Kaplan-Meier estimator is widely used in survival analysis to estimate survival functions over time, yet applying it to sensitive datasets, such as clinical records, risks revealing private information. To address this, we introduce a novel algorithm that applies time-indexed Laplace noise, dynamic clipping, and smoothing to produce a privacy-preserving survival curve while maintaining the cumulative structure of the Kaplan-Meier estimator. By scaling noise over time, the algorithm accounts for decreasing sensitivity as fewer individuals remain at risk, while dynamic clipping and smoothing prevent extreme values and reduce fluctuations, preserving the natural shape of the survival curve. Our results, evaluated on the NCCTG lung cancer dataset, show that the proposed method effectively lowers root mean squared error (RMSE) and enhances accuracy across privacy budgets ($\u03b5$). At $\u03b5= 10$, the algorithm achieves an RMSE as low as 0.04, closely approximating non-private estimates. Additionally, membership inference attacks reveal that higher $\u03b5$ values (e.g., $\u03b5\\geq 6$) significantly reduce influential points, particularly at higher thresholds, lowering susceptibility to inference attacks. These findings confirm that our approach balances privacy and utility, advancing privacy-preserving survival analysis.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05529",
        "abstract url": "https://arxiv.org/abs/2412.05529",
        "title": "Upcycling Noise for Federated Unlearning",
        "rating": "-2.5",
        "keywords": [
            [
                "Federated Learning"
            ],
            [
                "Unlearning"
            ],
            [
                "attacks"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "In Federated Learning (FL), multiple clients collaboratively train a model without sharing raw data. This paradigm can be further enhanced by Differential Privacy (DP) to protect local data from information inference attacks and is thus termed DPFL. An emerging privacy requirement, ``the right to be forgotten'' for clients, poses new challenges to DPFL but remains largely unexplored. Despite numerous studies on federated unlearning (FU), they are inapplicable to DPFL because the noise introduced by the DP mechanism compromises their effectiveness and efficiency. In this paper, we propose Federated Unlearning with Indistinguishability (FUI) to unlearn the local data of a target client in DPFL for the first time. FUI consists of two main steps: local model retraction and global noise calibration, resulting in an unlearning model that is statistically indistinguishable from the retrained model. Specifically, we demonstrate that the noise added in DPFL can endow the unlearning model with a certain level of indistinguishability after local model retraction, and then fortify the degree of unlearning through global noise calibration. Additionally, for the efficient and consistent implementation of the proposed FUI, we formulate a two-stage Stackelberg game to derive optimal unlearning strategies for both the server and the target client. Privacy and convergence analyses confirm theoretical guarantees, while experimental results based on four real-world datasets illustrate that our proposed FUI achieves superior model performance and higher efficiency compared to mainstream FU schemes. Simulation results further verify the optimality of the derived unlearning strategies.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05534",
        "abstract url": "https://arxiv.org/abs/2412.05534",
        "title": "Memory-enhanced Invariant Prompt Learning for Urban Flow Prediction under Distribution Shifts",
        "rating": "-2.5",
        "keywords": [
            [
                "Graph"
            ],
            [
                "forecasting"
            ],
            [
                "cs.AI",
                "cs.LG"
            ]
        ],
        "abstract": "Urban flow prediction is a classic spatial-temporal forecasting task that estimates the amount of future traffic flow for a given location. Though models represented by Spatial-Temporal Graph Neural Networks (STGNNs) have established themselves as capable predictors, they tend to suffer from distribution shifts that are common with the urban flow data due to the dynamics and unpredictability of spatial-temporal events. Unfortunately, in spatial-temporal applications, the dynamic environments can hardly be quantified via a fixed number of parameters, whereas learning time- and location-specific environments can quickly become computationally prohibitive. In this paper, we propose a novel framework named Memory-enhanced Invariant Prompt learning (MIP) for urban flow prediction under constant distribution shifts. Specifically, MIP is equipped with a learnable memory bank that is trained to memorize the causal features within the spatial-temporal graph. By querying a trainable memory bank that stores the causal features, we adaptively extract invariant and variant prompts (i.e., patterns) for a given location at every time step. Then, instead of intervening the raw data based on simulated environments, we directly perform intervention on variant prompts across space and time. With the intervened variant prompts in place, we use invariant learning to minimize the variance of predictions, so as to ensure that the predictions are only made with invariant features. With extensive comparative experiments on two public urban flow datasets, we thoroughly demonstrate the robustness of MIP against OOD data.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04793",
        "abstract url": "https://arxiv.org/abs/2412.04793",
        "title": "Distributed Massive MIMO-Aided Task Offloading in Satellite-Terrestrial Integrated Multi-Tier VEC Networks",
        "rating": "-3",
        "keywords": [
            [
                "vehicle"
            ],
            [
                "Satellite"
            ]
        ],
        "abstract": "This paper proposes a distributed massive multiple input multiple-output (DM-MIMO) aided multi-tier vehicular edge computing (VEC) system. In particular, each vehicle terminal (VT) offloads its computational task to the roadside unit (RSU) by orthogonal frequency division multiple access (OFDMA), which can be computed locally at the RSU and offloaded to the central processing unit (CPU) via massive satellite access points (SAPs) for remote computation. By considering the partial task offloading model, we consider the joint optimization of the task offloading, subchannel allocation and precoding optimization to minimize the total cost in terms of total delay and energy consumption. To solve this non-convex problem, we transform the original problem into three sub-problems and use the alternate optimization algorithm to solve it. First, we transform the subcarrier allocation problem of discrete variables into convex optimization problem of continuous variables. Then, we use multiple quadratic transformations and Lagrange multiplier method to transform the non-convex subproblem of optimizing precoding vectors into a convex problem, while the task offloading subproblem is a convex problem. Given the subcarrier and the task allocation and precoding result, we finally find the joint optimized results by iterative optimization algorithm. Simulation results show that our proposed algorithm is superior to other benchmarks.",
        "subjects": [
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04852",
        "abstract url": "https://arxiv.org/abs/2412.04852",
        "title": "SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models",
        "rating": "-3",
        "keywords": [
            [
                "Diffusion",
                "Text-to-image"
            ],
            [
                "attacks"
            ],
            [
                "Watermark"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Recent advances in large-scale text-to-image (T2I) diffusion models have enabled a variety of downstream applications, including style customization, subject-driven personalization, and conditional generation. As T2I models require extensive data and computational resources for training, they constitute highly valued intellectual property (IP) for their legitimate owners, yet making them incentive targets for unauthorized fine-tuning by adversaries seeking to leverage these models for customized, usually profitable applications. Existing IP protection methods for diffusion models generally involve embedding watermark patterns and then verifying ownership through generated outputs examination, or inspecting the model's feature space. However, these techniques are inherently ineffective in practical scenarios when the watermarked model undergoes fine-tuning, and the feature space is inaccessible during verification ((i.e., black-box setting). The model is prone to forgetting the previously learned watermark knowledge when it adapts to a new task. To address this challenge, we propose SleeperMark, a novel framework designed to embed resilient watermarks into T2I diffusion models. SleeperMark explicitly guides the model to disentangle the watermark information from the semantic concepts it learns, allowing the model to retain the embedded watermark while continuing to be fine-tuned to new downstream tasks. Our extensive experiments demonstrate the effectiveness of SleeperMark across various types of diffusion models, including latent diffusion models (e.g., Stable Diffusion) and pixel diffusion models (e.g., DeepFloyd-IF), showing robustness against downstream fine-tuning and various attacks at both the image and model levels, with minimal impact on the model's generative capability. The code is available at https://github.com/taco-group/SleeperMark.",
        "subjects": [
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04938",
        "abstract url": "https://arxiv.org/abs/2412.04938",
        "title": "Solving 1D Poisson problem with a Variational Quantum Linear Solver",
        "rating": "-3",
        "keywords": [
            [
                "depth"
            ],
            [
                "Quantum",
                "physics"
            ]
        ],
        "abstract": "Different hybrid quantum-classical algorithms have recently been developed as a near-term way to solve linear systems of equations on quantum devices. However, the focus has so far been mostly on the methods, rather than the problems that they need to tackle. In fact, these algorithms have been run on real hardware only for problems in quantum physics, such as Hamiltonians of a few qubits systems. These problems are particularly favorable for quantum hardware, since their matrices are the sum of just a few unitary terms and since only shallow quantum circuits are required to estimate the cost function. However, for many interesting problems in linear algebra, it appears far less trivial to find an efficient decomposition and to trade it off with the depth of the cost quantum circuits. A first simple yet interesting instance to consider are tridiagonal systems of equations. These arise, for instance, in the discretization of one-dimensional finite element analyses. This work presents a method to solve a class of tridiagonal systems of equations with the variational quantum linear solver (VQLS), a recently proposed variational hybrid algorithm for solving linear systems. In particular, we present a new decomposition for this class of matrices based on both Pauli strings and multi--qubit gates, resulting in less terms than those obtained by just using Pauli gates. Based on this decomposition, we discuss the tradeoff between the number of terms and the near-term implementability of the quantum circuits. Furthermore, we present the first simulated and real-hardware results obtained by solving tridiagonal linear systems with VQLS, using the decomposition proposed.",
        "subjects": [
            "cs.CE",
            "math.NA"
        ],
        "comment": "7 pages, 2 figures, 2 tables"
    },
    {
        "paper id": "2412.04987",
        "abstract url": "https://arxiv.org/abs/2412.04987",
        "title": "FlowPolicy: Enabling Fast and Robust 3D Flow-based Policy via Consistency Flow Matching for Robot Manipulation",
        "rating": "-3",
        "keywords": [
            [
                "3D",
                "point cloud"
            ],
            [
                "diffusion"
            ],
            [
                "robotics",
                "Robot"
            ]
        ],
        "abstract": "Robots can acquire complex manipulation skills by learning policies from expert demonstrations, which is often known as vision-based imitation learning. Generating policies based on diffusion and flow matching models has been shown to be effective, particularly in robotics manipulation tasks. However, recursion-based approaches are often inference inefficient in working from noise distributions to policy distributions, posing a challenging trade-off between efficiency and quality. This motivates us to propose FlowPolicy, a novel framework for fast policy generation based on consistency flow matching and 3D vision. Our approach refines the flow dynamics by normalizing the self-consistency of the velocity field, enabling the model to derive task execution policies in a single inference step. Specifically, FlowPolicy conditions on the observed 3D point cloud, where consistency flow matching directly defines straight-line flows from different time states to the same action space, while simultaneously constraining their velocity values, that is, we approximate the trajectories from noise to robot actions by normalizing the self-consistency of the velocity field within the action space, thus improving the inference efficiency. We validate the effectiveness of FlowPolicy on Adroit and Metaworld, demonstrating a 7$\\times$ increase in inference speed while maintaining competitive average success rates compared to state-of-the-art policy models. Codes will be made publicly available.",
        "subjects": [
            "cs.RO"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05010",
        "abstract url": "https://arxiv.org/abs/2412.05010",
        "title": "Backdooring Outlier Detection Methods: A Novel Attack Approach",
        "rating": "-3",
        "keywords": [
            [
                "autonomous driving"
            ],
            [
                "Attack"
            ],
            [
                "medical"
            ],
            [
                "cs.AI",
                "cs.LG",
                "cs.CV"
            ]
        ],
        "abstract": "There have been several efforts in backdoor attacks, but these have primarily focused on the closed-set performance of classifiers (i.e., classification). This has left a gap in addressing the threat to classifiers' open-set performance, referred to as outlier detection in the literature. Reliable outlier detection is crucial for deploying classifiers in critical real-world applications such as autonomous driving and medical image analysis. First, we show that existing backdoor attacks fall short in affecting the open-set performance of classifiers, as they have been specifically designed to confuse intra-closed-set decision boundaries. In contrast, an effective backdoor attack for outlier detection needs to confuse the decision boundary between the closed and open sets. Motivated by this, in this study, we propose BATOD, a novel Backdoor Attack targeting the Outlier Detection task. Specifically, we design two categories of triggers to shift inlier samples to outliers and vice versa. We evaluate BATOD using various real-world datasets and demonstrate its superior ability to degrade the open-set performance of classifiers compared to previous attacks, both before and after applying defenses.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.CV"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05026",
        "abstract url": "https://arxiv.org/abs/2412.05026",
        "title": "Quantum Security Analysis of the Key-Alternating Ciphers",
        "rating": "-3",
        "keywords": [
            [
                "attack"
            ],
            [
                "Quantum"
            ]
        ],
        "abstract": "We study the security of key-alternating ciphers (KAC), a generalization of Even-Mansour ciphers over multiple rounds, which serve as abstractions for many block cipher constructions, particularly AES. While the classical security of KAC has been extensively studied, little is known about its security against quantum adversaries. In this paper, we introduce the first nontrivial quantum key-recovery attack on multi-round KAC in a model where the adversary has quantum access to only one of the public permutations. Our attack applies to any $t$-round KAC, achieving quantum query complexity of $O(2^{\\frac{t(t+1)n}{(t+1)^2+1}})$, where $n$ is the size of each individual key, in a realistic quantum threat model, compared to the classical bound of $O(2^{\\frac{tn}{(t+1)}})$ queries given by Bogdanev et al. (EUROCRYPT 2012). Our quantum attack leverages a novel approach based on quantum walk algorithms. Additionally, using the quantum hybrid method in our new threat model, we extend the Even-Mansour lower bound of $\u03a9(2^{\\frac{n}{3}})$ given by Alagic et al. (EUROCRYPT 2022) to $\u03a9(2^{\\frac{(t-1)n}{t}})$ for the $t$-round KAC (for $t \\geq 2$).",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05053",
        "abstract url": "https://arxiv.org/abs/2412.05053",
        "title": "EvTTC: An Event Camera Dataset for Time-to-Collision Estimation",
        "rating": "-3",
        "keywords": [
            [
                "Event Camera"
            ],
            [
                "LiDAR"
            ],
            [
                "bio-inspired"
            ],
            [
                "cs.CV"
            ]
        ],
        "abstract": "Time-to-Collision (TTC) estimation lies in the core of the forward collision warning (FCW) functionality, which is key to all Automatic Emergency Braking (AEB) systems. Although the success of solutions using frame-based cameras (e.g., Mobileye's solutions) has been witnessed in normal situations, some extreme cases, such as the sudden variation in the relative speed of leading vehicles and the sudden appearance of pedestrians, still pose significant risks that cannot be handled. This is due to the inherent imaging principles of frame-based cameras, where the time interval between adjacent exposures introduces considerable system latency to AEB. Event cameras, as a novel bio-inspired sensor, offer ultra-high temporal resolution and can asynchronously report brightness changes at the microsecond level. To explore the potential of event cameras in the above-mentioned challenging cases, we propose EvTTC, which is, to the best of our knowledge, the first multi-sensor dataset focusing on TTC tasks under high-relative-speed scenarios. EvTTC consists of data collected using standard cameras and event cameras, covering various potential collision scenarios in daily driving and involving multiple collision objects. Additionally, LiDAR and GNSS/INS measurements are provided for the calculation of ground-truth TTC. Considering the high cost of testing TTC algorithms on full-scale mobile platforms, we also provide a small-scale TTC testbed for experimental validation and data augmentation. All the data and the design of the testbed are open sourced, and they can serve as a benchmark that will facilitate the development of vision-based TTC techniques.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "comment": "8 pages, 7 figures, 5 tables"
    },
    {
        "paper id": "2412.05197",
        "abstract url": "https://arxiv.org/abs/2412.05197",
        "title": "A Riemannian Take on Distance Fields and Geodesic Flows in Robotics",
        "rating": "-3",
        "keywords": [
            [
                "Robotics",
                "robot"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Distance functions are crucial in robotics for representing spatial relationships between the robot and the environment. It provides an implicit representation of continuous and differentiable shapes, which can seamlessly be combined with control, optimization, and learning techniques. While standard distance fields rely on the Euclidean metric, many robotic tasks inherently involve non-Euclidean structures. To this end, we generalize the use of Euclidean distance fields to more general metric spaces by solving a Riemannian eikonal equation, a first-order partial differential equation, whose solution defines a distance field and its associated gradient flow on the manifold, enabling the computation of geodesics and globally length-minimizing paths. We show that this \\emph{geodesic distance field} can also be exploited in the robot configuration space. To realize this concept, we exploit physics-informed neural networks to solve the eikonal equation for high-dimensional spaces, which provides a flexible and scalable representation without the need for discretization. Furthermore, a variant of our neural eikonal solver is introduced, which enables the gradient flow to march across both task and configuration spaces. As an example of application, we validate the proposed approach in an energy-aware motion generation task. This is achieved by considering a manifold defined by a Riemannian metric in configuration space, effectively taking the property of the robot's dynamics into account. Our approach produces minimal-energy trajectories for a 7-axis Franka robot by iteratively tracking geodesics through gradient flow backpropagation.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "17 pages, 11 figures"
    },
    {
        "paper id": "2412.05228",
        "abstract url": "https://arxiv.org/abs/2412.05228",
        "title": "MC3: Memory Contention based Covert Channel Communication on Shared DRAM System-on-Chips",
        "rating": "-3",
        "keywords": [
            [
                "attacks"
            ],
            [
                "IoT"
            ]
        ],
        "abstract": "Shared-memory system-on-chips (SM-SoC) are ubiquitously employed by a wide-range of mobile computing platforms, including edge/IoT devices, autonomous systems and smartphones. In SM-SoCs, system-wide shared physical memory enables a convenient and financially-feasible way to make data accessible by dozens of processing units (PUs), such as CPU cores and domain specific accelerators. In this study, we investigate vulnerabilities that stem from the shared use of physical memory in such systems. Due to the diverse computational characteristics of the PUs they embed, SM-SoCs often do not employ a shared last level cache (LLC). While the literature proposes covert channel attacks for shared memory systems, high-throughput communication is currently possible by either relying on an LLC or privileged/physical access to the shared memory subsystem. In this study, we introduce a new memory-contention based covert communication attack, MC3, which specifically targets the shared system memory in mobile SoCs. Different from existing attacks, our approach achieves high throughput communication between applications running on CPU and GPU without the need for an LLC or elevated access to the system. We extensively explore the effectiveness of our methodology by demonstrating the trade-off between the channel transmission rate and the robustness of the communication. We demonstrate the utility of MC3 on NVIDIA Orin AGX, Orin NX, and Orin Nano up to a transmit rate of 6.4 kbps with less than 1% error rate.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "This paper is accepted to 2025 Design, Automation Test in Europe Conference Exhibition (DATE)"
    },
    {
        "paper id": "2412.05240",
        "abstract url": "https://arxiv.org/abs/2412.05240",
        "title": "Automated, Unsupervised, and Auto-parameterized Inference of Data Patterns and Anomaly Detection",
        "rating": "-3",
        "keywords": [
            [
                "Anomaly Detection"
            ],
            [
                "industrial"
            ]
        ],
        "abstract": "With the advent of data-centric and machine learning (ML) systems, data quality is playing an increasingly critical role in ensuring the overall quality of software systems. Data preparation, an essential step towards high data quality, is known to be a highly effort-intensive process. Although prior studies have dealt with one of the most impacting issues, data pattern violations, these studies usually require data-specific configurations (i.e., parameterized) or use carefully curated data as learning examples (i.e., supervised), relying on domain knowledge and deep understanding of the data, or demanding significant manual effort. In this paper, we introduce RIOLU: Regex Inferencer auto-parameterized Learning with Uncleaned data. RIOLU is fully automated, automatically parameterized, and does not need labeled samples. RIOLU can generate precise patterns from datasets in various domains, with a high F1 score of 97.2%, exceeding the state-of-the-art baseline. In addition, according to our experiment on five datasets with anomalies, RIOLU can automatically estimate a data column's error rate, draw normal patterns, and predict anomalies from unlabeled data with higher performance (up to 800.4% improvement in terms of F1) than the state-of-the-art baseline, even outperforming ChatGPT in terms of both accuracy (12.3% higher F1) and efficiency (10% less inference time). A variant of RIOLU, with user guidance, can further boost its precision, with up to 37.4% improvement in terms of F1. Our evaluation in an industrial setting further demonstrates the practical benefits of RIOLU.",
        "subjects": [
            "cs.SE",
            "cs.DB"
        ],
        "comment": "Accepted in 2025 IEEE/ACM International Conference on Software Engineering (ICSE 2025)"
    },
    {
        "paper id": "2412.05345",
        "abstract url": "https://arxiv.org/abs/2412.05345",
        "title": "Osteoporosis Prediction from Hand X-ray Images Using Segmentation-for-Classification and Self-Supervised Learning",
        "rating": "-3",
        "keywords": [
            [
                "X-ray",
                "disease"
            ],
            [
                "mineral"
            ],
            [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "Osteoporosis is a widespread and chronic metabolic bone disease that often remains undiagnosed and untreated due to limited access to bone mineral density (BMD) tests like Dual-energy X-ray absorptiometry (DXA). In response to this challenge, current advancements are pivoting towards detecting osteoporosis by examining alternative indicators from peripheral bone areas, with the goal of increasing screening rates without added expenses or time. In this paper, we present a method to predict osteoporosis using hand and wrist X-ray images, which are both widely accessible and affordable, though their link to DXA-based data is not thoroughly explored. We employ a sophisticated image segmentation model that utilizes a mixture of probabilistic U-Net decoders, specifically designed to capture predictive uncertainty in the segmentation of the ulna, radius, and metacarpal bones. This model is formulated as an optimal transport (OT) problem, enabling it to handle the inherent uncertainties in image segmentation more effectively. Further, we adopt a self-supervised learning (SSL) approach to extract meaningful representations without the need for explicit labels, and move on to classify osteoporosis in a supervised manner. Our method is evaluated on a dataset with 192 individuals, cross-referencing their verified osteoporosis conditions against the standard DXA test. With a notable classification score, this integration of uncertainty-aware segmentation and self-supervised learning represents a pioneering effort in leveraging vision-based techniques for the early detection of osteoporosis from peripheral skeletal sites.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05427",
        "abstract url": "https://arxiv.org/abs/2412.05427",
        "title": "Machine Learning-Based mmWave MIMO Beam Tracking in V2I Scenarios: Algorithms and Datasets",
        "rating": "-3",
        "keywords": [
            [
                "LIDAR"
            ],
            [
                "5G"
            ]
        ],
        "abstract": "This work investigates the use of machine learning applied to the beam tracking problem in 5G networks and beyond. The goal is to decrease the overhead associated to MIMO millimeter wave beamforming. In comparison to beam selection (also called initial beam acquisition), ML-based beam tracking is less investigated in the literature due to factors such as the lack of comprehensive datasets. One of the contributions of this work is a new public multimodal dataset, which includes images, LIDAR information and GNSS positioning, enabling the evaluation of new data fusion algorithms applied to wireless communications. The work also contributes with an evaluation of the performance of beam tracking algorithms, and associated methodology. When considering as inputs the LIDAR data, the coordinates and the information from previously selected beams, the proposed deep neural network based on ResNet and using LSTM layers, significantly outperformed the other beam tracking models.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "5 pages, conference: 2024 IEEE Latin-American Conference on Communications (LATINCOM)"
    },
    {
        "paper id": "2412.06823",
        "abstract url": "https://arxiv.org/abs/2412.06823",
        "title": "Bio-Inspired Pneumatic Modular Actuator for Peristaltic Transport",
        "rating": "-3",
        "keywords": [
            [
                "robotics"
            ],
            [
                "Bio-Inspired"
            ]
        ],
        "abstract": "While its biological significance is well-documented, its application in soft robotics, particularly for the transport of fragile and irregularly shaped objects, remains underexplored. This study presents a modular soft robotic actuator system that addresses these challenges through a scalable, adaptable, and repairable framework, offering a cost-effective solution for versatile applications. The system integrates optimized donut-shaped actuation modules and utilizes real-time pressure feedback for synchronized operation, ensuring efficient object grasping and transport without relying on intricate sensing or control algorithms. Experimental results validate the system`s ability to accommodate objects with varying geometries and material characteristics, balancing robustness with flexibility. This work advances the principles of peristaltic actuation, establishing a pathway for safely and reliably manipulating delicate materials in a range of scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "comment": "7 pages, 6 figures"
    },
    {
        "paper id": "2412.05004",
        "abstract url": "https://arxiv.org/abs/2412.05004",
        "title": "Prompt Transfer for Dual-Aspect Cross Domain Cognitive Diagnosis",
        "rating": "-3.5",
        "keywords": [
            [
                "Diagnosis"
            ],
            [
                "recommendation"
            ],
            [
                "cs.LG",
                "cs.CY"
            ]
        ],
        "abstract": "Cognitive Diagnosis (CD) aims to evaluate students' cognitive states based on their interaction data, enabling downstream applications such as exercise recommendation and personalized learning guidance. However, existing methods often struggle with accuracy drops in cross-domain cognitive diagnosis (CDCD), a practical yet challenging task. While some efforts have explored exercise-aspect CDCD, such as crosssubject scenarios, they fail to address the broader dual-aspect nature of CDCD, encompassing both student- and exerciseaspect variations. This diversity creates significant challenges in developing a scenario-agnostic framework. To address these gaps, we propose PromptCD, a simple yet effective framework that leverages soft prompt transfer for cognitive diagnosis. PromptCD is designed to adapt seamlessly across diverse CDCD scenarios, introducing PromptCD-S for student-aspect CDCD and PromptCD-E for exercise-aspect CDCD. Extensive experiments on real-world datasets demonstrate the robustness and effectiveness of PromptCD, consistently achieving superior performance across various CDCD scenarios. Our work offers a unified and generalizable approach to CDCD, advancing both theoretical and practical understanding in this critical domain. The implementation of our framework is publicly available at https://github.com/Publisher-PromptCD/PromptCD.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05153",
        "abstract url": "https://arxiv.org/abs/2412.05153",
        "title": "A text-to-tabular approach to generate synthetic patient data using LLMs",
        "rating": "-3.5",
        "keywords": [
            [
                "medical",
                "healthcare",
                "clinical"
            ],
            [
                "tabular"
            ],
            [
                "cs.LG"
            ]
        ],
        "abstract": "Access to large-scale high-quality healthcare databases is key to accelerate medical research and make insightful discoveries about diseases. However, access to such data is often limited by patient privacy concerns, data sharing restrictions and high costs. To overcome these limitations, synthetic patient data has emerged as an alternative. However, synthetic data generation (SDG) methods typically rely on machine learning (ML) models trained on original data, leading back to the data scarcity problem. We propose an approach to generate synthetic tabular patient data that does not require access to the original data, but only a description of the desired database. We leverage prior medical knowledge and in-context learning capabilities of large language models (LLMs) to generate realistic patient data, even in a low-resource setting. We quantitatively evaluate our approach against state-of-the-art SDG models, using fidelity, privacy, and utility metrics. Our results show that while LLMs may not match the performance of state-of-the-art models trained on the original data, they effectively generate realistic patient data with well-preserved clinical correlations. An ablation study highlights key elements of our prompt contributing to high-quality synthetic patient data generation. This approach, which is easy to use and does not require original data or advanced ML skills, is particularly valuable for quickly generating custom-designed patient data, supporting project implementation and providing educational resources.",
        "subjects": [
            "cs.LG"
        ],
        "comment": "12 pages, 2 figures, 3 tables"
    },
    {
        "paper id": "2412.05208",
        "abstract url": "https://arxiv.org/abs/2412.05208",
        "title": "A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges",
        "rating": "-3.5",
        "keywords": [
            [
                "healthcare"
            ],
            [
                "SQL"
            ],
            [
                "cs.AI"
            ]
        ],
        "abstract": "Text-to-SQL systems facilitate smooth interaction with databases by translating natural language queries into Structured Query Language (SQL), bridging the gap between non-technical users and complex database management systems. This survey provides a comprehensive overview of the evolution of AI-driven text-to-SQL systems, highlighting their foundational components, advancements in large language model (LLM) architectures, and the critical role of datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examine the applications of text-to-SQL in domains like healthcare, education, and finance, emphasizing their transformative potential for improving data accessibility. Additionally, we analyze persistent challenges, including domain generalization, query optimization, support for multi-turn conversational interactions, and the limited availability of datasets tailored for NoSQL databases and dynamic real-world scenarios. To address these challenges, we outline future research directions, such as extending text-to-SQL capabilities to support NoSQL databases, designing datasets for dynamic multi-turn interactions, and optimizing systems for real-world scalability and robustness. By surveying current advancements and identifying key gaps, this paper aims to guide the next generation of research and applications in LLM-based text-to-SQL systems.",
        "subjects": [
            "cs.AI",
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04879",
        "abstract url": "https://arxiv.org/abs/2412.04879",
        "title": "Automatic Tissue Differentiation in Parotidectomy using Hyperspectral Imaging",
        "rating": "-4",
        "keywords": [
            [
                "3D"
            ],
            [
                "surgery",
                "clinical"
            ],
            [
                "Hyperspectral Imaging"
            ],
            [
                "cs.CV",
                "eess.IV"
            ]
        ],
        "abstract": "In head and neck surgery, continuous intraoperative tissue differentiation is of great importance to avoid injury to sensitive structures such as nerves and vessels. Hyperspectral imaging (HSI) with neural network analysis could support the surgeon in tissue differentiation. A 3D Convolutional Neural Network with hyperspectral data in the range of $400-1000$ nm is used in this work. The acquisition system consisted of two multispectral snapshot cameras creating a stereo-HSI-system. For the analysis, 27 images with annotations of glandular tissue, nerve, muscle, skin and vein in 18 patients undergoing parotidectomy are included. Three patients are removed for evaluation following the leave-one-subject-out principle. The remaining images are used for training, with the data randomly divided into a training group and a validation group. In the validation, an overall accuracy of $98.7\\%$ is achieved, indicating robust training. In the evaluation on the excluded patients, an overall accuracy of $83.4\\%$ has been achieved showing good detection and identification abilities. The results clearly show that it is possible to achieve robust intraoperative tissue differentiation using hyperspectral imaging. Especially the high sensitivity in parotid or nerve tissue is of clinical importance. It is interesting to note that vein was often confused with muscle. This requires further analysis and shows that a very good and comprehensive data basis is essential. This is a major challenge, especially in surgery.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "physics.med-ph"
        ],
        "comment": "Accepted and presented at 58th Annual Conference of the German Society for Biomedical Engineering in press at Current Directions in Biomedical Engineering"
    },
    {
        "paper id": "2412.04798",
        "abstract url": "https://arxiv.org/abs/2412.04798",
        "title": "A Multi-physics Model of Flow from Coronary Angiography: Insights into Microvascular Function",
        "rating": "-5",
        "keywords": [
            [
                "3D"
            ],
            [
                "diagnosing",
                "Disease",
                "clinical"
            ],
            [
                "physics"
            ]
        ],
        "abstract": "Coronary Artery Disease (CAD) and Coronary Microvascular Disease (CMD) can lead to insufficient blood flow to the myocardium, affecting millions of people globally. Coronary angiography, one of the most commonly used imaging modalities, offers valuable information that assists in diagnosing these diseases. However, these benefits are not fully understood or utilized in current clinical practice. In this study, a 3D-0D coupled multi-physics computational fluid dynamics (CFD) model was developed and calibrated to simulate and better understand the process of contrast injection and washout during clinical angiography. A contrast intensity profile (CIP) was introduced to capture the dynamics of coronary angiography data. Additionally, a sensitivity study was conducted to assess the influence of various coronary artery model parameters on CIP. The results demonstrate that the calibrated 3D-0D coupled multi-physics models are physiologically meaningful and produce accurate hemodynamic results. The sensitivity study further reveals that resistance has a greater impact on CIP than capacitance, with higher resistance amplifying this effect.",
        "subjects": [
            "cs.CE"
        ],
        "comment": "21 pages, 12 figures"
    },
    {
        "paper id": "2412.04908",
        "abstract url": "https://arxiv.org/abs/2412.04908",
        "title": "PERCY: A Multimodal Dataset and Conversational System for Personalized and Emotionally Aware Human-Robot Interaction",
        "rating": "-5",
        "keywords": [
            [
                "Robot"
            ],
            [
                "facial"
            ],
            [
                "music"
            ]
        ],
        "abstract": "The integration of conversational agents into our daily lives has become increasingly common, yet many of these agents cannot engage in deep interactions with humans. Despite this, there is a noticeable shortage of datasets that capture multimodal information from human-robot interaction dialogues. To address this gap, we have developed a Personal Emotional Robotic Conversational sYstem (PERCY) and recorded a novel multimodal dataset that encompasses rich embodied interaction data. The process involved asking participants to complete a questionnaire and gathering their profiles on ten topics, such as hobbies and favourite music. Subsequently, we initiated conversations between the robot and the participants, leveraging GPT-4 to generate contextually appropriate responses based on the participant's profile and emotional state, as determined by facial expression recognition and sentiment analysis. Automatic and user evaluations were conducted to assess the overall quality of the collected data. The results of both evaluations indicated a high level of naturalness, engagement, fluency, consistency, and relevance in the conversation, as well as the robot's ability to provide empathetic responses. It is worth noting that the dataset is derived from genuine interactions with the robot, involving participants who provided personal information and conveyed actual emotions.",
        "subjects": [
            "cs.HC",
            "cs.ET",
            "cs.RO"
        ],
        "comment": "9 pages, 5 Figures, Rejected from International Conference of Human Robot Interaction 2025, Melbourne, Australia"
    },
    {
        "paper id": "2412.04795",
        "abstract url": "https://arxiv.org/abs/2412.04795",
        "title": "Ternary near-extremal self-dual codes of lengths $36$, $48$ and $60$",
        "rating": "-10",
        "keywords": [],
        "abstract": "For lengths $36$, $48$ and $60$, we construct new ternary near-extremal self-dual codes with weight enumerators for which no ternary near-extremal self-dual codes were previously known to exist.",
        "subjects": [
            "cs.IT",
            "math.CO"
        ],
        "comment": "13 pages"
    },
    {
        "paper id": "2412.04805",
        "abstract url": "https://arxiv.org/abs/2412.04805",
        "title": "A Unified Approach for Multi-granularity Search over Spatial Datasets",
        "rating": "-10",
        "keywords": [],
        "abstract": "There has been increased interest in data search as a means to find relevant datasets or data points in data lakes and repositories. Although approaches have been proposed to support spatial dataset search and data point search, they consider the two types of searches independently. To enable search operations ranging from the coarse-grained dataset level to the fine-grained data point level, we provide an integrated one that supports diverse query types and distance metrics. In this paper, we focus on designing a multi-granularity spatial data search system, called Spadas, that supports both dataset and data point search operations. To address the challenges of the high cost of indexing and susceptibility to outliers, we propose a unified index that can drastically improve query efficiency in various scenarios by organizing data reasonably and removing outliers in datasets. Moreover, to accelerate all data search operations, we propose a set of pruning mechanisms based on the unified index, including fast bound estimation, approximation technique with error bound, and pruning in batch techniques, to effectively filter out non-relevant datasets and points. Finally, we report the results of a detailed experimental evaluation using six spatial data repositories, achieving orders of magnitude faster than the state-of-the-art algorithms and demonstrating the effectiveness by case study. An online spatial data search system of Spadas is also implemented and made accessible to users.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04822",
        "abstract url": "https://arxiv.org/abs/2412.04822",
        "title": "Space-Time-Modulated Wideband Radiation-Type Programmable Metasurface for Low Sidelobe Beamforming",
        "rating": "-10",
        "keywords": [],
        "abstract": "Programmable metasurfaces promise a great potential to construct low-cost phased array systems due to the capability of elaborate modulation over electromagnetic (EM) waves. However, they are in either reflective or transmissive mode, and usually possess a relatively high profile as a result of the external feed source. Besides, it is difficult to conduct multibit phase shift in metasurfaces, when comparing with conventional phased arrays. Here, we propose a strategy of space-time modulated wideband radiation-type programmable metasurface for low side-lobe beamforming. The wideband programmable metasurface avoids the space-feed external source required by its traditional counterpart, thus achieving a significant reduction of profile through integration of a highefficiency microwave-fed excitation network and metasurface. Furthermore, through introducing space-time-modulated strategy, the high-accuracy amplitude-phase weight algorithm can also be synchronously carried out on the first harmonic component for low side-lobe beam-scanning. Most importantly, adaptive beamforming and generation of interference null can further be created after analyzing the harmonic component characteristics of received signals.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04841",
        "abstract url": "https://arxiv.org/abs/2412.04841",
        "title": "Asynchronous Random Access in Massive MIMO Systems Facilitated by the Delay-Angle Domain",
        "rating": "-10",
        "keywords": [],
        "abstract": "The problem of uplink transmissions in massive connectivity is commonly dealt with using schemes for grant-free random access. When a large number of devices transmit almost synchronously, the receiver may not be able to resolve the collision. This could be addressed by assigning dedicated pilots to each user, leading to a contention-free random access (CFRA), which suffers from low scalability and efficiency. This paper explores contention-based random access (CBRA) schemes for asynchronous access in massive multiple-input multiple-output (MIMO) systems. The symmetry across the accessing users with the same pilots is broken by leveraging the delay information inherent to asynchronous systems and the angle information from massive MIMO to enhance activity detection (AD) and channel estimation (CE). The problem is formulated as a sparse recovery in the delay-angle domain. The challenge is that the recovery signal exhibits both row-sparse and cluster-sparse structure, with unknown cluster sizes and locations. We address this by a cluster-extended sparse Bayesian learning (CE-SBL) algorithm that introduces a new weighted prior to capture the signal structure and extends the expectation maximization (EM) algorithm for hyperparameter estimation. Simulation results demonstrate the superiority of the proposed method in joint AD and CE.",
        "subjects": [
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04848",
        "abstract url": "https://arxiv.org/abs/2412.04848",
        "title": "Quadratic Modelings of Syndrome Decoding",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents enhanced reductions of the bounded-weight and exact-weight Syndrome Decoding Problem (SDP) to a system of quadratic equations. Over $\\mathbb{F}_2$, we improve on a previous work and study the degree of regularity of the modeling of the exact weight SDP. Additionally, we introduce a novel technique that transforms SDP instances over $\\mathbb{F}_q$ into systems of polynomial equations and thoroughly investigate the dimension of their varieties. Experimental results are provided to evaluate the complexity of solving SDP instances using our models through Gr\u00f6bner bases techniques.",
        "subjects": [
            "cs.CR",
            "math.OC"
        ],
        "comment": "are welcome"
    },
    {
        "paper id": "2412.04850",
        "abstract url": "https://arxiv.org/abs/2412.04850",
        "title": "The Impact of Artificial Intelligence on Art Research: An Analysis of Academic Productivity and Multidisciplinary Integration",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study investigates the transformative impact of artificial intelligence on art research by analysing data from 749 art research projects and 555,982 non art research projects, as well as 23,999 journal articles. We utilized the SciBERT model for text analysis on research funding proposals and the econometric model to evaluate AI impact on the academic productivity and impact. Our findings reveal that AI has significantly reshaped the role of art across various disciplines. The integration of AI has led to a notable expansion in keyword networks, highlighting advancements in visual art creation, data driven methodologies, and interactive educational tools. AI has also facilitated the integration of art knowledge into nearly all research disciplines, contrasting with the traditionally confined distribution of art knowledge. Despite the substantial increase in publication impact and citation counts facilitated by AI, it has not markedly improved the likelihood of publishing in high-prestige journals. These insights illustrate the complex nature of AI's impact enhancing research impact while presenting challenges in publication efficiency and multidisciplinary integration. The study offers a nuanced understanding of AI's role in art research and suggests directions for addressing the ongoing challenges of integrating art and AI across disciplines.",
        "subjects": [
            "cs.DL"
        ],
        "comment": "Best Paper Award, 2024 International PhD Forum on Art Research, AI Era"
    },
    {
        "paper id": "2412.04853",
        "abstract url": "https://arxiv.org/abs/2412.04853",
        "title": "Budgeted Spatial Data Acquisition: When Coverage and Connectivity Matter",
        "rating": "-10",
        "keywords": [],
        "abstract": "Data is undoubtedly becoming a commodity like oil, land, and labor in the 21st century. Although there have been many successful marketplaces for data trading, the existing data marketplaces lack consideration of the case where buyers want to acquire a collection of datasets (instead of one), and the overall spatial coverage and connectivity matter. In this paper, we take the first attempt to formulate this problem as Budgeted Maximum Coverage with Connectivity Constraint (BMCC), which aims to acquire a dataset collection with the maximum spatial coverage under a limited budget while maintaining spatial connectivity. To solve the problem, we propose two approximate algorithms with detailed theoretical guarantees and time complexity analysis, followed by two acceleration strategies to further improve the efficiency of the algorithm. Experiments are conducted on five real-world spatial dataset collections to verify the efficiency and effectiveness of our algorithms.",
        "subjects": [
            "cs.DB"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04856",
        "abstract url": "https://arxiv.org/abs/2412.04856",
        "title": "Can Large Language Models Effectively Process and Execute Financial Trading Instructions?",
        "rating": "-10",
        "keywords": [],
        "abstract": "The development of Large Language Models (LLMs) has created transformative opportunities for the financial industry, especially in the area of financial trading. However, how to integrate LLMs with trading systems has become a challenge. To address this problem, we propose an intelligent trade order recognition pipeline that enables the conversion of trade orders into a standard format in trade execution. The system improves the ability of human traders to interact with trading platforms while addressing the problem of misinformation acquisition in trade execution. In addition, we have created a trade order dataset of 500 pieces of data to simulate real-world trading scenarios. Moreover, we designed several metrics to provide a comprehensive assessment of dataset reliability and the generative power of big models in finance by experimenting with five state-of-the-art LLMs on our dataset. The results indicate that while LLMs demonstrate high generation rates (87.50% to 98.33%) and perfect follow-up rates, they face significant challenges in accuracy (5% to 10%) and completeness, with high missing rates (14.29% to 67.29%). In addition, LLMs tend to over-interrogate, suggesting that large models tend to collect more information, carrying certain challenges for information security.",
        "subjects": [
            "cs.CE"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04866",
        "abstract url": "https://arxiv.org/abs/2412.04866",
        "title": "Near-field Communications with Extremely Large-Scale Uniform Arc Arrays: Channel Modelling and Performance Analysis",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this letter, we propose a new conformal array architecture, called extremely large-scale uniform arc array (XL-UAA), to improve near-field communication performance. Specifically,under the non-uniform spherical wavefront channel model, we establish mathematical modeling and performance analysis for XL-UAAs. It is shown that XL-UAAs have larger direction-dependent Rayleigh distance and uniform power distance than the conventional XL uniform linear arrays (XL-ULAs). Moreover, a closed-form expression for the signal-to-noise ratio (SNR) is obtained, which depends on collective properties of XL-UAAs, such as the distance between the user and the array center,as well as the arc radius. In addition, we show that the asymptotic SNR of XL-UAAs with the number of antennas depends on the projection distance of the user to the middle of the arc array. Finally, numerical results verify that XL-UAAs achieve a higher SNR than XL-ULAs, especially at larger user incident angles.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "5 pages, 3 figures"
    },
    {
        "paper id": "2412.04874",
        "abstract url": "https://arxiv.org/abs/2412.04874",
        "title": "Self-Organizing Complex Networks with AI-Driven Adaptive Nodes for Optimized Connectivity and Energy Efficiency",
        "rating": "-10",
        "keywords": [],
        "abstract": "High connectivity and robustness are critical requirements in distributed networks, as they ensure resilience, efficient communication, and adaptability in dynamic environments. Additionally, optimizing energy consumption is also paramount for ensuring sustainability of networks composed of energy-constrained devices and prolonging their operational lifespan. In this study, we introduce an Artificial Intelligence (AI)-enhanced self-organizing network model, where each adaptive node autonomously adjusts its transmission power to optimize network connectivity and redundancy while lowering energy consumption. Building on our previous Hamiltonian-based methodology, which is designed to lead networks toward globally optimized states of complete connectivity and minimal energy usage, this research integrates a Multi-Layer Perceptron (MLP)-based decision-making model at each node. By leveraging a dataset from the Hamiltonian approach, each node independently learns and adapts its transmission power in response to local conditions, resulting in emergent global behaviors marked by high connectivity and resilience against structural disruptions. This distributed, MLP-driven adaptability allows nodes to make context-aware power adjustments autonomously, enabling the network to maintain its optimized state over time. Simulation results show that the proposed AI-driven adaptive nodes collectively achieve stable complete connectivity, significant robustness, and optimized energy usage under various conditions, including static and mobile network scenarios. This work contributes to the growing field of self-organizing networks by illustrating the potential of AI to enhance complex network design, supporting the development of scalable, resilient, and energy-efficient distributed systems across diverse applications.",
        "subjects": [
            "physics.comp-ph",
            "cs.NI"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04877",
        "abstract url": "https://arxiv.org/abs/2412.04877",
        "title": "Fluid Antenna Grouping-Based Index Modulation: Transceiver Design for MIMO Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The fluid antenna (FA)-enabled multiple-input multiple-output (MIMO) system based on index modulation (IM), referred to as FA-IM, significantly enhances spectral efficiency (SE) compared to the conventional FA-assisted MIMO system. This paper proposes an innovative FA grouping-based IM (FAG-IM) system to improve performance in mitigating the high spatial correlation between multiple activated ports. A block grouping scheme is employed based on the spatial correlation model and the distribution structure of the ports. Then, a closed-form expression for the average bit error probability (ABEP) upper bound of the FAG-IM system is derived. In order to reduce the receiver complexity of the proposed system, the message passing mechanism is first incorporated into the FAG-IM system. Subsequently, within the approximate message passing (AMP) framework, an efficient structured AMP (S-AMP) detector is devised by leveraging the structural characteristics of the transmission signal vector. Simulation results confirm that the proposed FAG-IM system significantly outperforms the existing FA-IM system in the presence of spatial correlation. The derived ABEP curve aligns well with the numerical results, providing an efficient theoretical tool for evaluating the system performance. Additionally, simulation results demonstrate that the proposed low-complexity S-AMP detector not only reduces the time complexity to a linear scale but also substantially improves bit error rate (BER) performance compared to the minimum mean square error (MMSE) detector, thus facilitating the practical implementation of the FAG-IM system.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "Submitted to an IEEE journal"
    },
    {
        "paper id": "2412.04889",
        "abstract url": "https://arxiv.org/abs/2412.04889",
        "title": "Super-Polynomial Growth of the Generalized Persistence Diagram",
        "rating": "-10",
        "keywords": [],
        "abstract": "The Generalized Persistence Diagram (GPD) for multi-parameter persistence naturally extends the classical notion of persistence diagram for one-parameter persistence. However, unlike its classical counterpart, computing the GPD remains a significant challenge. The main hurdle is that, while the GPD is defined as the M\u00f6bius inversion of the Generalized Rank Invariant (GRI), computing the GRI is intractable due to the formidable size of its domain, i.e., the set of all connected and convex subsets in a finite grid in $\\mathbb{R}^d$ with $d \\geq 2$. This computational intractability suggests seeking alternative approaches to computing the GPD. In order to study the complexity associated to computing the GPD, it is useful to consider its classical one-parameter counterpart, where for a filtration of a simplicial complex with $n$ simplices, its persistence diagram contains at most $n$ points. This observation leads to the question: 'Given a $d$-parameter simplicial filtration, could the cardinality of its GPD (specifically, the support of the GPD) also be bounded by a polynomial in the number of simplices in the filtration?' This is the case for $d=1$, where we compute the persistence diagram directly at the simplicial filtration level. If this were also the case for $d\\geq2$, it might be possible to compute the GPD directly and much more efficiently without relying on the GRI. We show that the answer to the question above is negative, demonstrating the inherent difficulty of computing the GPD. More specifically, we construct a sequence of $d$-parameter simplicial filtrations where the cardinalities of their GPDs are not bounded by any polynomial in the the number of simplices. Furthermore, we show that several commonly used methods for constructing multi-parameter filtrations can give rise to such \"wild\" filtrations.",
        "subjects": [
            "math.AT",
            "cs.CG"
        ],
        "comment": "23 pages, 9 figures"
    },
    {
        "paper id": "2412.04899",
        "abstract url": "https://arxiv.org/abs/2412.04899",
        "title": "A free lunch: manifolds of positive reach can be smoothed without decreasing the reach",
        "rating": "-10",
        "keywords": [],
        "abstract": "Assumptions on the reach are crucial for ensuring the correctness of many geometric and topological algorithms, including triangulation, manifold reconstruction and learning, homotopy reconstruction, and methods for estimating curvature or reach. However, these assumptions are often coupled with the requirement that the manifold be smooth, typically at least C^2 .In this paper, we prove that any manifold with positive reach can be approximated arbitrarily well by a C^$\\infty$ manifold without significantly reducing the reach, by employing techniques from differential topology -partitions of unity and smoothing using convolution kernels. This result implies that nearly all theorems established for C^2 manifolds with a certain reach naturally extend to manifolds with the same reach, even if they are not C^2 , for free!",
        "subjects": [
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04902",
        "abstract url": "https://arxiv.org/abs/2412.04902",
        "title": "On Process Awareness in Detecting Multi-stage Cyberattacks in Smart Grids",
        "rating": "-10",
        "keywords": [],
        "abstract": "This study delves into the role of process awareness in enhancing intrusion detection within Smart Grids, considering the increasing fusion of ICT in power systems and the associated emerging threats. The research harnesses a co-simulation environment, encapsulating IT, OT, and ET layers, to model multi-stage cyberattacks and evaluate machine learning-based IDS strategies. The key observation is that process-aware IDS demonstrate superior detection capabilities, especially in scenarios closely tied to operational processes, as opposed to IT-only IDS. This improvement is notable in distinguishing complex cyber threats from regular IT activities. The findings underscore the significance of further developing sophisticated IDS benchmarks and digital twin datasets in Smart Grid environments, paving the way for more resilient cybersecurity infrastructures.",
        "subjects": [
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04913",
        "abstract url": "https://arxiv.org/abs/2412.04913",
        "title": "Bridging Culture and Finance: A Multimodal Analysis of Memecoins in the Web3 Ecosystem",
        "rating": "-10",
        "keywords": [],
        "abstract": "Memecoins, driven by social media engagement and cultural narratives, have rapidly grown within the Web3 ecosystem. Unlike traditional cryptocurrencies, they are shaped by humor, memes, and community sentiment. This paper introduces the Coin-Meme dataset, an open-source collection of visual, textual, community, and financial data from the Pump.fun platform on the Solana blockchain. We also propose a multimodal framework to analyze memecoins, uncovering patterns in cultural themes, community interaction, and financial behavior. Through clustering, sentiment analysis, and word cloud visualizations, we identify distinct thematic groups centered on humor, animals, and political satire. Additionally, we provide financial insights by analyzing metrics such as Market Entry Time and Market Capitalization, offering a comprehensive view of memecoins as both cultural artifacts and financial instruments within Web3. The Coin-Meme dataset is publicly available at https://github.com/hwlongCUHK/Coin-Meme.git.",
        "subjects": [
            "cs.HC"
        ],
        "comment": "4 pages, 2 figures, conference"
    },
    {
        "paper id": "2412.04928",
        "abstract url": "https://arxiv.org/abs/2412.04928",
        "title": "Hahn series and Mahler equations: Algorithmic aspects",
        "rating": "-10",
        "keywords": [],
        "abstract": "Many articles have recently been devoted to Mahler equations, partly because of their links with other branches of mathematics such as automata theory. Hahn series (a generalization of the Puiseux series allowing arbitrary exponents of the indeterminate as long as the set that supports them is well-ordered) play a central role in the theory of Mahler equations. In this paper, we address the following fundamental question: is there an algorithm to calculate the Hahn series solutions of a given linear Mahler equation? What makes this question interesting is the fact that the Hahn series appearing in this context can have complicated supports with infinitely many accumulation points. Our (positive) answer to the above question involves among other things the construction of a computable well-ordered receptacle for the supports of the potential Hahn series solutions.",
        "subjects": [
            "cs.SC",
            "math.NT"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04943",
        "abstract url": "https://arxiv.org/abs/2412.04943",
        "title": "A Subquadratic Time Approximation Algorithm for Individually Fair k-Center",
        "rating": "-10",
        "keywords": [],
        "abstract": "We study the $k$-center problem in the context of individual fairness. Let $P$ be a set of $n$ points in a metric space and $r_x$ be the distance between $x \\in P$ and its $\\lceil n/k \\rceil$-th nearest neighbor. The problem asks to optimize the $k$-center objective under the constraint that, for every point $x$, there is a center within distance $r_x$. We give bicriteria $(\u03b2,\u03b3)$-approximation algorithms that compute clusterings such that every point $x \\in P$ has a center within distance $\u03b2r_x$ and the clustering cost is at most $\u03b3$ times the optimal cost. Our main contributions are a deterministic $O(n^2+ kn \\log n)$ time $(2,2)$-approximation algorithm and a randomized $O(nk\\log(n/\u03b4)+k^2/\\varepsilon)$ time $(10,2+\\varepsilon)$-approximation algorithm, where $\u03b4$ denotes the failure probability. For the latter, we develop a randomized sampling procedure to compute constant factor approximations for the values $r_x$ for all $x\\in P$ in subquadratic time; we believe this procedure to be of independent interest within the context of individual fairness.",
        "subjects": [
            "cs.DS",
            "cs.CG"
        ],
        "comment": null
    },
    {
        "paper id": "2412.04965",
        "abstract url": "https://arxiv.org/abs/2412.04965",
        "title": "Succinct Data Structures for Segments",
        "rating": "-10",
        "keywords": [],
        "abstract": "We consider succinct data structures for representing a set of $n$ horizontal line segments in the plane given in rank space to support \\emph{segment access}, \\emph{segment selection}, and \\emph{segment rank} queries. A segment access query finds the segment $(x_1, x_2, y)$ given its $y$-coordinate ($y$-coordinates of the segments are distinct), a segment selection query finds the $j$th smallest segment (the segment with the $j$th smallest $y$-coordinate) among the segments crossing the vertical line for a given $x$-coordinate, and a segment rank query finds the number of segments crossing the vertical line through $x$-coordinate $i$ with $y$-coordinate at most $y$, for a given $x$ and $y$. This problem is a central component in compressed data structures for persistent strings supporting random access. Our main result is data structure using $2n\\lg{n} + O(n\\lg{n}/\\lg{\\lg{n}})$ bits of space and $O(\\lg{n}/\\lg{\\lg{n}})$ query time for all operations. We show that this space bound is optimal up to lower-order terms. We will also show that the query time for segment rank is optimal. The query time for segment selection is also optimal by a previous bound. To obtain our results, we present a novel segment wavelet tree data structure of independent interest. This structure is inspired by and extends the classic wavelet tree for sequences. This leads to a simple, succinct solution with $O(\\log n)$ query times. We then extend this solution to obtain optimal query time. Our space lower bound follows from a simple counting argument, and our lower bound for segment rank is obtained by a reduction from 2-dimensional counting.",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05006",
        "abstract url": "https://arxiv.org/abs/2412.05006",
        "title": "Analog-Only Beamforming for Near-Field Multiuser MIMO Communications",
        "rating": "-10",
        "keywords": [],
        "abstract": "For the existing near-field multiuser communications based on hybrid beamforming (HBF) architectures, high-quality effective channel estimation is required to obtain the channel state information (CSI) for the design of the digital beamformer. To simplify the system reconfiguration and eliminate the pilot overhead required by the effective channel estimation, we considered an analog-only beamforming (AoBF) architecture in this study. The AoBF is designed with the aim of maximizing the sum rate, which is then transformed into a problem, maximizing the power transmitted to the target user equipment (UE) and meanwhile minimizing the power leaked to the other UEs. To solve this problem, we used beam focusing and beam nulling and proposed two AoBF schemes based on the majorization-minimization (MM) algorithm. First, the AoBF scheme based on perfect CSI is proposed, with the focus on the beamforming performance and regardless of the CSI acquisition. Then, the AoBF scheme based on imperfect CSI is proposed, where the low-dimensional imperfect CSI is obtained by beam sweeping based on a near-field codebook. Simulation results demonstrate that the two AoBF schemes can approach the sum rate of the HBF schemes but outperform HBF schemes in terms of energy efficiency (EE).",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05017",
        "abstract url": "https://arxiv.org/abs/2412.05017",
        "title": "Reduction from the partition problem: Dynamic lot sizing problem with polynomial complexity",
        "rating": "-10",
        "keywords": [],
        "abstract": "In this note, we reduce an instance of the partition problem to a dynamic lot sizing problem in polynomial time, and show that solving the latter problem solves the former problem. We further show that the instance of the partition problem can be solved using polynomial number of addition, multiplication and sort operations in input data using the reduction.",
        "subjects": [
            "cs.CC",
            "math.OC"
        ],
        "comment": "9 pages"
    },
    {
        "paper id": "2412.05075",
        "abstract url": "https://arxiv.org/abs/2412.05075",
        "title": "Towards the interoperability of low-code platforms",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the promise of accelerating software development, low-code platforms (LCPs) are becoming popular across various industries. Nevertheless, there are still barriers hindering their adoption. Among them, vendor lock-in is a major concern, especially considering the lack of interoperability between these platforms. Typically, after modeling an application in one LCP, migrating to another requires starting from scratch remodeling everything (the data model, the graphical user interface, workflows, etc.), in the new platform. To overcome this situation, this work proposes an approach to improve the interoperability of LCPs by (semi)automatically migrating models specified in one platform to another one. The concrete migration path depends on the capabilities of the source and target tools. We first analyze popular LCPs, characterize their import and export alternatives and define transformations between those data formats when available. This is then complemented with an LLM-based solution, where image recognition features of large language models are employed to migrate models based on a simple image export of the model at hand. The full pipelines are implemented on top of the BESSER modeling framework that acts as a pivot representation between the tools.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Submitted to International Conference on Advanced Information Systems Engineering (CAiSE25)"
    },
    {
        "paper id": "2412.05078",
        "abstract url": "https://arxiv.org/abs/2412.05078",
        "title": "An Experimental Framework for Implementing Decentralized Autonomous Database Systems in Rust",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents an experimental framework for implementing Decentralized Autonomous Database Systems (DADBS) using the Rust programming language. As traditional centralized databases face challenges in scalability, security, and autonomy, DADBS emerge as a promising solution, using blockchain principles to create distributed, self-governing database systems. Our framework explores the practical aspects of building a DADBS, focusing on Rust's unique features that improves system reliability and performance. We evaluated our DADBS implementation across several key performance metrics: throughput, latency(read), latency(write), scalability, CPU utilization, Memory Usage and Network I/O, The average results obtained over a 24-hour period of continuous operation were 3,000 transactions/second, 75 ms, 250 ms, 55%, 2.5 GB, 100MB/s. The security analysis depicts that even with an increase in the percentage of malicious nodes, DADBS still maintains high throughput and consistency. The paper discusses key design decisions, highlighting how Rust's ownership model and concurrency features address common challenges in distributed systems. We also examine the current limitations of our approach and potential areas for future research. By providing this comprehensive overview of a Rust-based DADBS implementation, we aim to contribute to the growing body of knowledge on decentralized database architectures and their practical realization.",
        "subjects": [
            "cs.DB",
            "cs.DC"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05091",
        "abstract url": "https://arxiv.org/abs/2412.05091",
        "title": "Designing a Secure, Scalable, and Cost-Effective Cloud Storage Solution: A Novel Approach to Data Management using NextCloud, TrueNAS, and QEMU/KVM",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper presents a novel approach to cloud storage challenges by integrating NextCloud, TrueNAS, and QEMU/KVM. Our research demonstrates how this combination creates a robust, flexible, and economical cloud storage system suitable for various applications. We detail the architecture, highlighting TrueNAS's ZFS-based storage, QEMU/KVM's virtualization, and NextCloud's user interface. Extensive testing showssuperior data integrity and protection compared to traditional solutions. Performance benchmarks reveal high read/write speeds(up to 1.22 GB/s for sequential reads and 620 MB/s for writes) and also efficient small file handling. We demonstrate the solution's scalability under increasing workloads. Security analysis showcases effective jail isolation techniques in TrueNAS. Cost analysis indicates potential 50% reduction in total ownership cost over five years compared to commercial alternatives. This research contributes a practical, high-performance, cost-effective alternative to proprietary solutions, paving new ways for organizations to implement secure, scalable cloud storage while maintaining data control. Future work will focus on improving automated scaling and integration with emerging technologies like containerization and serverless computing.",
        "subjects": [
            "cs.DB",
            "cs.CR"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05128",
        "abstract url": "https://arxiv.org/abs/2412.05128",
        "title": "How permanent are metadata for research data? Understanding changes in DataCite DOI metadata",
        "rating": "-10",
        "keywords": [],
        "abstract": "With the move towards open research information, the DOI registration agency DataCite is increasingly used as a source for metadata describing research data, for example to perform scientometric analyses. However, there is a lack of research on how DOI metadata describing research data are created and maintained. This paper adresses this gap by using DataCite metadata provenance information to analyze the overall prevalence and patterns of change to DataCite DOI metadata records. The results show that change of DataCite DOI metadata records is common, but it tends to be incremental and not extensive. DataCite DOI metadata records offer reliable descriptions of datasets and are stable enough to be used in scientometric research. The findings mirror insights from previous studies of metadata change in other contexts, suggesting that there are similarities in metadata practices between research data repositories and more traditional cataloging environments. However, the observed changes don't seem to fully align with idealized conceptualizations of metadata creation and maintenance for research data. In particular, the data does not show that metadata records are maintained continuously, and metadata change has a limited effect on metadata completeness.",
        "subjects": [
            "cs.DL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05136",
        "abstract url": "https://arxiv.org/abs/2412.05136",
        "title": "Recursive Projection-Free Identification with Binary-Valued Observations",
        "rating": "-10",
        "keywords": [],
        "abstract": "This paper is concerned with parameter identification problem for finite impulse response (FIR) systems with binary-valued observations under low computational complexity. Most of the existing algorithms under binary-valued observations rely on projection operators, which leads to a high computational complexity of much higher than O(n^2). In response, this paper introduces a recursive projection-free identification algorithm that incorporates a specialized cut-off coefficient to fully utilize prior information, thereby eliminating the need for projection operators. The algorithm is proved to be mean square and almost surely convergent. Furthermore, to better leverage prior information, an adaptive accelerated coefficient is introduced, resulting in a mean square convergence rate of O(1/k) , which matches the convergence rate with accurate observations. Inspired by the structure of the Cramer-Rao lower bound, the algorithm can be extended to an information-matrix projection-free algorithm by designing adaptive weight coefficients. This extension is proved to be asymptotically efficient for first-order FIR systems, with simulations indicating similar results for high order FIR systems. Finally, numerical examples are provided to demonstrate the main results.",
        "subjects": [
            "eess.SY"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05157",
        "abstract url": "https://arxiv.org/abs/2412.05157",
        "title": "Covering points by hyperplanes and related problems",
        "rating": "-10",
        "keywords": [],
        "abstract": "For a set $P$ of $n$ points in $\\mathbb R^d$, for any $d\\ge 2$, a hyperplane $h$ is called $k$-rich with respect to $P$ if it contains at least $k$ points of $P$. Answering and generalizing a question asked by Peyman Afshani, we show that if the number of $k$-rich hyperplanes in $\\mathbb R^d$, $d \\geq 3$, is at least $\u03a9(n^d/k^\u03b1+ n/k)$, with a sufficiently large constant of proportionality and with $d\\le \u03b1< 2d-1$, then there exists a $(d-2)$-flat that contains $\u03a9(k^{(2d-1-\u03b1)/(d-1)})$ points of $P$. We also present upper bound constructions that give instances in which the above lower bound is tight. An extension of our analysis yields similar lower bounds for $k$-rich spheres or $k$-rich flats.",
        "subjects": [
            "math.CO",
            "cs.CG"
        ],
        "comment": "8 pages"
    },
    {
        "paper id": "2412.05162",
        "abstract url": "https://arxiv.org/abs/2412.05162",
        "title": "Responsibility in Actor-Based Systems",
        "rating": "-10",
        "keywords": [],
        "abstract": "The enormous growth of the complexity of modern computer systems leads to an increasing demand for techniques that support the comprehensibility of systems. This has motivated the very active research field of formal methods that enhance the understanding of why systems behave the way they do. One important line of research within the verification community relies on formal notions that measure the degree of responsibility of different actors. In this paper, we first provide a uniform presentation of recent work on responsibility notions based on Shapley values for reactive systems modeled by transition systems and considering safety properties. The paper then discusses how to use these formal responsibility notions and corresponding algorithms for three different types of actor sets: the module-based notion serves to reason about the impact of system components on the satisfaction or violation of a safety property. Responsibility values for value-based actor sets and action-based actors allow for the identification of program instructions and control points that have the most influence on a specification violation. Beyond the theoretical considerations, this paper reports on experimental results that provide initial insights into applicability and scalability.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05168",
        "abstract url": "https://arxiv.org/abs/2412.05168",
        "title": "GRFsaw: A lightweight stochastic microstructure generator",
        "rating": "-10",
        "keywords": [],
        "abstract": "This article presents GRFsaw, an open-source software for generating two-phase (binary) microstructures with user-defined structural properties. Unlike most standard software for microstructure generation, GRFsaw is based on the concept of thresholding Gaussian random fields (GRF). It is designed to be used by researchers or engineers in need of a lightweight tool to generate microstructures of various geometries, for example as input to simulations or to other models where such geometries are needed. This could be simulations of fluid flow through porous media, in predictive models of electromagnetic scattering by materials, or in mechanical loading simulations in order to assess, e.g., the material's elasticity or strength.",
        "subjects": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ],
        "comment": "7 pages, 4 figures, code available on https://github.com/larsblatny/GRFsaw/"
    },
    {
        "paper id": "2412.05182",
        "abstract url": "https://arxiv.org/abs/2412.05182",
        "title": "Integer and Unsplittable Multiflows in Series-Parallel Digraphs",
        "rating": "-10",
        "keywords": [],
        "abstract": "An unsplittable multiflow routes the demand of each commodity along a single path from its source to its sink node. As our main result, we prove that in series-parallel digraphs, any given multiflow can be expressed as a convex combination of unsplittable multiflows, where the total flow on any arc deviates from the given flow by less than the maximum demand of any commodity. This result confirms a 25-year-old conjecture by Goemans for single-source unsplittable flows, as well as a stronger recent conjecture by Morell and Skutella, for series-parallel digraphs - even for general multiflow instances where commodities have distinct source and sink nodes. Previously, no non-trivial class of digraphs was known for which either conjecture holds. En route to proving this result, we also establish strong integrality results for multiflows on series-parallel digraphs, showing that their computation can be reduced to a simple single-commodity network flow problem.",
        "subjects": [
            "math.CO",
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05190",
        "abstract url": "https://arxiv.org/abs/2412.05190",
        "title": "A note on Erd\u0151s's mysterious remark",
        "rating": "-10",
        "keywords": [],
        "abstract": "We give an alternative proof of the statement, by using elimination from algebraic geometry, that the only set $S\\subset\\mathbb{R}^2$, $\\left|S\\right|=6$ such that all subsets that form a triangle are isosceles triangles, is the regular pentagon with its center. Our proof can be extended to answer some related questions raised by Erd\u0151s.",
        "subjects": [
            "cs.CG",
            "math.MG"
        ],
        "comment": "7 pages, 3 figures"
    },
    {
        "paper id": "2412.05198",
        "abstract url": "https://arxiv.org/abs/2412.05198",
        "title": "Probabilistic Finite Automaton Emptiness is Undecidable for a Fixed Automaton",
        "rating": "-10",
        "keywords": [],
        "abstract": "We construct a probabilistic finite automaton (PFA) with 7 states and an input alphabet of 5 symbols for which the PFA Emptiness Problem is undecidable. The only input for the decision problem is the starting distribution. For the proof, we use reductions from special instances of the Post Correspondence Problem. We also consider some variations: The input alphabet of the PFA can be restricted to a binary alphabet at the expense of a larger number of states. If we allow a rational output value for each state instead of a yes-no acceptance decision, the number of states can even be reduced to 6.",
        "subjects": [
            "cs.FL"
        ],
        "comment": "28 pages, 2 figures, 3 appendices"
    },
    {
        "paper id": "2412.05201",
        "abstract url": "https://arxiv.org/abs/2412.05201",
        "title": "On Models with Power Conservation in Reflective Intelligent Surfaces and their Design Implications",
        "rating": "-10",
        "keywords": [],
        "abstract": "Reconfigurable intelligent surfaces (RISs) are potential enablers of future wireless communications and sensing applications and use-cases. The RIS is envisioned as a dynamically controllable surface that is capable of transforming impinging electromagnetic waves in terms of angles and polarization. Many models has been proposed to predict the wave-transformation capabilities of potential RISs, where power conservation is ensured by enforcing that the scattered power equals the power impinging upon the aperture of the RIS, without considering whether the scattered field adds coherently of destructively with the source field. In effect, this means that power is not conserved, as elaborated in this paper. With the goal of investigating the implications of global and local power conservation in RISs, work considers a single-layer metasurface based RIS. A complete end-to-end communications channel is given through polarizability modeling and conditions for power conservation and channel reciprocity are derived. The implications of the power conservation conditions upon the end-to-end communications channel is analyzed.",
        "subjects": [
            "eess.SP"
        ],
        "comment": "13 pages, 8 figures"
    },
    {
        "paper id": "2412.05211",
        "abstract url": "https://arxiv.org/abs/2412.05211",
        "title": "Gaze into the Pattern: Characterizing Spatial Patterns with Internal Temporal Correlations for Hardware Prefetching",
        "rating": "-10",
        "keywords": [],
        "abstract": "Hardware prefetching is one of the most widely-used techniques for hiding long data access latency. To address the challenges faced by hardware prefetching, architects have proposed to detect and exploit the spatial locality at the granularity of spatial region. When a new region is activated, they try to find similar previously accessed regions for footprint prediction based on system-level environmental features such as the trigger instruction or data address. However, we find that such context-based prediction cannot capture the essential characteristics of access patterns, leading to limited flexibility, practicality and suboptimal prefetching performance. In this paper, inspired by the temporal property of memory accessing, we note that the temporal correlation exhibited within the spatial footprint is a key feature of spatial patterns. To this end, we propose Gaze, a simple and efficient hardware spatial prefetcher that skillfully utilizes footprint-internal temporal correlations to efficiently characterize spatial patterns. Meanwhile, we observe a unique unresolved challenge in utilizing spatial footprints generated by spatial streaming, which exhibit extremely high access density. Therefore, we further enhance Gaze with a dedicated two-stage approach that mitigates the over-prefetching problem commonly encountered in conventional schemes. Our comprehensive and diverse set of experiments show that Gaze can effectively enhance the performance across a wider range of scenarios. Specifically, Gaze improves performance by 5.7\\% and 5.4\\% at single-core, 11.4\\% and 8.8\\% at eight-core, compared to most recent low-cost solutions PMP and vBerti.",
        "subjects": [
            "cs.AR"
        ],
        "comment": "Accepted by HPCA 2025"
    },
    {
        "paper id": "2412.05249",
        "abstract url": "https://arxiv.org/abs/2412.05249",
        "title": "An Information Theoretic Analysis of Ghost Modulation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Side channels have become an essential component of many modern information-theoretic schemes. The emerging field of cross technology communications (CTC) provides practical methods for creating intentional side channels between existing communications technologies. This paper describes a theoretical foundation for one such, recently proposed, CTC scheme: Ghost Modulation (GM). Designed to modulate a low-data-rate message atop an existing network stream, GM is particularly suited for transmitting identification or covert information. The implementation only requires firmware updates to existing hardware, making it a cost-effective solution. However, GM provides an interesting technical challenge due to a highly asymmetric binary crossover erasure channel (BCEC) that results from packet drops and network delays. In this work, we provide a mathematical description of the signal and channel models for GM. A heuristic decision rule based on maximum-likelihood principles for simplified channel models is proposed. We describe an algorithm for GM packet acquisition and timing synchronization, supported by simulation results. Several well known short block codes are applied, and bit error rate (BER) results are presented.",
        "subjects": [
            "cs.IT",
            "eess.SP"
        ],
        "comment": "7 Pages, 5 Figures"
    },
    {
        "paper id": "2412.05254",
        "abstract url": "https://arxiv.org/abs/2412.05254",
        "title": "Preprocessing is All You Need: Boosting the Performance of Log Parsers With a General Preprocessing Framework",
        "rating": "-10",
        "keywords": [],
        "abstract": "Log parsing has been a long-studied area in software engineering due to its importance in identifying dynamic variables and constructing log templates. Prior work has proposed many statistic-based log parsers (e.g., Drain), which are highly efficient; they, unfortunately, met the bottleneck of parsing performance in comparison to semantic-based log parsers, which require labeling and more computational resources. Meanwhile, we noticed that previous studies mainly focused on parsing and often treated preprocessing as an ad hoc step (e.g., masking numbers). However, we argue that both preprocessing and parsing are essential for log parsers to identify dynamic variables: the lack of understanding of preprocessing may hinder the optimal use of parsers and future research. Therefore, our work studied existing log preprocessing approaches based on Loghub, a popular log parsing benchmark. We developed a general preprocessing framework with our findings and evaluated its impact on existing parsers. Our experiments show that the preprocessing framework significantly boosts the performance of four state-of-the-art statistic-based parsers. Drain, the best statistic-based parser, obtained improvements across all four parsing metrics (e.g., F1 score of template accuracy, FTA, increased by 108.9%). Compared to semantic-based parsers, it achieved a 28.3% improvement in grouping accuracy (GA), 38.1% in FGA, and an 18.6% increase in FTA. Our work pioneers log preprocessing and provides a generalizable framework to enhance log parsing.",
        "subjects": [
            "cs.SE"
        ],
        "comment": "Accepted in 2025 IEEE International Conference on Software Analysis, Evolution, and Reengineering (SANER)"
    },
    {
        "paper id": "2412.05259",
        "abstract url": "https://arxiv.org/abs/2412.05259",
        "title": "A Machine Learning-Based Approach For Detecting Malicious PyPI Packages",
        "rating": "-10",
        "keywords": [],
        "abstract": "Background. In modern software development, the use of external libraries and packages is increasingly prevalent, streamlining the software development process and enabling developers to deploy feature-rich systems with little coding. While this reliance on reusing code offers substantial benefits, it also introduces serious risks for deployed software in the form of malicious packages - harmful and vulnerable code disguised as useful libraries. Aims. Popular ecosystems, such PyPI, receive thousands of new package contributions every week, and distinguishing safe contributions from harmful ones presents a significant challenge. There is a dire need for reliable methods to detect and address the presence of malicious packages in these environments. Method. To address these challenges, we propose a data-driven approach that uses machine learning and static analysis to examine the package's metadata, code, files, and textual characteristics to identify malicious packages. Results. In evaluations conducted within the PyPI ecosystem, we achieved an F1-measure of 0.94 for identifying malicious packages using a stacking ensemble classifier. Conclusions. This tool can be seamlessly integrated into package vetting pipelines and has the capability to flag entire packages, not just malicious function calls. This enhancement strengthens security measures and reduces the manual workload for developers and registry maintainers, thereby contributing to the overall integrity of the ecosystem.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05366",
        "abstract url": "https://arxiv.org/abs/2412.05366",
        "title": "ExploraCoder: Advancing code generation for multiple unseen APIs via planning and chained exploration",
        "rating": "-10",
        "keywords": [],
        "abstract": "Through training on publicly available source code libraries, large language models (LLMs) can invoke multiple encapsulated APIs to solve complex programming problems. However, existing models inherently cannot generalize to use APIs that are unseen in their training corpora. As libraries continuously evolve, it becomes impractical to exhaustively retrain LLMs with new API knowledge. This limitation hampers LLMs from solving problems which require newly introduced or privately maintained libraries. Human programmers often explore unfamiliar APIs by writing experimental code before invoking them for a more complex problem. Inspired by this behavior, we propose , a training-free framework that empowers LLMs to invoke multiple unseen APIs in code solution by (1) planning a complex problem into several API invocation subtasks, and (2) exploring correct API usage through a novel chain-of-API-exploration. Concretely, ExploraCoder guides the LLM to iteratively generate several experimental API invocations for each simple subtask, where the promising execution experience are exploited by subsequent subtasks. This forms a chained exploration trace that ultimately guides LLM in generating the final solution. We evaluate ExploraCoder on Torchdata-Github benchmark as well as a newly constructed benchmark that involves more complex API interactions. Experimental results demonstrate that ExploraCoder significantly improves performance for models lacking prior API knowledge, achieving an absolute increase of 11.24% over niave RAG approaches and 14.07% over pretraining methods in pass@10. Moreover, the integration of a self-debug mechanism further boosts ExploraCoder's performance on more challenging tasks. Comprehensive ablation and case studies provide further insights into the effectiveness of ExploraCoder.",
        "subjects": [
            "cs.SE"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05409",
        "abstract url": "https://arxiv.org/abs/2412.05409",
        "title": "Multilinear analysis of quaternion arrays: theory and computation",
        "rating": "-10",
        "keywords": [],
        "abstract": "Multidimensional quaternion arrays (often referred to as \"quaternion tensors\") and their decompositions have recently gained increasing attention in various fields such as color and polarimetric imaging or video processing. Despite this growing interest, the theoretical development of quaternion tensors remains limited. This paper introduces a novel multilinear framework for quaternion arrays, which extends the classical tensor analysis to multidimensional quaternion data in a rigorous manner. Specifically, we propose a new definition of quaternion tensors as $\\mathbb{H}\\mathbb{R}$-multilinear forms, addressing the challenges posed by the non-commutativity of quaternion multiplication. Within this framework, we establish the Tucker decomposition for quaternion tensors and develop a quaternion Canonical Polyadic Decomposition (Q-CPD). We thoroughly investigate the properties of the Q-CPD, including trivial ambiguities, complex equivalent models, and sufficient conditions for uniqueness. Additionally, we present two algorithms for computing the Q-CPD and demonstrate their effectiveness through numerical experiments. Our results provide a solid theoretical foundation for further research on quaternion tensor decompositions and offer new computational tools for practitioners working with quaternion multiway data.",
        "subjects": [
            "math.NA",
            "eess.SP"
        ],
        "comment": "27 pages, 1 figure"
    },
    {
        "paper id": "2412.05476",
        "abstract url": "https://arxiv.org/abs/2412.05476",
        "title": "Digging for Decision Trees: A Case Study in Strategy Sampling and Learning",
        "rating": "-10",
        "keywords": [],
        "abstract": "We introduce a formal model of transportation in an open-pit mine for the purpose of optimising the mine's operations. The model is a network of Markov automata (MA); the optimisation goal corresponds to maximising a time-bounded expected reward property. Today's model checking algorithms exacerbate the state space explosion problem by applying a discretisation approach to such properties on MA. We show that model checking is infeasible even for small mine instances. Instead, we propose statistical model checking with lightweight strategy sampling or table-based Q-learning over untimed strategies as an alternative to approach the optimisation task, using the Modest Toolset's modes tool. We add support for partial observability to modes so that strategies can be based on carefully selected model features, and we implement a connection from modes to the dtControl tool to convert sampled or learned strategies into decision trees. We experimentally evaluate the adequacy of our new tooling on the open-pit mine case study. Our experiments demonstrate the limitations of Q-learning, the impact of feature selection, and the usefulness of decision trees as an explainable representation.",
        "subjects": [
            "cs.FL"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05497",
        "abstract url": "https://arxiv.org/abs/2412.05497",
        "title": "Accelerating Proximal Gradient Descent via Silver Stepsizes",
        "rating": "-10",
        "keywords": [],
        "abstract": "Surprisingly, recent work has shown that gradient descent can be accelerated without using momentum -- just by judiciously choosing stepsizes. An open question raised by several papers is whether this phenomenon of stepsize-based acceleration holds more generally for constrained and/or composite convex optimization via projected and/or proximal versions of gradient descent. We answer this in the affirmative by proving that the silver stepsize schedule yields analogously accelerated rates in these settings. These rates are conjectured to be asymptotically optimal among all stepsize schedules, and match the silver convergence rate of vanilla gradient descent (Altschuler and Parrilo, 2023), namely $O(\\varepsilon^{- \\log_\u03c1 2})$ for smooth convex optimization and $O(\u03ba^{\\log_\u03c12} \\log \\frac{1}{\\varepsilon})$ under strong convexity, where $\\varepsilon$ is the precision, $\u03ba$ is the condition number, and $\u03c1= 1 + \\sqrt{2}$ is the silver ratio. The key technical insight is the combination of recursive gluing -- the technique underlying all analyses of gradient descent accelerated with time-varying stepsizes -- with a certain Laplacian-structured sum-of-squares certificate for the analysis of proximal point updates.",
        "subjects": [
            "math.OC",
            "cs.DS"
        ],
        "comment": "Main text (12 pages) + references + appendix"
    },
    {
        "paper id": "2412.05502",
        "abstract url": "https://arxiv.org/abs/2412.05502",
        "title": "EC-Chain: Cost-Effective Storage Solution for Permissionless Blockchains",
        "rating": "-10",
        "keywords": [],
        "abstract": "Permissionless blockchains face considerable challenges due to increasing storage demands, driven by the proliferation of Decentralized Applications (DApps). This paper introduces EC-Chain, a cost-effective storage solution for permissionless blockchains. EC-Chain reduces storage overheads of ledger and state data, which comprise blockchain data. For ledger data, EC-Chain refines existing erasure coding-based storage optimization techniques by incorporating batch encoding and height-based encoding. We also introduce an easy-to-implement dual-trie state management system that enhances state storage and retrieval through state expiry, mining, and creation procedures. To ensure data availability in permissionless environments, EC-Chain introduces a network maintenance scheme tailored for dynamism. Collectively, these contributions allow EC-Chain to provide an effective solution to the storage challenges faced by permissionless blockchains. Our evaluation demonstrates that EC-Chain can achieve a storage reduction of over \\(90\\%\\) compared to native Ethereum Geth.",
        "subjects": [
            "cs.CR"
        ],
        "comment": "Accepted to IEEE INFOCOM 2025, 10 pages, 9 figures"
    },
    {
        "paper id": "2412.05512",
        "abstract url": "https://arxiv.org/abs/2412.05512",
        "title": "Partially Synchronous BFT Consensus Made Practical in Wireless Networks",
        "rating": "-10",
        "keywords": [],
        "abstract": "Consensus is becoming increasingly important in wireless networks. Partially synchronous BFT consensus, a significant branch of consensus, has made considerable progress in wired networks. However, its implementation in wireless networks, especially in dynamic ad hoc wireless networks, remains challenging. Existing wireless synchronous consensus protocols, despite being well-developed, are not readily adaptable to partially synchronous settings. Additionally, reliable communication, a cornerstone of BFT consensus, can lead to high message and time complexity in wireless networks. To address these challenges, we propose a wireless communication protocol called ReduceCatch (Reduce and Catch) that supports reliable 1-to-N, N-to-1, and N-to-N communications. We employ ReduceCatch to tailor three partially synchronous BFT consensus protocols (PBFT, Tendermint, and HotStuff) for seamless adaptation from wired to ad hoc wireless networks. To evaluate the performance of the ReduceCatch-enabled consensus protocols, we develop a three-layer wireless consensus testbed, based on which we implement 20 distinct consensus protocols and measure their latency and throughput. The experimental results demonstrate the superiority of the ReduceCatch-based consensus protocol in terms of latency and throughput.",
        "subjects": [
            "cs.NI",
            "cs.CR",
            "cs.DC"
        ],
        "comment": "Accepted to IEEE INFOCOM 2025, 10 pages, 7 figures"
    },
    {
        "paper id": "2412.05526",
        "abstract url": "https://arxiv.org/abs/2412.05526",
        "title": "Multicriteria Spanners -- A New Tool for Network Design",
        "rating": "-10",
        "keywords": [],
        "abstract": "Designing sparse directed spanners, which are subgraphs that approximately maintain distance constraints, has attracted sustained interest in TCS, especially due to their wide applicability, as well as the difficulty to obtain tight results. However, a significant drawback of the notion of spanners is that it cannot capture multiple distance-like constraints for the same demand pair. In this paper we initiate the study of directed multicriteria spanners, in which the notion of edge lengths is replaced by the notion of resource consumption vectors, where each entry corresponds to the consumption of the respective resource on that edge. The goal is to find a minimum-cost routing solution that satisfies the multiple constraints. To the best of our knowledge, we obtain the first approximation algorithms for the directed multicriteria spanners problems, under natural assumptions. Our results match the state-of-the-art approximation ratios in special cases of ours. We also establish reductions from other natural network connectivity problems to the directed multicriteria spanners problems, including Group Steiner Distances, introduced in the undirected setting by Bil\u00f2, Gual\u00e0, Leucci and Straziota (ESA 2024), and Edge-Avoiding spanners. Our reductions imply approximation algorithms for these problems and illustrate that the notion of directed multicriteria spanners is an appropriate abstraction and generalization of natural special cases from the literature. Our main technical tool is a delicate generalization of the minimum-density junction tree framework of Chekuri, Even, Gupta, and Segev (SODA 2008, TALG 2011) to the notion of minimum-density resource-constrained junction trees, which also extends ideas from Chlamt\u00e1\u010d, Dinitz, Kortsarz, and Laekhanukit (SODA 2017, TALG 2020).",
        "subjects": [
            "cs.DS"
        ],
        "comment": null
    },
    {
        "paper id": "2412.05527",
        "abstract url": "https://arxiv.org/abs/2412.05527",
        "title": "Dynamic Digital Twins of Blockchain Systems: State Extraction and Mirroring",
        "rating": "-10",
        "keywords": [],
        "abstract": "Blockchain adoption is reaching an all-time high, with a plethora of blockchain architectures being developed to cover the needs of applications eager to integrate blockchain into their operations. However, blockchain systems suffer from the trilemma trade-off problem, which limits their ability to scale without sacrificing essential metrics such as decentralisation and security. The balance of the trilemma trade-off is primarily dictated by the consensus protocol used. Since consensus protocols are designed to function well under specific system conditions, and consequently, due to the blockchain's complex and dynamic nature, systems operating under a single consensus protocol are bound to face periods of inefficiency. The work presented in this paper constitutes part of an effort to design a Digital Twin-based blockchain management framework to balance the trilemma trade-off problem, which aims to adapt the consensus process to fit the conditions of the underlying system. Specifically, this work addresses the problems of extracting the blockchain system and mirroring it in its digital twin by proposing algorithms that overcome the challenges posed by blockchains' decentralised and asynchronous nature and the fundamental problems of global state and synchronisation in such systems. The robustness of the proposed algorithms is experimentally evaluated.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "comment": "8 pages, 6 figures, Distributed Simulation and Real Time Applications (DS-RT 2024)"
    }
]